<!DOCTYPE html><html lang="ko" class="no-js"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="stylesheet" href="/secrett2633.github.io/_next/static/css/b9d6ec750ad82add.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/secrett2633.github.io/_next/static/chunks/webpack-69f14ab6f9497210.js"/><script src="/secrett2633.github.io/_next/static/chunks/fd9d1056-62aaf4b921c84028.js" async=""></script><script src="/secrett2633.github.io/_next/static/chunks/23-ca4408d024135d8d.js" async=""></script><script src="/secrett2633.github.io/_next/static/chunks/main-app-6d0231ce06c8f62f.js" async=""></script><script src="/secrett2633.github.io/_next/static/chunks/231-c4b666723e6aae68.js" async=""></script><script src="/secrett2633.github.io/_next/static/chunks/app/categories/%5Bcategory%5D/page-0d5ca9ae8400631f.js" async=""></script><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-NE2W3CFPNY"></script><link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"/><meta name="msapplication-TileColor" content="#ffc40d"/><meta name="theme-color" content="#ffffff"/><title>secrett2633&#x27;s blog</title><meta name="description" content="기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트"/><meta name="author" content="secrett2633"/><meta name="keywords" content="Django, Python, DevOps, AI, ML, 블로그, 기술"/><meta name="creator" content="secrett2633"/><meta name="publisher" content="secrett2633"/><meta name="robots" content="index, follow"/><meta name="googlebot" content="index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1"/><link rel="canonical" href="https://secrett2633.github.io/"/><meta name="format-detection" content="telephone=no, address=no, email=no"/><meta property="og:title" content="secrett2633&#x27;s blog"/><meta property="og:description" content="기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트"/><meta property="og:url" content="https://secrett2633.github.io/"/><meta property="og:site_name" content="secrett2633&#x27;s blog"/><meta property="og:locale" content="ko_KR"/><meta property="og:type" content="website"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:title" content="secrett2633&#x27;s blog"/><meta name="twitter:description" content="기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트"/><script>
              window.dataLayer = window.dataLayer || [];
              function gtag(){dataLayer.push(arguments);}
              gtag('js', new Date());
              gtag('config', 'G-NE2W3CFPNY');
            </script><script src="/secrett2633.github.io/_next/static/chunks/polyfills-78c92fac7aa8fdd8.js" noModule=""></script></head><body class="__className_9012cf layout--default"><div class="min-h-screen bg-gray-50"><div class="masthead"><div class="masthead__inner-wrap"><div class="masthead__menu"><nav id="site-nav" class="greedy-nav"><a class="site-title" href="/secrett2633.github.io">secrett2633&#x27;s blog</a><div class="flex items-center space-x-4"><ul class="visible-links"><li class="masthead__menu-item"><a href="https://github.com/secrett2633" target="_blank" rel="noopener noreferrer">GitHub</a></li></ul><button class="search__toggle" type="button"><svg class="icon" width="16" height="16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 15.99 16"><path d="M15.5,13.12L13.19,10.8a1.69,1.69,0,0,0-1.28-.55l-0.06-.06A6.5,6.5,0,0,0,5.77,0,6.5,6.5,0,0,0,2.46,11.59a6.47,6.47,0,0,0,7.74.26l0.05,0.05a1.65,1.65,0,0,0,.5,1.24l2.38,2.38A1.68,1.68,0,0,0,15.5,13.12ZM6.4,2A4.41,4.41,0,1,1,2,6.4,4.43,4.43,0,0,1,6.4,2Z" transform="translate(-.01)"></path></svg></button><button class="greedy-nav__toggle" type="button"><div class="navicon"></div></button></div><ul class="hidden-links hidden md:hidden"><li><a href="https://github.com/secrett2633" target="_blank" rel="noopener noreferrer" class="block py-2">GitHub</a></li></ul></nav></div></div></div><main class="initial-content"><!--$--><div class="masthead"><div class="masthead__inner-wrap"><div class="masthead__menu"><nav id="site-nav" class="greedy-nav"><a class="site-title" href="/secrett2633.github.io">secrett2633&#x27;s blog</a><div class="flex items-center space-x-4"><ul class="visible-links"><li class="masthead__menu-item"><a href="https://github.com/secrett2633" target="_blank" rel="noopener noreferrer">GitHub</a></li></ul><button class="search__toggle" type="button"><svg class="icon" width="16" height="16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 15.99 16"><path d="M15.5,13.12L13.19,10.8a1.69,1.69,0,0,0-1.28-.55l-0.06-.06A6.5,6.5,0,0,0,5.77,0,6.5,6.5,0,0,0,2.46,11.59a6.47,6.47,0,0,0,7.74.26l0.05,0.05a1.65,1.65,0,0,0,.5,1.24l2.38,2.38A1.68,1.68,0,0,0,15.5,13.12ZM6.4,2A4.41,4.41,0,1,1,2,6.4,4.43,4.43,0,0,1,6.4,2Z" transform="translate(-.01)"></path></svg></button><button class="greedy-nav__toggle" type="button"><div class="navicon"></div></button></div><ul class="hidden-links hidden md:hidden"><li><a href="https://github.com/secrett2633" target="_blank" rel="noopener noreferrer" class="block py-2">GitHub</a></li></ul></nav></div></div></div><div class="initial-content"><div class="flex flex-col lg:flex-row gap-8"><main class="flex-1"><h1 class="page__title">Review<!-- --> 카테고리</h1><div class="entries-list"><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-10-2-Why_Cant_Transformers_Learn_Multiplication_Reverse-Engineering_Reveals_Long-Range_Dependency_Pitfalls/">[논문리뷰] Why Can&#x27;t Transformers Learn Multiplication? Reverse-Engineering Reveals Long-Range Dependency Pitfalls</a></h2><div class="archive__item-excerpt">Stuart Shieber이 [arXiv]에 게시한 &#x27;Why Can&#x27;t Transformers Learn Multiplication? Reverse-Engineering Reveals Long-Range Dependency Pitfalls&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-10-02 13:30:22+0900">2025년 10월 2일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Transformers</span><span class="page__taxonomy-item">#<!-- -->Multiplication</span><span class="page__taxonomy-item">#<!-- -->Long-Range Dependencies</span><span class="page__taxonomy-item">#<!-- -->Implicit Chain-of-Thought</span><span class="page__taxonomy-item">#<!-- -->Attention Mechanisms</span><span class="page__taxonomy-item">#<!-- -->Inductive Bias</span><span class="page__taxonomy-item">#<!-- -->Reverse Engineering</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-10-2-VLM-FO1_Bridging_the_Gap_Between_High-Level_Reasoning_and_Fine-Grained_Perception_in_VLMs/">[논문리뷰] VLM-FO1: Bridging the Gap Between High-Level Reasoning and Fine-Grained Perception in VLMs</a></h2><div class="archive__item-excerpt">이 [arXiv]에 게시한 &#x27;VLM-FO1: Bridging the Gap Between High-Level Reasoning and Fine-Grained Perception in VLMs&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-10-02 13:30:22+0900">2025년 10월 2일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Vision-Language Models</span><span class="page__taxonomy-item">#<!-- -->Object Grounding</span><span class="page__taxonomy-item">#<!-- -->Fine-grained Perception</span><span class="page__taxonomy-item">#<!-- -->Hybrid Region Encoder</span><span class="page__taxonomy-item">#<!-- -->Plug-and-play</span><span class="page__taxonomy-item">#<!-- -->Two-stage Training</span><span class="page__taxonomy-item">#<!-- -->Visual Reasoning</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-10-2-VLA-RFT_Vision-Language-Action_Reinforcement_Fine-tuning_with_Verified_Rewards_in_World_Simulators/">[논문리뷰] VLA-RFT: Vision-Language-Action Reinforcement Fine-tuning with Verified Rewards in World Simulators</a></h2><div class="archive__item-excerpt">Zirui Ge이 [arXiv]에 게시한 &#x27;VLA-RFT: Vision-Language-Action Reinforcement Fine-tuning with Verified Rewards in World Simulators&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-10-02 13:30:22+0900">2025년 10월 2일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Vision-Language-Action Models</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->World Models</span><span class="page__taxonomy-item">#<!-- -->Fine-tuning</span><span class="page__taxonomy-item">#<!-- -->Embodied AI</span><span class="page__taxonomy-item">#<!-- -->Robotics</span><span class="page__taxonomy-item">#<!-- -->Reward Design</span><span class="page__taxonomy-item">#<!-- -->Distribution Shift</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-10-2-Training_Vision-Language_Process_Reward_Models_for_Test-Time_Scaling_in_Multimodal_Reasoning_Key_Insights_and_Lessons_Learned/">[논문리뷰] Training Vision-Language Process Reward Models for Test-Time Scaling in Multimodal Reasoning: Key Insights and Lessons Learned</a></h2><div class="archive__item-excerpt">이 [arXiv]에 게시한 &#x27;Training Vision-Language Process Reward Models for Test-Time Scaling in Multimodal Reasoning: Key Insights and Lessons Learned&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-10-02 13:30:22+0900">2025년 10월 2일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Vision-Language Models (VLMs)</span><span class="page__taxonomy-item">#<!-- -->Process Reward Models (PRMs)</span><span class="page__taxonomy-item">#<!-- -->Multimodal Reasoning</span><span class="page__taxonomy-item">#<!-- -->Test-Time Scaling (TTS)</span><span class="page__taxonomy-item">#<!-- -->Process Supervision</span><span class="page__taxonomy-item">#<!-- -->Dataset Construction</span><span class="page__taxonomy-item">#<!-- -->Perception Errors</span><span class="page__taxonomy-item">#<!-- -->MCTS</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-10-2-ReSWD_ReSTIRd_not_shaken._Combining_Reservoir_Sampling_and_Sliced_Wasserstein_Distance_for_Variance_Reduction">[논문리뷰] ReSWD: ReSTIR&#x27;d, not shaken. Combining Reservoir Sampling and Sliced Wasserstein Distance for Variance Reduction</a></h2><div class="archive__item-excerpt">이 [arXiv]에 게시한 &#x27;ReSWD: ReSTIR&#x27;d, not shaken. Combining Reservoir Sampling and Sliced Wasserstein Distance for Variance Reduction&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-10-02 13:30:22+0900">2025년 10월 2일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Sliced Wasserstein Distance</span><span class="page__taxonomy-item">#<!-- -->Reservoir Sampling</span><span class="page__taxonomy-item">#<!-- -->Variance Reduction</span><span class="page__taxonomy-item">#<!-- -->Distribution Matching</span><span class="page__taxonomy-item">#<!-- -->Diffusion Guidance</span><span class="page__taxonomy-item">#<!-- -->Color Correction</span><span class="page__taxonomy-item">#<!-- -->Monte Carlo Estimation</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-10-2-PIPer_On-Device_Environment_Setup_via_Online_Reinforcement_Learning/">[논문리뷰] PIPer: On-Device Environment Setup via Online Reinforcement Learning</a></h2><div class="archive__item-excerpt">이 [arXiv]에 게시한 &#x27;PIPer: On-Device Environment Setup via Online Reinforcement Learning&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-10-02 13:30:22+0900">2025년 10월 2일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Environment Setup</span><span class="page__taxonomy-item">#<!-- -->LLMs</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Supervised Fine-tuning</span><span class="page__taxonomy-item">#<!-- -->On-device AI</span><span class="page__taxonomy-item">#<!-- -->Software Engineering</span><span class="page__taxonomy-item">#<!-- -->Verifiable Rewards</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-10-2-On_Predictability_of_Reinforcement_Learning_Dynamics_for_Large_Language_Models/">[논문리뷰] On Predictability of Reinforcement Learning Dynamics for Large Language Models</a></h2><div class="archive__item-excerpt">Yuqing Huang이 [arXiv]에 게시한 &#x27;On Predictability of Reinforcement Learning Dynamics for Large Language Models&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-10-02 13:30:22+0900">2025년 10월 2일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Parameter Dynamics</span><span class="page__taxonomy-item">#<!-- -->Rank-1 Dominance</span><span class="page__taxonomy-item">#<!-- -->Linear Dynamics</span><span class="page__taxonomy-item">#<!-- -->SVD</span><span class="page__taxonomy-item">#<!-- -->Model Acceleration</span><span class="page__taxonomy-item">#<!-- -->Predictability</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-10-2-Making_not_Taking_the_Best_of_N/">[논문리뷰] Making, not Taking, the Best of N</a></h2><div class="archive__item-excerpt">이 [arXiv]에 게시한 &#x27;Making, not Taking, the Best of N&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-10-02 13:30:22+0900">2025년 10월 2일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLM Aggregation</span><span class="page__taxonomy-item">#<!-- -->Generative Fusion</span><span class="page__taxonomy-item">#<!-- -->Best-of-N</span><span class="page__taxonomy-item">#<!-- -->Synthetic Data Generation</span><span class="page__taxonomy-item">#<!-- -->Test-Time Scaling</span><span class="page__taxonomy-item">#<!-- -->Multilingual Models</span><span class="page__taxonomy-item">#<!-- -->Ensemble Learning</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-10-2-Knapsack_RL_Unlocking_Exploration_of_LLMs_via_Optimizing_Budget_Allocation/">[논문리뷰] Knapsack RL: Unlocking Exploration of LLMs via Optimizing Budget Allocation</a></h2><div class="archive__item-excerpt">이 [arXiv]에 게시한 &#x27;Knapsack RL: Unlocking Exploration of LLMs via Optimizing Budget Allocation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-10-02 13:30:22+0900">2025년 10월 2일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Large Language Models (LLMs)</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning (RL)</span><span class="page__taxonomy-item">#<!-- -->Exploration Budget Allocation</span><span class="page__taxonomy-item">#<!-- -->Knapsack Problem</span><span class="page__taxonomy-item">#<!-- -->Group Relative Policy Optimization (GRPO)</span><span class="page__taxonomy-item">#<!-- -->Mathematical Reasoning</span><span class="page__taxonomy-item">#<!-- -->Resource Optimization</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-10-2-JoyAgent-JDGenie_Technical_Report_on_the_GAIA/">[논문리뷰] JoyAgent-JDGenie: Technical Report on the GAIA</a></h2><div class="archive__item-excerpt">이 [arXiv]에 게시한 &#x27;JoyAgent-JDGenie: Technical Report on the GAIA&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-10-02 13:30:22+0900">2025년 10월 2일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Generalist Agent</span><span class="page__taxonomy-item">#<!-- -->Multi-Agent System</span><span class="page__taxonomy-item">#<!-- -->Plan-Execute</span><span class="page__taxonomy-item">#<!-- -->ReAct</span><span class="page__taxonomy-item">#<!-- -->Hierarchical Memory</span><span class="page__taxonomy-item">#<!-- -->Tool Integration</span><span class="page__taxonomy-item">#<!-- -->GAIA Benchmark</span><span class="page__taxonomy-item">#<!-- -->LLM Agent</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-10-2-Infusing_Theory_of_Mind_into_Socially_Intelligent_LLM_Agents/">[논문리뷰] Infusing Theory of Mind into Socially Intelligent LLM Agents</a></h2><div class="archive__item-excerpt">이 [arXiv]에 게시한 &#x27;Infusing Theory of Mind into Socially Intelligent LLM Agents&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-10-02 13:30:22+0900">2025년 10월 2일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Theory of Mind</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Social Agents</span><span class="page__taxonomy-item">#<!-- -->Dialogue Systems</span><span class="page__taxonomy-item">#<!-- -->Mental State Modeling</span><span class="page__taxonomy-item">#<!-- -->Look-ahead Planning</span><span class="page__taxonomy-item">#<!-- -->Supervised Fine-tuning</span><span class="page__taxonomy-item">#<!-- -->Sotopia Benchmark</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-10-2-In-Place_Feedback_A_New_Paradigm_for_Guiding_LLMs_in_Multi-Turn_Reasoning/">[논문리뷰] In-Place Feedback: A New Paradigm for Guiding LLMs in Multi-Turn Reasoning</a></h2><div class="archive__item-excerpt">Chaehyeon Chung이 [arXiv]에 게시한 &#x27;In-Place Feedback: A New Paradigm for Guiding LLMs in Multi-Turn Reasoning&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-10-02 13:30:22+0900">2025년 10월 2일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLM Feedback</span><span class="page__taxonomy-item">#<!-- -->Multi-turn Reasoning</span><span class="page__taxonomy-item">#<!-- -->In-place Editing</span><span class="page__taxonomy-item">#<!-- -->Token Efficiency</span><span class="page__taxonomy-item">#<!-- -->Error Correction</span><span class="page__taxonomy-item">#<!-- -->Human-AI Interaction</span><span class="page__taxonomy-item">#<!-- -->Reasoning Tasks</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-10-2-Hyperdimensional_Probe_Decoding_LLM_Representations_via_Vector_Symbolic_Architectures/">[논문리뷰] Hyperdimensional Probe: Decoding LLM Representations via Vector Symbolic Architectures</a></h2><div class="archive__item-excerpt">Andrea Passerini이 [arXiv]에 게시한 &#x27;Hyperdimensional Probe: Decoding LLM Representations via Vector Symbolic Architectures&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-10-02 13:30:22+0900">2025년 10월 2일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLM Interpretability</span><span class="page__taxonomy-item">#<!-- -->Vector Symbolic Architectures</span><span class="page__taxonomy-item">#<!-- -->Neural Probing</span><span class="page__taxonomy-item">#<!-- -->Information Decoding</span><span class="page__taxonomy-item">#<!-- -->Hyperdimensional Computing</span><span class="page__taxonomy-item">#<!-- -->Latent Representations</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-10-2-GUI-KV_Efficient_GUI_Agents_via_KV_Cache_with_Spatio-Temporal_Awareness/">[논문리뷰] GUI-KV: Efficient GUI Agents via KV Cache with Spatio-Temporal Awareness</a></h2><div class="archive__item-excerpt">Chien-Sheng Wu이 [arXiv]에 게시한 &#x27;GUI-KV: Efficient GUI Agents via KV Cache with Spatio-Temporal Awareness&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-10-02 13:30:22+0900">2025년 10월 2일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->GUI Agents</span><span class="page__taxonomy-item">#<!-- -->KV Cache Compression</span><span class="page__taxonomy-item">#<!-- -->Spatio-Temporal Awareness</span><span class="page__taxonomy-item">#<!-- -->Vision-Language Models</span><span class="page__taxonomy-item">#<!-- -->Efficiency</span><span class="page__taxonomy-item">#<!-- -->Attention Sparsity</span><span class="page__taxonomy-item">#<!-- -->QR Decomposition</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-10-2-GEM_A_Gym_for_Agentic_LLMs/">[논문리뷰] GEM: A Gym for Agentic LLMs</a></h2><div class="archive__item-excerpt">이 [arXiv]에 게시한 &#x27;GEM: A Gym for Agentic LLMs&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-10-02 13:30:22+0900">2025년 10월 2일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Agentic LLMs</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Environment Simulator</span><span class="page__taxonomy-item">#<!-- -->Multi-turn Interactions</span><span class="page__taxonomy-item">#<!-- -->Return Batch Normalization</span><span class="page__taxonomy-item">#<!-- -->Tool Integration</span><span class="page__taxonomy-item">#<!-- -->Benchmarking</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-10-2-Flash-Searcher_Fast_and_Effective_Web_Agents_via_DAG-Based_Parallel_Execution/">[논문리뷰] Flash-Searcher: Fast and Effective Web Agents via DAG-Based Parallel Execution</a></h2><div class="archive__item-excerpt">이 [arXiv]에 게시한 &#x27;Flash-Searcher: Fast and Effective Web Agents via DAG-Based Parallel Execution&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-10-02 13:30:22+0900">2025년 10월 2일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLM Agents</span><span class="page__taxonomy-item">#<!-- -->Parallel Execution</span><span class="page__taxonomy-item">#<!-- -->DAG-based Planning</span><span class="page__taxonomy-item">#<!-- -->Tool Orchestration</span><span class="page__taxonomy-item">#<!-- -->Web Agents</span><span class="page__taxonomy-item">#<!-- -->Reasoning Framework</span><span class="page__taxonomy-item">#<!-- -->Efficiency</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-10-2-Eliciting_Secret_Knowledge_from_Language_Models/">[논문리뷰] Eliciting Secret Knowledge from Language Models</a></h2><div class="archive__item-excerpt">Neel Nanda이 [arXiv]에 게시한 &#x27;Eliciting Secret Knowledge from Language Models&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-10-02 13:30:22+0900">2025년 10월 2일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Language Models</span><span class="page__taxonomy-item">#<!-- -->Secret Elicitation</span><span class="page__taxonomy-item">#<!-- -->Mechanistic Interpretability</span><span class="page__taxonomy-item">#<!-- -->Black-box Methods</span><span class="page__taxonomy-item">#<!-- -->White-box Methods</span><span class="page__taxonomy-item">#<!-- -->AI Auditing</span><span class="page__taxonomy-item">#<!-- -->Model Organisms</span><span class="page__taxonomy-item">#<!-- -->Prefill Attacks</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-10-2-DeepSearch_Overcome_the_Bottleneck_of_Reinforcement_Learning_with_Verifiable_Rewards_via_Monte_Carlo_Tree_Search/">[논문리뷰] DeepSearch: Overcome the Bottleneck of Reinforcement Learning with Verifiable Rewards via Monte Carlo Tree Search</a></h2><div class="archive__item-excerpt">이 [arXiv]에 게시한 &#x27;DeepSearch: Overcome the Bottleneck of Reinforcement Learning with Verifiable Rewards via Monte Carlo Tree Search&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-10-02 13:30:22+0900">2025년 10월 2일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning with Verifiable Rewards (RLVR)</span><span class="page__taxonomy-item">#<!-- -->Monte Carlo Tree Search (MCTS)</span><span class="page__taxonomy-item">#<!-- -->Mathematical Reasoning</span><span class="page__taxonomy-item">#<!-- -->Large Language Models (LLMs)</span><span class="page__taxonomy-item">#<!-- -->Systematic Exploration</span><span class="page__taxonomy-item">#<!-- -->Adaptive Training</span><span class="page__taxonomy-item">#<!-- -->Tree-GRPO</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-10-2-CurES_From_Gradient_Analysis_to_Efficient_Curriculum_Learning_for_Reasoning_LLMs/">[논문리뷰] CurES: From Gradient Analysis to Efficient Curriculum Learning for Reasoning LLMs</a></h2><div class="archive__item-excerpt">Hengyi Cai이 [arXiv]에 게시한 &#x27;CurES: From Gradient Analysis to Efficient Curriculum Learning for Reasoning LLMs&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-10-02 13:30:22+0900">2025년 10월 2일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Curriculum Learning</span><span class="page__taxonomy-item">#<!-- -->LLMs</span><span class="page__taxonomy-item">#<!-- -->Reasoning</span><span class="page__taxonomy-item">#<!-- -->Gradient Optimization</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Bayesian Inference</span><span class="page__taxonomy-item">#<!-- -->Sample Efficiency</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-10-2-Code2Video_A_Code-centric_Paradigm_for_Educational_Video_Generation/">[논문리뷰] Code2Video: A Code-centric Paradigm for Educational Video Generation</a></h2><div class="archive__item-excerpt">이 [arXiv]에 게시한 &#x27;Code2Video: A Code-centric Paradigm for Educational Video Generation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-10-02 13:30:22+0900">2025년 10월 2일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Educational Video Generation</span><span class="page__taxonomy-item">#<!-- -->Code-centric AI</span><span class="page__taxonomy-item">#<!-- -->Multi-agent Framework</span><span class="page__taxonomy-item">#<!-- -->Manim</span><span class="page__taxonomy-item">#<!-- -->Vision-Language Models</span><span class="page__taxonomy-item">#<!-- -->Knowledge Transfer</span><span class="page__taxonomy-item">#<!-- -->Code Generation</span><span class="page__taxonomy-item">#<!-- -->MMMC Benchmark</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-10-2-BroRL_Scaling_Reinforcement_Learning_via_Broadened_Exploration/">[논문리뷰] BroRL: Scaling Reinforcement Learning via Broadened Exploration</a></h2><div class="archive__item-excerpt">이 [arXiv]에 게시한 &#x27;BroRL: Scaling Reinforcement Learning via Broadened Exploration&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-10-02 13:30:22+0900">2025년 10월 2일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->LLMs</span><span class="page__taxonomy-item">#<!-- -->Scaling Laws</span><span class="page__taxonomy-item">#<!-- -->Exploration</span><span class="page__taxonomy-item">#<!-- -->Rollout Size</span><span class="page__taxonomy-item">#<!-- -->Verifiable Rewards</span><span class="page__taxonomy-item">#<!-- -->PPO</span><span class="page__taxonomy-item">#<!-- -->Mass Balance Equation</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-10-2-Boolean_Satisfiability_via_Imitation_Learning/">[논문리뷰] Boolean Satisfiability via Imitation Learning</a></h2><div class="archive__item-excerpt">Xiangyu Xu이 [arXiv]에 게시한 &#x27;Boolean Satisfiability via Imitation Learning&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-10-02 13:30:22+0900">2025년 10월 2일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Boolean Satisfiability</span><span class="page__taxonomy-item">#<!-- -->Imitation Learning</span><span class="page__taxonomy-item">#<!-- -->CDCL Solvers</span><span class="page__taxonomy-item">#<!-- -->Branching Policy</span><span class="page__taxonomy-item">#<!-- -->KeyTrace</span><span class="page__taxonomy-item">#<!-- -->Transformer Architecture</span><span class="page__taxonomy-item">#<!-- -->Perceiver AR</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-10-2-BindWeave_Subject-Consistent_Video_Generation_via_Cross-Modal_Integration/">[논문리뷰] BindWeave: Subject-Consistent Video Generation via Cross-Modal Integration</a></h2><div class="archive__item-excerpt">Xiangyang Xia이 [arXiv]에 게시한 &#x27;BindWeave: Subject-Consistent Video Generation via Cross-Modal Integration&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-10-02 13:30:22+0900">2025년 10월 2일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Video Generation</span><span class="page__taxonomy-item">#<!-- -->Subject Consistency</span><span class="page__taxonomy-item">#<!-- -->Cross-Modal Integration</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->Multimodal LLM</span><span class="page__taxonomy-item">#<!-- -->Diffusion Transformer</span><span class="page__taxonomy-item">#<!-- -->Text-to-Video</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-10-2-BiasFreeBench_a_Benchmark_for_Mitigating_Bias_in_Large_Language_Model_Responses/">[논문리뷰] BiasFreeBench: a Benchmark for Mitigating Bias in Large Language Model Responses</a></h2><div class="archive__item-excerpt">Julian McAuley이 [arXiv]에 게시한 &#x27;BiasFreeBench: a Benchmark for Mitigating Bias in Large Language Model Responses&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-10-02 13:30:22+0900">2025년 10월 2일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLM Bias Mitigation</span><span class="page__taxonomy-item">#<!-- -->Benchmark</span><span class="page__taxonomy-item">#<!-- -->Evaluation Metrics</span><span class="page__taxonomy-item">#<!-- -->Prompt Engineering</span><span class="page__taxonomy-item">#<!-- -->Fine-tuning</span><span class="page__taxonomy-item">#<!-- -->Bias-Free Score</span><span class="page__taxonomy-item">#<!-- -->Fairness</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-10-2-Beyond_Log_Likelihood_Probability-Based_Objectives_for_Supervised_Fine-Tuning_across_the_Model_Capability_Continuum/">[논문리뷰] Beyond Log Likelihood: Probability-Based Objectives for Supervised Fine-Tuning across the Model Capability Continuum</a></h2><div class="archive__item-excerpt">Hanghang Tong이 [arXiv]에 게시한 &#x27;Beyond Log Likelihood: Probability-Based Objectives for Supervised Fine-Tuning across the Model Capability Continuum&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-10-02 13:30:22+0900">2025년 10월 2일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Supervised Fine-tuning (SFT)</span><span class="page__taxonomy-item">#<!-- -->Large Language Models (LLMs)</span><span class="page__taxonomy-item">#<!-- -->Training Objectives</span><span class="page__taxonomy-item">#<!-- -->Negative Log Likelihood (NLL)</span><span class="page__taxonomy-item">#<!-- -->Model Capability Continuum</span><span class="page__taxonomy-item">#<!-- -->Generalization</span><span class="page__taxonomy-item">#<!-- -->Probability-based Loss Functions</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-10-2-An_Empirical_Study_of_Testing_Practices_in_Open_Source_AI_Agent_Frameworks_and_Agentic_Applications/">[논문리뷰] An Empirical Study of Testing Practices in Open Source AI Agent Frameworks and Agentic Applications</a></h2><div class="archive__item-excerpt">Bram Adams이 [arXiv]에 게시한 &#x27;An Empirical Study of Testing Practices in Open Source AI Agent Frameworks and Agentic Applications&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-10-02 13:30:22+0900">2025년 10월 2일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->AI Agent</span><span class="page__taxonomy-item">#<!-- -->LLM Agent</span><span class="page__taxonomy-item">#<!-- -->Testing</span><span class="page__taxonomy-item">#<!-- -->Empirical Study</span><span class="page__taxonomy-item">#<!-- -->Software Quality</span><span class="page__taxonomy-item">#<!-- -->Agent Frameworks</span><span class="page__taxonomy-item">#<!-- -->Agentic Applications</span><span class="page__taxonomy-item">#<!-- -->Non-Determinism</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-10-2-ACON_Optimizing_Context_Compression_for_Long-horizon_LLM_Agents/">[논문리뷰] ACON: Optimizing Context Compression for Long-horizon LLM Agents</a></h2><div class="archive__item-excerpt">이 [arXiv]에 게시한 &#x27;ACON: Optimizing Context Compression for Long-horizon LLM Agents&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-10-02 13:30:22+0900">2025년 10월 2일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLM Agents</span><span class="page__taxonomy-item">#<!-- -->Context Compression</span><span class="page__taxonomy-item">#<!-- -->Long-horizon Tasks</span><span class="page__taxonomy-item">#<!-- -->Prompt Optimization</span><span class="page__taxonomy-item">#<!-- -->Knowledge Distillation</span><span class="page__taxonomy-item">#<!-- -->Memory Efficiency</span><span class="page__taxonomy-item">#<!-- -->Task Performance</span><span class="page__taxonomy-item">#<!-- -->Failure Analysis</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-10-1-Winning_the_Pruning_Gamble_A_Unified_Approach_to_Joint_Sample_and_Token_Pruning_for_Efficient_Supervised_Fine-Tuning/">[논문리뷰] Winning the Pruning Gamble: A Unified Approach to Joint Sample and Token Pruning for Efficient Supervised Fine-Tuning</a></h2><div class="archive__item-excerpt">Yue Min이 [arXiv]에 게시한 &#x27;Winning the Pruning Gamble: A Unified Approach to Joint Sample and Token Pruning for Efficient Supervised Fine-Tuning&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-10-01 14:04:08+0900">2025년 10월 1일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLM SFT</span><span class="page__taxonomy-item">#<!-- -->Data Pruning</span><span class="page__taxonomy-item">#<!-- -->Sample Pruning</span><span class="page__taxonomy-item">#<!-- -->Token Pruning</span><span class="page__taxonomy-item">#<!-- -->Error-Uncertainty Plane</span><span class="page__taxonomy-item">#<!-- -->Q-Tuning</span><span class="page__taxonomy-item">#<!-- -->Data Efficiency</span><span class="page__taxonomy-item">#<!-- -->Dynamic Pruning</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-10-1-Who_invented_deep_residual_learning/">[논문리뷰] Who invented deep residual learning?</a></h2><div class="archive__item-excerpt">Juergen Schmidhuber이 [arXiv]에 게시한 &#x27;Who invented deep residual learning?&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-10-01 14:04:08+0900">2025년 10월 1일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Deep Learning History</span><span class="page__taxonomy-item">#<!-- -->Residual Connections</span><span class="page__taxonomy-item">#<!-- -->Recurrent Neural Networks (RNN)</span><span class="page__taxonomy-item">#<!-- -->Long Short-Term Memory (LSTM)</span><span class="page__taxonomy-item">#<!-- -->Feedforward Neural Networks (FNN)</span><span class="page__taxonomy-item">#<!-- -->Highway Networks</span><span class="page__taxonomy-item">#<!-- -->ResNet</span><span class="page__taxonomy-item">#<!-- -->Vanishing Gradient</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-10-1-Whos_Your_Judge_On_the_Detectability_of_LLM-Generated_Judgments/">[논문리뷰] Who&#x27;s Your Judge? On the Detectability of LLM-Generated Judgments</a></h2><div class="archive__item-excerpt">이 [arXiv]에 게시한 &#x27;Who&#x27;s Your Judge? On the Detectability of LLM-Generated Judgments&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-10-01 14:04:08+0900">2025년 10월 1일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLM-as-a-judge</span><span class="page__taxonomy-item">#<!-- -->Judgment Detection</span><span class="page__taxonomy-item">#<!-- -->Bias Quantification</span><span class="page__taxonomy-item">#<!-- -->Feature Engineering</span><span class="page__taxonomy-item">#<!-- -->Interpretability</span><span class="page__taxonomy-item">#<!-- -->Peer Review</span><span class="page__taxonomy-item">#<!-- -->AI Ethics</span><span class="page__taxonomy-item">#<!-- -->Evaluation</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-10-1-Voice_Evaluation_of_Reasoning_Ability_Diagnosing_the_Modality-Induced_Performance_Gap/">[논문리뷰] Voice Evaluation of Reasoning Ability: Diagnosing the Modality-Induced Performance Gap</a></h2><div class="archive__item-excerpt">Hengfan Zhang이 [arXiv]에 게시한 &#x27;Voice Evaluation of Reasoning Ability: Diagnosing the Modality-Induced Performance Gap&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-10-01 14:04:08+0900">2025년 10월 1일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Voice AI</span><span class="page__taxonomy-item">#<!-- -->LLM</span><span class="page__taxonomy-item">#<!-- -->Reasoning</span><span class="page__taxonomy-item">#<!-- -->Benchmark</span><span class="page__taxonomy-item">#<!-- -->Modality Gap</span><span class="page__taxonomy-item">#<!-- -->Latency</span><span class="page__taxonomy-item">#<!-- -->Speech Recognition</span><span class="page__taxonomy-item">#<!-- -->Generative AI</span><span class="page__taxonomy-item">#<!-- -->Real-time Systems</span><span class="page__taxonomy-item">#<!-- -->Conversational AI</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-10-1-VitaBench_Benchmarking_LLM_Agents_with_Versatile_Interactive_Tasks_in_Real-world_Applications/">[논문리뷰] VitaBench: Benchmarking LLM Agents with Versatile Interactive Tasks in Real-world Applications</a></h2><div class="archive__item-excerpt">이 [arXiv]에 게시한 &#x27;VitaBench: Benchmarking LLM Agents with Versatile Interactive Tasks in Real-world Applications&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-10-01 14:04:08+0900">2025년 10월 1일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLM Agents</span><span class="page__taxonomy-item">#<!-- -->Benchmarking</span><span class="page__taxonomy-item">#<!-- -->Interactive Tasks</span><span class="page__taxonomy-item">#<!-- -->Real-world Applications</span><span class="page__taxonomy-item">#<!-- -->Tool Use</span><span class="page__taxonomy-item">#<!-- -->Multi-turn Conversation</span><span class="page__taxonomy-item">#<!-- -->Task Complexity</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-10-1-VisualOverload_Probing_Visual_Understanding_of_VLMs_in_Really_Dense_Scenes/">[논문리뷰] VisualOverload: Probing Visual Understanding of VLMs in Really Dense Scenes</a></h2><div class="archive__item-excerpt">Muhammad Huzaifa이 [arXiv]에 게시한 &#x27;VisualOverload: Probing Visual Understanding of VLMs in Really Dense Scenes&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-10-01 14:04:08+0900">2025년 10월 1일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Visual Question Answering</span><span class="page__taxonomy-item">#<!-- -->Multimodal Models</span><span class="page__taxonomy-item">#<!-- -->Dense Scenes</span><span class="page__taxonomy-item">#<!-- -->Fine-Grained Perception</span><span class="page__taxonomy-item">#<!-- -->Benchmark</span><span class="page__taxonomy-item">#<!-- -->Error Analysis</span><span class="page__taxonomy-item">#<!-- -->Counting</span><span class="page__taxonomy-item">#<!-- -->OCR</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-10-1-Vision-Zero_Scalable_VLM_Self-Improvement_via_Strategic_Gamified_Self-Play/">[논문리뷰] Vision-Zero: Scalable VLM Self-Improvement via Strategic Gamified Self-Play</a></h2><div class="archive__item-excerpt">Jing Shi이 [arXiv]에 게시한 &#x27;Vision-Zero: Scalable VLM Self-Improvement via Strategic Gamified Self-Play&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-10-01 14:04:08+0900">2025년 10월 1일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Vision-Language Models (VLMs)</span><span class="page__taxonomy-item">#<!-- -->Self-Play</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Gamification</span><span class="page__taxonomy-item">#<!-- -->Data Efficiency</span><span class="page__taxonomy-item">#<!-- -->Strategic Reasoning</span><span class="page__taxonomy-item">#<!-- -->Multimodal AI</span><span class="page__taxonomy-item">#<!-- -->Self-Improvement</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-10-1-TTT3R_3D_Reconstruction_as_Test-Time_Training/">[논문리뷰] TTT3R: 3D Reconstruction as Test-Time Training</a></h2><div class="archive__item-excerpt">Anpei Chen이 [arXiv]에 게시한 &#x27;TTT3R: 3D Reconstruction as Test-Time Training&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-10-01 14:04:08+0900">2025년 10월 1일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->3D Reconstruction</span><span class="page__taxonomy-item">#<!-- -->Test-Time Training (TTT)</span><span class="page__taxonomy-item">#<!-- -->Recurrent Neural Networks (RNN)</span><span class="page__taxonomy-item">#<!-- -->Online Learning</span><span class="page__taxonomy-item">#<!-- -->Length Generalization</span><span class="page__taxonomy-item">#<!-- -->Associative Memory</span><span class="page__taxonomy-item">#<!-- -->State Update Rule</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-10-1-TruthRL_Incentivizing_Truthful_LLMs_via_Reinforcement_Learning/">[논문리뷰] TruthRL: Incentivizing Truthful LLMs via Reinforcement Learning</a></h2><div class="archive__item-excerpt">이 [arXiv]에 게시한 &#x27;TruthRL: Incentivizing Truthful LLMs via Reinforcement Learning&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-10-01 14:04:08+0900">2025년 10월 1일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLM Hallucination</span><span class="page__taxonomy-item">#<!-- -->Truthfulness</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Ternary Reward</span><span class="page__taxonomy-item">#<!-- -->Abstention</span><span class="page__taxonomy-item">#<!-- -->Knowledge Boundary</span><span class="page__taxonomy-item">#<!-- -->GRPO</span><span class="page__taxonomy-item">#<!-- -->RLHF</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-10-1-Thinking_Sparks_Emergent_Attention_Heads_in_Reasoning_Models_During_Post_Training/">[논문리뷰] Thinking Sparks!: Emergent Attention Heads in Reasoning Models During Post Training</a></h2><div class="archive__item-excerpt">이 [arXiv]에 게시한 &#x27;Thinking Sparks!: Emergent Attention Heads in Reasoning Models During Post Training&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-10-01 14:04:08+0900">2025년 10월 1일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Mechanistic Interpretability</span><span class="page__taxonomy-item">#<!-- -->Attention Heads</span><span class="page__taxonomy-item">#<!-- -->Post-Training</span><span class="page__taxonomy-item">#<!-- -->Supervised Fine-Tuning (SFT)</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning (RL)</span><span class="page__taxonomy-item">#<!-- -->Circuit Analysis</span><span class="page__taxonomy-item">#<!-- -->Reasoning Models</span><span class="page__taxonomy-item">#<!-- -->Transformer Architecture</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-10-1-The_Dragon_Hatchling_The_Missing_Link_between_the_Transformer_and_Models_of_the_Brain/">[논문리뷰] The Dragon Hatchling: The Missing Link between the Transformer and Models of the Brain</a></h2><div class="archive__item-excerpt">이 [arXiv]에 게시한 &#x27;The Dragon Hatchling: The Missing Link between the Transformer and Models of the Brain&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-10-01 14:04:08+0900">2025년 10월 1일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Brain-Inspired AI</span><span class="page__taxonomy-item">#<!-- -->Graph Neural Networks</span><span class="page__taxonomy-item">#<!-- -->Hebbian Learning</span><span class="page__taxonomy-item">#<!-- -->Scale-Free Networks</span><span class="page__taxonomy-item">#<!-- -->Model Interpretability</span><span class="page__taxonomy-item">#<!-- -->Transformer Architecture</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-10-1-Test-Time_Policy_Adaptation_for_Enhanced_Multi-Turn_Interactions_with_LLMs/">[논문리뷰] Test-Time Policy Adaptation for Enhanced Multi-Turn Interactions with LLMs</a></h2><div class="archive__item-excerpt">Yao Shu이 [arXiv]에 게시한 &#x27;Test-Time Policy Adaptation for Enhanced Multi-Turn Interactions with LLMs&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-10-01 14:04:08+0900">2025년 10월 1일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Multi-turn Interaction</span><span class="page__taxonomy-item">#<!-- -->Test-Time Adaptation</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning from Human Feedback</span><span class="page__taxonomy-item">#<!-- -->Policy Optimization</span><span class="page__taxonomy-item">#<!-- -->Online Learning</span><span class="page__taxonomy-item">#<!-- -->Self-Correction</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-10-1-TAU_A_Benchmark_for_Cultural_Sound_Understanding_Beyond_Semantics/">[논문리뷰] TAU: A Benchmark for Cultural Sound Understanding Beyond Semantics</a></h2><div class="archive__item-excerpt">Szu-Chi Chen이 [arXiv]에 게시한 &#x27;TAU: A Benchmark for Cultural Sound Understanding Beyond Semantics&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-10-01 14:04:08+0900">2025년 10월 1일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Audio Language Models</span><span class="page__taxonomy-item">#<!-- -->Cultural Sound Understanding</span><span class="page__taxonomy-item">#<!-- -->Localized Benchmark</span><span class="page__taxonomy-item">#<!-- -->Non-semantic Audio</span><span class="page__taxonomy-item">#<!-- -->Human-in-the-loop</span><span class="page__taxonomy-item">#<!-- -->Multimodal AI</span><span class="page__taxonomy-item">#<!-- -->Taipei Soundscape</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-10-1-Stable_Cinemetrics_Structured_Taxonomy_and_Evaluation_for_Professional_Video_Generation/">[논문리뷰] Stable Cinemetrics : Structured Taxonomy and Evaluation for Professional Video Generation</a></h2><div class="archive__item-excerpt">이 [arXiv]에 게시한 &#x27;Stable Cinemetrics : Structured Taxonomy and Evaluation for Professional Video Generation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-10-01 14:04:08+0900">2025년 10월 1일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Video Generation</span><span class="page__taxonomy-item">#<!-- -->Evaluation Framework</span><span class="page__taxonomy-item">#<!-- -->Cinematic Control</span><span class="page__taxonomy-item">#<!-- -->Taxonomy</span><span class="page__taxonomy-item">#<!-- -->Human Annotation</span><span class="page__taxonomy-item">#<!-- -->Vision-Language Models</span><span class="page__taxonomy-item">#<!-- -->Text-to-Video</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-10-1-Specialization_after_Generalization_Towards_Understanding_Test-Time_Training_in_Foundation_Models/">[논문리뷰] Specialization after Generalization: Towards Understanding Test-Time Training in Foundation Models</a></h2><div class="archive__item-excerpt">이 [arXiv]에 게시한 &#x27;Specialization after Generalization: Towards Understanding Test-Time Training in Foundation Models&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-10-01 14:04:08+0900">2025년 10월 1일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Test-Time Training (TTT)</span><span class="page__taxonomy-item">#<!-- -->Foundation Models</span><span class="page__taxonomy-item">#<!-- -->Underparameterization</span><span class="page__taxonomy-item">#<!-- -->Sparse Autoencoders (SAE)</span><span class="page__taxonomy-item">#<!-- -->Linear Representation Hypothesis (LRH)</span><span class="page__taxonomy-item">#<!-- -->Specialization</span><span class="page__taxonomy-item">#<!-- -->Scaling Laws</span><span class="page__taxonomy-item">#<!-- -->In-Distribution Data</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-10-1-Regression_Language_Models_for_Code/">[논문리뷰] Regression Language Models for Code</a></h2><div class="archive__item-excerpt">이 [arXiv]에 게시한 &#x27;Regression Language Models for Code&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-10-01 14:04:08+0900">2025년 10월 1일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Regression Language Model</span><span class="page__taxonomy-item">#<!-- -->Code Performance Prediction</span><span class="page__taxonomy-item">#<!-- -->Static Analysis</span><span class="page__taxonomy-item">#<!-- -->Neural Architecture Search</span><span class="page__taxonomy-item">#<!-- -->Text-to-Text Regression</span><span class="page__taxonomy-item">#<!-- -->Multi-task Learning</span><span class="page__taxonomy-item">#<!-- -->T5Gemma</span><span class="page__taxonomy-item">#<!-- -->ONNX</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-10-1-ProfVLM_A_Lightweight_Video-Language_Model_for_Multi-View_Proficiency_Estimation/">[논문리뷰] ProfVLM: A Lightweight Video-Language Model for Multi-View Proficiency Estimation</a></h2><div class="archive__item-excerpt">Antonio Liotta이 [arXiv]에 게시한 &#x27;ProfVLM: A Lightweight Video-Language Model for Multi-View Proficiency Estimation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-10-01 14:04:08+0900">2025년 10월 1일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Video-Language Model</span><span class="page__taxonomy-item">#<!-- -->Proficiency Estimation</span><span class="page__taxonomy-item">#<!-- -->Multi-View Video</span><span class="page__taxonomy-item">#<!-- -->Action Quality Assessment</span><span class="page__taxonomy-item">#<!-- -->Lightweight Model</span><span class="page__taxonomy-item">#<!-- -->Generative Feedback</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-10-1-Probing_the_Critical_Point_CritPt_of_AI_Reasoning_a_Frontier_Physics_Research_Benchmark/">[논문리뷰] Probing the Critical Point (CritPt) of AI Reasoning: a Frontier Physics Research Benchmark</a></h2><div class="archive__item-excerpt">Penghao Zhu이 [arXiv]에 게시한 &#x27;Probing the Critical Point (CritPt) of AI Reasoning: a Frontier Physics Research Benchmark&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-10-01 14:04:08+0900">2025년 10월 1일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->AI Reasoning</span><span class="page__taxonomy-item">#<!-- -->Physics Research</span><span class="page__taxonomy-item">#<!-- -->LLM Evaluation</span><span class="page__taxonomy-item">#<!-- -->Scientific Benchmark</span><span class="page__taxonomy-item">#<!-- -->Frontier Physics</span><span class="page__taxonomy-item">#<!-- -->Problem Solving</span><span class="page__taxonomy-item">#<!-- -->Model Reliability</span><span class="page__taxonomy-item">#<!-- -->Auto-grading</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-10-1-OffTopicEval_When_Large_Language_Models_Enter_the_Wrong_Chat_Almost_Always/">[논문리뷰] OffTopicEval: When Large Language Models Enter the Wrong Chat, Almost Always!</a></h2><div class="archive__item-excerpt">이 [arXiv]에 게시한 &#x27;OffTopicEval: When Large Language Models Enter the Wrong Chat, Almost Always!&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-10-01 14:04:08+0900">2025년 10월 1일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Large Language Models (LLMs)</span><span class="page__taxonomy-item">#<!-- -->Operational Safety</span><span class="page__taxonomy-item">#<!-- -->Out-of-Domain (OOD)</span><span class="page__taxonomy-item">#<!-- -->Prompt Steering</span><span class="page__taxonomy-item">#<!-- -->Jailbreak Attacks</span><span class="page__taxonomy-item">#<!-- -->Evaluation Benchmark</span><span class="page__taxonomy-item">#<!-- -->Refusal Rate</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-10-1-OceanGym_A_Benchmark_Environment_for_Underwater_Embodied_Agents/">[논문리뷰] OceanGym: A Benchmark Environment for Underwater Embodied Agents</a></h2><div class="archive__item-excerpt">이 [arXiv]에 게시한 &#x27;OceanGym: A Benchmark Environment for Underwater Embodied Agents&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-10-01 14:04:08+0900">2025년 10월 1일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Underwater Robotics</span><span class="page__taxonomy-item">#<!-- -->Embodied AI</span><span class="page__taxonomy-item">#<!-- -->Benchmark Environment</span><span class="page__taxonomy-item">#<!-- -->Multi-modal Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Autonomous Underwater Vehicles</span><span class="page__taxonomy-item">#<!-- -->Perception</span><span class="page__taxonomy-item">#<!-- -->Decision-Making</span><span class="page__taxonomy-item">#<!-- -->Simulation</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-10-1-MotionRAG_Motion_Retrieval-Augmented_Image-to-Video_Generation/">[논문리뷰] MotionRAG: Motion Retrieval-Augmented Image-to-Video Generation</a></h2><div class="archive__item-excerpt">Limin Wang이 [arXiv]에 게시한 &#x27;MotionRAG: Motion Retrieval-Augmented Image-to-Video Generation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-10-01 14:04:08+0900">2025년 10월 1일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Image-to-Video Generation</span><span class="page__taxonomy-item">#<!-- -->Motion Transfer</span><span class="page__taxonomy-item">#<!-- -->Retrieval-Augmented Generation (RAG)</span><span class="page__taxonomy-item">#<!-- -->In-Context Learning</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->Video Diffusion</span><span class="page__taxonomy-item">#<!-- -->Motion Realism</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-10-1-More_Thought_Less_Accuracy_On_the_Dual_Nature_of_Reasoning_in_Vision-Language_Models/">[논문리뷰] More Thought, Less Accuracy? On the Dual Nature of Reasoning in Vision-Language Models</a></h2><div class="archive__item-excerpt">Fabian Waschkowski이 [arXiv]에 게시한 &#x27;More Thought, Less Accuracy? On the Dual Nature of Reasoning in Vision-Language Models&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-10-01 14:04:08+0900">2025년 10월 1일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Vision-Language Models</span><span class="page__taxonomy-item">#<!-- -->Multimodal Reasoning</span><span class="page__taxonomy-item">#<!-- -->Reasoning</span><span class="page__taxonomy-item">#<!-- -->Visual Forgetting</span><span class="page__taxonomy-item">#<!-- -->Perceptual Grounding</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Policy Optimization</span><span class="page__taxonomy-item">#<!-- -->Visual Anchors</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-10-1-Mem-α_Learning_Memory_Construction_via_Reinforcement_Learning/">[논문리뷰] Mem-α: Learning Memory Construction via Reinforcement Learning</a></h2><div class="archive__item-excerpt">Yuzhen Mao이 [arXiv]에 게시한 &#x27;Mem-α: Learning Memory Construction via Reinforcement Learning&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-10-01 14:04:08+0900">2025년 10월 1일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLM Agents</span><span class="page__taxonomy-item">#<!-- -->External Memory</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Memory Management</span><span class="page__taxonomy-item">#<!-- -->Long-Context Understanding</span><span class="page__taxonomy-item">#<!-- -->Tool Learning</span><span class="page__taxonomy-item">#<!-- -->RAG</span><span class="page__taxonomy-item">#<!-- -->Memory Architecture</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-10-1-MCPMark_A_Benchmark_for_Stress-Testing_Realistic_and_Comprehensive_MCP_Use/">[논문리뷰] MCPMark: A Benchmark for Stress-Testing Realistic and Comprehensive MCP Use</a></h2><div class="archive__item-excerpt">이 [arXiv]에 게시한 &#x27;MCPMark: A Benchmark for Stress-Testing Realistic and Comprehensive MCP Use&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-10-01 14:04:08+0900">2025년 10월 1일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLM Agents</span><span class="page__taxonomy-item">#<!-- -->Model Context Protocol</span><span class="page__taxonomy-item">#<!-- -->Benchmark</span><span class="page__taxonomy-item">#<!-- -->Tool Use</span><span class="page__taxonomy-item">#<!-- -->CRUD Operations</span><span class="page__taxonomy-item">#<!-- -->Workflow Automation</span><span class="page__taxonomy-item">#<!-- -->Stress Testing</span><span class="page__taxonomy-item">#<!-- -->Evaluation</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-10-1-MANI-Pure_Magnitude-Adaptive_Noise_Injection_for_Adversarial_Purification/">[논문리뷰] MANI-Pure: Magnitude-Adaptive Noise Injection for Adversarial Purification</a></h2><div class="archive__item-excerpt">Zhiming Luo이 [arXiv]에 게시한 &#x27;MANI-Pure: Magnitude-Adaptive Noise Injection for Adversarial Purification&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-10-01 14:04:08+0900">2025년 10월 1일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Adversarial Purification</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->Frequency Domain</span><span class="page__taxonomy-item">#<!-- -->Adaptive Noise Injection</span><span class="page__taxonomy-item">#<!-- -->Robustness</span><span class="page__taxonomy-item">#<!-- -->Image Security</span><span class="page__taxonomy-item">#<!-- -->Magnitude Spectrum</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-10-1-Learning_to_See_Before_Seeing_Demystifying_LLM_Visual_Priors_from_Language_Pre-training/">[논문리뷰] Learning to See Before Seeing: Demystifying LLM Visual Priors from Language Pre-training</a></h2><div class="archive__item-excerpt">Koustuv Sinha이 [arXiv]에 게시한 &#x27;Learning to See Before Seeing: Demystifying LLM Visual Priors from Language Pre-training&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-10-01 14:04:08+0900">2025년 10월 1일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLM Visual Priors</span><span class="page__taxonomy-item">#<!-- -->Language Pre-training</span><span class="page__taxonomy-item">#<!-- -->Multimodal LLM</span><span class="page__taxonomy-item">#<!-- -->Data Mixture Optimization</span><span class="page__taxonomy-item">#<!-- -->Reasoning Prior</span><span class="page__taxonomy-item">#<!-- -->Perception Prior</span><span class="page__taxonomy-item">#<!-- -->VQA</span><span class="page__taxonomy-item">#<!-- -->MLE-Bench</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-10-1-Learning_Human-Perceived_Fakeness_in_AI-Generated_Videos_via_Multimodal_LLMs/">[논문리뷰] Learning Human-Perceived Fakeness in AI-Generated Videos via Multimodal LLMs</a></h2><div class="archive__item-excerpt">이 [arXiv]에 게시한 &#x27;Learning Human-Perceived Fakeness in AI-Generated Videos via Multimodal LLMs&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-10-01 14:04:08+0900">2025년 10월 1일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->AI-Generated Videos</span><span class="page__taxonomy-item">#<!-- -->Deepfake Detection</span><span class="page__taxonomy-item">#<!-- -->Multimodal LLMs</span><span class="page__taxonomy-item">#<!-- -->Human Perception</span><span class="page__taxonomy-item">#<!-- -->Video Generation Evaluation</span><span class="page__taxonomy-item">#<!-- -->Spatiotemporal Annotation</span><span class="page__taxonomy-item">#<!-- -->Reward Modeling</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-10-1-LayerD_Decomposing_Raster_Graphic_Designs_into_Layers/">[논문리뷰] LayerD: Decomposing Raster Graphic Designs into Layers</a></h2><div class="archive__item-excerpt">Kota Yamaguchi이 [arXiv]에 게시한 &#x27;LayerD: Decomposing Raster Graphic Designs into Layers&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-10-01 14:04:08+0900">2025년 10월 1일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Graphic Design</span><span class="page__taxonomy-item">#<!-- -->Image Decomposition</span><span class="page__taxonomy-item">#<!-- -->Layer Extraction</span><span class="page__taxonomy-item">#<!-- -->Image Matting</span><span class="page__taxonomy-item">#<!-- -->Background Completion</span><span class="page__taxonomy-item">#<!-- -->Deep Learning</span><span class="page__taxonomy-item">#<!-- -->Creative AI</span><span class="page__taxonomy-item">#<!-- -->Dynamic Time Warping</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-10-1-Knowledge_Homophily_in_Large_Language_Models/">[논문리뷰] Knowledge Homophily in Large Language Models</a></h2><div class="archive__item-excerpt">Nedim Lipka이 [arXiv]에 게시한 &#x27;Knowledge Homophily in Large Language Models&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-10-01 14:04:08+0900">2025년 10월 1일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLM</span><span class="page__taxonomy-item">#<!-- -->Knowledge Homophily</span><span class="page__taxonomy-item">#<!-- -->Graph Neural Networks</span><span class="page__taxonomy-item">#<!-- -->Knowledge Graph</span><span class="page__taxonomy-item">#<!-- -->Knowledge Injection</span><span class="page__taxonomy-item">#<!-- -->Question Answering</span><span class="page__taxonomy-item">#<!-- -->Fine-tuning</span><span class="page__taxonomy-item">#<!-- -->Knowledge Retrieval</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-10-1-jina-reranker-v3_Last_but_Not_Late_Interaction_for_Document_Reranking/">[논문리뷰] jina-reranker-v3: Last but Not Late Interaction for Document Reranking</a></h2><div class="archive__item-excerpt">이 [arXiv]에 게시한 &#x27;jina-reranker-v3: Last but Not Late Interaction for Document Reranking&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-10-01 14:04:08+0900">2025년 10월 1일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Document Reranking</span><span class="page__taxonomy-item">#<!-- -->Last but Not Late Interaction</span><span class="page__taxonomy-item">#<!-- -->Multilingual</span><span class="page__taxonomy-item">#<!-- -->Transformer Architecture</span><span class="page__taxonomy-item">#<!-- -->Cross-Encoder</span><span class="page__taxonomy-item">#<!-- -->InfoNCE Loss</span><span class="page__taxonomy-item">#<!-- -->Contextual Embedding</span><span class="page__taxonomy-item">#<!-- -->Qwen3</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-10-1-InfoAgent_Advancing_Autonomous_Information-Seeking_Agents/">[논문리뷰] InfoAgent: Advancing Autonomous Information-Seeking Agents</a></h2><div class="archive__item-excerpt">이 [arXiv]에 게시한 &#x27;InfoAgent: Advancing Autonomous Information-Seeking Agents&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-10-01 14:04:08+0900">2025년 10월 1일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLM Agents</span><span class="page__taxonomy-item">#<!-- -->Information Seeking</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Data Synthesis</span><span class="page__taxonomy-item">#<!-- -->Web Search Tools</span><span class="page__taxonomy-item">#<!-- -->Tool Use</span><span class="page__taxonomy-item">#<!-- -->Deep Research Agents</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-10-1-IMG_Calibrating_Diffusion_Models_via_Implicit_Multimodal_Guidance/">[논문리뷰] IMG: Calibrating Diffusion Models via Implicit Multimodal Guidance</a></h2><div class="archive__item-excerpt">이 [arXiv]에 게시한 &#x27;IMG: Calibrating Diffusion Models via Implicit Multimodal Guidance&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-10-01 14:04:08+0900">2025년 10월 1일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->Multimodal Alignment</span><span class="page__taxonomy-item">#<!-- -->MLLM</span><span class="page__taxonomy-item">#<!-- -->Image Re-generation</span><span class="page__taxonomy-item">#<!-- -->Preference Learning</span><span class="page__taxonomy-item">#<!-- -->Implicit Guidance</span><span class="page__taxonomy-item">#<!-- -->Text-to-Image</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-10-1-Humanline_Online_Alignment_as_Perceptual_Loss/">[논문리뷰] Humanline: Online Alignment as Perceptual Loss</a></h2><div class="archive__item-excerpt">이 [arXiv]에 게시한 &#x27;Humanline: Online Alignment as Perceptual Loss&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-10-01 14:04:08+0900">2025년 10월 1일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLM Alignment</span><span class="page__taxonomy-item">#<!-- -->Online RLHF</span><span class="page__taxonomy-item">#<!-- -->Offline RLHF</span><span class="page__taxonomy-item">#<!-- -->Prospect Theory</span><span class="page__taxonomy-item">#<!-- -->Perceptual Loss</span><span class="page__taxonomy-item">#<!-- -->Human-Centric AI</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-10-1-Ferret-UI_Lite_Lessons_from_Building_Small_On-Device_GUI_Agents/">[논문리뷰] Ferret-UI Lite: Lessons from Building Small On-Device GUI Agents</a></h2><div class="archive__item-excerpt">이 [arXiv]에 게시한 &#x27;Ferret-UI Lite: Lessons from Building Small On-Device GUI Agents&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-10-01 14:04:08+0900">2025년 10월 1일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->GUI Agents</span><span class="page__taxonomy-item">#<!-- -->On-Device AI</span><span class="page__taxonomy-item">#<!-- -->Multimodal LLM</span><span class="page__taxonomy-item">#<!-- -->GUI Grounding</span><span class="page__taxonomy-item">#<!-- -->GUI Navigation</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Supervised Fine-tuning</span><span class="page__taxonomy-item">#<!-- -->Synthetic Data</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-10-1-Estimating_Time_Series_Foundation_Model_Transferability_via_In-Context_Learning/">[논문리뷰] Estimating Time Series Foundation Model Transferability via In-Context Learning</a></h2><div class="archive__item-excerpt">Jun Qi이 [arXiv]에 게시한 &#x27;Estimating Time Series Foundation Model Transferability via In-Context Learning&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-10-01 14:04:08+0900">2025년 10월 1일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Time Series Foundation Models</span><span class="page__taxonomy-item">#<!-- -->Transferability Estimation</span><span class="page__taxonomy-item">#<!-- -->In-Context Learning</span><span class="page__taxonomy-item">#<!-- -->Tabular Foundation Models</span><span class="page__taxonomy-item">#<!-- -->Model Selection</span><span class="page__taxonomy-item">#<!-- -->Entropy Profile</span><span class="page__taxonomy-item">#<!-- -->Meta-learning</span><span class="page__taxonomy-item">#<!-- -->Forecasting</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-10-1-EntroPE_Entropy-Guided_Dynamic_Patch_Encoder_for_Time_Series_Forecasting/">[논문리뷰] EntroPE: Entropy-Guided Dynamic Patch Encoder for Time Series Forecasting</a></h2><div class="archive__item-excerpt">이 [arXiv]에 게시한 &#x27;EntroPE: Entropy-Guided Dynamic Patch Encoder for Time Series Forecasting&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-10-01 14:04:08+0900">2025년 10월 1일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Time Series Forecasting</span><span class="page__taxonomy-item">#<!-- -->Transformer</span><span class="page__taxonomy-item">#<!-- -->Dynamic Patching</span><span class="page__taxonomy-item">#<!-- -->Entropy</span><span class="page__taxonomy-item">#<!-- -->Predictive Uncertainty</span><span class="page__taxonomy-item">#<!-- -->Adaptive Encoding</span><span class="page__taxonomy-item">#<!-- -->Attention Mechanisms</span><span class="page__taxonomy-item">#<!-- -->Causal Transformer</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-10-1-Efficient_Audio-Visual_Speech_Separation_with_Discrete_Lip_Semantics_and_Multi-Scale_Global-Local_Attention/">[논문리뷰] Efficient Audio-Visual Speech Separation with Discrete Lip Semantics and Multi-Scale Global-Local Attention</a></h2><div class="archive__item-excerpt">이 [arXiv]에 게시한 &#x27;Efficient Audio-Visual Speech Separation with Discrete Lip Semantics and Multi-Scale Global-Local Attention&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-10-01 14:04:08+0900">2025년 10월 1일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Audio-Visual Speech Separation</span><span class="page__taxonomy-item">#<!-- -->Deep Learning</span><span class="page__taxonomy-item">#<!-- -->Efficiency</span><span class="page__taxonomy-item">#<!-- -->Discrete Lip Semantics</span><span class="page__taxonomy-item">#<!-- -->Global-Local Attention</span><span class="page__taxonomy-item">#<!-- -->Lightweight Models</span><span class="page__taxonomy-item">#<!-- -->VQ-VAE</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-10-1-dParallel_Learnable_Parallel_Decoding_for_dLLMs/">[논문리뷰] dParallel: Learnable Parallel Decoding for dLLMs</a></h2><div class="archive__item-excerpt">이 [arXiv]에 게시한 &#x27;dParallel: Learnable Parallel Decoding for dLLMs&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-10-01 14:04:08+0900">2025년 10월 1일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Diffusion Language Models</span><span class="page__taxonomy-item">#<!-- -->Parallel Decoding</span><span class="page__taxonomy-item">#<!-- -->Inference Acceleration</span><span class="page__taxonomy-item">#<!-- -->Certainty Distillation</span><span class="page__taxonomy-item">#<!-- -->Self-Distillation</span><span class="page__taxonomy-item">#<!-- -->Masked Language Models</span><span class="page__taxonomy-item">#<!-- -->LLaDA</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-10-1-DeepScientist_Advancing_Frontier-Pushing_Scientific_Findings_Progressively/">[논문리뷰] DeepScientist: Advancing Frontier-Pushing Scientific Findings Progressively</a></h2><div class="archive__item-excerpt">이 [arXiv]에 게시한 &#x27;DeepScientist: Advancing Frontier-Pushing Scientific Findings Progressively&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-10-01 14:04:08+0900">2025년 10월 1일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->AI Scientist</span><span class="page__taxonomy-item">#<!-- -->Autonomous Scientific Discovery</span><span class="page__taxonomy-item">#<!-- -->Bayesian Optimization</span><span class="page__taxonomy-item">#<!-- -->LLM-based Agents</span><span class="page__taxonomy-item">#<!-- -->SOTA-Surpassing</span><span class="page__taxonomy-item">#<!-- -->Findings Memory</span><span class="page__taxonomy-item">#<!-- -->Exploration-Exploitation</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-10-1-DC-VideoGen_Efficient_Video_Generation_with_Deep_Compression_Video_Autoencoder/">[논문리뷰] DC-VideoGen: Efficient Video Generation with Deep Compression Video Autoencoder</a></h2><div class="archive__item-excerpt">이 [arXiv]에 게시한 &#x27;DC-VideoGen: Efficient Video Generation with Deep Compression Video Autoencoder&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-10-01 14:04:08+0900">2025년 10월 1일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Video Generation</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->Video Autoencoder</span><span class="page__taxonomy-item">#<!-- -->Deep Compression</span><span class="page__taxonomy-item">#<!-- -->Model Acceleration</span><span class="page__taxonomy-item">#<!-- -->Fine-tuning</span><span class="page__taxonomy-item">#<!-- -->Latent Space</span><span class="page__taxonomy-item">#<!-- -->Temporal Modeling</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-10-1-DA2_Depth_Anything_in_Any_Direction/">[논문리뷰] DA^2: Depth Anything in Any Direction</a></h2><div class="archive__item-excerpt">이 [arXiv]에 게시한 &#x27;DA^2: Depth Anything in Any Direction&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-10-01 14:04:08+0900">2025년 10월 1일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Panoramic Depth Estimation</span><span class="page__taxonomy-item">#<!-- -->Zero-shot Generalization</span><span class="page__taxonomy-item">#<!-- -->Data Curation</span><span class="page__taxonomy-item">#<!-- -->SphereViT</span><span class="page__taxonomy-item">#<!-- -->Spherical Geometry</span><span class="page__taxonomy-item">#<!-- -->360-degree Imaging</span><span class="page__taxonomy-item">#<!-- -->Vision Transformer</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-10-1-d2Cache_Accelerating_Diffusion-Based_LLMs_via_Dual_Adaptive_Caching/">[논문리뷰] d^2Cache: Accelerating Diffusion-Based LLMs via Dual Adaptive Caching</a></h2><div class="archive__item-excerpt">Jiarui Wang이 [arXiv]에 게시한 &#x27;d^2Cache: Accelerating Diffusion-Based LLMs via Dual Adaptive Caching&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-10-01 14:04:08+0900">2025년 10월 1일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->Large Language Models (LLMs)</span><span class="page__taxonomy-item">#<!-- -->Inference Acceleration</span><span class="page__taxonomy-item">#<!-- -->KV Cache</span><span class="page__taxonomy-item">#<!-- -->Bidirectional Attention</span><span class="page__taxonomy-item">#<!-- -->Adaptive Caching</span><span class="page__taxonomy-item">#<!-- -->Token Selection</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-10-1-Context_Is_What_You_Need_The_Maximum_Effective_Context_Window_for_Real_World_Limits_of_LLMs/">[논문리뷰] Context Is What You Need: The Maximum Effective Context Window for Real World Limits of LLMs</a></h2><div class="archive__item-excerpt">normanpaulsen이 [arXiv]에 게시한 &#x27;Context Is What You Need: The Maximum Effective Context Window for Real World Limits of LLMs&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-10-01 14:04:08+0900">2025년 10월 1일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Context Window</span><span class="page__taxonomy-item">#<!-- -->Effective Context Window</span><span class="page__taxonomy-item">#<!-- -->Model Performance</span><span class="page__taxonomy-item">#<!-- -->Hallucination Rates</span><span class="page__taxonomy-item">#<!-- -->RAG Systems</span><span class="page__taxonomy-item">#<!-- -->Token Limits</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-10-1-BuildBench_Benchmarking_LLM_Agents_on_Compiling_Real-World_Open-Source_Software/">[논문리뷰] BuildBench: Benchmarking LLM Agents on Compiling Real-World Open-Source Software</a></h2><div class="archive__item-excerpt">이 [arXiv]에 게시한 &#x27;BuildBench: Benchmarking LLM Agents on Compiling Real-World Open-Source Software&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-10-01 14:04:08+0900">2025년 10월 1일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLM Agents</span><span class="page__taxonomy-item">#<!-- -->Open-Source Software</span><span class="page__taxonomy-item">#<!-- -->Compilation</span><span class="page__taxonomy-item">#<!-- -->Benchmarking</span><span class="page__taxonomy-item">#<!-- -->Software Engineering</span><span class="page__taxonomy-item">#<!-- -->Error Resolution</span><span class="page__taxonomy-item">#<!-- -->Retrieval-Augmented Generation</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-10-1-Benefits_and_Pitfalls_of_Reinforcement_Learning_for_Language_Model_Planning_A_Theoretical_Perspective/">[논문리뷰] Benefits and Pitfalls of Reinforcement Learning for Language Model Planning: A Theoretical Perspective</a></h2><div class="archive__item-excerpt">이 [arXiv]에 게시한 &#x27;Benefits and Pitfalls of Reinforcement Learning for Language Model Planning: A Theoretical Perspective&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-10-01 14:04:08+0900">2025년 10월 1일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Planning</span><span class="page__taxonomy-item">#<!-- -->Policy Gradient</span><span class="page__taxonomy-item">#<!-- -->Q-learning</span><span class="page__taxonomy-item">#<!-- -->Supervised Fine-Tuning</span><span class="page__taxonomy-item">#<!-- -->Diversity Collapse</span><span class="page__taxonomy-item">#<!-- -->Reward Hacking</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-10-1-A_Cartography_of_Open_Collaboration_in_Open_Source_AI_Mapping_Practices_Motivations_and_Governance_in_14_Open_Large_Language_Model_Projects/">[논문리뷰] A Cartography of Open Collaboration in Open Source AI: Mapping Practices, Motivations, and Governance in 14 Open Large Language Model Projects</a></h2><div class="archive__item-excerpt">Jennifer Ding이 [arXiv]에 게시한 &#x27;A Cartography of Open Collaboration in Open Source AI: Mapping Practices, Motivations, and Governance in 14 Open Large Language Model Projects&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-10-01 14:04:08+0900">2025년 10월 1일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Open Source AI</span><span class="page__taxonomy-item">#<!-- -->LLM Development</span><span class="page__taxonomy-item">#<!-- -->Open Collaboration</span><span class="page__taxonomy-item">#<!-- -->Governance Models</span><span class="page__taxonomy-item">#<!-- -->Developer Motivations</span><span class="page__taxonomy-item">#<!-- -->Community Engagement</span><span class="page__taxonomy-item">#<!-- -->AI Ecosystem</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-10-1-Attention_as_a_Compass_Efficient_Exploration_for_Process-Supervised_RL_in_Reasoning_Models/">[논문리뷰] Attention as a Compass: Efficient Exploration for Process-Supervised RL in Reasoning Models</a></h2><div class="archive__item-excerpt">이 [arXiv]에 게시한 &#x27;Attention as a Compass: Efficient Exploration for Process-Supervised RL in Reasoning Models&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-10-01 14:04:08+0900">2025년 10월 1일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Process-Supervised RL</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Reasoning Models</span><span class="page__taxonomy-item">#<!-- -->Attention Mechanism</span><span class="page__taxonomy-item">#<!-- -->Efficient Exploration</span><span class="page__taxonomy-item">#<!-- -->Adaptive Sampling</span><span class="page__taxonomy-item">#<!-- -->Off-Policy Training</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-30-Visual_Jigsaw_Post-Training_Improves_MLLMs/">[논문리뷰] Visual Jigsaw Post-Training Improves MLLMs</a></h2><div class="archive__item-excerpt">Lewei Lu이 [arXiv]에 게시한 &#x27;Visual Jigsaw Post-Training Improves MLLMs&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-30 13:52:24+0900">2025년 9월 30일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->MLLMs</span><span class="page__taxonomy-item">#<!-- -->Post-training</span><span class="page__taxonomy-item">#<!-- -->Self-supervised Learning</span><span class="page__taxonomy-item">#<!-- -->Visual Understanding</span><span class="page__taxonomy-item">#<!-- -->Jigsaw Puzzles</span><span class="page__taxonomy-item">#<!-- -->RLVR</span><span class="page__taxonomy-item">#<!-- -->Multimodal Perception</span><span class="page__taxonomy-item">#<!-- -->Spatial Reasoning</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-30-StableToken_A_Noise-Robust_Semantic_Speech_Tokenizer_for_Resilient_SpeechLLMs/">[논문리뷰] StableToken: A Noise-Robust Semantic Speech Tokenizer for Resilient SpeechLLMs</a></h2><div class="archive__item-excerpt">Wei Jia이 [arXiv]에 게시한 &#x27;StableToken: A Noise-Robust Semantic Speech Tokenizer for Resilient SpeechLLMs&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-30 13:52:24+0900">2025년 9월 30일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Speech Tokenizer</span><span class="page__taxonomy-item">#<!-- -->Noise Robustness</span><span class="page__taxonomy-item">#<!-- -->Semantic Tokens</span><span class="page__taxonomy-item">#<!-- -->SpeechLLMs</span><span class="page__taxonomy-item">#<!-- -->Voting-LFQ</span><span class="page__taxonomy-item">#<!-- -->Consensus Training</span><span class="page__taxonomy-item">#<!-- -->Automatic Speech Recognition</span><span class="page__taxonomy-item">#<!-- -->Speech Synthesis</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-30-SLA_Beyond_Sparsity_in_Diffusion_Transformers_via_Fine-Tunable_Sparse-Linear_Attention/">[논문리뷰] SLA: Beyond Sparsity in Diffusion Transformers via Fine-Tunable Sparse-Linear Attention</a></h2><div class="archive__item-excerpt">이 [arXiv]에 게시한 &#x27;SLA: Beyond Sparsity in Diffusion Transformers via Fine-Tunable Sparse-Linear Attention&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-30 13:52:24+0900">2025년 9월 30일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Diffusion Transformers</span><span class="page__taxonomy-item">#<!-- -->Sparse Attention</span><span class="page__taxonomy-item">#<!-- -->Linear Attention</span><span class="page__taxonomy-item">#<!-- -->Model Acceleration</span><span class="page__taxonomy-item">#<!-- -->Video Generation</span><span class="page__taxonomy-item">#<!-- -->Attention Mechanisms</span><span class="page__taxonomy-item">#<!-- -->Fine-tuning</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-30-SANA-Video_Efficient_Video_Generation_with_Block_Linear_Diffusion_Transformer/">[논문리뷰] SANA-Video: Efficient Video Generation with Block Linear Diffusion Transformer</a></h2><div class="archive__item-excerpt">이 [arXiv]에 게시한 &#x27;SANA-Video: Efficient Video Generation with Block Linear Diffusion Transformer&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-30 13:52:24+0900">2025년 9월 30일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Video Generation</span><span class="page__taxonomy-item">#<!-- -->Diffusion Model</span><span class="page__taxonomy-item">#<!-- -->Linear Attention</span><span class="page__taxonomy-item">#<!-- -->Transformer</span><span class="page__taxonomy-item">#<!-- -->Long Video</span><span class="page__taxonomy-item">#<!-- -->Efficient Inference</span><span class="page__taxonomy-item">#<!-- -->Constant Memory</span><span class="page__taxonomy-item">#<!-- -->Low-Cost Training</span><span class="page__taxonomy-item">#<!-- -->RTX Deployment</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-30-RealUnify_Do_Unified_Models_Truly_Benefit_from_Unification_A_Comprehensive_Benchmark/">[논문리뷰] RealUnify: Do Unified Models Truly Benefit from Unification? A Comprehensive Benchmark</a></h2><div class="archive__item-excerpt">Yuran Wang이 [arXiv]에 게시한 &#x27;RealUnify: Do Unified Models Truly Benefit from Unification? A Comprehensive Benchmark&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-30 13:52:24+0900">2025년 9월 30일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Unified Models</span><span class="page__taxonomy-item">#<!-- -->Multimodal AI</span><span class="page__taxonomy-item">#<!-- -->Benchmark</span><span class="page__taxonomy-item">#<!-- -->Capability Synergy</span><span class="page__taxonomy-item">#<!-- -->Visual Understanding</span><span class="page__taxonomy-item">#<!-- -->Image Generation</span><span class="page__taxonomy-item">#<!-- -->Dual-Evaluation Protocol</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-30-Random_Policy_Valuation_is_Enough_for_LLM_Reasoning_with_Verifiable_Rewards/">[논문리뷰] Random Policy Valuation is Enough for LLM Reasoning with Verifiable Rewards</a></h2><div class="archive__item-excerpt">Binxing Jiao이 [arXiv]에 게시한 &#x27;Random Policy Valuation is Enough for LLM Reasoning with Verifiable Rewards&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-30 13:52:24+0900">2025년 9월 30일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->LLM Reasoning</span><span class="page__taxonomy-item">#<!-- -->Policy Valuation</span><span class="page__taxonomy-item">#<!-- -->Markov Decision Process</span><span class="page__taxonomy-item">#<!-- -->Diversity</span><span class="page__taxonomy-item">#<!-- -->Math Reasoning</span><span class="page__taxonomy-item">#<!-- -->Verifiable Rewards</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-30-OpenGPT-4o-Image_A_Comprehensive_Dataset_for_Advanced_Image_Generation_and_Editing/">[논문리뷰] OpenGPT-4o-Image: A Comprehensive Dataset for Advanced Image Generation and Editing</a></h2><div class="archive__item-excerpt">Huanyu Zhang이 [arXiv]에 게시한 &#x27;OpenGPT-4o-Image: A Comprehensive Dataset for Advanced Image Generation and Editing&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-30 13:52:24+0900">2025년 9월 30일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Image Generation</span><span class="page__taxonomy-item">#<!-- -->Image Editing</span><span class="page__taxonomy-item">#<!-- -->Multimodal AI</span><span class="page__taxonomy-item">#<!-- -->Dataset</span><span class="page__taxonomy-item">#<!-- -->Instruction Following</span><span class="page__taxonomy-item">#<!-- -->Taxonomy</span><span class="page__taxonomy-item">#<!-- -->GPT-40</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-30-Multiplayer_Nash_Preference_Optimization/">[논문리뷰] Multiplayer Nash Preference Optimization</a></h2><div class="archive__item-excerpt">이 [arXiv]에 게시한 &#x27;Multiplayer Nash Preference Optimization&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-30 13:52:24+0900">2025년 9월 30일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->RLHF</span><span class="page__taxonomy-item">#<!-- -->LLM Alignment</span><span class="page__taxonomy-item">#<!-- -->Nash Equilibrium</span><span class="page__taxonomy-item">#<!-- -->Multiplayer Games</span><span class="page__taxonomy-item">#<!-- -->Preference Optimization</span><span class="page__taxonomy-item">#<!-- -->Non-transitive Preferences</span><span class="page__taxonomy-item">#<!-- -->Game Theory</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-30-EditScore_Unlocking_Online_RL_for_Image_Editing_via_High-Fidelity_Reward_Modeling/">[논문리뷰] EditScore: Unlocking Online RL for Image Editing via High-Fidelity Reward Modeling</a></h2><div class="archive__item-excerpt">이 [arXiv]에 게시한 &#x27;EditScore: Unlocking Online RL for Image Editing via High-Fidelity Reward Modeling&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-30 13:52:24+0900">2025년 9월 30일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Image Editing</span><span class="page__taxonomy-item">#<!-- -->Reward Modeling</span><span class="page__taxonomy-item">#<!-- -->Instruction-Guided Editing</span><span class="page__taxonomy-item">#<!-- -->Online RL</span><span class="page__taxonomy-item">#<!-- -->Visual Language Models</span><span class="page__taxonomy-item">#<!-- -->Benchmark</span><span class="page__taxonomy-item">#<!-- -->Self-Ensembling</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-30-EasySteer_A_Unified_Framework_for_High-Performance_and_Extensible_LLM_Steering/">[논문리뷰] EasySteer: A Unified Framework for High-Performance and Extensible LLM Steering</a></h2><div class="archive__item-excerpt">이 [arXiv]에 게시한 &#x27;EasySteer: A Unified Framework for High-Performance and Extensible LLM Steering&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-30 13:52:24+0900">2025년 9월 30일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLM Steering Framework</span><span class="page__taxonomy-item">#<!-- -->vLLM Integration</span><span class="page__taxonomy-item">#<!-- -->Hidden State Manipulation</span><span class="page__taxonomy-item">#<!-- -->Inference Optimization</span><span class="page__taxonomy-item">#<!-- -->Extensibility</span><span class="page__taxonomy-item">#<!-- -->Modular Architecture</span><span class="page__taxonomy-item">#<!-- -->Reasoning Mitigation</span><span class="page__taxonomy-item">#<!-- -->Hallucination Reduction</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-29-X-Streamer_Unified_Human_World_Modeling_with_Audiovisual_Interaction/">[논문리뷰] X-Streamer: Unified Human World Modeling with Audiovisual Interaction</a></h2><div class="archive__item-excerpt">Guoxian Song이 [arXiv]에 게시한 &#x27;X-Streamer: Unified Human World Modeling with Audiovisual Interaction&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-29 13:47:46+0900">2025년 9월 29일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Digital Human</span><span class="page__taxonomy-item">#<!-- -->Multimodal AI</span><span class="page__taxonomy-item">#<!-- -->Real-time Streaming</span><span class="page__taxonomy-item">#<!-- -->Video Generation</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->Transformer Architecture</span><span class="page__taxonomy-item">#<!-- -->Audiovisual Synchronization</span><span class="page__taxonomy-item">#<!-- -->World Modeling</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-29-X-CoT_Explainable_Text-to-Video_Retrieval_via_LLM-based_Chain-of-Thought_Reasoning/">[논문리뷰] X-CoT: Explainable Text-to-Video Retrieval via LLM-based Chain-of-Thought Reasoning</a></h2><div class="archive__item-excerpt">Raghuveer Rao이 [arXiv]에 게시한 &#x27;X-CoT: Explainable Text-to-Video Retrieval via LLM-based Chain-of-Thought Reasoning&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-29 13:47:46+0900">2025년 9월 29일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Text-to-Video Retrieval</span><span class="page__taxonomy-item">#<!-- -->LLM</span><span class="page__taxonomy-item">#<!-- -->Chain-of-Thought</span><span class="page__taxonomy-item">#<!-- -->Explainable AI</span><span class="page__taxonomy-item">#<!-- -->Multimodal Retrieval</span><span class="page__taxonomy-item">#<!-- -->Bradley-Terry Model</span><span class="page__taxonomy-item">#<!-- -->Video Annotation</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-29-WoW_Towards_a_World_omniscient_World_model_Through_Embodied_Interaction/">[논문리뷰] WoW: Towards a World omniscient World model Through Embodied Interaction</a></h2><div class="archive__item-excerpt">Weishi Mi이 [arXiv]에 게시한 &#x27;WoW: Towards a World omniscient World model Through Embodied Interaction&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-29 13:47:46+0900">2025년 9월 29일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->World Model</span><span class="page__taxonomy-item">#<!-- -->Embodied AI</span><span class="page__taxonomy-item">#<!-- -->Robotics</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->Physical Reasoning</span><span class="page__taxonomy-item">#<!-- -->Vision Language Models</span><span class="page__taxonomy-item">#<!-- -->Interaction Data</span><span class="page__taxonomy-item">#<!-- -->Self-Optimization</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-29-Where_MLLMs_Attend_and_What_They_Rely_On_Explaining_Autoregressive_Token_Generation/">[논문리뷰] Where MLLMs Attend and What They Rely On: Explaining Autoregressive Token Generation</a></h2><div class="archive__item-excerpt">Shiming Liu이 [arXiv]에 게시한 &#x27;Where MLLMs Attend and What They Rely On: Explaining Autoregressive Token Generation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-29 13:47:46+0900">2025년 9월 29일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->MLLM</span><span class="page__taxonomy-item">#<!-- -->Interpretability</span><span class="page__taxonomy-item">#<!-- -->Attribution</span><span class="page__taxonomy-item">#<!-- -->Token Generation</span><span class="page__taxonomy-item">#<!-- -->Black-box Explanation</span><span class="page__taxonomy-item">#<!-- -->Hallucination Diagnosis</span><span class="page__taxonomy-item">#<!-- -->Multimodality</span><span class="page__taxonomy-item">#<!-- -->VQA</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-29-WebGen-Agent_Enhancing_Interactive_Website_Generation_with_Multi-Level_Feedback_and_Step-Level_Reinforcement_Learning/">[논문리뷰] WebGen-Agent: Enhancing Interactive Website Generation with Multi-Level Feedback and Step-Level Reinforcement Learning</a></h2><div class="archive__item-excerpt">Zhuofan Zong이 [arXiv]에 게시한 &#x27;WebGen-Agent: Enhancing Interactive Website Generation with Multi-Level Feedback and Step-Level Reinforcement Learning&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-29 13:47:46+0900">2025년 9월 29일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Website Generation</span><span class="page__taxonomy-item">#<!-- -->Code Agent</span><span class="page__taxonomy-item">#<!-- -->LLM</span><span class="page__taxonomy-item">#<!-- -->VLM</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Multi-Level Feedback</span><span class="page__taxonomy-item">#<!-- -->GUI Agent</span><span class="page__taxonomy-item">#<!-- -->Step-GRPO</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-29-VoiceAssistant-Eval_Benchmarking_AI_Assistants_across_Listening_Speaking_and_Viewing/">[논문리뷰] VoiceAssistant-Eval: Benchmarking AI Assistants across Listening, Speaking, and Viewing</a></h2><div class="archive__item-excerpt">이 [arXiv]에 게시한 &#x27;VoiceAssistant-Eval: Benchmarking AI Assistants across Listening, Speaking, and Viewing&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-29 13:47:46+0900">2025년 9월 29일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->AI Assistants</span><span class="page__taxonomy-item">#<!-- -->Multimodal Benchmarking</span><span class="page__taxonomy-item">#<!-- -->Audio Understanding</span><span class="page__taxonomy-item">#<!-- -->Speech Synthesis</span><span class="page__taxonomy-item">#<!-- -->Vision-Language Models</span><span class="page__taxonomy-item">#<!-- -->Role-play</span><span class="page__taxonomy-item">#<!-- -->Safety</span><span class="page__taxonomy-item">#<!-- -->Robustness</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-29-Variational_Reasoning_for_Language_Models/">[논문리뷰] Variational Reasoning for Language Models</a></h2><div class="archive__item-excerpt">이 [arXiv]에 게시한 &#x27;Variational Reasoning for Language Models&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-29 13:47:46+0900">2025년 9월 29일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Variational Inference</span><span class="page__taxonomy-item">#<!-- -->Language Models</span><span class="page__taxonomy-item">#<!-- -->Reasoning</span><span class="page__taxonomy-item">#<!-- -->ELBO</span><span class="page__taxonomy-item">#<!-- -->IWAE</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Latent Variables</span><span class="page__taxonomy-item">#<!-- -->Forward-KL</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-29-UniVid_Unifying_Vision_Tasks_with_Pre-trained_Video_Generation_Models/">[논문리뷰] UniVid: Unifying Vision Tasks with Pre-trained Video Generation Models</a></h2><div class="archive__item-excerpt">Yuchao Gu이 [arXiv]에 게시한 &#x27;UniVid: Unifying Vision Tasks with Pre-trained Video Generation Models&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-29 13:47:46+0900">2025년 9월 29일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Unified Vision Modeling</span><span class="page__taxonomy-item">#<!-- -->Video Generation</span><span class="page__taxonomy-item">#<!-- -->Diffusion Transformer</span><span class="page__taxonomy-item">#<!-- -->Supervised Fine-tuning</span><span class="page__taxonomy-item">#<!-- -->Cross-modal</span><span class="page__taxonomy-item">#<!-- -->Cross-source Tasks</span><span class="page__taxonomy-item">#<!-- -->Visual Sentences</span><span class="page__taxonomy-item">#<!-- -->LoRA</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-29-UltraHorizon_Benchmarking_Agent_Capabilities_in_Ultra_Long-Horizon_Scenarios/">[논문리뷰] UltraHorizon: Benchmarking Agent Capabilities in Ultra Long-Horizon Scenarios</a></h2><div class="archive__item-excerpt">Zeyu Qin이 [arXiv]에 게시한 &#x27;UltraHorizon: Benchmarking Agent Capabilities in Ultra Long-Horizon Scenarios&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-29 13:47:46+0900">2025년 9월 29일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLM Agents</span><span class="page__taxonomy-item">#<!-- -->Long-Horizon Reasoning</span><span class="page__taxonomy-item">#<!-- -->Benchmarking</span><span class="page__taxonomy-item">#<!-- -->Partially Observable</span><span class="page__taxonomy-item">#<!-- -->Tool Use</span><span class="page__taxonomy-item">#<!-- -->Memory Management</span><span class="page__taxonomy-item">#<!-- -->Exploration</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-29-TUN3D_Towards_Real-World_Scene_Understanding_from_Unposed_Images/">[논문리뷰] TUN3D: Towards Real-World Scene Understanding from Unposed Images</a></h2><div class="archive__item-excerpt">Anna Vorontsova이 [arXiv]에 게시한 &#x27;TUN3D: Towards Real-World Scene Understanding from Unposed Images&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-29 13:47:46+0900">2025년 9월 29일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->3D Scene Understanding</span><span class="page__taxonomy-item">#<!-- -->Layout Estimation</span><span class="page__taxonomy-item">#<!-- -->3D Object Detection</span><span class="page__taxonomy-item">#<!-- -->Unposed Images</span><span class="page__taxonomy-item">#<!-- -->Sparse Convolutional Networks</span><span class="page__taxonomy-item">#<!-- -->Multi-view Stereo</span><span class="page__taxonomy-item">#<!-- -->Real-time AI</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-29-Think-on-Graph_3.0_Efficient_and_Adaptive_LLM_Reasoning_on_Heterogeneous_Graphs_via_Multi-Agent_Dual-Evolving_Context_Retrieval">[논문리뷰] Think-on-Graph 3.0: Efficient and Adaptive LLM Reasoning on Heterogeneous Graphs via Multi-Agent Dual-Evolving Context Retrieval</a></h2><div class="archive__item-excerpt">이 [arXiv]에 게시한 &#x27;Think-on-Graph 3.0: Efficient and Adaptive LLM Reasoning on Heterogeneous Graphs via Multi-Agent Dual-Evolving Context Retrieval&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-29 13:47:46+0900">2025년 9월 29일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->RAG</span><span class="page__taxonomy-item">#<!-- -->LLM Reasoning</span><span class="page__taxonomy-item">#<!-- -->Knowledge Graphs</span><span class="page__taxonomy-item">#<!-- -->Multi-Agent Systems</span><span class="page__taxonomy-item">#<!-- -->Context Retrieval</span><span class="page__taxonomy-item">#<!-- -->Heterogeneous Graphs</span><span class="page__taxonomy-item">#<!-- -->Adaptive Learning</span><span class="page__taxonomy-item">#<!-- -->Dual-Evolution</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-29-StateX_Enhancing_RNN_Recall_via_Post-training_State_Expansion/">[논문리뷰] StateX: Enhancing RNN Recall via Post-training State Expansion</a></h2><div class="archive__item-excerpt">Zhiyuan Liu이 [arXiv]에 게시한 &#x27;StateX: Enhancing RNN Recall via Post-training State Expansion&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-29 13:47:46+0900">2025년 9월 29일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->RNN</span><span class="page__taxonomy-item">#<!-- -->State Expansion</span><span class="page__taxonomy-item">#<!-- -->Post-training</span><span class="page__taxonomy-item">#<!-- -->Long-context Recall</span><span class="page__taxonomy-item">#<!-- -->Linear Attention</span><span class="page__taxonomy-item">#<!-- -->State Space Models</span><span class="page__taxonomy-item">#<!-- -->GLA</span><span class="page__taxonomy-item">#<!-- -->Mamba2</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-29-SPARK_Synergistic_Policy_And_Reward_Co-Evolving_Framework/">[논문리뷰] SPARK: Synergistic Policy And Reward Co-Evolving Framework</a></h2><div class="archive__item-excerpt">이 [arXiv]에 게시한 &#x27;SPARK: Synergistic Policy And Reward Co-Evolving Framework&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-29 13:47:46+0900">2025년 9월 29일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->LLMs</span><span class="page__taxonomy-item">#<!-- -->LVLMs</span><span class="page__taxonomy-item">#<!-- -->Reward Modeling</span><span class="page__taxonomy-item">#<!-- -->Policy Optimization</span><span class="page__taxonomy-item">#<!-- -->Self-Reflection</span><span class="page__taxonomy-item">#<!-- -->Verifiable Rewards</span><span class="page__taxonomy-item">#<!-- -->Co-evolution</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-29-See_Point_Fly_A_Learning-Free_VLM_Framework_for_Universal_Unmanned_Aerial_Navigation/">[논문리뷰] See, Point, Fly: A Learning-Free VLM Framework for Universal Unmanned Aerial Navigation</a></h2><div class="archive__item-excerpt">Chih-Hai Su이 [arXiv]에 게시한 &#x27;See, Point, Fly: A Learning-Free VLM Framework for Universal Unmanned Aerial Navigation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-29 13:47:46+0900">2025년 9월 29일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Vision-Language Models</span><span class="page__taxonomy-item">#<!-- -->UAV Navigation</span><span class="page__taxonomy-item">#<!-- -->Zero-shot</span><span class="page__taxonomy-item">#<!-- -->Spatial Grounding</span><span class="page__taxonomy-item">#<!-- -->Waypoint Prompting</span><span class="page__taxonomy-item">#<!-- -->Autonomous Navigation</span><span class="page__taxonomy-item">#<!-- -->Adaptive Control</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-29-ReviewScore_Misinformed_Peer_Review_Detection_with_Large_Language_Models/">[논문리뷰] ReviewScore: Misinformed Peer Review Detection with Large Language Models</a></h2><div class="archive__item-excerpt">이 [arXiv]에 게시한 &#x27;ReviewScore: Misinformed Peer Review Detection with Large Language Models&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-29 13:47:46+0900">2025년 9월 29일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Peer Review</span><span class="page__taxonomy-item">#<!-- -->Review Quality</span><span class="page__taxonomy-item">#<!-- -->Large Language Models (LLMs)</span><span class="page__taxonomy-item">#<!-- -->Misinformed Review</span><span class="page__taxonomy-item">#<!-- -->Argument Reconstruction</span><span class="page__taxonomy-item">#<!-- -->Factuality Evaluation</span><span class="page__taxonomy-item">#<!-- -->Natural Language Processing</span><span class="page__taxonomy-item">#<!-- -->Automated Evaluation</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-29-RefAM_Attention_Magnets_for_Zero-Shot_Referral_Segmentation/">[논문리뷰] RefAM: Attention Magnets for Zero-Shot Referral Segmentation</a></h2><div class="archive__item-excerpt">Federico Tombari이 [arXiv]에 게시한 &#x27;RefAM: Attention Magnets for Zero-Shot Referral Segmentation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-29 13:47:46+0900">2025년 9월 29일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Zero-Shot Segmentation</span><span class="page__taxonomy-item">#<!-- -->Referring Segmentation</span><span class="page__taxonomy-item">#<!-- -->Diffusion Transformers (DiTs)</span><span class="page__taxonomy-item">#<!-- -->Attention Mechanisms</span><span class="page__taxonomy-item">#<!-- -->Attention Sinks</span><span class="page__taxonomy-item">#<!-- -->Stop Words</span><span class="page__taxonomy-item">#<!-- -->Vision-Language Models</span><span class="page__taxonomy-item">#<!-- -->Training-Free Methods</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-29-Real-Time_Object_Detection_Meets_DINOv3/">[논문리뷰] Real-Time Object Detection Meets DINOv3</a></h2><div class="archive__item-excerpt">Xi Shen이 [arXiv]에 게시한 &#x27;Real-Time Object Detection Meets DINOv3&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-29 13:47:46+0900">2025년 9월 29일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Real-time Object Detection</span><span class="page__taxonomy-item">#<!-- -->DINOv3</span><span class="page__taxonomy-item">#<!-- -->DEIMv2</span><span class="page__taxonomy-item">#<!-- -->Vision Transformer</span><span class="page__taxonomy-item">#<!-- -->Multi-scale Features</span><span class="page__taxonomy-item">#<!-- -->Spatial Tuning Adapter</span><span class="page__taxonomy-item">#<!-- -->Lightweight Models</span><span class="page__taxonomy-item">#<!-- -->Object Detection Framework</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-29-Quantile_Advantage_Estimation_for_Entropy-Safe_Reasoning/">[논문리뷰] Quantile Advantage Estimation for Entropy-Safe Reasoning</a></h2><div class="archive__item-excerpt">An Zhang이 [arXiv]에 게시한 &#x27;Quantile Advantage Estimation for Entropy-Safe Reasoning&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-29 13:47:46+0900">2025년 9월 29일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->LLM Reasoning</span><span class="page__taxonomy-item">#<!-- -->Entropy Control</span><span class="page__taxonomy-item">#<!-- -->Advantage Estimation</span><span class="page__taxonomy-item">#<!-- -->Quantile Baseline</span><span class="page__taxonomy-item">#<!-- -->Exploration-Exploitation</span><span class="page__taxonomy-item">#<!-- -->RLVR</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-29-PromptCoT_2.0_Scaling_Prompt_Synthesis_for_Large_Language_Model_Reasoning">[논문리뷰] PromptCoT 2.0: Scaling Prompt Synthesis for Large Language Model Reasoning</a></h2><div class="archive__item-excerpt">Lingpeng Kong이 [arXiv]에 게시한 &#x27;PromptCoT 2.0: Scaling Prompt Synthesis for Large Language Model Reasoning&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-29 13:47:46+0900">2025년 9월 29일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Prompt Synthesis</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Reasoning</span><span class="page__taxonomy-item">#<!-- -->Expectation-Maximization</span><span class="page__taxonomy-item">#<!-- -->Self-Play</span><span class="page__taxonomy-item">#<!-- -->Supervised Fine-Tuning</span><span class="page__taxonomy-item">#<!-- -->Task Generation</span><span class="page__taxonomy-item">#<!-- -->Rationale Generation</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-29-No_Prompt_Left_Behind_Exploiting_Zero-Variance_Prompts_in_LLM_Reinforcement_Learning_via_Entropy-Guided_Advantage_Shaping/">[논문리뷰] No Prompt Left Behind: Exploiting Zero-Variance Prompts in LLM Reinforcement Learning via Entropy-Guided Advantage Shaping</a></h2><div class="archive__item-excerpt">이 [arXiv]에 게시한 &#x27;No Prompt Left Behind: Exploiting Zero-Variance Prompts in LLM Reinforcement Learning via Entropy-Guided Advantage Shaping&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-29 13:47:46+0900">2025년 9월 29일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLM Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Zero-Variance Prompts</span><span class="page__taxonomy-item">#<!-- -->Advantage Shaping</span><span class="page__taxonomy-item">#<!-- -->Entropy-Guided</span><span class="page__taxonomy-item">#<!-- -->Math Reasoning</span><span class="page__taxonomy-item">#<!-- -->RLVR</span><span class="page__taxonomy-item">#<!-- -->Group Relative Policy Optimization</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-29-MinerU2.5_A_Decoupled_Vision-Language_Model_for_Efficient_High-Resolution_Document_Parsing">[논문리뷰] MinerU2.5: A Decoupled Vision-Language Model for Efficient High-Resolution Document Parsing</a></h2><div class="archive__item-excerpt">SunYuefeng이 [arXiv]에 게시한 &#x27;MinerU2.5: A Decoupled Vision-Language Model for Efficient High-Resolution Document Parsing&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-29 13:47:46+0900">2025년 9월 29일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Document Parsing</span><span class="page__taxonomy-item">#<!-- -->Vision-Language Model</span><span class="page__taxonomy-item">#<!-- -->High-Resolution</span><span class="page__taxonomy-item">#<!-- -->Two-Stage Inference</span><span class="page__taxonomy-item">#<!-- -->Layout Analysis</span><span class="page__taxonomy-item">#<!-- -->Content Recognition</span><span class="page__taxonomy-item">#<!-- -->Data Engine</span><span class="page__taxonomy-item">#<!-- -->Computational Efficiency</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-29-Mind-the-Glitch_Visual_Correspondence_for_Detecting_Inconsistencies_in_Subject-Driven_Generation/">[논문리뷰] Mind-the-Glitch: Visual Correspondence for Detecting Inconsistencies in Subject-Driven Generation</a></h2><div class="archive__item-excerpt">Peter Wonka이 [arXiv]에 게시한 &#x27;Mind-the-Glitch: Visual Correspondence for Detecting Inconsistencies in Subject-Driven Generation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-29 13:47:46+0900">2025년 9월 29일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Subject-Driven Generation</span><span class="page__taxonomy-item">#<!-- -->Visual Inconsistency Detection</span><span class="page__taxonomy-item">#<!-- -->Feature Disentanglement</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->Semantic Correspondence</span><span class="page__taxonomy-item">#<!-- -->Evaluation Metric</span><span class="page__taxonomy-item">#<!-- -->Spatial Localization</span><span class="page__taxonomy-item">#<!-- -->Contrastive Learning</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-29-MesaTask_Towards_Task-Driven_Tabletop_Scene_Generation_via_3D_Spatial_Reasoning/">[논문리뷰] MesaTask: Towards Task-Driven Tabletop Scene Generation via 3D Spatial Reasoning</a></h2><div class="archive__item-excerpt">Weipeng Zhong이 [arXiv]에 게시한 &#x27;MesaTask: Towards Task-Driven Tabletop Scene Generation via 3D Spatial Reasoning&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-29 13:47:46+0900">2025년 9월 29일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->3D Scene Generation</span><span class="page__taxonomy-item">#<!-- -->Robotic Manipulation</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Spatial Reasoning</span><span class="page__taxonomy-item">#<!-- -->Dataset</span><span class="page__taxonomy-item">#<!-- -->Direct Preference Optimization</span><span class="page__taxonomy-item">#<!-- -->Tabletop Scene</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-29-LucidFlux_Caption-Free_Universal_Image_Restoration_via_a_Large-Scale_Diffusion_Transformer/">[논문리뷰] LucidFlux: Caption-Free Universal Image Restoration via a Large-Scale Diffusion Transformer</a></h2><div class="archive__item-excerpt">이 [arXiv]에 게시한 &#x27;LucidFlux: Caption-Free Universal Image Restoration via a Large-Scale Diffusion Transformer&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-29 13:47:46+0900">2025년 9월 29일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Universal Image Restoration</span><span class="page__taxonomy-item">#<!-- -->Diffusion Transformer</span><span class="page__taxonomy-item">#<!-- -->Caption-Free</span><span class="page__taxonomy-item">#<!-- -->Semantic Alignment</span><span class="page__taxonomy-item">#<!-- -->Image Quality Assessment</span><span class="page__taxonomy-item">#<!-- -->Data Curation</span><span class="page__taxonomy-item">#<!-- -->Real-World Degradations</span><span class="page__taxonomy-item">#<!-- -->Deep Learning</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-29-LongLive_Real-time_Interactive_Long_Video_Generation/">[논문리뷰] LongLive: Real-time Interactive Long Video Generation</a></h2><div class="archive__item-excerpt">이 [arXiv]에 게시한 &#x27;LongLive: Real-time Interactive Long Video Generation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-29 13:47:46+0900">2025년 9월 29일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Long Video Generation</span><span class="page__taxonomy-item">#<!-- -->Real-time</span><span class="page__taxonomy-item">#<!-- -->Interactive AI</span><span class="page__taxonomy-item">#<!-- -->Autoregressive Models</span><span class="page__taxonomy-item">#<!-- -->KV Cache</span><span class="page__taxonomy-item">#<!-- -->Streaming Tuning</span><span class="page__taxonomy-item">#<!-- -->Attention Sink</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-29-Learn_the_Ropes_Then_Trust_the_Wins_Self-imitation_with_Progressive_Exploration_for_Agentic_Reinforcement_Learning/">[논문리뷰] Learn the Ropes, Then Trust the Wins: Self-imitation with Progressive Exploration for Agentic Reinforcement Learning</a></h2><div class="archive__item-excerpt">Gang Li이 [arXiv]에 게시한 &#x27;Learn the Ropes, Then Trust the Wins: Self-imitation with Progressive Exploration for Agentic Reinforcement Learning&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-29 13:47:46+0900">2025년 9월 29일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->LLM Agents</span><span class="page__taxonomy-item">#<!-- -->Exploration-Exploitation</span><span class="page__taxonomy-item">#<!-- -->Self-Imitation Learning</span><span class="page__taxonomy-item">#<!-- -->Intrinsic Rewards</span><span class="page__taxonomy-item">#<!-- -->Curriculum Learning</span><span class="page__taxonomy-item">#<!-- -->Policy Entropy</span><span class="page__taxonomy-item">#<!-- -->Tool Use</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-29-Language_Models_Can_Learn_from_Verbal_Feedback_Without_Scalar_Rewards/">[논문리뷰] Language Models Can Learn from Verbal Feedback Without Scalar Rewards</a></h2><div class="archive__item-excerpt">이 [arXiv]에 게시한 &#x27;Language Models Can Learn from Verbal Feedback Without Scalar Rewards&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-29 13:47:46+0900">2025년 9월 29일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Verbal Feedback</span><span class="page__taxonomy-item">#<!-- -->Conditional Generation</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Feedback-Conditional Policy</span><span class="page__taxonomy-item">#<!-- -->Offline-Online Learning</span><span class="page__taxonomy-item">#<!-- -->Reward Hypothesis Bypass</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-29-Instruction-Following_Evaluation_in_Function_Calling_for_Large_Language_Models/">[논문리뷰] Instruction-Following Evaluation in Function Calling for Large Language Models</a></h2><div class="archive__item-excerpt">NikolaiSkripko이 [arXiv]에 게시한 &#x27;Instruction-Following Evaluation in Function Calling for Large Language Models&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-29 13:47:46+0900">2025년 9월 29일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Function Calling</span><span class="page__taxonomy-item">#<!-- -->LLMs</span><span class="page__taxonomy-item">#<!-- -->Instruction Following</span><span class="page__taxonomy-item">#<!-- -->Benchmarking</span><span class="page__taxonomy-item">#<!-- -->JSON Schema</span><span class="page__taxonomy-item">#<!-- -->AI Agents</span><span class="page__taxonomy-item">#<!-- -->Evaluation Metrics</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-29-HiGS_History-Guided_Sampling_for_Plug-and-Play_Enhancement_of_Diffusion_Models/">[논문리뷰] HiGS: History-Guided Sampling for Plug-and-Play Enhancement of Diffusion Models</a></h2><div class="archive__item-excerpt">Romann M. Weber이 [arXiv]에 게시한 &#x27;HiGS: History-Guided Sampling for Plug-and-Play Enhancement of Diffusion Models&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-29 13:47:46+0900">2025년 9월 29일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->Sampling</span><span class="page__taxonomy-item">#<!-- -->Generative AI</span><span class="page__taxonomy-item">#<!-- -->Image Generation</span><span class="page__taxonomy-item">#<!-- -->Plug-and-Play</span><span class="page__taxonomy-item">#<!-- -->Training-Free</span><span class="page__taxonomy-item">#<!-- -->Guidance</span><span class="page__taxonomy-item">#<!-- -->Momentum-Based Methods</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-29-FlashEdit_Decoupling_Speed_Structure_and_Semantics_for_Precise_Image_Editing/">[논문리뷰] FlashEdit: Decoupling Speed, Structure, and Semantics for Precise Image Editing</a></h2><div class="archive__item-excerpt">Linghe Kong이 [arXiv]에 게시한 &#x27;FlashEdit: Decoupling Speed, Structure, and Semantics for Precise Image Editing&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-29 13:47:46+0900">2025년 9월 29일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Text-Guided Image Editing</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->Real-Time Editing</span><span class="page__taxonomy-item">#<!-- -->One-Step Inversion</span><span class="page__taxonomy-item">#<!-- -->Attention Control</span><span class="page__taxonomy-item">#<!-- -->Background Preservation</span><span class="page__taxonomy-item">#<!-- -->Semantic Disentanglement</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-29-Fine-tuning_Done_Right_in_Model_Editing/">[논문리뷰] Fine-tuning Done Right in Model Editing</a></h2><div class="archive__item-excerpt">Du Su이 [arXiv]에 게시한 &#x27;Fine-tuning Done Right in Model Editing&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-29 13:47:46+0900">2025년 9월 29일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Model Editing</span><span class="page__taxonomy-item">#<!-- -->Fine-tuning</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Catastrophic Forgetting</span><span class="page__taxonomy-item">#<!-- -->Breadth-First Pipeline</span><span class="page__taxonomy-item">#<!-- -->Depth-First Pipeline</span><span class="page__taxonomy-item">#<!-- -->Localized Tuning</span><span class="page__taxonomy-item">#<!-- -->Lifelong Learning</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-29-Finding_3D_Positions_of_Distant_Objects_from_Noisy_Camera_Movement_and_Semantic_Segmentation_Sequences/">[논문리뷰] Finding 3D Positions of Distant Objects from Noisy Camera Movement and Semantic Segmentation Sequences</a></h2><div class="archive__item-excerpt">Eija Honkavaara이 [arXiv]에 게시한 &#x27;Finding 3D Positions of Distant Objects from Noisy Camera Movement and Semantic Segmentation Sequences&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-29 13:47:46+0900">2025년 9월 29일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->3D Object Localization</span><span class="page__taxonomy-item">#<!-- -->Particle Filter</span><span class="page__taxonomy-item">#<!-- -->Multi-target Tracking</span><span class="page__taxonomy-item">#<!-- -->Drone Surveillance</span><span class="page__taxonomy-item">#<!-- -->Wildfire Monitoring</span><span class="page__taxonomy-item">#<!-- -->Semantic Segmentation</span><span class="page__taxonomy-item">#<!-- -->Camera Pose Estimation</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-29-ERGO_Efficient_High-Resolution_Visual_Understanding_for_Vision-Language_Models/">[논문리뷰] ERGO: Efficient High-Resolution Visual Understanding for Vision-Language Models</a></h2><div class="archive__item-excerpt">Ki-Ung Song이 [arXiv]에 게시한 &#x27;ERGO: Efficient High-Resolution Visual Understanding for Vision-Language Models&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-29 13:47:46+0900">2025년 9월 29일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->High-Resolution Vision</span><span class="page__taxonomy-item">#<!-- -->Vision-Language Models</span><span class="page__taxonomy-item">#<!-- -->Efficient Reasoning</span><span class="page__taxonomy-item">#<!-- -->Coarse-to-Fine</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Visual Understanding</span><span class="page__taxonomy-item">#<!-- -->Attention Mechanism</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-29-EPO_Entropy-regularized_Policy_Optimization_for_LLM_Agents_Reinforcement_Learning/">[논문리뷰] EPO: Entropy-regularized Policy Optimization for LLM Agents Reinforcement Learning</a></h2><div class="archive__item-excerpt">Li Yu-Jhe이 [arXiv]에 게시한 &#x27;EPO: Entropy-regularized Policy Optimization for LLM Agents Reinforcement Learning&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-29 13:47:46+0900">2025년 9월 29일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLM Agents</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Entropy Regularization</span><span class="page__taxonomy-item">#<!-- -->Policy Optimization</span><span class="page__taxonomy-item">#<!-- -->Sparse Rewards</span><span class="page__taxonomy-item">#<!-- -->Multi-turn Environments</span><span class="page__taxonomy-item">#<!-- -->Exploration-Exploitation</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-29-D-Artemis_A_Deliberative_Cognitive_Framework_for_Mobile_GUI_Multi-Agents/">[논문리뷰] D-Artemis: A Deliberative Cognitive Framework for Mobile GUI Multi-Agents</a></h2><div class="archive__item-excerpt">Jinyuan Li이 [arXiv]에 게시한 &#x27;D-Artemis: A Deliberative Cognitive Framework for Mobile GUI Multi-Agents&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-29 13:47:46+0900">2025년 9월 29일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Mobile GUI Automation</span><span class="page__taxonomy-item">#<!-- -->Multi-Agent System</span><span class="page__taxonomy-item">#<!-- -->Cognitive Architecture</span><span class="page__taxonomy-item">#<!-- -->Pre-execution Alignment</span><span class="page__taxonomy-item">#<!-- -->Post-execution Reflection</span><span class="page__taxonomy-item">#<!-- -->Retrieval-Augmented Generation</span><span class="page__taxonomy-item">#<!-- -->Multimodal LLM</span><span class="page__taxonomy-item">#<!-- -->Deliberative AI</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-29-CHURRO_Making_History_Readable_with_an_Open-Weight_Large_Vision-Language_Model_for_High-Accuracy_Low-Cost_Historical_Text_Recognition/">[논문리뷰] CHURRO: Making History Readable with an Open-Weight Large Vision-Language Model for High-Accuracy, Low-Cost Historical Text Recognition</a></h2><div class="archive__item-excerpt">이 [arXiv]에 게시한 &#x27;CHURRO: Making History Readable with an Open-Weight Large Vision-Language Model for High-Accuracy, Low-Cost Historical Text Recognition&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-29 13:47:46+0900">2025년 9월 29일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Historical Text Recognition</span><span class="page__taxonomy-item">#<!-- -->Vision-Language Model</span><span class="page__taxonomy-item">#<!-- -->Open-Weight Model</span><span class="page__taxonomy-item">#<!-- -->OCR</span><span class="page__taxonomy-item">#<!-- -->Cultural Heritage</span><span class="page__taxonomy-item">#<!-- -->Low-Cost AI</span><span class="page__taxonomy-item">#<!-- -->Dataset Curation</span><span class="page__taxonomy-item">#<!-- -->Fine-tuning</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-29-Chasing_the_Tail_Effective_Rubric-based_Reward_Modeling_for_Large_Language_Model_Post-Training/">[논문리뷰] Chasing the Tail: Effective Rubric-based Reward Modeling for Large Language Model Post-Training</a></h2><div class="archive__item-excerpt">이 [arXiv]에 게시한 &#x27;Chasing the Tail: Effective Rubric-based Reward Modeling for Large Language Model Post-Training&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-29 13:47:46+0900">2025년 9월 29일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLM</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Fine-tuning</span><span class="page__taxonomy-item">#<!-- -->Reward Modeling</span><span class="page__taxonomy-item">#<!-- -->Reward Over-optimization</span><span class="page__taxonomy-item">#<!-- -->Rubric-based Rewards</span><span class="page__taxonomy-item">#<!-- -->High-reward Tail</span><span class="page__taxonomy-item">#<!-- -->Off-policy Data</span><span class="page__taxonomy-item">#<!-- -->LLM Alignment</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-29-CapRL_Stimulating_Dense_Image_Caption_Capabilities_via_Reinforcement_Learning/">[논문리뷰] CapRL: Stimulating Dense Image Caption Capabilities via Reinforcement Learning</a></h2><div class="archive__item-excerpt">이 [arXiv]에 게시한 &#x27;CapRL: Stimulating Dense Image Caption Capabilities via Reinforcement Learning&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-29 13:47:46+0900">2025년 9월 29일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Image Captioning</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Verifiable Rewards</span><span class="page__taxonomy-item">#<!-- -->LVLMs</span><span class="page__taxonomy-item">#<!-- -->VQA</span><span class="page__taxonomy-item">#<!-- -->Data Curation</span><span class="page__taxonomy-item">#<!-- -->Caption Quality</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-26-When_Judgment_Becomes_Noise_How_Design_Failures_in_LLM_Judge_Benchmarks_Silently_Undermine_Validity/">[논문리뷰] When Judgment Becomes Noise: How Design Failures in LLM Judge Benchmarks Silently Undermine Validity</a></h2><div class="archive__item-excerpt">John P Dickerson이 [arXiv]에 게시한 &#x27;When Judgment Becomes Noise: How Design Failures in LLM Judge Benchmarks Silently Undermine Validity&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-26 13:35:32+0900">2025년 9월 26일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLM Judge</span><span class="page__taxonomy-item">#<!-- -->Benchmark Evaluation</span><span class="page__taxonomy-item">#<!-- -->Validity</span><span class="page__taxonomy-item">#<!-- -->Reliability</span><span class="page__taxonomy-item">#<!-- -->Psychometrics</span><span class="page__taxonomy-item">#<!-- -->Factor Analysis</span><span class="page__taxonomy-item">#<!-- -->Schema Adherence</span><span class="page__taxonomy-item">#<!-- -->ELO Ranking</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-26-VCRL_Variance-based_Curriculum_Reinforcement_Learning_for_Large_Language_Models/">[논문리뷰] VCRL: Variance-based Curriculum Reinforcement Learning for Large Language Models</a></h2><div class="archive__item-excerpt">Yuewei Zhang이 [arXiv]에 게시한 &#x27;VCRL: Variance-based Curriculum Reinforcement Learning for Large Language Models&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-26 13:35:32+0900">2025년 9월 26일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Curriculum Learning</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Mathematical Reasoning</span><span class="page__taxonomy-item">#<!-- -->Variance-based Sampling</span><span class="page__taxonomy-item">#<!-- -->Replay Learning</span><span class="page__taxonomy-item">#<!-- -->Policy Optimization</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-26-V-GameGym_Visual_Game_Generation_for_Code_Large_Language_Models/">[논문리뷰] V-GameGym: Visual Game Generation for Code Large Language Models</a></h2><div class="archive__item-excerpt">Shawn Guo이 [arXiv]에 게시한 &#x27;V-GameGym: Visual Game Generation for Code Large Language Models&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-26 13:35:32+0900">2025년 9월 26일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Code Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Visual Game Generation</span><span class="page__taxonomy-item">#<!-- -->Benchmark</span><span class="page__taxonomy-item">#<!-- -->Pygame</span><span class="page__taxonomy-item">#<!-- -->Multimodal Evaluation</span><span class="page__taxonomy-item">#<!-- -->Software Engineering</span><span class="page__taxonomy-item">#<!-- -->AI-assisted Game Development</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-26-Understanding_the_Thinking_Process_of_Reasoning_Models_A_Perspective_from_Schoenfelds_Episode_Theory/">[논문리뷰] Understanding the Thinking Process of Reasoning Models: A Perspective from Schoenfeld&#x27;s Episode Theory</a></h2><div class="archive__item-excerpt">Yanbin Fu이 [arXiv]에 게시한 &#x27;Understanding the Thinking Process of Reasoning Models: A Perspective from Schoenfeld&#x27;s Episode Theory&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-26 13:35:32+0900">2025년 9월 26일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Large Reasoning Models</span><span class="page__taxonomy-item">#<!-- -->Cognitive Science</span><span class="page__taxonomy-item">#<!-- -->Schoenfeld&#x27;s Episode Theory</span><span class="page__taxonomy-item">#<!-- -->Math Problem Solving</span><span class="page__taxonomy-item">#<!-- -->Chain-of-Thought</span><span class="page__taxonomy-item">#<!-- -->Behavioral Analysis</span><span class="page__taxonomy-item">#<!-- -->Dataset Annotation</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-26-TrustJudge_Inconsistencies_of_LLM-as-a-Judge_and_How_to_Alleviate_Them/">[논문리뷰] TrustJudge: Inconsistencies of LLM-as-a-Judge and How to Alleviate Them</a></h2><div class="archive__item-excerpt">Zhuohao Yu이 [arXiv]에 게시한 &#x27;TrustJudge: Inconsistencies of LLM-as-a-Judge and How to Alleviate Them&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-26 13:35:32+0900">2025년 9월 26일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLM-as-a-Judge</span><span class="page__taxonomy-item">#<!-- -->Evaluation Frameworks</span><span class="page__taxonomy-item">#<!-- -->Inconsistency Reduction</span><span class="page__taxonomy-item">#<!-- -->Probabilistic Scoring</span><span class="page__taxonomy-item">#<!-- -->Transitivity</span><span class="page__taxonomy-item">#<!-- -->Information Loss</span><span class="page__taxonomy-item">#<!-- -->Perplexity</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-26-Tree_Search_for_LLM_Agent_Reinforcement_Learning/">[논문리뷰] Tree Search for LLM Agent Reinforcement Learning</a></h2><div class="archive__item-excerpt">Xiangxiang Chu이 [arXiv]에 게시한 &#x27;Tree Search for LLM Agent Reinforcement Learning&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-26 13:35:32+0900">2025년 9월 26일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLM Agents</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Tree Search</span><span class="page__taxonomy-item">#<!-- -->Policy Optimization</span><span class="page__taxonomy-item">#<!-- -->Preference Learning</span><span class="page__taxonomy-item">#<!-- -->Sparse Rewards</span><span class="page__taxonomy-item">#<!-- -->Multi-turn Tasks</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-26-Thinking_While_Listening_Simple_Test_Time_Scaling_For_Audio_Classification/">[논문리뷰] Thinking While Listening: Simple Test Time Scaling For Audio Classification</a></h2><div class="archive__item-excerpt">Mert Pilanci이 [arXiv]에 게시한 &#x27;Thinking While Listening: Simple Test Time Scaling For Audio Classification&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-26 13:35:32+0900">2025년 9월 26일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Audio Classification</span><span class="page__taxonomy-item">#<!-- -->Test-Time Scaling</span><span class="page__taxonomy-item">#<!-- -->Reasoning Traces</span><span class="page__taxonomy-item">#<!-- -->Large Language Models (LLMs)</span><span class="page__taxonomy-item">#<!-- -->Transformer Architectures</span><span class="page__taxonomy-item">#<!-- -->Zero-shot Reasoning</span><span class="page__taxonomy-item">#<!-- -->Computational Efficiency</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-26-Thinking_Augmented_Pre-training/">[논문리뷰] Thinking Augmented Pre-training</a></h2><div class="archive__item-excerpt">Furu Wei이 [arXiv]에 게시한 &#x27;Thinking Augmented Pre-training&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-26 13:35:32+0900">2025년 9월 26일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Large Language Models (LLMs)</span><span class="page__taxonomy-item">#<!-- -->Pre-training</span><span class="page__taxonomy-item">#<!-- -->Data Augmentation</span><span class="page__taxonomy-item">#<!-- -->Reasoning</span><span class="page__taxonomy-item">#<!-- -->Data Efficiency</span><span class="page__taxonomy-item">#<!-- -->Thinking Trajectories</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-26-The_Unanticipated_Asymmetry_Between_Perceptual_Optimization_and_Assessment/">[논문리뷰] The Unanticipated Asymmetry Between Perceptual Optimization and Assessment</a></h2><div class="archive__item-excerpt">Du Chen이 [arXiv]에 게시한 &#x27;The Unanticipated Asymmetry Between Perceptual Optimization and Assessment&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-26 13:35:32+0900">2025년 9월 26일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Perceptual Optimization</span><span class="page__taxonomy-item">#<!-- -->Image Quality Assessment (IQA)</span><span class="page__taxonomy-item">#<!-- -->Adversarial Training</span><span class="page__taxonomy-item">#<!-- -->Discriminators</span><span class="page__taxonomy-item">#<!-- -->Super-Resolution</span><span class="page__taxonomy-item">#<!-- -->Fidelity Metrics</span><span class="page__taxonomy-item">#<!-- -->Deep Learning</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-26-StyleBench_Evaluating_thinking_styles_in_Large_Language_Models/">[논문리뷰] StyleBench: Evaluating thinking styles in Large Language Models</a></h2><div class="archive__item-excerpt">Javad Lavaei이 [arXiv]에 게시한 &#x27;StyleBench: Evaluating thinking styles in Large Language Models&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-26 13:35:32+0900">2025년 9월 26일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Reasoning Strategies</span><span class="page__taxonomy-item">#<!-- -->Prompt Engineering</span><span class="page__taxonomy-item">#<!-- -->LLM Evaluation</span><span class="page__taxonomy-item">#<!-- -->Benchmark</span><span class="page__taxonomy-item">#<!-- -->Thinking Styles</span><span class="page__taxonomy-item">#<!-- -->Scaling Laws</span><span class="page__taxonomy-item">#<!-- -->Meta-Reasoning</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-26-Seedream_4.0_Toward_Next-generation_Multimodal_Image_Generation">[논문리뷰] Seedream 4.0: Toward Next-generation Multimodal Image Generation</a></h2><div class="archive__item-excerpt">Yunpeng Chen이 [arXiv]에 게시한 &#x27;Seedream 4.0: Toward Next-generation Multimodal Image Generation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-26 13:35:32+0900">2025년 9월 26일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Multimodal Image Generation</span><span class="page__taxonomy-item">#<!-- -->Diffusion Transformer</span><span class="page__taxonomy-item">#<!-- -->VAE</span><span class="page__taxonomy-item">#<!-- -->Image Editing</span><span class="page__taxonomy-item">#<!-- -->Text-to-Image</span><span class="page__taxonomy-item">#<!-- -->Model Acceleration</span><span class="page__taxonomy-item">#<!-- -->Human Evaluation</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-26-SD3.5-Flash_Distribution-Guided_Distillation_of_Generative_Flows">[논문리뷰] SD3.5-Flash: Distribution-Guided Distillation of Generative Flows</a></h2><div class="archive__item-excerpt">Yi-Zhe Song이 [arXiv]에 게시한 &#x27;SD3.5-Flash: Distribution-Guided Distillation of Generative Flows&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-26 13:35:32+0900">2025년 9월 26일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Generative AI</span><span class="page__taxonomy-item">#<!-- -->Image Generation</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->Rectified Flow</span><span class="page__taxonomy-item">#<!-- -->Model Distillation</span><span class="page__taxonomy-item">#<!-- -->Few-Step Generation</span><span class="page__taxonomy-item">#<!-- -->Computational Efficiency</span><span class="page__taxonomy-item">#<!-- -->Prompt Alignment</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-26-SciReasoner_Laying_the_Scientific_Reasoning_Ground_Across_Disciplines/">[논문리뷰] SciReasoner: Laying the Scientific Reasoning Ground Across Disciplines</a></h2><div class="archive__item-excerpt">Jiabei Xiao이 [arXiv]에 게시한 &#x27;SciReasoner: Laying the Scientific Reasoning Ground Across Disciplines&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-26 13:35:32+0900">2025년 9월 26일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Scientific Reasoning</span><span class="page__taxonomy-item">#<!-- -->Foundation Models</span><span class="page__taxonomy-item">#<!-- -->Multi-modal Learning</span><span class="page__taxonomy-item">#<!-- -->Cross-domain Generalization</span><span class="page__taxonomy-item">#<!-- -->Chain-of-Thought</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Scientific Discovery</span><span class="page__taxonomy-item">#<!-- -->Molecular Design</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-26-SceneWeaver_All-in-One_3D_Scene_Synthesis_with_an_Extensible_and_Self-Reflective_Agent/">[논문리뷰] SceneWeaver: All-in-One 3D Scene Synthesis with an Extensible and Self-Reflective Agent</a></h2><div class="archive__item-excerpt">Siyuan Huang이 [arXiv]에 게시한 &#x27;SceneWeaver: All-in-One 3D Scene Synthesis with an Extensible and Self-Reflective Agent&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-26 13:35:32+0900">2025년 9월 26일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->3D Scene Synthesis</span><span class="page__taxonomy-item">#<!-- -->Agentic Framework</span><span class="page__taxonomy-item">#<!-- -->LLMs</span><span class="page__taxonomy-item">#<!-- -->Self-Reflection</span><span class="page__taxonomy-item">#<!-- -->Tool-Use</span><span class="page__taxonomy-item">#<!-- -->Physical Plausibility</span><span class="page__taxonomy-item">#<!-- -->Iterative Refinement</span><span class="page__taxonomy-item">#<!-- -->Embodied AI</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-26-ScaleDiff_Scaling_Difficult_Problems_for_Advanced_Mathematical_Reasoning/">[논문리뷰] ScaleDiff: Scaling Difficult Problems for Advanced Mathematical Reasoning</a></h2><div class="archive__item-excerpt">Yu Li이 [arXiv]에 게시한 &#x27;ScaleDiff: Scaling Difficult Problems for Advanced Mathematical Reasoning&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-26 13:35:32+0900">2025년 9월 26일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Mathematical Reasoning</span><span class="page__taxonomy-item">#<!-- -->Large Reasoning Models (LRMs)</span><span class="page__taxonomy-item">#<!-- -->Difficulty Scaling</span><span class="page__taxonomy-item">#<!-- -->Data Augmentation</span><span class="page__taxonomy-item">#<!-- -->Supervised Fine-Tuning (SFT)</span><span class="page__taxonomy-item">#<!-- -->Problem Generation</span><span class="page__taxonomy-item">#<!-- -->Solution Distillation</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-26-Residual_Off-Policy_RL_for_Finetuning_Behavior_Cloning_Policies/">[논문리뷰] Residual Off-Policy RL for Finetuning Behavior Cloning Policies</a></h2><div class="archive__item-excerpt">Pieter Abbeel이 [arXiv]에 게시한 &#x27;Residual Off-Policy RL for Finetuning Behavior Cloning Policies&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-26 13:35:32+0900">2025년 9월 26일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning (RL)</span><span class="page__taxonomy-item">#<!-- -->Behavior Cloning (BC)</span><span class="page__taxonomy-item">#<!-- -->Residual Learning</span><span class="page__taxonomy-item">#<!-- -->Off-Policy RL</span><span class="page__taxonomy-item">#<!-- -->Robot Manipulation</span><span class="page__taxonomy-item">#<!-- -->Real-World Robotics</span><span class="page__taxonomy-item">#<!-- -->High-DoF Systems</span><span class="page__taxonomy-item">#<!-- -->Sample Efficiency</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-26-Recon-Act_A_Self-Evolving_Multi-Agent_Browser-Use_System_via_Web_Reconnaissance_Tool_Generation_and_Task_Execution/">[논문리뷰] Recon-Act: A Self-Evolving Multi-Agent Browser-Use System via Web Reconnaissance, Tool Generation, and Task Execution</a></h2><div class="archive__item-excerpt">Jinjie Gu이 [arXiv]에 게시한 &#x27;Recon-Act: A Self-Evolving Multi-Agent Browser-Use System via Web Reconnaissance, Tool Generation, and Task Execution&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-26 13:35:32+0900">2025년 9월 26일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Multi-Agent System</span><span class="page__taxonomy-item">#<!-- -->Browser Automation</span><span class="page__taxonomy-item">#<!-- -->Web Reconnaissance</span><span class="page__taxonomy-item">#<!-- -->Tool Generation</span><span class="page__taxonomy-item">#<!-- -->Task Execution</span><span class="page__taxonomy-item">#<!-- -->Self-Evolving AI</span><span class="page__taxonomy-item">#<!-- -->LLM/VLM</span><span class="page__taxonomy-item">#<!-- -->VisualWebArena</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-26-Quantized_Visual_Geometry_Grounded_Transformer/">[논문리뷰] Quantized Visual Geometry Grounded Transformer</a></h2><div class="archive__item-excerpt">Yuqi Li이 [arXiv]에 게시한 &#x27;Quantized Visual Geometry Grounded Transformer&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-26 13:35:32+0900">2025년 9월 26일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Quantization</span><span class="page__taxonomy-item">#<!-- -->Post-Training Quantization</span><span class="page__taxonomy-item">#<!-- -->3D Reconstruction</span><span class="page__taxonomy-item">#<!-- -->Visual Transformer</span><span class="page__taxonomy-item">#<!-- -->Model Compression</span><span class="page__taxonomy-item">#<!-- -->Efficient Inference</span><span class="page__taxonomy-item">#<!-- -->Hadamard Rotation</span><span class="page__taxonomy-item">#<!-- -->Calibration Sampling</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-26-MOSS-ChatV_Reinforcement_Learning_with_Process_Reasoning_Reward_for_Video_Temporal_Reasoning/">[논문리뷰] MOSS-ChatV: Reinforcement Learning with Process Reasoning Reward for Video Temporal Reasoning</a></h2><div class="archive__item-excerpt">Junyan Zhang이 [arXiv]에 게시한 &#x27;MOSS-ChatV: Reinforcement Learning with Process Reasoning Reward for Video Temporal Reasoning&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-26 13:35:32+0900">2025년 9월 26일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Video Temporal Reasoning</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Process Supervision</span><span class="page__taxonomy-item">#<!-- -->Dynamic Time Warping</span><span class="page__taxonomy-item">#<!-- -->Multimodal Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Video State Prediction</span><span class="page__taxonomy-item">#<!-- -->Reward Hacking</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-26-MMR1_Enhancing_Multimodal_Reasoning_with_Variance-Aware_Sampling_and_Open_Resources/">[논문리뷰] MMR1: Enhancing Multimodal Reasoning with Variance-Aware Sampling and Open Resources</a></h2><div class="archive__item-excerpt">Jing Wang이 [arXiv]에 게시한 &#x27;MMR1: Enhancing Multimodal Reasoning with Variance-Aware Sampling and Open Resources&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-26 13:35:32+0900">2025년 9월 26일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Multimodal Reasoning</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Variance-Aware Sampling</span><span class="page__taxonomy-item">#<!-- -->Gradient Vanishing</span><span class="page__taxonomy-item">#<!-- -->Data Curation</span><span class="page__taxonomy-item">#<!-- -->Chain-of-Thought</span><span class="page__taxonomy-item">#<!-- -->GRPO</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-26-MI-Fuse_Label_Fusion_for_Unsupervised_Domain_Adaptation_with_Closed-Source_Large-Audio_Language_Model/">[논문리뷰] MI-Fuse: Label Fusion for Unsupervised Domain Adaptation with Closed-Source Large-Audio Language Model</a></h2><div class="archive__item-excerpt">Hung-yi Lee이 [arXiv]에 게시한 &#x27;MI-Fuse: Label Fusion for Unsupervised Domain Adaptation with Closed-Source Large-Audio Language Model&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-26 13:35:32+0900">2025년 9월 26일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Speech Emotion Recognition</span><span class="page__taxonomy-item">#<!-- -->Source-Free Unsupervised Domain Adaptation</span><span class="page__taxonomy-item">#<!-- -->Large Audio-Language Models</span><span class="page__taxonomy-item">#<!-- -->Label Fusion</span><span class="page__taxonomy-item">#<!-- -->Mutual Information</span><span class="page__taxonomy-item">#<!-- -->API-Only Models</span><span class="page__taxonomy-item">#<!-- -->Domain Mismatch</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-26-Interactive_Recommendation_Agent_with_Active_User_Commands/">[논문리뷰] Interactive Recommendation Agent with Active User Commands</a></h2><div class="archive__item-excerpt">Xueyang Feng이 [arXiv]에 게시한 &#x27;Interactive Recommendation Agent with Active User Commands&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-26 13:35:32+0900">2025년 9월 26일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Interactive Recommendation</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Multi-Agent System</span><span class="page__taxonomy-item">#<!-- -->Natural Language Processing</span><span class="page__taxonomy-item">#<!-- -->Knowledge Distillation</span><span class="page__taxonomy-item">#<!-- -->User Control</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-26-Hunyuan3D-Omni_A_Unified_Framework_for_Controllable_Generation_of_3D_Assets/">[논문리뷰] Hunyuan3D-Omni: A Unified Framework for Controllable Generation of 3D Assets</a></h2><div class="archive__item-excerpt">Bowen Zhang이 [arXiv]에 게시한 &#x27;Hunyuan3D-Omni: A Unified Framework for Controllable Generation of 3D Assets&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-26 13:35:32+0900">2025년 9월 26일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->3D Generation</span><span class="page__taxonomy-item">#<!-- -->Controllable Generation</span><span class="page__taxonomy-item">#<!-- -->Multi-modal Conditioning</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->Point Clouds</span><span class="page__taxonomy-item">#<!-- -->Voxels</span><span class="page__taxonomy-item">#<!-- -->Bounding Boxes</span><span class="page__taxonomy-item">#<!-- -->Skeletons</span><span class="page__taxonomy-item">#<!-- -->Hunyuan3D</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-26-Does_FLUX_Already_Know_How_to_Perform_Physically_Plausible_Image_Composition/">[논문리뷰] Does FLUX Already Know How to Perform Physically Plausible Image Composition?</a></h2><div class="archive__item-excerpt">Chen Zhao이 [arXiv]에 게시한 &#x27;Does FLUX Already Know How to Perform Physically Plausible Image Composition?&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-26 13:35:32+0900">2025년 9월 26일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Image Composition</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->Training-Free</span><span class="page__taxonomy-item">#<!-- -->Physically Plausible</span><span class="page__taxonomy-item">#<!-- -->FLUX</span><span class="page__taxonomy-item">#<!-- -->Adapter</span><span class="page__taxonomy-item">#<!-- -->Guidance</span><span class="page__taxonomy-item">#<!-- -->Benchmark</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-26-Discrete_Diffusion_for_Reflective_Vision-Language-Action_Models_in_Autonomous_Driving/">[논문리뷰] Discrete Diffusion for Reflective Vision-Language-Action Models in Autonomous Driving</a></h2><div class="archive__item-excerpt">Hang Zhao이 [arXiv]에 게시한 &#x27;Discrete Diffusion for Reflective Vision-Language-Action Models in Autonomous Driving&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-26 13:35:32+0900">2025년 9월 26일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Autonomous Driving</span><span class="page__taxonomy-item">#<!-- -->Vision-Language-Action Models</span><span class="page__taxonomy-item">#<!-- -->Discrete Diffusion</span><span class="page__taxonomy-item">#<!-- -->Reflection Mechanism</span><span class="page__taxonomy-item">#<!-- -->Trajectory Generation</span><span class="page__taxonomy-item">#<!-- -->Safety Constraints</span><span class="page__taxonomy-item">#<!-- -->Imitation Learning</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-26-CHARM_Control-point-based_3D_Anime_Hairstyle_Auto-Regressive_Modeling/">[논문리뷰] CHARM: Control-point-based 3D Anime Hairstyle Auto-Regressive Modeling</a></h2><div class="archive__item-excerpt">Yushi Bai이 [arXiv]에 게시한 &#x27;CHARM: Control-point-based 3D Anime Hairstyle Auto-Regressive Modeling&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-26 13:35:32+0900">2025년 9월 26일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->3D Anime Hairstyle</span><span class="page__taxonomy-item">#<!-- -->Autoregressive Modeling</span><span class="page__taxonomy-item">#<!-- -->Control Points</span><span class="page__taxonomy-item">#<!-- -->Parametric Representation</span><span class="page__taxonomy-item">#<!-- -->Transformer</span><span class="page__taxonomy-item">#<!-- -->Generative AI</span><span class="page__taxonomy-item">#<!-- -->Dataset (AnimeHair)</span><span class="page__taxonomy-item">#<!-- -->Computer Graphics</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-26-CE-GPPO_Controlling_Entropy_via_Gradient-Preserving_Clipping_Policy_Optimization_in_Reinforcement_Learning/">[논문리뷰] CE-GPPO: Controlling Entropy via Gradient-Preserving Clipping Policy Optimization in Reinforcement Learning</a></h2><div class="archive__item-excerpt">Wenping Hu이 [arXiv]에 게시한 &#x27;CE-GPPO: Controlling Entropy via Gradient-Preserving Clipping Policy Optimization in Reinforcement Learning&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-26 13:35:32+0900">2025년 9월 26일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Policy Optimization</span><span class="page__taxonomy-item">#<!-- -->PPO</span><span class="page__taxonomy-item">#<!-- -->Entropy Control</span><span class="page__taxonomy-item">#<!-- -->Gradient Clipping</span><span class="page__taxonomy-item">#<!-- -->Exploration-Exploitation</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-26-Blueprints_of_Trust_AI_System_Cards_for_End_to_End_Transparency_and_Governance/">[논문리뷰] Blueprints of Trust: AI System Cards for End to End Transparency and Governance</a></h2><div class="archive__item-excerpt">Roman Zhukov이 [arXiv]에 게시한 &#x27;Blueprints of Trust: AI System Cards for End to End Transparency and Governance&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-26 13:35:32+0900">2025년 9월 26일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->AI Governance</span><span class="page__taxonomy-item">#<!-- -->Transparency</span><span class="page__taxonomy-item">#<!-- -->AI System Card</span><span class="page__taxonomy-item">#<!-- -->Hazard-Aware System Card</span><span class="page__taxonomy-item">#<!-- -->Data Provenance</span><span class="page__taxonomy-item">#<!-- -->AI Safety</span><span class="page__taxonomy-item">#<!-- -->AI Risk Management</span><span class="page__taxonomy-item">#<!-- -->ISO/IEC 42001</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-26-BESPOKE_Benchmark_for_Search-Augmented_Large_Language_Model_Personalization_via_Diagnostic_Feedback/">[논문리뷰] BESPOKE: Benchmark for Search-Augmented Large Language Model Personalization via Diagnostic Feedback</a></h2><div class="archive__item-excerpt">Dongha Lee이 [arXiv]에 게시한 &#x27;BESPOKE: Benchmark for Search-Augmented Large Language Model Personalization via Diagnostic Feedback&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-26 13:35:32+0900">2025년 9월 26일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Search-Augmented LLMs</span><span class="page__taxonomy-item">#<!-- -->Personalization</span><span class="page__taxonomy-item">#<!-- -->Benchmark</span><span class="page__taxonomy-item">#<!-- -->Diagnostic Feedback</span><span class="page__taxonomy-item">#<!-- -->User History</span><span class="page__taxonomy-item">#<!-- -->Evaluation Framework</span><span class="page__taxonomy-item">#<!-- -->RAG</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-26-Behind_RoPE_How_Does_Causal_Mask_Encode_Positional_Information/">[논문리뷰] Behind RoPE: How Does Causal Mask Encode Positional Information?</a></h2><div class="archive__item-excerpt">Yeyun Gong이 [arXiv]에 게시한 &#x27;Behind RoPE: How Does Causal Mask Encode Positional Information?&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-26 13:35:32+0900">2025년 9월 26일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Transformer Decoder</span><span class="page__taxonomy-item">#<!-- -->Causal Mask</span><span class="page__taxonomy-item">#<!-- -->Positional Encoding</span><span class="page__taxonomy-item">#<!-- -->RoPE</span><span class="page__taxonomy-item">#<!-- -->Attention Mechanism</span><span class="page__taxonomy-item">#<!-- -->Length Generalization</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-26-AutoIntent_AutoML_for_Text_Classification/">[논문리뷰] AutoIntent: AutoML for Text Classification</a></h2><div class="archive__item-excerpt">Denis Kuznetsov이 [arXiv]에 게시한 &#x27;AutoIntent: AutoML for Text Classification&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-26 13:35:32+0900">2025년 9월 26일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->AutoML</span><span class="page__taxonomy-item">#<!-- -->Text Classification</span><span class="page__taxonomy-item">#<!-- -->Intent Classification</span><span class="page__taxonomy-item">#<!-- -->Transformer Embeddings</span><span class="page__taxonomy-item">#<!-- -->Out-of-Scope Detection</span><span class="page__taxonomy-item">#<!-- -->Multi-label Classification</span><span class="page__taxonomy-item">#<!-- -->Few-shot Learning</span><span class="page__taxonomy-item">#<!-- -->Sklearn-like Interface</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-25-Video_models_are_zero-shot_learners_and_reasoners/">[논문리뷰] Video models are zero-shot learners and reasoners</a></h2><div class="archive__item-excerpt">rgeirhos이 [arXiv]에 게시한 &#x27;Video models are zero-shot learners and reasoners&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-25 13:08:16+0900">2025년 9월 25일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Video Models</span><span class="page__taxonomy-item">#<!-- -->Zero-shot Learning</span><span class="page__taxonomy-item">#<!-- -->Visual Reasoning</span><span class="page__taxonomy-item">#<!-- -->Foundation Models</span><span class="page__taxonomy-item">#<!-- -->Generative AI</span><span class="page__taxonomy-item">#<!-- -->Perception</span><span class="page__taxonomy-item">#<!-- -->Manipulation</span><span class="page__taxonomy-item">#<!-- -->Modeling</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-25-SIM-CoT_Supervised_Implicit_Chain-of-Thought/">[논문리뷰] SIM-CoT: Supervised Implicit Chain-of-Thought</a></h2><div class="archive__item-excerpt">Yuhang Cao이 [arXiv]에 게시한 &#x27;SIM-CoT: Supervised Implicit Chain-of-Thought&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-25 13:08:16+0900">2025년 9월 25일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Implicit Reasoning</span><span class="page__taxonomy-item">#<!-- -->Chain-of-Thought</span><span class="page__taxonomy-item">#<!-- -->LLM</span><span class="page__taxonomy-item">#<!-- -->Latent Space</span><span class="page__taxonomy-item">#<!-- -->Supervised Learning</span><span class="page__taxonomy-item">#<!-- -->Model Stability</span><span class="page__taxonomy-item">#<!-- -->Interpretability</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-25-PhysCtrl_Generative_Physics_for_Controllable_and_Physics-Grounded_Video_Generation/">[논문리뷰] PhysCtrl: Generative Physics for Controllable and Physics-Grounded Video Generation</a></h2><div class="archive__item-excerpt">Yiming Huang이 [arXiv]에 게시한 &#x27;PhysCtrl: Generative Physics for Controllable and Physics-Grounded Video Generation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-25 13:08:16+0900">2025년 9월 25일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Video Generation</span><span class="page__taxonomy-item">#<!-- -->Physics-Grounded</span><span class="page__taxonomy-item">#<!-- -->Controllable Generation</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->Point Cloud Trajectories</span><span class="page__taxonomy-item">#<!-- -->Material Simulation</span><span class="page__taxonomy-item">#<!-- -->Generative Physics</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-25-On_the_Use_of_Agentic_Coding_An_Empirical_Study_of_Pull_Requests_on_GitHub/">[논문리뷰] On the Use of Agentic Coding: An Empirical Study of Pull Requests on GitHub</a></h2><div class="archive__item-excerpt">Hajimu Iida이 [arXiv]에 게시한 &#x27;On the Use of Agentic Coding: An Empirical Study of Pull Requests on GitHub&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-25 13:08:16+0900">2025년 9월 25일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Agentic Coding</span><span class="page__taxonomy-item">#<!-- -->AI Agents</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->GitHub Pull Requests</span><span class="page__taxonomy-item">#<!-- -->Software Engineering</span><span class="page__taxonomy-item">#<!-- -->Empirical Study</span><span class="page__taxonomy-item">#<!-- -->Code Generation</span><span class="page__taxonomy-item">#<!-- -->Software Development</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-25-Logics-Parsing_Technical_Report/">[논문리뷰] Logics-Parsing Technical Report</a></h2><div class="archive__item-excerpt">Fan Yang이 [arXiv]에 게시한 &#x27;Logics-Parsing Technical Report&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-25 13:08:16+0900">2025년 9월 25일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Document Parsing</span><span class="page__taxonomy-item">#<!-- -->Large Vision-Language Models (LVLM)</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning (RL)</span><span class="page__taxonomy-item">#<!-- -->Layout Analysis</span><span class="page__taxonomy-item">#<!-- -->Reading Order</span><span class="page__taxonomy-item">#<!-- -->Supervised Fine-Tuning (SFT)</span><span class="page__taxonomy-item">#<!-- -->HTML Annotation</span><span class="page__taxonomy-item">#<!-- -->Benchmarking</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-25-LLMs4All_A_Review_on_Large_Language_Models_for_Research_and_Applications_in_Academic_Disciplines/">[논문리뷰] LLMs4All: A Review on Large Language Models for Research and Applications in Academic Disciplines</a></h2><div class="archive__item-excerpt">Yanfang이 [arXiv]에 게시한 &#x27;LLMs4All: A Review on Large Language Models for Research and Applications in Academic Disciplines&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-25 13:08:16+0900">2025년 9월 25일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Generative AI</span><span class="page__taxonomy-item">#<!-- -->Academic Disciplines</span><span class="page__taxonomy-item">#<!-- -->LLM Applications</span><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Cross-disciplinary Research</span><span class="page__taxonomy-item">#<!-- -->Benchmarks</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-25-Lavida-O_Elastic_Large_Masked_Diffusion_Models_for_Unified_Multimodal_Understanding_and_Generation/">[논문리뷰] Lavida-O: Elastic Large Masked Diffusion Models for Unified Multimodal Understanding and Generation</a></h2><div class="archive__item-excerpt">Zhe Lin이 [arXiv]에 게시한 &#x27;Lavida-O: Elastic Large Masked Diffusion Models for Unified Multimodal Understanding and Generation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-25 13:08:16+0900">2025년 9월 25일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Multimodal AI</span><span class="page__taxonomy-item">#<!-- -->Masked Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->Image Understanding</span><span class="page__taxonomy-item">#<!-- -->Image Generation</span><span class="page__taxonomy-item">#<!-- -->Image Editing</span><span class="page__taxonomy-item">#<!-- -->Object Grounding</span><span class="page__taxonomy-item">#<!-- -->ElasticMoT</span><span class="page__taxonomy-item">#<!-- -->Self-reflection</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-25-EmbeddingGemma_Powerful_and_Lightweight_Text_Representations/">[논문리뷰] EmbeddingGemma: Powerful and Lightweight Text Representations</a></h2><div class="archive__item-excerpt">Marksherwood이 [arXiv]에 게시한 &#x27;EmbeddingGemma: Powerful and Lightweight Text Representations&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-25 13:08:16+0900">2025년 9월 25일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Text Embeddings</span><span class="page__taxonomy-item">#<!-- -->Lightweight Models</span><span class="page__taxonomy-item">#<!-- -->Encoder-Decoder</span><span class="page__taxonomy-item">#<!-- -->Knowledge Distillation</span><span class="page__taxonomy-item">#<!-- -->Model Souping</span><span class="page__taxonomy-item">#<!-- -->Quantization</span><span class="page__taxonomy-item">#<!-- -->Multilingual</span><span class="page__taxonomy-item">#<!-- -->Gemma</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-25-EditVerse_Unifying_Image_and_Video_Editing_and_Generation_with_In-Context_Learning/">[논문리뷰] EditVerse: Unifying Image and Video Editing and Generation with In-Context Learning</a></h2><div class="archive__item-excerpt">Tianyu Wang이 [arXiv]에 게시한 &#x27;EditVerse: Unifying Image and Video Editing and Generation with In-Context Learning&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-25 13:08:16+0900">2025년 9월 25일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Unified Multimodal Model</span><span class="page__taxonomy-item">#<!-- -->In-Context Learning</span><span class="page__taxonomy-item">#<!-- -->Image and Video Editing</span><span class="page__taxonomy-item">#<!-- -->Video Generation</span><span class="page__taxonomy-item">#<!-- -->Full Self-Attention</span><span class="page__taxonomy-item">#<!-- -->Rotary Positional Embedding</span><span class="page__taxonomy-item">#<!-- -->Cross-Modal Knowledge Transfer</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-25-Advancing_Speech_Understanding_in_Speech-Aware_Language_Models_with_GRPO/">[논문리뷰] Advancing Speech Understanding in Speech-Aware Language Models with GRPO</a></h2><div class="archive__item-excerpt">Avihu이 [arXiv]에 게시한 &#x27;Advancing Speech Understanding in Speech-Aware Language Models with GRPO&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-25 13:08:16+0900">2025년 9월 25일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Speech-Aware Language Models</span><span class="page__taxonomy-item">#<!-- -->SALLMs</span><span class="page__taxonomy-item">#<!-- -->GRPO</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Speech Understanding</span><span class="page__taxonomy-item">#<!-- -->Spoken Question Answering</span><span class="page__taxonomy-item">#<!-- -->Automatic Speech Translation</span><span class="page__taxonomy-item">#<!-- -->BLEU Metric</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-24-Zero-Shot_Multi-Spectral_Learning_Reimagining_a_Generalist_Multimodal_Gemini_2.5_Model_for_Remote_Sensing_Applications">[논문리뷰] Zero-Shot Multi-Spectral Learning: Reimagining a Generalist Multimodal Gemini 2.5 Model for Remote Sensing Applications</a></h2><div class="archive__item-excerpt">Genady Beryozkin이 [arXiv]에 게시한 &#x27;Zero-Shot Multi-Spectral Learning: Reimagining a Generalist Multimodal Gemini 2.5 Model for Remote Sensing Applications&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-24 13:14:19+0900">2025년 9월 24일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Remote Sensing</span><span class="page__taxonomy-item">#<!-- -->Zero-Shot Learning</span><span class="page__taxonomy-item">#<!-- -->Multimodal Models</span><span class="page__taxonomy-item">#<!-- -->Multi-spectral Imagery</span><span class="page__taxonomy-item">#<!-- -->Gemini 2.5</span><span class="page__taxonomy-item">#<!-- -->Prompt Engineering</span><span class="page__taxonomy-item">#<!-- -->Land Cover Classification</span><span class="page__taxonomy-item">#<!-- -->Pseudo-Image</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-24-What_Characterizes_Effective_Reasoning_Revisiting_Length_Review_and_Structure_of_CoT/">[논문리뷰] What Characterizes Effective Reasoning? Revisiting Length, Review, and Structure of CoT</a></h2><div class="archive__item-excerpt">Anthony Hartshorn이 [arXiv]에 게시한 &#x27;What Characterizes Effective Reasoning? Revisiting Length, Review, and Structure of CoT&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-24 13:14:19+0900">2025년 9월 24일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Chain-of-Thought</span><span class="page__taxonomy-item">#<!-- -->Reasoning Effectiveness</span><span class="page__taxonomy-item">#<!-- -->Large Reasoning Models</span><span class="page__taxonomy-item">#<!-- -->Failed-Step Fraction</span><span class="page__taxonomy-item">#<!-- -->Test-time Scaling</span><span class="page__taxonomy-item">#<!-- -->Reasoning Graph</span><span class="page__taxonomy-item">#<!-- -->Model Evaluation</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-24-VolSplat_Rethinking_Feed-Forward_3D_Gaussian_Splatting_with_Voxel-Aligned_Prediction/">[논문리뷰] VolSplat: Rethinking Feed-Forward 3D Gaussian Splatting with Voxel-Aligned Prediction</a></h2><div class="archive__item-excerpt">Haoxiao Wang이 [arXiv]에 게시한 &#x27;VolSplat: Rethinking Feed-Forward 3D Gaussian Splatting with Voxel-Aligned Prediction&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-24 13:14:19+0900">2025년 9월 24일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->3D Gaussian Splatting</span><span class="page__taxonomy-item">#<!-- -->Novel View Synthesis</span><span class="page__taxonomy-item">#<!-- -->Voxel-Aligned Prediction</span><span class="page__taxonomy-item">#<!-- -->Feed-Forward Reconstruction</span><span class="page__taxonomy-item">#<!-- -->Multi-View Consistency</span><span class="page__taxonomy-item">#<!-- -->Scene Representation</span><span class="page__taxonomy-item">#<!-- -->Computer Vision</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-24-VIR-Bench_Evaluating_Geospatial_and_Temporal_Understanding_of_MLLMs_via_Travel_Video_Itinerary_Reconstruction/">[논문리뷰] VIR-Bench: Evaluating Geospatial and Temporal Understanding of MLLMs via Travel Video Itinerary Reconstruction</a></h2><div class="archive__item-excerpt">So Fukuda이 [arXiv]에 게시한 &#x27;VIR-Bench: Evaluating Geospatial and Temporal Understanding of MLLMs via Travel Video Itinerary Reconstruction&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-24 13:14:19+0900">2025년 9월 24일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Multimodal LLMs</span><span class="page__taxonomy-item">#<!-- -->Video Understanding</span><span class="page__taxonomy-item">#<!-- -->Geospatial Reasoning</span><span class="page__taxonomy-item">#<!-- -->Temporal Reasoning</span><span class="page__taxonomy-item">#<!-- -->Travel Itinerary Reconstruction</span><span class="page__taxonomy-item">#<!-- -->Benchmark</span><span class="page__taxonomy-item">#<!-- -->Agent System</span><span class="page__taxonomy-item">#<!-- -->VLOG</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-24-Reinforcement_Learning_on_Pre-Training_Data/">[논문리뷰] Reinforcement Learning on Pre-Training Data</a></h2><div class="archive__item-excerpt">Evander Yang이 [arXiv]에 게시한 &#x27;Reinforcement Learning on Pre-Training Data&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-24 13:14:19+0900">2025년 9월 24일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Pre-training</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Self-supervised Learning</span><span class="page__taxonomy-item">#<!-- -->Scaling Laws</span><span class="page__taxonomy-item">#<!-- -->Next-segment Reasoning</span><span class="page__taxonomy-item">#<!-- -->Reward Modeling</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-24-OpenGVL_-_Benchmarking_Visual_Temporal_Progress_for_Data_Curation/">[논문리뷰] OpenGVL - Benchmarking Visual Temporal Progress for Data Curation</a></h2><div class="archive__item-excerpt">Viktor Petrenko이 [arXiv]에 게시한 &#x27;OpenGVL - Benchmarking Visual Temporal Progress for Data Curation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-24 13:14:19+0900">2025년 9월 24일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Robotics Data Curation</span><span class="page__taxonomy-item">#<!-- -->Visual Temporal Progress</span><span class="page__taxonomy-item">#<!-- -->Generative Value Learning (GVL)</span><span class="page__taxonomy-item">#<!-- -->Vision-Language Models (VLMs)</span><span class="page__taxonomy-item">#<!-- -->Benchmark</span><span class="page__taxonomy-item">#<!-- -->Task Progress Prediction</span><span class="page__taxonomy-item">#<!-- -->Value-Order Correlation (VOC)</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-24-MiniCPM-V_4.5_Cooking_Efficient_MLLMs_via_Architecture_Data_and_Training_Recipe">[논문리뷰] MiniCPM-V 4.5: Cooking Efficient MLLMs via Architecture, Data, and Training Recipe</a></h2><div class="archive__item-excerpt">Wenshuo Ma이 [arXiv]에 게시한 &#x27;MiniCPM-V 4.5: Cooking Efficient MLLMs via Architecture, Data, and Training Recipe&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-24 13:14:19+0900">2025년 9월 24일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->MLLM Efficiency</span><span class="page__taxonomy-item">#<!-- -->Multimodal Transformer</span><span class="page__taxonomy-item">#<!-- -->3D-Resampler</span><span class="page__taxonomy-item">#<!-- -->Document AI</span><span class="page__taxonomy-item">#<!-- -->Hybrid Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Video Understanding</span><span class="page__taxonomy-item">#<!-- -->Efficient Inference</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-24-MAPO_Mixed_Advantage_Policy_Optimization/">[논문리뷰] MAPO: Mixed Advantage Policy Optimization</a></h2><div class="archive__item-excerpt">Xuankun Rong이 [arXiv]에 게시한 &#x27;MAPO: Mixed Advantage Policy Optimization&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-24 13:14:19+0900">2025년 9월 24일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Foundation Models</span><span class="page__taxonomy-item">#<!-- -->Policy Optimization</span><span class="page__taxonomy-item">#<!-- -->Advantage Function</span><span class="page__taxonomy-item">#<!-- -->Trajectory Certainty</span><span class="page__taxonomy-item">#<!-- -->Multimodal Reasoning</span><span class="page__taxonomy-item">#<!-- -->GRPO</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-24-Lyra_Generative_3D_Scene_Reconstruction_via_Video_Diffusion_Model_Self-Distillation/">[논문리뷰] Lyra: Generative 3D Scene Reconstruction via Video Diffusion Model Self-Distillation</a></h2><div class="archive__item-excerpt">Yifeng Jiang이 [arXiv]에 게시한 &#x27;Lyra: Generative 3D Scene Reconstruction via Video Diffusion Model Self-Distillation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-24 13:14:19+0900">2025년 9월 24일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Generative AI</span><span class="page__taxonomy-item">#<!-- -->3D Scene Reconstruction</span><span class="page__taxonomy-item">#<!-- -->Video Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->Self-Distillation</span><span class="page__taxonomy-item">#<!-- -->3D Gaussian Splatting</span><span class="page__taxonomy-item">#<!-- -->Dynamic 4D Generation</span><span class="page__taxonomy-item">#<!-- -->Monocular Input</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-24-Large_Language_Models_Discriminate_Against_Speakers_of_German_Dialects/">[논문리뷰] Large Language Models Discriminate Against Speakers of German Dialects</a></h2><div class="archive__item-excerpt">Katharina von der Wense이 [arXiv]에 게시한 &#x27;Large Language Models Discriminate Against Speakers of German Dialects&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-24 13:14:19+0900">2025년 9월 24일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Bias</span><span class="page__taxonomy-item">#<!-- -->German Dialects</span><span class="page__taxonomy-item">#<!-- -->Sociolinguistics</span><span class="page__taxonomy-item">#<!-- -->Stereotypes</span><span class="page__taxonomy-item">#<!-- -->Implicit Association Test</span><span class="page__taxonomy-item">#<!-- -->Decision Making</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-24-HyRF_Hybrid_Radiance_Fields_for_Memory-efficient_and_High-quality_Novel_View_Synthesis/">[논문리뷰] HyRF: Hybrid Radiance Fields for Memory-efficient and High-quality Novel View Synthesis</a></h2><div class="archive__item-excerpt">Dan Xu이 [arXiv]에 게시한 &#x27;HyRF: Hybrid Radiance Fields for Memory-efficient and High-quality Novel View Synthesis&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-24 13:14:19+0900">2025년 9월 24일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Novel View Synthesis</span><span class="page__taxonomy-item">#<!-- -->3D Gaussian Splatting (3DGS)</span><span class="page__taxonomy-item">#<!-- -->Neural Radiance Fields (NeRF)</span><span class="page__taxonomy-item">#<!-- -->Memory Efficiency</span><span class="page__taxonomy-item">#<!-- -->High-Quality Rendering</span><span class="page__taxonomy-item">#<!-- -->Hybrid Representation</span><span class="page__taxonomy-item">#<!-- -->Real-time Rendering</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-24-Hyper-Bagel_A_Unified_Acceleration_Framework_for_Multimodal_Understanding_and_Generation/">[논문리뷰] Hyper-Bagel: A Unified Acceleration Framework for Multimodal Understanding and Generation</a></h2><div class="archive__item-excerpt">Jianbin Zheng이 [arXiv]에 게시한 &#x27;Hyper-Bagel: A Unified Acceleration Framework for Multimodal Understanding and Generation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-24 13:14:19+0900">2025년 9월 24일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Multimodal AI</span><span class="page__taxonomy-item">#<!-- -->Acceleration Framework</span><span class="page__taxonomy-item">#<!-- -->Speculative Decoding</span><span class="page__taxonomy-item">#<!-- -->Diffusion Distillation</span><span class="page__taxonomy-item">#<!-- -->Unified Models</span><span class="page__taxonomy-item">#<!-- -->Text-to-Image Generation</span><span class="page__taxonomy-item">#<!-- -->Image Editing</span><span class="page__taxonomy-item">#<!-- -->Computational Efficiency</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-24-GeoSVR_Taming_Sparse_Voxels_for_Geometrically_Accurate_Surface_Reconstruction/">[논문리뷰] GeoSVR: Taming Sparse Voxels for Geometrically Accurate Surface Reconstruction</a></h2><div class="archive__item-excerpt">Jin Zheng이 [arXiv]에 게시한 &#x27;GeoSVR: Taming Sparse Voxels for Geometrically Accurate Surface Reconstruction&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-24 13:14:19+0900">2025년 9월 24일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Surface Reconstruction</span><span class="page__taxonomy-item">#<!-- -->Sparse Voxels</span><span class="page__taxonomy-item">#<!-- -->Geometric Accuracy</span><span class="page__taxonomy-item">#<!-- -->Neural Radiance Fields</span><span class="page__taxonomy-item">#<!-- -->3D Gaussian Splatting</span><span class="page__taxonomy-item">#<!-- -->Monocular Depth</span><span class="page__taxonomy-item">#<!-- -->Voxel Uncertainty</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-24-Do_You_Need_Proprioceptive_States_in_Visuomotor_Policies/">[논문리뷰] Do You Need Proprioceptive States in Visuomotor Policies?</a></h2><div class="archive__item-excerpt">Yushen Liang이 [arXiv]에 게시한 &#x27;Do You Need Proprioceptive States in Visuomotor Policies?&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-24 13:14:19+0900">2025년 9월 24일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Visuomotor Policies</span><span class="page__taxonomy-item">#<!-- -->Spatial Generalization</span><span class="page__taxonomy-item">#<!-- -->Imitation Learning</span><span class="page__taxonomy-item">#<!-- -->Proprioception</span><span class="page__taxonomy-item">#<!-- -->State-free Policies</span><span class="page__taxonomy-item">#<!-- -->Robot Manipulation</span><span class="page__taxonomy-item">#<!-- -->End-Effector Control</span><span class="page__taxonomy-item">#<!-- -->Data Efficiency</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-24-CAR-Flow_Condition-Aware_Reparameterization_Aligns_Source_and_Target_for_Better_Flow_Matching/">[논문리뷰] CAR-Flow: Condition-Aware Reparameterization Aligns Source and Target for Better Flow Matching</a></h2><div class="archive__item-excerpt">Rui Qian이 [arXiv]에 게시한 &#x27;CAR-Flow: Condition-Aware Reparameterization Aligns Source and Target for Better Flow Matching&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-24 13:14:19+0900">2025년 9월 24일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Flow Matching</span><span class="page__taxonomy-item">#<!-- -->Conditional Generative Models</span><span class="page__taxonomy-item">#<!-- -->Reparameterization</span><span class="page__taxonomy-item">#<!-- -->Mode Collapse</span><span class="page__taxonomy-item">#<!-- -->Image Generation</span><span class="page__taxonomy-item">#<!-- -->Latent Space Alignment</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-24-Baseer_A_Vision-Language_Model_for_Arabic_Document-to-Markdown_OCR/">[논문리뷰] Baseer: A Vision-Language Model for Arabic Document-to-Markdown OCR</a></h2><div class="archive__item-excerpt">Zeina Aldallal이 [arXiv]에 게시한 &#x27;Baseer: A Vision-Language Model for Arabic Document-to-Markdown OCR&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-24 13:14:19+0900">2025년 9월 24일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Arabic OCR</span><span class="page__taxonomy-item">#<!-- -->Vision-Language Model</span><span class="page__taxonomy-item">#<!-- -->Fine-tuning</span><span class="page__taxonomy-item">#<!-- -->Document Understanding</span><span class="page__taxonomy-item">#<!-- -->Markdown Conversion</span><span class="page__taxonomy-item">#<!-- -->Benchmark</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-23-When_Big_Models_Train_Small_Ones_Label-Free_Model_Parity_Alignment_for_Efficient_Visual_Question_Answering_using_Small_VLMs/">[논문리뷰] When Big Models Train Small Ones: Label-Free Model Parity Alignment for Efficient Visual Question Answering using Small VLMs</a></h2><div class="archive__item-excerpt">Anand Mishra이 [arXiv]에 게시한 &#x27;When Big Models Train Small Ones: Label-Free Model Parity Alignment for Efficient Visual Question Answering using Small VLMs&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-23 13:36:03+0900">2025년 9월 23일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->VQA</span><span class="page__taxonomy-item">#<!-- -->Small VLMs</span><span class="page__taxonomy-item">#<!-- -->Large VLMs</span><span class="page__taxonomy-item">#<!-- -->Knowledge Transfer</span><span class="page__taxonomy-item">#<!-- -->Pseudo-labeling</span><span class="page__taxonomy-item">#<!-- -->Label-Free Learning</span><span class="page__taxonomy-item">#<!-- -->Model Parity Alignment</span><span class="page__taxonomy-item">#<!-- -->Computational Efficiency</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-23-VideoFrom3D_3D_Scene_Video_Generation_via_Complementary_Image_and_Video_Diffusion_Models/">[논문리뷰] VideoFrom3D: 3D Scene Video Generation via Complementary Image and Video Diffusion Models</a></h2><div class="archive__item-excerpt">Sunghyun Cho이 [arXiv]에 게시한 &#x27;VideoFrom3D: 3D Scene Video Generation via Complementary Image and Video Diffusion Models&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-23 13:36:03+0900">2025년 9월 23일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->3D Scene Generation</span><span class="page__taxonomy-item">#<!-- -->Video Diffusion</span><span class="page__taxonomy-item">#<!-- -->Image Diffusion</span><span class="page__taxonomy-item">#<!-- -->Generative Models</span><span class="page__taxonomy-item">#<!-- -->Computer Graphics</span><span class="page__taxonomy-item">#<!-- -->Temporal Consistency</span><span class="page__taxonomy-item">#<!-- -->Sparse Anchor Views</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-23-VaseVQA_Multimodal_Agent_and_Benchmark_for_Ancient_Greek_Pottery/">[논문리뷰] VaseVQA: Multimodal Agent and Benchmark for Ancient Greek Pottery</a></h2><div class="archive__item-excerpt">Shiya Huang이 [arXiv]에 게시한 &#x27;VaseVQA: Multimodal Agent and Benchmark for Ancient Greek Pottery&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-23 13:36:03+0900">2025년 9월 23일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Multimodal Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Visual Question Answering</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Cultural Heritage</span><span class="page__taxonomy-item">#<!-- -->Ancient Greek Pottery</span><span class="page__taxonomy-item">#<!-- -->Supervised Fine-Tuning</span><span class="page__taxonomy-item">#<!-- -->Benchmark</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-23-Understanding_Embedding_Scaling_in_Collaborative_Filtering/">[논문리뷰] Understanding Embedding Scaling in Collaborative Filtering</a></h2><div class="archive__item-excerpt">Yonghui Yang이 [arXiv]에 게시한 &#x27;Understanding Embedding Scaling in Collaborative Filtering&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-23 13:36:03+0900">2025년 9월 23일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Collaborative Filtering</span><span class="page__taxonomy-item">#<!-- -->Embedding Scaling</span><span class="page__taxonomy-item">#<!-- -->Noise Robustness</span><span class="page__taxonomy-item">#<!-- -->Recommender Systems</span><span class="page__taxonomy-item">#<!-- -->Graph Neural Networks</span><span class="page__taxonomy-item">#<!-- -->Self-supervised Learning</span><span class="page__taxonomy-item">#<!-- -->Performance Degradation</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-23-Turk-LettuceDetect_A_Hallucination_Detection_Models_for_Turkish_RAG_Applications/">[논문리뷰] Turk-LettuceDetect: A Hallucination Detection Models for Turkish RAG Applications</a></h2><div class="archive__item-excerpt">Fatma Betül Terzioğlu이 [arXiv]에 게시한 &#x27;Turk-LettuceDetect: A Hallucination Detection Models for Turkish RAG Applications&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-23 13:36:03+0900">2025년 9월 23일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Hallucination Detection</span><span class="page__taxonomy-item">#<!-- -->Retrieval Augmented Generation</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Turkish NLP</span><span class="page__taxonomy-item">#<!-- -->Token Classification</span><span class="page__taxonomy-item">#<!-- -->ModernBERT</span><span class="page__taxonomy-item">#<!-- -->Low-Resource Languages</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-23-TempSamp-R1_Effective_Temporal_Sampling_with_Reinforcement_Fine-Tuning_for_Video_LLMs/">[논문리뷰] TempSamp-R1: Effective Temporal Sampling with Reinforcement Fine-Tuning for Video LLMs</a></h2><div class="archive__item-excerpt">Shaohui Jiao이 [arXiv]에 게시한 &#x27;TempSamp-R1: Effective Temporal Sampling with Reinforcement Fine-Tuning for Video LLMs&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-23 13:36:03+0900">2025년 9월 23일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Video LLMs</span><span class="page__taxonomy-item">#<!-- -->Temporal Grounding</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Off-policy Learning</span><span class="page__taxonomy-item">#<!-- -->Reward Shaping</span><span class="page__taxonomy-item">#<!-- -->Chain-of-Thought</span><span class="page__taxonomy-item">#<!-- -->Multimodal LLMs</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-23-Synthetic_bootstrapped_pretraining/">[논문리뷰] Synthetic bootstrapped pretraining</a></h2><div class="archive__item-excerpt">Emmanuel Candès이 [arXiv]에 게시한 &#x27;Synthetic bootstrapped pretraining&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-23 13:36:03+0900">2025년 9월 23일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Language Model Pretraining</span><span class="page__taxonomy-item">#<!-- -->Synthetic Data</span><span class="page__taxonomy-item">#<!-- -->Inter-document Correlation</span><span class="page__taxonomy-item">#<!-- -->Data Augmentation</span><span class="page__taxonomy-item">#<!-- -->Transformer</span><span class="page__taxonomy-item">#<!-- -->Bootstrapping</span><span class="page__taxonomy-item">#<!-- -->Concept Learning</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-23-SWE-Bench_Pro_Can_AI_Agents_Solve_Long-Horizon_Software_Engineering_Tasks/">[논문리뷰] SWE-Bench Pro: Can AI Agents Solve Long-Horizon Software Engineering Tasks?</a></h2><div class="archive__item-excerpt">Yannis Yiming He이 [arXiv]에 게시한 &#x27;SWE-Bench Pro: Can AI Agents Solve Long-Horizon Software Engineering Tasks?&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-23 13:36:03+0900">2025년 9월 23일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->AI Agents</span><span class="page__taxonomy-item">#<!-- -->Software Engineering</span><span class="page__taxonomy-item">#<!-- -->LLMs</span><span class="page__taxonomy-item">#<!-- -->Code Generation</span><span class="page__taxonomy-item">#<!-- -->Benchmark</span><span class="page__taxonomy-item">#<!-- -->Contamination Resistance</span><span class="page__taxonomy-item">#<!-- -->Long-Horizon Tasks</span><span class="page__taxonomy-item">#<!-- -->Enterprise Software</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-23-SCAN_Self-Denoising_Monte_Carlo_Annotation_for_Robust_Process_Reward_Learning/">[논문리뷰] SCAN: Self-Denoising Monte Carlo Annotation for Robust Process Reward Learning</a></h2><div class="archive__item-excerpt">Zhaopeng Tu이 [arXiv]에 게시한 &#x27;SCAN: Self-Denoising Monte Carlo Annotation for Robust Process Reward Learning&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-23 13:36:03+0900">2025년 9월 23일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Process Reward Models</span><span class="page__taxonomy-item">#<!-- -->Monte Carlo Annotation</span><span class="page__taxonomy-item">#<!-- -->Noise Denoising</span><span class="page__taxonomy-item">#<!-- -->Robust Learning</span><span class="page__taxonomy-item">#<!-- -->Self-Supervision</span><span class="page__taxonomy-item">#<!-- -->Mathematical Reasoning</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-23-Reasoning_Core_A_Scalable_RL_Environment_for_LLM_Symbolic_Reasoning/">[논문리뷰] Reasoning Core: A Scalable RL Environment for LLM Symbolic Reasoning</a></h2><div class="archive__item-excerpt">Damien Sileo이 [arXiv]에 게시한 &#x27;Reasoning Core: A Scalable RL Environment for LLM Symbolic Reasoning&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-23 13:36:03+0900">2025년 9월 23일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLM Reasoning</span><span class="page__taxonomy-item">#<!-- -->Symbolic AI</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Procedural Content Generation</span><span class="page__taxonomy-item">#<!-- -->Verifiable Rewards</span><span class="page__taxonomy-item">#<!-- -->Adaptive Curricula</span><span class="page__taxonomy-item">#<!-- -->First-Order Logic</span><span class="page__taxonomy-item">#<!-- -->PDDL Planning</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-23-QWHA_Quantization-Aware_Walsh-Hadamard_Adaptation_for_Parameter-Efficient_Fine-Tuning_on_Large_Language_Models/">[논문리뷰] QWHA: Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-Tuning on Large Language Models</a></h2><div class="archive__item-excerpt">Jae-Joon Kim이 [arXiv]에 게시한 &#x27;QWHA: Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-Tuning on Large Language Models&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-23 13:36:03+0900">2025년 9월 23일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLM Fine-tuning</span><span class="page__taxonomy-item">#<!-- -->Quantization-Aware PEFT</span><span class="page__taxonomy-item">#<!-- -->Walsh-Hadamard Transform</span><span class="page__taxonomy-item">#<!-- -->Sparse Adaptation</span><span class="page__taxonomy-item">#<!-- -->Low-bit Quantization</span><span class="page__taxonomy-item">#<!-- -->Parameter-Efficient Learning</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-23-Qwen3-Omni_Technical_Report/">[논문리뷰] Qwen3-Omni Technical Report</a></h2><div class="archive__item-excerpt">Lhma-aslp이 [arXiv]에 게시한 &#x27;Qwen3-Omni Technical Report&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-23 13:36:03+0900">2025년 9월 23일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Multimodal Model</span><span class="page__taxonomy-item">#<!-- -->Thinker-Talker Architecture</span><span class="page__taxonomy-item">#<!-- -->Mixture-of-Experts</span><span class="page__taxonomy-item">#<!-- -->Low-latency</span><span class="page__taxonomy-item">#<!-- -->Audio Understanding</span><span class="page__taxonomy-item">#<!-- -->Cross-modal Reasoning</span><span class="page__taxonomy-item">#<!-- -->State-of-the-Art</span><span class="page__taxonomy-item">#<!-- -->Real-time Interaction</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-23-OmniInsert_Mask-Free_Video_Insertion_of_Any_Reference_via_Diffusion_Transformer_Models/">[논문리뷰] OmniInsert: Mask-Free Video Insertion of Any Reference via Diffusion Transformer Models</a></h2><div class="archive__item-excerpt">Pengze Zhang이 [arXiv]에 게시한 &#x27;OmniInsert: Mask-Free Video Insertion of Any Reference via Diffusion Transformer Models&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-23 13:36:03+0900">2025년 9월 23일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Video Insertion</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->Diffusion Transformers</span><span class="page__taxonomy-item">#<!-- -->Mask-Free</span><span class="page__taxonomy-item">#<!-- -->Data Augmentation</span><span class="page__taxonomy-item">#<!-- -->Progressive Training</span><span class="page__taxonomy-item">#<!-- -->Preference Optimization</span><span class="page__taxonomy-item">#<!-- -->Video Generation</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-23-MetaEmbed_Scaling_Multimodal_Retrieval_at_Test-Time_with_Flexible_Late_Interaction/">[논문리뷰] MetaEmbed: Scaling Multimodal Retrieval at Test-Time with Flexible Late Interaction</a></h2><div class="archive__item-excerpt">Xintao Chen이 [arXiv]에 게시한 &#x27;MetaEmbed: Scaling Multimodal Retrieval at Test-Time with Flexible Late Interaction&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-23 13:36:03+0900">2025년 9월 23일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Multimodal Retrieval</span><span class="page__taxonomy-item">#<!-- -->Late Interaction</span><span class="page__taxonomy-item">#<!-- -->Meta Tokens</span><span class="page__taxonomy-item">#<!-- -->Matryoshka Representation Learning</span><span class="page__taxonomy-item">#<!-- -->Test-Time Scaling</span><span class="page__taxonomy-item">#<!-- -->Vision-Language Models</span><span class="page__taxonomy-item">#<!-- -->Dense Retrieval</span><span class="page__taxonomy-item">#<!-- -->Efficiency</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-23-Mano_Report/">[논문리뷰] Mano Report</a></h2><div class="archive__item-excerpt">Minghui Wu이 [arXiv]에 게시한 &#x27;Mano Report&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-23 13:36:03+0900">2025년 9월 23일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->GUI Agent</span><span class="page__taxonomy-item">#<!-- -->Multi-modal Foundation Model</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Supervised Fine-tuning</span><span class="page__taxonomy-item">#<!-- -->Simulated Environment</span><span class="page__taxonomy-item">#<!-- -->Data Generation</span><span class="page__taxonomy-item">#<!-- -->Error Recovery</span><span class="page__taxonomy-item">#<!-- -->Web Automation</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-23-LIMI_Less_is_More_for_Agency/">[논문리뷰] LIMI: Less is More for Agency</a></h2><div class="archive__item-excerpt">happyZYM이 [arXiv]에 게시한 &#x27;LIMI: Less is More for Agency&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-23 13:36:03+0900">2025년 9월 23일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->AI Agency</span><span class="page__taxonomy-item">#<!-- -->Data Curation</span><span class="page__taxonomy-item">#<!-- -->Less Is More</span><span class="page__taxonomy-item">#<!-- -->Agentic Intelligence</span><span class="page__taxonomy-item">#<!-- -->Foundation Models</span><span class="page__taxonomy-item">#<!-- -->Evaluation Benchmark</span><span class="page__taxonomy-item">#<!-- -->Efficiency Principle</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-23-GeoPQA_Bridging_the_Visual_Perception_Gap_in_MLLMs_for_Geometric_Reasoning/">[논문리뷰] GeoPQA: Bridging the Visual Perception Gap in MLLMs for Geometric Reasoning</a></h2><div class="archive__item-excerpt">Hou Pong Chan이 [arXiv]에 게시한 &#x27;GeoPQA: Bridging the Visual Perception Gap in MLLMs for Geometric Reasoning&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-23 13:36:03+0900">2025년 9월 23일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Multimodal Large Language Models (MLLMs)</span><span class="page__taxonomy-item">#<!-- -->Geometric Reasoning</span><span class="page__taxonomy-item">#<!-- -->Visual Perception</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning (RL)</span><span class="page__taxonomy-item">#<!-- -->Two-stage Training</span><span class="page__taxonomy-item">#<!-- -->GeoPQA Benchmark</span><span class="page__taxonomy-item">#<!-- -->Perceptual Bottleneck</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-23-From_Uniform_to_Heterogeneous_Tailoring_Policy_Optimization_to_Every_Tokens_Nature/">[논문리뷰] From Uniform to Heterogeneous: Tailoring Policy Optimization to Every Token&#x27;s Nature</a></h2><div class="archive__item-excerpt">Bin Cui이 [arXiv]에 게시한 &#x27;From Uniform to Heterogeneous: Tailoring Policy Optimization to Every Token&#x27;s Nature&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-23 13:36:03+0900">2025년 9월 23일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->LLMs</span><span class="page__taxonomy-item">#<!-- -->Policy Optimization</span><span class="page__taxonomy-item">#<!-- -->Token Heterogeneity</span><span class="page__taxonomy-item">#<!-- -->Adaptive Sampling</span><span class="page__taxonomy-item">#<!-- -->Advantage Redistribution</span><span class="page__taxonomy-item">#<!-- -->Asymmetric Clipping</span><span class="page__taxonomy-item">#<!-- -->Entropy-based RL</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-23-From_Hugging_Face_to_GitHub_Tracing_License_Drift_in_the_Open-Source_AI_Ecosystem/">[논문리뷰] From Hugging Face to GitHub: Tracing License Drift in the Open-Source AI Ecosystem</a></h2><div class="archive__item-excerpt">Ahmed E. Hassan이 [arXiv]에 게시한 &#x27;From Hugging Face to GitHub: Tracing License Drift in the Open-Source AI Ecosystem&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-23 13:36:03+0900">2025년 9월 23일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Open-Source AI</span><span class="page__taxonomy-item">#<!-- -->License Compliance</span><span class="page__taxonomy-item">#<!-- -->License Drift</span><span class="page__taxonomy-item">#<!-- -->AI Supply Chain</span><span class="page__taxonomy-item">#<!-- -->Hugging Face</span><span class="page__taxonomy-item">#<!-- -->GitHub</span><span class="page__taxonomy-item">#<!-- -->LicenseRec</span><span class="page__taxonomy-item">#<!-- -->Legal Risk</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-23-FlagEval_Findings_Report_A_Preliminary_Evaluation_of_Large_Reasoning_Models_on_Automatically_Verifiable_Textual_and_Visual_Questions/">[논문리뷰] FlagEval Findings Report: A Preliminary Evaluation of Large Reasoning Models on Automatically Verifiable Textual and Visual Questions</a></h2><div class="archive__item-excerpt">tengdai722이 [arXiv]에 게시한 &#x27;FlagEval Findings Report: A Preliminary Evaluation of Large Reasoning Models on Automatically Verifiable Textual and Visual Questions&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-23 13:36:03+0900">2025년 9월 23일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Large Reasoning Models</span><span class="page__taxonomy-item">#<!-- -->LLM Evaluation</span><span class="page__taxonomy-item">#<!-- -->Multimodal AI</span><span class="page__taxonomy-item">#<!-- -->Reasoning Behaviors</span><span class="page__taxonomy-item">#<!-- -->Hallucination</span><span class="page__taxonomy-item">#<!-- -->Contamination-Free</span><span class="page__taxonomy-item">#<!-- -->AI Safety</span><span class="page__taxonomy-item">#<!-- -->Instruction Following</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-23-EpiCache_Episodic_KV_Cache_Management_for_Long_Conversational_Question_Answering/">[논문리뷰] EpiCache: Episodic KV Cache Management for Long Conversational Question Answering</a></h2><div class="archive__item-excerpt">Minsik Cho이 [arXiv]에 게시한 &#x27;EpiCache: Episodic KV Cache Management for Long Conversational Question Answering&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-23 13:36:03+0900">2025년 9월 23일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->KV Cache Management</span><span class="page__taxonomy-item">#<!-- -->Long Conversational QA</span><span class="page__taxonomy-item">#<!-- -->LLMs</span><span class="page__taxonomy-item">#<!-- -->Memory Efficiency</span><span class="page__taxonomy-item">#<!-- -->Episodic Clustering</span><span class="page__taxonomy-item">#<!-- -->Block Prefill Eviction</span><span class="page__taxonomy-item">#<!-- -->Sensitivity-aware Allocation</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-23-DIWALI_-_Diversity_and_Inclusivity_aWare_cuLture_specific_Items_for_India_Dataset_and_Assessment_of_LLMs_for_Cultural_Text_Adaptation_in_Indian_Context/">[논문리뷰] DIWALI - Diversity and Inclusivity aWare cuLture specific Items for India: Dataset and Assessment of LLMs for Cultural Text Adaptation in Indian Context</a></h2><div class="archive__item-excerpt">Maunendra Sankar Desarkar이 [arXiv]에 게시한 &#x27;DIWALI - Diversity and Inclusivity aWare cuLture specific Items for India: Dataset and Assessment of LLMs for Cultural Text Adaptation in Indian Context&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-23 13:36:03+0900">2025년 9월 23일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Cultural Adaptation</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Indian Culture</span><span class="page__taxonomy-item">#<!-- -->Dataset Creation</span><span class="page__taxonomy-item">#<!-- -->CSI</span><span class="page__taxonomy-item">#<!-- -->Human Evaluation</span><span class="page__taxonomy-item">#<!-- -->LLM Evaluation</span><span class="page__taxonomy-item">#<!-- -->Cultural Bias</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-23-DiffusionNFT_Online_Diffusion_Reinforcement_with_Forward_Process/">[논문리뷰] DiffusionNFT: Online Diffusion Reinforcement with Forward Process</a></h2><div class="archive__item-excerpt">Qinsheng Zhang이 [arXiv]에 게시한 &#x27;DiffusionNFT: Online Diffusion Reinforcement with Forward Process&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-23 13:36:03+0900">2025년 9월 23일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Online RL</span><span class="page__taxonomy-item">#<!-- -->Flow Matching</span><span class="page__taxonomy-item">#<!-- -->Forward Process</span><span class="page__taxonomy-item">#<!-- -->CFG-free</span><span class="page__taxonomy-item">#<!-- -->Image Generation</span><span class="page__taxonomy-item">#<!-- -->Negative-Aware FineTuning</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-23-Cross-Attention_is_Half_Explanation_in_Speech-to-Text_Models/">[논문리뷰] Cross-Attention is Half Explanation in Speech-to-Text Models</a></h2><div class="archive__item-excerpt">Luisa Bentivogli이 [arXiv]에 게시한 &#x27;Cross-Attention is Half Explanation in Speech-to-Text Models&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-23 13:36:03+0900">2025년 9월 23일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Cross-attention</span><span class="page__taxonomy-item">#<!-- -->Speech-to-Text (S2T)</span><span class="page__taxonomy-item">#<!-- -->Explainable AI (XAI)</span><span class="page__taxonomy-item">#<!-- -->Saliency Maps</span><span class="page__taxonomy-item">#<!-- -->Feature Attribution</span><span class="page__taxonomy-item">#<!-- -->Transformer</span><span class="page__taxonomy-item">#<!-- -->Context Mixing</span><span class="page__taxonomy-item">#<!-- -->Correlation</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-23-ContextFlow_Training-Free_Video_Object_Editing_via_Adaptive_Context_Enrichment/">[논문리뷰] ContextFlow: Training-Free Video Object Editing via Adaptive Context Enrichment</a></h2><div class="archive__item-excerpt">Yue Ma이 [arXiv]에 게시한 &#x27;ContextFlow: Training-Free Video Object Editing via Adaptive Context Enrichment&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-23 13:36:03+0900">2025년 9월 23일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Video Object Editing</span><span class="page__taxonomy-item">#<!-- -->Training-Free</span><span class="page__taxonomy-item">#<!-- -->Diffusion Transformers</span><span class="page__taxonomy-item">#<!-- -->Rectified Flow</span><span class="page__taxonomy-item">#<!-- -->Adaptive Context Enrichment</span><span class="page__taxonomy-item">#<!-- -->Guidance Responsiveness</span><span class="page__taxonomy-item">#<!-- -->Temporal Consistency</span><span class="page__taxonomy-item">#<!-- -->Image-to-Video</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-23-CodeFuse-CR-Bench_A_Comprehensiveness-aware_Benchmark_for_End-to-End_Code_Review_Evaluation_in_Python_Projects/">[논문리뷰] CodeFuse-CR-Bench: A Comprehensiveness-aware Benchmark for End-to-End Code Review Evaluation in Python Projects</a></h2><div class="archive__item-excerpt">Hang Yu이 [arXiv]에 게시한 &#x27;CodeFuse-CR-Bench: A Comprehensiveness-aware Benchmark for End-to-End Code Review Evaluation in Python Projects&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-23 13:36:03+0900">2025년 9월 23일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Code Review</span><span class="page__taxonomy-item">#<!-- -->LLMs</span><span class="page__taxonomy-item">#<!-- -->Benchmark</span><span class="page__taxonomy-item">#<!-- -->Python Projects</span><span class="page__taxonomy-item">#<!-- -->End-to-End Evaluation</span><span class="page__taxonomy-item">#<!-- -->Context-Awareness</span><span class="page__taxonomy-item">#<!-- -->Software Engineering</span><span class="page__taxonomy-item">#<!-- -->LLM-as-a-Judge</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-23-ByteWrist_A_Parallel_Robotic_Wrist_Enabling_Flexible_and_Anthropomorphic_Motion_for_Confined_Spaces/">[논문리뷰] ByteWrist: A Parallel Robotic Wrist Enabling Flexible and Anthropomorphic Motion for Confined Spaces</a></h2><div class="archive__item-excerpt">Jiafeng Xu이 [arXiv]에 게시한 &#x27;ByteWrist: A Parallel Robotic Wrist Enabling Flexible and Anthropomorphic Motion for Confined Spaces&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-23 13:36:03+0900">2025년 9월 23일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Robotics</span><span class="page__taxonomy-item">#<!-- -->Parallel Manipulator</span><span class="page__taxonomy-item">#<!-- -->Robotic Wrist</span><span class="page__taxonomy-item">#<!-- -->Confined Space Manipulation</span><span class="page__taxonomy-item">#<!-- -->Kinematics</span><span class="page__taxonomy-item">#<!-- -->Anthropomorphic Robot</span><span class="page__taxonomy-item">#<!-- -->Robot Design</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-23-AuditoryBench_Can_Language_Models_Understand_Auditory_Knowledge_without_Hearing/">[논문리뷰] AuditoryBench++: Can Language Models Understand Auditory Knowledge without Hearing?</a></h2><div class="archive__item-excerpt">Jaeho Lee이 [arXiv]에 게시한 &#x27;AuditoryBench++: Can Language Models Understand Auditory Knowledge without Hearing?&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-23 13:36:03+0900">2025년 9월 23일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Auditory Knowledge</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Multimodal Reasoning</span><span class="page__taxonomy-item">#<!-- -->Benchmark</span><span class="page__taxonomy-item">#<!-- -->Chain-of-Thought</span><span class="page__taxonomy-item">#<!-- -->Auditory Imagination</span><span class="page__taxonomy-item">#<!-- -->Text-only Reasoning</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-23-ARE_Scaling_Up_Agent_Environments_and_Evaluations/">[논문리뷰] ARE: Scaling Up Agent Environments and Evaluations</a></h2><div class="archive__item-excerpt">Matteo Bettini이 [arXiv]에 게시한 &#x27;ARE: Scaling Up Agent Environments and Evaluations&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-23 13:36:03+0900">2025년 9월 23일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Agent Environments</span><span class="page__taxonomy-item">#<!-- -->Agent Evaluation</span><span class="page__taxonomy-item">#<!-- -->LLM Agents</span><span class="page__taxonomy-item">#<!-- -->Asynchronous Systems</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Tool Use</span><span class="page__taxonomy-item">#<!-- -->Multi-agent Collaboration</span><span class="page__taxonomy-item">#<!-- -->Benchmark</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-23-Analyzing_the_Effects_of_Supervised_Fine-Tuning_on_Model_Knowledge_from_Token_and_Parameter_Levels/">[논문리뷰] Analyzing the Effects of Supervised Fine-Tuning on Model Knowledge from Token and Parameter Levels</a></h2><div class="archive__item-excerpt">Qi Zhang이 [arXiv]에 게시한 &#x27;Analyzing the Effects of Supervised Fine-Tuning on Model Knowledge from Token and Parameter Levels&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-23 13:36:03+0900">2025년 9월 23일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Supervised Fine-Tuning (SFT)</span><span class="page__taxonomy-item">#<!-- -->Large Language Models (LLMs)</span><span class="page__taxonomy-item">#<!-- -->Model Knowledge</span><span class="page__taxonomy-item">#<!-- -->Closed-Book Question Answering (CBQA)</span><span class="page__taxonomy-item">#<!-- -->Parameter Restoration</span><span class="page__taxonomy-item">#<!-- -->Kullback-Leibler Divergence</span><span class="page__taxonomy-item">#<!-- -->Knowledge Forgetting</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-22-WhisTLE_Deeply_Supervised_Text-Only_Domain_Adaptation_for_Pretrained_Speech_Recognition_Transformers/">[논문리뷰] WhisTLE: Deeply Supervised, Text-Only Domain Adaptation for Pretrained Speech Recognition Transformers</a></h2><div class="archive__item-excerpt">Karun Kumar이 [arXiv]에 게시한 &#x27;WhisTLE: Deeply Supervised, Text-Only Domain Adaptation for Pretrained Speech Recognition Transformers&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-22 13:11:29+0900">2025년 9월 22일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->ASR</span><span class="page__taxonomy-item">#<!-- -->Domain Adaptation</span><span class="page__taxonomy-item">#<!-- -->Text-Only Training</span><span class="page__taxonomy-item">#<!-- -->Transformer</span><span class="page__taxonomy-item">#<!-- -->Variational Autoencoder</span><span class="page__taxonomy-item">#<!-- -->Deep Supervision</span><span class="page__taxonomy-item">#<!-- -->Whisper</span><span class="page__taxonomy-item">#<!-- -->Encoder-Decoder Models</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-22-Video2Roleplay_A_Multimodal_Dataset_and_Framework_for_Video-Guided_Role-playing_Agents/">[논문리뷰] Video2Roleplay: A Multimodal Dataset and Framework for Video-Guided Role-playing Agents</a></h2><div class="archive__item-excerpt">Chao Zhang이 [arXiv]에 게시한 &#x27;Video2Roleplay: A Multimodal Dataset and Framework for Video-Guided Role-playing Agents&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-22 13:11:29+0900">2025년 9월 22일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Role-playing Agents (RPAs)</span><span class="page__taxonomy-item">#<!-- -->Multimodal AI</span><span class="page__taxonomy-item">#<!-- -->Video Understanding</span><span class="page__taxonomy-item">#<!-- -->Large Language Models (LLMs)</span><span class="page__taxonomy-item">#<!-- -->Dataset Creation</span><span class="page__taxonomy-item">#<!-- -->Dynamic Role Profiles</span><span class="page__taxonomy-item">#<!-- -->Adaptive Temporal Sampling</span><span class="page__taxonomy-item">#<!-- -->Fine-tuning</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-22-SPATIALGEN_Layout-guided_3D_Indoor_Scene_Generation/">[논문리뷰] SPATIALGEN: Layout-guided 3D Indoor Scene Generation</a></h2><div class="archive__item-excerpt">Yongsen Mao이 [arXiv]에 게시한 &#x27;SPATIALGEN: Layout-guided 3D Indoor Scene Generation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-22 13:11:29+0900">2025년 9월 22일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->3D Scene Generation</span><span class="page__taxonomy-item">#<!-- -->Layout Guidance</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->Multi-view Synthesis</span><span class="page__taxonomy-item">#<!-- -->Synthetic Dataset</span><span class="page__taxonomy-item">#<!-- -->Indoor Environments</span><span class="page__taxonomy-item">#<!-- -->Gaussian Splatting</span><span class="page__taxonomy-item">#<!-- -->Semantic Consistency</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-22-RPG_A_Repository_Planning_Graph_for_Unified_and_Scalable_Codebase_Generation/">[논문리뷰] RPG: A Repository Planning Graph for Unified and Scalable Codebase Generation</a></h2><div class="archive__item-excerpt">Steven Liu이 [arXiv]에 게시한 &#x27;RPG: A Repository Planning Graph for Unified and Scalable Codebase Generation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-22 13:11:29+0900">2025년 9월 22일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Code Generation</span><span class="page__taxonomy-item">#<!-- -->LLMs</span><span class="page__taxonomy-item">#<!-- -->Repository Planning</span><span class="page__taxonomy-item">#<!-- -->Graph-based Representation</span><span class="page__taxonomy-item">#<!-- -->Software Engineering</span><span class="page__taxonomy-item">#<!-- -->Agent Frameworks</span><span class="page__taxonomy-item">#<!-- -->Scalable Codebase</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-22-RGB-Only_Supervised_Camera_Parameter_Optimization_in_Dynamic_Scenes/">[논문리뷰] RGB-Only Supervised Camera Parameter Optimization in Dynamic Scenes</a></h2><div class="archive__item-excerpt">Narendra Ahuja이 [arXiv]에 게시한 &#x27;RGB-Only Supervised Camera Parameter Optimization in Dynamic Scenes&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-22 13:11:29+0900">2025년 9월 22일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Camera Parameter Optimization</span><span class="page__taxonomy-item">#<!-- -->Dynamic Scenes</span><span class="page__taxonomy-item">#<!-- -->RGB-Only Supervision</span><span class="page__taxonomy-item">#<!-- -->Structure from Motion</span><span class="page__taxonomy-item">#<!-- -->Outlier Robustness</span><span class="page__taxonomy-item">#<!-- -->3D Gaussian Splatting</span><span class="page__taxonomy-item">#<!-- -->Two-stage Optimization</span><span class="page__taxonomy-item">#<!-- -->Point Tracking</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-22-MANZANO_A_Simple_and_Scalable_Unified_Multimodal_Model_with_a_Hybrid_Vision_Tokenizer/">[논문리뷰] MANZANO: A Simple and Scalable Unified Multimodal Model with a Hybrid Vision Tokenizer</a></h2><div class="archive__item-excerpt">jialingt이 [arXiv]에 게시한 &#x27;MANZANO: A Simple and Scalable Unified Multimodal Model with a Hybrid Vision Tokenizer&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-22 13:11:29+0900">2025년 9월 22일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Multimodal LLM</span><span class="page__taxonomy-item">#<!-- -->Hybrid Tokenizer</span><span class="page__taxonomy-item">#<!-- -->Text-to-Image Generation</span><span class="page__taxonomy-item">#<!-- -->Visual Question Answering</span><span class="page__taxonomy-item">#<!-- -->Autoregressive Model</span><span class="page__taxonomy-item">#<!-- -->Diffusion Decoder</span><span class="page__taxonomy-item">#<!-- -->Unified Architecture</span><span class="page__taxonomy-item">#<!-- -->Model Scaling</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-22-Lynx_Towards_High-Fidelity_Personalized_Video_Generation/">[논문리뷰] Lynx: Towards High-Fidelity Personalized Video Generation</a></h2><div class="archive__item-excerpt">Linjie Luo이 [arXiv]에 게시한 &#x27;Lynx: Towards High-Fidelity Personalized Video Generation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-22 13:11:29+0900">2025년 9월 22일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Personalized Video Generation</span><span class="page__taxonomy-item">#<!-- -->Diffusion Transformer</span><span class="page__taxonomy-item">#<!-- -->Identity Preservation</span><span class="page__taxonomy-item">#<!-- -->Video Synthesis</span><span class="page__taxonomy-item">#<!-- -->Adapter Networks</span><span class="page__taxonomy-item">#<!-- -->Facial Recognition</span><span class="page__taxonomy-item">#<!-- -->Cross-Attention</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-22-Latent_Zoning_Network_A_Unified_Principle_for_Generative_Modeling_Representation_Learning_and_Classification/">[논문리뷰] Latent Zoning Network: A Unified Principle for Generative Modeling, Representation Learning, and Classification</a></h2><div class="archive__item-excerpt">Wenyu Wang이 [arXiv]에 게시한 &#x27;Latent Zoning Network: A Unified Principle for Generative Modeling, Representation Learning, and Classification&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-22 13:11:29+0900">2025년 9월 22일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Generative Modeling</span><span class="page__taxonomy-item">#<!-- -->Representation Learning</span><span class="page__taxonomy-item">#<!-- -->Classification</span><span class="page__taxonomy-item">#<!-- -->Unified Framework</span><span class="page__taxonomy-item">#<!-- -->Latent Space</span><span class="page__taxonomy-item">#<!-- -->Flow Matching</span><span class="page__taxonomy-item">#<!-- -->Deep Learning</span><span class="page__taxonomy-item">#<!-- -->Image Generation</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-22-Do_You_Hear_What_I_Mean_Quantifying_the_Instruction-Perception_Gap_in_Instruction-Guided_Expressive_Text-To-Speech_Systems/">[논문리뷰] Do You Hear What I Mean? Quantifying the Instruction-Perception Gap in Instruction-Guided Expressive Text-To-Speech Systems</a></h2><div class="archive__item-excerpt">Hung-yi Lee이 [arXiv]에 게시한 &#x27;Do You Hear What I Mean? Quantifying the Instruction-Perception Gap in Instruction-Guided Expressive Text-To-Speech Systems&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-22 13:11:29+0900">2025년 9월 22일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Instruction-Guided TTS</span><span class="page__taxonomy-item">#<!-- -->Expressive Speech Synthesis</span><span class="page__taxonomy-item">#<!-- -->Human Perception</span><span class="page__taxonomy-item">#<!-- -->Subjective Evaluation</span><span class="page__taxonomy-item">#<!-- -->Controllability</span><span class="page__taxonomy-item">#<!-- -->Instruction Following</span><span class="page__taxonomy-item">#<!-- -->Evaluation Metrics</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-22-BTL-UI_Blink-Think-Link_Reasoning_Model_for_GUI_Agent/">[논문리뷰] BTL-UI: Blink-Think-Link Reasoning Model for GUI Agent</a></h2><div class="archive__item-excerpt">Jiahui Yang이 [arXiv]에 게시한 &#x27;BTL-UI: Blink-Think-Link Reasoning Model for GUI Agent&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-22 13:11:29+0900">2025년 9월 22일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->GUI Agent</span><span class="page__taxonomy-item">#<!-- -->Human-GUI Interaction</span><span class="page__taxonomy-item">#<!-- -->Cognitive Modeling</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Multimodal Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Attention Mechanisms</span><span class="page__taxonomy-item">#<!-- -->Action Planning</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-22-BaseReward_A_Strong_Baseline_for_Multimodal_Reward_Model/">[논문리뷰] BaseReward: A Strong Baseline for Multimodal Reward Model</a></h2><div class="archive__item-excerpt">jianfeipan이 [arXiv]에 게시한 &#x27;BaseReward: A Strong Baseline for Multimodal Reward Model&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-22 13:11:29+0900">2025년 9월 22일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Multimodal Reward Model</span><span class="page__taxonomy-item">#<!-- -->MLLM Alignment</span><span class="page__taxonomy-item">#<!-- -->RLHF</span><span class="page__taxonomy-item">#<!-- -->Reward Head Architecture</span><span class="page__taxonomy-item">#<!-- -->Data Curation</span><span class="page__taxonomy-item">#<!-- -->Ensemble Methods</span><span class="page__taxonomy-item">#<!-- -->BaseReward</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-22-A_Vision-Language-Action-Critic_Model_for_Robotic_Real-World_Reinforcement_Learning/">[논문리뷰] A Vision-Language-Action-Critic Model for Robotic Real-World Reinforcement Learning</a></h2><div class="archive__item-excerpt">Jiangmiao이 [arXiv]에 게시한 &#x27;A Vision-Language-Action-Critic Model for Robotic Real-World Reinforcement Learning&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-22 13:11:29+0900">2025년 9월 22일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Robotics</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning (RL)</span><span class="page__taxonomy-item">#<!-- -->Vision-Language-Action (VLA) Models</span><span class="page__taxonomy-item">#<!-- -->Reward Modeling</span><span class="page__taxonomy-item">#<!-- -->Human-in-the-Loop</span><span class="page__taxonomy-item">#<!-- -->Dense Rewards</span><span class="page__taxonomy-item">#<!-- -->Generalization</span><span class="page__taxonomy-item">#<!-- -->Autoregressive Models</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-22-Ask-to-Clarify_Resolving_Instruction_Ambiguity_through_Multi-turn_Dialogue/">[논문리뷰] Ask-to-Clarify: Resolving Instruction Ambiguity through Multi-turn Dialogue</a></h2><div class="archive__item-excerpt">Hui Zhang이 [arXiv]에 게시한 &#x27;Ask-to-Clarify: Resolving Instruction Ambiguity through Multi-turn Dialogue&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-22 13:11:29+0900">2025년 9월 22일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Embodied AI</span><span class="page__taxonomy-item">#<!-- -->Human-Robot Interaction</span><span class="page__taxonomy-item">#<!-- -->Multi-turn Dialogue</span><span class="page__taxonomy-item">#<!-- -->Instruction Following</span><span class="page__taxonomy-item">#<!-- -->Vision-Language Models</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->Ambiguity Resolution</span><span class="page__taxonomy-item">#<!-- -->Low-level Actions</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-19-WorldForge_Unlocking_Emergent_3D4D_Generation_in_Video_Diffusion_Model_via_Training-Free_Guidance/">[논문리뷰] WorldForge: Unlocking Emergent 3D/4D Generation in Video Diffusion Model via Training-Free Guidance</a></h2><div class="archive__item-excerpt">Ruibo Li이 [arXiv]에 게시한 &#x27;WorldForge: Unlocking Emergent 3D/4D Generation in Video Diffusion Model via Training-Free Guidance&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-19 13:12:21+0900">2025년 9월 19일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Video Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->3D/4D Generation</span><span class="page__taxonomy-item">#<!-- -->Training-Free Guidance</span><span class="page__taxonomy-item">#<!-- -->Camera Trajectory Control</span><span class="page__taxonomy-item">#<!-- -->Novel View Synthesis</span><span class="page__taxonomy-item">#<!-- -->Geometric Consistency</span><span class="page__taxonomy-item">#<!-- -->Inference-Time Optimization</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-19-Unleashing_the_Potential_of_Multimodal_LLMs_for_Zero-Shot_Spatio-Temporal_Video_Grounding/">[논문리뷰] Unleashing the Potential of Multimodal LLMs for Zero-Shot Spatio-Temporal Video Grounding</a></h2><div class="archive__item-excerpt">Rynson W. H. Lau이 [arXiv]에 게시한 &#x27;Unleashing the Potential of Multimodal LLMs for Zero-Shot Spatio-Temporal Video Grounding&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-19 13:12:21+0900">2025년 9월 19일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Spatio-Temporal Video Grounding</span><span class="page__taxonomy-item">#<!-- -->Multimodal Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Zero-Shot Learning</span><span class="page__taxonomy-item">#<!-- -->Visual Grounding</span><span class="page__taxonomy-item">#<!-- -->Decomposed Spatio-Temporal Highlighting</span><span class="page__taxonomy-item">#<!-- -->Logit-Guided Re-attention</span><span class="page__taxonomy-item">#<!-- -->Temporal-Augmented Assembling</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-19-Understand_Before_You_Generate_Self-Guided_Training_for_Autoregressive_Image_Generation/">[논문리뷰] Understand Before You Generate: Self-Guided Training for Autoregressive Image Generation</a></h2><div class="archive__item-excerpt">Xihui Liu이 [arXiv]에 게시한 &#x27;Understand Before You Generate: Self-Guided Training for Autoregressive Image Generation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-19 13:12:21+0900">2025년 9월 19일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Autoregressive Models</span><span class="page__taxonomy-item">#<!-- -->Image Generation</span><span class="page__taxonomy-item">#<!-- -->Self-Supervised Learning</span><span class="page__taxonomy-item">#<!-- -->Visual Understanding</span><span class="page__taxonomy-item">#<!-- -->Masked Image Modeling</span><span class="page__taxonomy-item">#<!-- -->Contrastive Learning</span><span class="page__taxonomy-item">#<!-- -->Next-Token Prediction</span><span class="page__taxonomy-item">#<!-- -->LlamaGen</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-19-ScaleCUA_Scaling_Open-Source_Computer_Use_Agents_with_Cross-Platform_Data/">[논문리뷰] ScaleCUA: Scaling Open-Source Computer Use Agents with Cross-Platform Data</a></h2><div class="archive__item-excerpt">Zehao Li이 [arXiv]에 게시한 &#x27;ScaleCUA: Scaling Open-Source Computer Use Agents with Cross-Platform Data&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-19 13:12:21+0900">2025년 9월 19일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Computer Use Agents</span><span class="page__taxonomy-item">#<!-- -->Vision-Language Models</span><span class="page__taxonomy-item">#<!-- -->Cross-Platform Data</span><span class="page__taxonomy-item">#<!-- -->GUI Automation</span><span class="page__taxonomy-item">#<!-- -->Data Scaling</span><span class="page__taxonomy-item">#<!-- -->Open-Source</span><span class="page__taxonomy-item">#<!-- -->Task Completion</span><span class="page__taxonomy-item">#<!-- -->GUI Grounding</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-19-RynnVLA-001_Using_Human_Demonstrations_to_Improve_Robot_Manipulation/">[논문리뷰] RynnVLA-001: Using Human Demonstrations to Improve Robot Manipulation</a></h2><div class="archive__item-excerpt">SpaceProduct이 [arXiv]에 게시한 &#x27;RynnVLA-001: Using Human Demonstrations to Improve Robot Manipulation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-19 13:12:21+0900">2025년 9월 19일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Vision-Language-Action (VLA) Model</span><span class="page__taxonomy-item">#<!-- -->Robot Manipulation</span><span class="page__taxonomy-item">#<!-- -->Human Demonstrations</span><span class="page__taxonomy-item">#<!-- -->Video Generative Pretraining</span><span class="page__taxonomy-item">#<!-- -->Ego-Centric Video</span><span class="page__taxonomy-item">#<!-- -->Trajectory Prediction</span><span class="page__taxonomy-item">#<!-- -->ActionVAE</span><span class="page__taxonomy-item">#<!-- -->Transformer</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-19-RecoWorld_Building_Simulated_Environments_for_Agentic_Recommender_Systems/">[논문리뷰] RecoWorld: Building Simulated Environments for Agentic Recommender Systems</a></h2><div class="archive__item-excerpt">Mingyuan Wu이 [arXiv]에 게시한 &#x27;RecoWorld: Building Simulated Environments for Agentic Recommender Systems&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-19 13:12:21+0900">2025년 9월 19일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Agentic Recommender Systems</span><span class="page__taxonomy-item">#<!-- -->Simulated Environments</span><span class="page__taxonomy-item">#<!-- -->LLM-driven Simulation</span><span class="page__taxonomy-item">#<!-- -->Multi-turn Interaction</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->User Retention</span><span class="page__taxonomy-item">#<!-- -->Instruction Following</span><span class="page__taxonomy-item">#<!-- -->Multi-agent Systems</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-19-Reasoning_over_Boundaries_Enhancing_Specification_Alignment_via_Test-time_Delibration/">[논문리뷰] Reasoning over Boundaries: Enhancing Specification Alignment via Test-time Delibration</a></h2><div class="archive__item-excerpt">Zhilin Wang이 [arXiv]에 게시한 &#x27;Reasoning over Boundaries: Enhancing Specification Alignment via Test-time Delibration&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-19 13:12:21+0900">2025년 9월 19일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLMs</span><span class="page__taxonomy-item">#<!-- -->Specification Alignment</span><span class="page__taxonomy-item">#<!-- -->Test-Time Deliberation</span><span class="page__taxonomy-item">#<!-- -->Safety-Behavior Trade-off</span><span class="page__taxonomy-item">#<!-- -->ALIGN3</span><span class="page__taxonomy-item">#<!-- -->SPECBENCH</span><span class="page__taxonomy-item">#<!-- -->Prompt Engineering</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-19-MultiEdit_Advancing_Instruction-based_Image_Editing_on_Diverse_and_Challenging_Tasks/">[논문리뷰] MultiEdit: Advancing Instruction-based Image Editing on Diverse and Challenging Tasks</a></h2><div class="archive__item-excerpt">Xijun Gu이 [arXiv]에 게시한 &#x27;MultiEdit: Advancing Instruction-based Image Editing on Diverse and Challenging Tasks&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-19 13:12:21+0900">2025년 9월 19일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Instruction-based Image Editing</span><span class="page__taxonomy-item">#<!-- -->Dataset</span><span class="page__taxonomy-item">#<!-- -->Multi-modal LLM</span><span class="page__taxonomy-item">#<!-- -->Image Generation</span><span class="page__taxonomy-item">#<!-- -->Style Transfer</span><span class="page__taxonomy-item">#<!-- -->Multi-task Learning</span><span class="page__taxonomy-item">#<!-- -->Fine-tuning</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-19-Mind_the_Gap_A_Closer_Look_at_Tokenization_for_Multiple-Choice_Question_Answering_with_LLMs/">[논문리뷰] Mind the Gap: A Closer Look at Tokenization for Multiple-Choice Question Answering with LLMs</a></h2><div class="archive__item-excerpt">Katharina von der Wense이 [arXiv]에 게시한 &#x27;Mind the Gap: A Closer Look at Tokenization for Multiple-Choice Question Answering with LLMs&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-19 13:12:21+0900">2025년 9월 19일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLM Evaluation</span><span class="page__taxonomy-item">#<!-- -->Multiple-Choice QA</span><span class="page__taxonomy-item">#<!-- -->Tokenization</span><span class="page__taxonomy-item">#<!-- -->Prompt Sensitivity</span><span class="page__taxonomy-item">#<!-- -->Accuracy</span><span class="page__taxonomy-item">#<!-- -->Calibration</span><span class="page__taxonomy-item">#<!-- -->Model Ranking</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-19-FSG-Net_Frequency-Spatial_Synergistic_Gated_Network_for_High-Resolution_Remote_Sensing_Change_Detection/">[논문리뷰] FSG-Net: Frequency-Spatial Synergistic Gated Network for High-Resolution Remote Sensing Change Detection</a></h2><div class="archive__item-excerpt">Zhewei Zhang이 [arXiv]에 게시한 &#x27;FSG-Net: Frequency-Spatial Synergistic Gated Network for High-Resolution Remote Sensing Change Detection&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-19 13:12:21+0900">2025년 9월 19일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Change Detection</span><span class="page__taxonomy-item">#<!-- -->Remote Sensing</span><span class="page__taxonomy-item">#<!-- -->Frequency-Spatial Analysis</span><span class="page__taxonomy-item">#<!-- -->Wavelet Transform</span><span class="page__taxonomy-item">#<!-- -->Attention Mechanism</span><span class="page__taxonomy-item">#<!-- -->Gated Fusion</span><span class="page__taxonomy-item">#<!-- -->Deep Learning</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-19-FlowRL_Matching_Reward_Distributions_for_LLM_Reasoning/">[논문리뷰] FlowRL: Matching Reward Distributions for LLM Reasoning</a></h2><div class="archive__item-excerpt">Hengli Li이 [arXiv]에 게시한 &#x27;FlowRL: Matching Reward Distributions for LLM Reasoning&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-19 13:12:21+0900">2025년 9월 19일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Reward Distribution Matching</span><span class="page__taxonomy-item">#<!-- -->GFlowNets</span><span class="page__taxonomy-item">#<!-- -->Mode Collapse</span><span class="page__taxonomy-item">#<!-- -->Diverse Reasoning</span><span class="page__taxonomy-item">#<!-- -->Flow-Balanced Optimization</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-19-FinSearchComp_Towards_a_Realistic_Expert-Level_Evaluation_of_Financial_Search_and_Reasoning/">[논문리뷰] FinSearchComp: Towards a Realistic, Expert-Level Evaluation of Financial Search and Reasoning</a></h2><div class="archive__item-excerpt">Jiashuo Liu이 [arXiv]에 게시한 &#x27;FinSearchComp: Towards a Realistic, Expert-Level Evaluation of Financial Search and Reasoning&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-19 13:12:21+0900">2025년 9월 19일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Financial LLMs</span><span class="page__taxonomy-item">#<!-- -->Agent Benchmarking</span><span class="page__taxonomy-item">#<!-- -->Open-domain Search</span><span class="page__taxonomy-item">#<!-- -->Financial Reasoning</span><span class="page__taxonomy-item">#<!-- -->Time-Sensitive Data</span><span class="page__taxonomy-item">#<!-- -->Multi-hop QA</span><span class="page__taxonomy-item">#<!-- -->Tool Use</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-19-Evolving_Language_Models_without_Labels_Majority_Drives_Selection_Novelty_Promotes_Variation/">[논문리뷰] Evolving Language Models without Labels: Majority Drives Selection, Novelty Promotes Variation</a></h2><div class="archive__item-excerpt">Kishan Panaganti이 [arXiv]에 게시한 &#x27;Evolving Language Models without Labels: Majority Drives Selection, Novelty Promotes Variation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-19 13:12:21+0900">2025년 9월 19일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Label-free Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->LLMs</span><span class="page__taxonomy-item">#<!-- -->Self-improvement</span><span class="page__taxonomy-item">#<!-- -->Entropy Collapse</span><span class="page__taxonomy-item">#<!-- -->Novelty Reward</span><span class="page__taxonomy-item">#<!-- -->Test-Time RL</span><span class="page__taxonomy-item">#<!-- -->GRPO</span><span class="page__taxonomy-item">#<!-- -->Evolutionary Computing Principles</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-19-EchoVLM_Dynamic_Mixture-of-Experts_Vision-Language_Model_for_Universal_Ultrasound_Intelligence/">[논문리뷰] EchoVLM: Dynamic Mixture-of-Experts Vision-Language Model for Universal Ultrasound Intelligence</a></h2><div class="archive__item-excerpt">Qinghua Huang이 [arXiv]에 게시한 &#x27;EchoVLM: Dynamic Mixture-of-Experts Vision-Language Model for Universal Ultrasound Intelligence&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-19 13:12:21+0900">2025년 9월 19일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Vision-Language Models</span><span class="page__taxonomy-item">#<!-- -->Ultrasound Imaging</span><span class="page__taxonomy-item">#<!-- -->Medical Diagnosis</span><span class="page__taxonomy-item">#<!-- -->Mixture-of-Experts (MoE)</span><span class="page__taxonomy-item">#<!-- -->Instruction Tuning</span><span class="page__taxonomy-item">#<!-- -->Multimodal AI</span><span class="page__taxonomy-item">#<!-- -->Report Generation</span><span class="page__taxonomy-item">#<!-- -->VQA</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-19-AToken_A_Unified_Tokenizer_for_Vision/">[논문리뷰] AToken: A Unified Tokenizer for Vision</a></h2><div class="archive__item-excerpt">Mingze Xu이 [arXiv]에 게시한 &#x27;AToken: A Unified Tokenizer for Vision&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-19 13:12:21+0900">2025년 9월 19일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Unified Visual Tokenizer</span><span class="page__taxonomy-item">#<!-- -->Multimodal AI</span><span class="page__taxonomy-item">#<!-- -->Transformer Architecture</span><span class="page__taxonomy-item">#<!-- -->4D Representation</span><span class="page__taxonomy-item">#<!-- -->Adversarial-free Training</span><span class="page__taxonomy-item">#<!-- -->Reconstruction</span><span class="page__taxonomy-item">#<!-- -->Semantic Understanding</span><span class="page__taxonomy-item">#<!-- -->Generative Models</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-18-Wan-Animate_Unified_Character_Animation_and_Replacement_with_Holistic_Replication/">[논문리뷰] Wan-Animate: Unified Character Animation and Replacement with Holistic Replication</a></h2><div class="archive__item-excerpt">Mingyang Huang이 [arXiv]에 게시한 &#x27;Wan-Animate: Unified Character Animation and Replacement with Holistic Replication&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-18 13:07:00+0900">2025년 9월 18일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Character Animation</span><span class="page__taxonomy-item">#<!-- -->Video Replacement</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->Transformer</span><span class="page__taxonomy-item">#<!-- -->DiT</span><span class="page__taxonomy-item">#<!-- -->Relighting LoRA</span><span class="page__taxonomy-item">#<!-- -->Holistic Replication</span><span class="page__taxonomy-item">#<!-- -->Open-Source</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-18-THOR_Tool-Integrated_Hierarchical_Optimization_via_RL_for_Mathematical_Reasoning/">[논문리뷰] THOR: Tool-Integrated Hierarchical Optimization via RL for Mathematical Reasoning</a></h2><div class="archive__item-excerpt">Yicheng Pan이 [arXiv]에 게시한 &#x27;THOR: Tool-Integrated Hierarchical Optimization via RL for Mathematical Reasoning&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-18 13:07:00+0900">2025년 9월 18일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Mathematical Reasoning</span><span class="page__taxonomy-item">#<!-- -->Tool-Integrated Reasoning</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Hierarchical Optimization</span><span class="page__taxonomy-item">#<!-- -->Self-Correction</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Code Generation</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-18-SteeringControl_Holistic_Evaluation_of_Alignment_Steering_in_LLMs/">[논문리뷰] SteeringControl: Holistic Evaluation of Alignment Steering in LLMs</a></h2><div class="archive__item-excerpt">Zhun Wang이 [arXiv]에 게시한 &#x27;SteeringControl: Holistic Evaluation of Alignment Steering in LLMs&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-18 13:07:00+0900">2025년 9월 18일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLM Alignment</span><span class="page__taxonomy-item">#<!-- -->Representation Steering</span><span class="page__taxonomy-item">#<!-- -->Benchmark</span><span class="page__taxonomy-item">#<!-- -->Behavioral Entanglement</span><span class="page__taxonomy-item">#<!-- -->Bias Mitigation</span><span class="page__taxonomy-item">#<!-- -->Harmful Generation</span><span class="page__taxonomy-item">#<!-- -->Hallucination Control</span><span class="page__taxonomy-item">#<!-- -->Modular Framework</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-18-Scrub_It_Out_Erasing_Sensitive_Memorization_in_Code_Language_Models_via_Machine_Unlearning/">[논문리뷰] Scrub It Out! Erasing Sensitive Memorization in Code Language Models via Machine Unlearning</a></h2><div class="archive__item-excerpt">Zhou Yang이 [arXiv]에 게시한 &#x27;Scrub It Out! Erasing Sensitive Memorization in Code Language Models via Machine Unlearning&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-18 13:07:00+0900">2025년 9월 18일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Code Language Models</span><span class="page__taxonomy-item">#<!-- -->Machine Unlearning</span><span class="page__taxonomy-item">#<!-- -->Sensitive Memorization</span><span class="page__taxonomy-item">#<!-- -->Privacy</span><span class="page__taxonomy-item">#<!-- -->Gradient Ascent</span><span class="page__taxonomy-item">#<!-- -->Model Utility</span><span class="page__taxonomy-item">#<!-- -->Code Generation</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-18-SAIL-VL2_Technical_Report/">[논문리뷰] SAIL-VL2 Technical Report</a></h2><div class="archive__item-excerpt">Zijian Kang이 [arXiv]에 게시한 &#x27;SAIL-VL2 Technical Report&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-18 13:07:00+0900">2025년 9월 18일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Vision-Language Model</span><span class="page__taxonomy-item">#<!-- -->Multimodal Understanding</span><span class="page__taxonomy-item">#<!-- -->Mixture-of-Experts</span><span class="page__taxonomy-item">#<!-- -->Progressive Training</span><span class="page__taxonomy-item">#<!-- -->Data Curation</span><span class="page__taxonomy-item">#<!-- -->Supervised Fine-tuning</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->SAIL-ViT</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-18-PANORAMA_The_Rise_of_Omnidirectional_Vision_in_the_Embodied_AI_Era/">[논문리뷰] PANORAMA: The Rise of Omnidirectional Vision in the Embodied AI Era</a></h2><div class="archive__item-excerpt">Zihao Dongfang이 [arXiv]에 게시한 &#x27;PANORAMA: The Rise of Omnidirectional Vision in the Embodied AI Era&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-18 13:07:00+0900">2025년 9월 18일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Omnidirectional Vision</span><span class="page__taxonomy-item">#<!-- -->Embodied AI</span><span class="page__taxonomy-item">#<!-- -->Panoramic Perception</span><span class="page__taxonomy-item">#<!-- -->Multi-modal Learning</span><span class="page__taxonomy-item">#<!-- -->Dataset Development</span><span class="page__taxonomy-item">#<!-- -->Robot Navigation</span><span class="page__taxonomy-item">#<!-- -->Spatial Reasoning</span><span class="page__taxonomy-item">#<!-- -->System Architecture</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-18-MARS2_2025_Challenge_on_Multimodal_Reasoning_Datasets_Methods_Results_Discussion_and_Outlook/">[논문리뷰] MARS2 2025 Challenge on Multimodal Reasoning: Datasets, Methods, Results, Discussion, and Outlook</a></h2><div class="archive__item-excerpt">Bowen Zhou이 [arXiv]에 게시한 &#x27;MARS2 2025 Challenge on Multimodal Reasoning: Datasets, Methods, Results, Discussion, and Outlook&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-18 13:07:00+0900">2025년 9월 18일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Multimodal Reasoning</span><span class="page__taxonomy-item">#<!-- -->Large Language Models (LLMs)</span><span class="page__taxonomy-item">#<!-- -->Multimodal Large Language Models (MLLMs)</span><span class="page__taxonomy-item">#<!-- -->Visual Grounding</span><span class="page__taxonomy-item">#<!-- -->Visual Question Answering</span><span class="page__taxonomy-item">#<!-- -->Advertisement Video Analysis</span><span class="page__taxonomy-item">#<!-- -->Real-world Scenarios</span><span class="page__taxonomy-item">#<!-- -->Challenge Benchmark</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-18-Improving_Context_Fidelity_via_Native_Retrieval-Augmented_Reasoning/">[논문리뷰] Improving Context Fidelity via Native Retrieval-Augmented Reasoning</a></h2><div class="archive__item-excerpt">Xiangru Tang이 [arXiv]에 게시한 &#x27;Improving Context Fidelity via Native Retrieval-Augmented Reasoning&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-18 13:07:00+0900">2025년 9월 18일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Context Fidelity</span><span class="page__taxonomy-item">#<!-- -->Retrieval-Augmented Generation (RAG)</span><span class="page__taxonomy-item">#<!-- -->Large Language Models (LLMs)</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning (RL)</span><span class="page__taxonomy-item">#<!-- -->Supervised Fine-Tuning (SFT)</span><span class="page__taxonomy-item">#<!-- -->Hallucination</span><span class="page__taxonomy-item">#<!-- -->Question Answering</span><span class="page__taxonomy-item">#<!-- -->In-context Retrieval</span><span class="page__taxonomy-item">#<!-- -->Curriculum Learning</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-18-Hala_Technical_Report_Building_Arabic-Centric_Instruction_Translation_Models_at_Scale/">[논문리뷰] Hala Technical Report: Building Arabic-Centric Instruction &amp; Translation Models at Scale</a></h2><div class="archive__item-excerpt">Bernard Ghanem이 [arXiv]에 게시한 &#x27;Hala Technical Report: Building Arabic-Centric Instruction &amp; Translation Models at Scale&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-18 13:07:00+0900">2025년 9월 18일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Arabic NLP</span><span class="page__taxonomy-item">#<!-- -->Instruction Tuning</span><span class="page__taxonomy-item">#<!-- -->Machine Translation</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->FP8 Quantization</span><span class="page__taxonomy-item">#<!-- -->Data Bootstrapping</span><span class="page__taxonomy-item">#<!-- -->Model Merging</span><span class="page__taxonomy-item">#<!-- -->Language-Centric AI</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-18-GenExam_A_Multidisciplinary_Text-to-Image_Exam/">[논문리뷰] GenExam: A Multidisciplinary Text-to-Image Exam</a></h2><div class="archive__item-excerpt">Yu Qiao이 [arXiv]에 게시한 &#x27;GenExam: A Multidisciplinary Text-to-Image Exam&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-18 13:07:00+0900">2025년 9월 18일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Text-to-Image Generation</span><span class="page__taxonomy-item">#<!-- -->Multidisciplinary</span><span class="page__taxonomy-item">#<!-- -->Benchmark</span><span class="page__taxonomy-item">#<!-- -->Evaluation</span><span class="page__taxonomy-item">#<!-- -->AGI</span><span class="page__taxonomy-item">#<!-- -->Reasoning</span><span class="page__taxonomy-item">#<!-- -->Scoring System</span><span class="page__taxonomy-item">#<!-- -->Visual Question Answering</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-17-WebWeaver_Structuring_Web-Scale_Evidence_with_Dynamic_Outlines_for_Open-Ended_Deep_Research/">[논문리뷰] WebWeaver: Structuring Web-Scale Evidence with Dynamic Outlines for Open-Ended Deep Research</a></h2><div class="archive__item-excerpt">Houquan Zhou이 [arXiv]에 게시한 &#x27;WebWeaver: Structuring Web-Scale Evidence with Dynamic Outlines for Open-Ended Deep Research&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-17 13:16:01+0900">2025년 9월 17일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Open-Ended Deep Research</span><span class="page__taxonomy-item">#<!-- -->LLM Agents</span><span class="page__taxonomy-item">#<!-- -->Dynamic Outline</span><span class="page__taxonomy-item">#<!-- -->Evidence Acquisition</span><span class="page__taxonomy-item">#<!-- -->Hierarchical Writing</span><span class="page__taxonomy-item">#<!-- -->Memory Bank</span><span class="page__taxonomy-item">#<!-- -->State-of-the-Art</span><span class="page__taxonomy-item">#<!-- -->Supervised Fine-Tuning</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-17-WebSailor-V2_Bridging_the_Chasm_to_Proprietary_Agents_via_Synthetic_Data_and_Scalable_Reinforcement_Learning/">[논문리뷰] WebSailor-V2: Bridging the Chasm to Proprietary Agents via Synthetic Data and Scalable Reinforcement Learning</a></h2><div class="archive__item-excerpt">Huifeng Yin이 [arXiv]에 게시한 &#x27;WebSailor-V2: Bridging the Chasm to Proprietary Agents via Synthetic Data and Scalable Reinforcement Learning&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-17 13:16:01+0900">2025년 9월 17일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Web Agents</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Synthetic Data</span><span class="page__taxonomy-item">#<!-- -->Knowledge Graphs</span><span class="page__taxonomy-item">#<!-- -->LLMs</span><span class="page__taxonomy-item">#<!-- -->Supervised Fine-Tuning</span><span class="page__taxonomy-item">#<!-- -->Sim-to-Real Transfer</span><span class="page__taxonomy-item">#<!-- -->Agentic AI</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-17-WebResearcher_Unleashing_unbounded_reasoning_capability_in_Long-Horizon_Agents/">[논문리뷰] WebResearcher: Unleashing unbounded reasoning capability in Long-Horizon Agents</a></h2><div class="archive__item-excerpt">Wenbiao Yin이 [arXiv]에 게시한 &#x27;WebResearcher: Unleashing unbounded reasoning capability in Long-Horizon Agents&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-17 13:16:01+0900">2025년 9월 17일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Agentic AI</span><span class="page__taxonomy-item">#<!-- -->Deep Research</span><span class="page__taxonomy-item">#<!-- -->Iterative Reasoning</span><span class="page__taxonomy-item">#<!-- -->Long-Horizon Tasks</span><span class="page__taxonomy-item">#<!-- -->Context Management</span><span class="page__taxonomy-item">#<!-- -->Data Synthesis</span><span class="page__taxonomy-item">#<!-- -->Tool-Augmented LLMs</span><span class="page__taxonomy-item">#<!-- -->Markov Decision Process</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-17-Towards_General_Agentic_Intelligence_via_Environment_Scaling/">[논문리뷰] Towards General Agentic Intelligence via Environment Scaling</a></h2><div class="archive__item-excerpt">Guangyu Li이 [arXiv]에 게시한 &#x27;Towards General Agentic Intelligence via Environment Scaling&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-17 13:16:01+0900">2025년 9월 17일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Agentic AI</span><span class="page__taxonomy-item">#<!-- -->Environment Scaling</span><span class="page__taxonomy-item">#<!-- -->Function Calling</span><span class="page__taxonomy-item">#<!-- -->Tool Use</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Synthetic Data Generation</span><span class="page__taxonomy-item">#<!-- -->Supervised Fine-tuning</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-17-Single-stream_Policy_Optimization/">[논문리뷰] Single-stream Policy Optimization</a></h2><div class="archive__item-excerpt">Zihan Ding이 [arXiv]에 게시한 &#x27;Single-stream Policy Optimization&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-17 13:16:01+0900">2025년 9월 17일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->LLM Optimization</span><span class="page__taxonomy-item">#<!-- -->Policy Gradient</span><span class="page__taxonomy-item">#<!-- -->Variance Reduction</span><span class="page__taxonomy-item">#<!-- -->Adaptive Sampling</span><span class="page__taxonomy-item">#<!-- -->Scalability</span><span class="page__taxonomy-item">#<!-- -->Agentic Systems</span><span class="page__taxonomy-item">#<!-- -->RLVR</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-17-Scaling_Agents_via_Continual_Pre-training/">[논문리뷰] Scaling Agents via Continual Pre-training</a></h2><div class="archive__item-excerpt">Guangyu Li이 [arXiv]에 게시한 &#x27;Scaling Agents via Continual Pre-training&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-17 13:16:01+0900">2025년 9월 17일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Agentic LLMs</span><span class="page__taxonomy-item">#<!-- -->Continual Pre-training</span><span class="page__taxonomy-item">#<!-- -->Deep Research Agents</span><span class="page__taxonomy-item">#<!-- -->Tool Use</span><span class="page__taxonomy-item">#<!-- -->Multi-step Reasoning</span><span class="page__taxonomy-item">#<!-- -->Data Synthesis</span><span class="page__taxonomy-item">#<!-- -->Scaling Laws</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-17-ReSum_Unlocking_Long-Horizon_Search_Intelligence_via_Context_Summarization/">[논문리뷰] ReSum: Unlocking Long-Horizon Search Intelligence via Context Summarization</a></h2><div class="archive__item-excerpt">Litu Ou이 [arXiv]에 게시한 &#x27;ReSum: Unlocking Long-Horizon Search Intelligence via Context Summarization&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-17 13:16:01+0900">2025년 9월 17일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLM Agents</span><span class="page__taxonomy-item">#<!-- -->Context Management</span><span class="page__taxonomy-item">#<!-- -->Summarization</span><span class="page__taxonomy-item">#<!-- -->ReAct</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Web Search</span><span class="page__taxonomy-item">#<!-- -->Long-Horizon Reasoning</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-17-Optimal_Brain_Restoration_for_Joint_Quantization_and_Sparsification_of_LLMs/">[논문리뷰] Optimal Brain Restoration for Joint Quantization and Sparsification of LLMs</a></h2><div class="archive__item-excerpt">Luca Benini이 [arXiv]에 게시한 &#x27;Optimal Brain Restoration for Joint Quantization and Sparsification of LLMs&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-17 13:16:01+0900">2025년 9월 17일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLM Compression</span><span class="page__taxonomy-item">#<!-- -->Quantization</span><span class="page__taxonomy-item">#<!-- -->Sparsification</span><span class="page__taxonomy-item">#<!-- -->Post-training Quantization</span><span class="page__taxonomy-item">#<!-- -->Hessian-based Optimization</span><span class="page__taxonomy-item">#<!-- -->Error Compensation</span><span class="page__taxonomy-item">#<!-- -->Low-bit LLMs</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-17-Multiple_Instance_Learning_Framework_with_Masked_Hard_Instance_Mining_for_Gigapixel_Histopathology_Image_Analysis/">[논문리뷰] Multiple Instance Learning Framework with Masked Hard Instance Mining for Gigapixel Histopathology Image Analysis</a></h2><div class="archive__item-excerpt">Bo Liu이 [arXiv]에 게시한 &#x27;Multiple Instance Learning Framework with Masked Hard Instance Mining for Gigapixel Histopathology Image Analysis&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-17 13:16:01+0900">2025년 9월 17일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Multiple Instance Learning</span><span class="page__taxonomy-item">#<!-- -->Hard Instance Mining</span><span class="page__taxonomy-item">#<!-- -->Computational Pathology</span><span class="page__taxonomy-item">#<!-- -->Whole Slide Images</span><span class="page__taxonomy-item">#<!-- -->Masked Learning</span><span class="page__taxonomy-item">#<!-- -->Siamese Network</span><span class="page__taxonomy-item">#<!-- -->Medical Image Analysis</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-17-Multimodal_Reasoning_for_Science_Technical_Report_and_1st_Place_Solution_to_the_ICML_2025_SeePhys_Challenge/">[논문리뷰] Multimodal Reasoning for Science: Technical Report and 1st Place Solution to the ICML 2025 SeePhys Challenge</a></h2><div class="archive__item-excerpt">Wentao Zhang이 [arXiv]에 게시한 &#x27;Multimodal Reasoning for Science: Technical Report and 1st Place Solution to the ICML 2025 SeePhys Challenge&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-17 13:16:01+0900">2025년 9월 17일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Multimodal Reasoning</span><span class="page__taxonomy-item">#<!-- -->Science AI</span><span class="page__taxonomy-item">#<!-- -->Caption-assisted Reasoning</span><span class="page__taxonomy-item">#<!-- -->SeePhys Challenge</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Visual Question Answering</span><span class="page__taxonomy-item">#<!-- -->Physics Problems</span><span class="page__taxonomy-item">#<!-- -->Cross-modal Alignment</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-17-Hunyuan3D_Studio_End-to-End_AI_Pipeline_for_Game-Ready_3D_Asset_Generation/">[논문리뷰] Hunyuan3D Studio: End-to-End AI Pipeline for Game-Ready 3D Asset Generation</a></h2><div class="archive__item-excerpt">Lixin Xu이 [arXiv]에 게시한 &#x27;Hunyuan3D Studio: End-to-End AI Pipeline for Game-Ready 3D Asset Generation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-17 13:16:01+0900">2025년 9월 17일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->3D Asset Generation</span><span class="page__taxonomy-item">#<!-- -->AI Pipeline</span><span class="page__taxonomy-item">#<!-- -->Generative AI</span><span class="page__taxonomy-item">#<!-- -->Game Development</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->Neural Modules</span><span class="page__taxonomy-item">#<!-- -->Retopology</span><span class="page__taxonomy-item">#<!-- -->UV Unwrapping</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-17-Exact_Coset_Sampling_for_Quantum_Lattice_Algorithms/">[논문리뷰] Exact Coset Sampling for Quantum Lattice Algorithms</a></h2><div class="archive__item-excerpt">Yifan Zhang이 [arXiv]에 게시한 &#x27;Exact Coset Sampling for Quantum Lattice Algorithms&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-17 13:16:01+0900">2025년 9월 17일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Quantum Algorithms</span><span class="page__taxonomy-item">#<!-- -->Lattice Problems</span><span class="page__taxonomy-item">#<!-- -->Coset Sampling</span><span class="page__taxonomy-item">#<!-- -->Quantum Fourier Transform (QFT)</span><span class="page__taxonomy-item">#<!-- -->Modular Arithmetic</span><span class="page__taxonomy-item">#<!-- -->Quantum Cryptography</span><span class="page__taxonomy-item">#<!-- -->Exact Sampling</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-17-EconProver_Towards_More_Economical_Test-Time_Scaling_for_Automated_Theorem_Proving/">[논문리뷰] EconProver: Towards More Economical Test-Time Scaling for Automated Theorem Proving</a></h2><div class="archive__item-excerpt">Shansan Gong이 [arXiv]에 게시한 &#x27;EconProver: Towards More Economical Test-Time Scaling for Automated Theorem Proving&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-17 13:16:01+0900">2025년 9월 17일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Automated Theorem Proving</span><span class="page__taxonomy-item">#<!-- -->LLM</span><span class="page__taxonomy-item">#<!-- -->Test-Time Scaling</span><span class="page__taxonomy-item">#<!-- -->Chain-of-Thought</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Efficiency Optimization</span><span class="page__taxonomy-item">#<!-- -->Token Cost</span><span class="page__taxonomy-item">#<!-- -->Sampling Cost</span><span class="page__taxonomy-item">#<!-- -->Dynamic CoT Switching</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-17-3D_Aware_Region_Prompted_Vision_Language_Model/">[논문리뷰] 3D Aware Region Prompted Vision Language Model</a></h2><div class="archive__item-excerpt">Xiaolong Li이 [arXiv]에 게시한 &#x27;3D Aware Region Prompted Vision Language Model&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-17 13:16:01+0900">2025년 9월 17일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->3D Vision</span><span class="page__taxonomy-item">#<!-- -->Vision-Language Models</span><span class="page__taxonomy-item">#<!-- -->Spatial Reasoning</span><span class="page__taxonomy-item">#<!-- -->Region Prompting</span><span class="page__taxonomy-item">#<!-- -->Multi-view Learning</span><span class="page__taxonomy-item">#<!-- -->Depth Estimation</span><span class="page__taxonomy-item">#<!-- -->Unified Representation</span><span class="page__taxonomy-item">#<!-- -->Generative AI</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-16-UI-S1_Advancing_GUI_Automation_via_Semi-online_Reinforcement_Learning/">[논문리뷰] UI-S1: Advancing GUI Automation via Semi-online Reinforcement Learning</a></h2><div class="archive__item-excerpt">Yongliang Shen이 [arXiv]에 게시한 &#x27;UI-S1: Advancing GUI Automation via Semi-online Reinforcement Learning&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-16 13:16:41+0900">2025년 9월 16일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->GUI Automation</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Semi-online RL</span><span class="page__taxonomy-item">#<!-- -->Offline RL</span><span class="page__taxonomy-item">#<!-- -->Online RL</span><span class="page__taxonomy-item">#<!-- -->Patch Module</span><span class="page__taxonomy-item">#<!-- -->Multi-turn Interaction</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-16-SearchInstruct_Enhancing_Domain_Adaptation_via_Retrieval-Based_Instruction_Dataset_Creation/">[논문리뷰] SearchInstruct: Enhancing Domain Adaptation via Retrieval-Based Instruction Dataset Creation</a></h2><div class="archive__item-excerpt">Heshaam Faili이 [arXiv]에 게시한 &#x27;SearchInstruct: Enhancing Domain Adaptation via Retrieval-Based Instruction Dataset Creation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-16 13:16:41+0900">2025년 9월 16일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLM</span><span class="page__taxonomy-item">#<!-- -->Instruction Tuning</span><span class="page__taxonomy-item">#<!-- -->Domain Adaptation</span><span class="page__taxonomy-item">#<!-- -->Retrieval-Augmented Generation</span><span class="page__taxonomy-item">#<!-- -->Dataset Creation</span><span class="page__taxonomy-item">#<!-- -->Model Editing</span><span class="page__taxonomy-item">#<!-- -->Supervised Fine-Tuning</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-16-PersonaX_Multimodal_Datasets_with_LLM-Inferred_Behavior_Traits/">[논문리뷰] PersonaX: Multimodal Datasets with LLM-Inferred Behavior Traits</a></h2><div class="archive__item-excerpt">Zhenhao Chen이 [arXiv]에 게시한 &#x27;PersonaX: Multimodal Datasets with LLM-Inferred Behavior Traits&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-16 13:16:41+0900">2025년 9월 16일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Multimodal Dataset</span><span class="page__taxonomy-item">#<!-- -->LLM Inference</span><span class="page__taxonomy-item">#<!-- -->Behavioral Traits</span><span class="page__taxonomy-item">#<!-- -->Causal Representation Learning</span><span class="page__taxonomy-item">#<!-- -->Big Five</span><span class="page__taxonomy-item">#<!-- -->Multimodal AI</span><span class="page__taxonomy-item">#<!-- -->Causal Discovery</span><span class="page__taxonomy-item">#<!-- -->Human-Computer Interaction</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-16-OmniWorld_A_Multi-Domain_and_Multi-Modal_Dataset_for_4D_World_Modeling/">[논문리뷰] OmniWorld: A Multi-Domain and Multi-Modal Dataset for 4D World Modeling</a></h2><div class="archive__item-excerpt">Yang Zhou이 [arXiv]에 게시한 &#x27;OmniWorld: A Multi-Domain and Multi-Modal Dataset for 4D World Modeling&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-16 13:16:41+0900">2025년 9월 16일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->4D World Modeling</span><span class="page__taxonomy-item">#<!-- -->Multi-Modal Dataset</span><span class="page__taxonomy-item">#<!-- -->Multi-Domain Data</span><span class="page__taxonomy-item">#<!-- -->Geometric Foundation Models</span><span class="page__taxonomy-item">#<!-- -->Video Generation</span><span class="page__taxonomy-item">#<!-- -->Spatio-Temporal Data</span><span class="page__taxonomy-item">#<!-- -->Dataset Benchmark</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-16-Measuring_Epistemic_Humility_in_Multimodal_Large_Language_Models/">[논문리뷰] Measuring Epistemic Humility in Multimodal Large Language Models</a></h2><div class="archive__item-excerpt">Kaiyang Zhou이 [arXiv]에 게시한 &#x27;Measuring Epistemic Humility in Multimodal Large Language Models&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-16 13:16:41+0900">2025년 9월 16일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Multimodal Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Hallucination</span><span class="page__taxonomy-item">#<!-- -->Epistemic Humility</span><span class="page__taxonomy-item">#<!-- -->Benchmark</span><span class="page__taxonomy-item">#<!-- -->False-Option Rejection</span><span class="page__taxonomy-item">#<!-- -->Visual Question Answering</span><span class="page__taxonomy-item">#<!-- -->Scene Graph</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-16-Lost_in_Embeddings_Information_Loss_in_Vision-Language_Models/">[논문리뷰] Lost in Embeddings: Information Loss in Vision-Language Models</a></h2><div class="archive__item-excerpt">Ivan Vulić이 [arXiv]에 게시한 &#x27;Lost in Embeddings: Information Loss in Vision-Language Models&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-16 13:16:41+0900">2025년 9월 16일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Vision-Language Models</span><span class="page__taxonomy-item">#<!-- -->Information Loss</span><span class="page__taxonomy-item">#<!-- -->Embeddings</span><span class="page__taxonomy-item">#<!-- -->Connectors</span><span class="page__taxonomy-item">#<!-- -->k-NN Overlap Ratio</span><span class="page__taxonomy-item">#<!-- -->Embedding Reconstruction</span><span class="page__taxonomy-item">#<!-- -->Multimodal AI</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-16-Look_Again_Think_Slowly_Enhancing_Visual_Reflection_in_Vision-Language_Models/">[논문리뷰] Look Again, Think Slowly: Enhancing Visual Reflection in Vision-Language Models</a></h2><div class="archive__item-excerpt">Shuo Ren이 [arXiv]에 게시한 &#x27;Look Again, Think Slowly: Enhancing Visual Reflection in Vision-Language Models&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-16 13:16:41+0900">2025년 9월 16일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Vision-Language Models</span><span class="page__taxonomy-item">#<!-- -->Visual Reasoning</span><span class="page__taxonomy-item">#<!-- -->Reflection</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Visual Attention</span><span class="page__taxonomy-item">#<!-- -->Slow Thinking</span><span class="page__taxonomy-item">#<!-- -->Multimodal Agents</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-16-Locality_in_Image_Diffusion_Models_Emerges_from_Data_Statistics/">[논문리뷰] Locality in Image Diffusion Models Emerges from Data Statistics</a></h2><div class="archive__item-excerpt">Vincent Sitzmann이 [arXiv]에 게시한 &#x27;Locality in Image Diffusion Models Emerges from Data Statistics&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-16 13:16:41+0900">2025년 9월 16일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->Locality</span><span class="page__taxonomy-item">#<!-- -->Data Statistics</span><span class="page__taxonomy-item">#<!-- -->Optimal Denoiser</span><span class="page__taxonomy-item">#<!-- -->Wiener Filter</span><span class="page__taxonomy-item">#<!-- -->Sensitivity Fields</span><span class="page__taxonomy-item">#<!-- -->Generative Models</span><span class="page__taxonomy-item">#<!-- -->Inductive Bias</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-16-Learning_to_Optimize_Multi-Objective_Alignment_Through_Dynamic_Reward_Weighting/">[논문리뷰] Learning to Optimize Multi-Objective Alignment Through Dynamic Reward Weighting</a></h2><div class="archive__item-excerpt">Changlong Yu이 [arXiv]에 게시한 &#x27;Learning to Optimize Multi-Objective Alignment Through Dynamic Reward Weighting&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-16 13:16:41+0900">2025년 9월 16일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Multi-objective Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->LLM Alignment</span><span class="page__taxonomy-item">#<!-- -->Dynamic Reward Weighting</span><span class="page__taxonomy-item">#<!-- -->Pareto Front Optimization</span><span class="page__taxonomy-item">#<!-- -->Hypervolume Indicator</span><span class="page__taxonomy-item">#<!-- -->Gradient-based Optimization</span><span class="page__taxonomy-item">#<!-- -->Online RL</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-16-LazyDrag_Enabling_Stable_Drag-Based_Editing_on_Multi-Modal_Diffusion_Transformers_via_Explicit_Correspondence/">[논문리뷰] LazyDrag: Enabling Stable Drag-Based Editing on Multi-Modal Diffusion Transformers via Explicit Correspondence</a></h2><div class="archive__item-excerpt">Lionel M. Ni이 [arXiv]에 게시한 &#x27;LazyDrag: Enabling Stable Drag-Based Editing on Multi-Modal Diffusion Transformers via Explicit Correspondence&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-16 13:16:41+0900">2025년 9월 16일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Image Editing</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->Multi-Modal Transformers</span><span class="page__taxonomy-item">#<!-- -->Drag-based Editing</span><span class="page__taxonomy-item">#<!-- -->Explicit Correspondence</span><span class="page__taxonomy-item">#<!-- -->Attention Control</span><span class="page__taxonomy-item">#<!-- -->Identity Preservation</span><span class="page__taxonomy-item">#<!-- -->Training-Free</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-16-InternScenes_A_Large-scale_Simulatable_Indoor_Scene_Dataset_with_Realistic_Layouts/">[논문리뷰] InternScenes: A Large-scale Simulatable Indoor Scene Dataset with Realistic Layouts</a></h2><div class="archive__item-excerpt">Wenzhe Cai이 [arXiv]에 게시한 &#x27;InternScenes: A Large-scale Simulatable Indoor Scene Dataset with Realistic Layouts&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-16 13:16:41+0900">2025년 9월 16일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Embodied AI</span><span class="page__taxonomy-item">#<!-- -->3D Scene Dataset</span><span class="page__taxonomy-item">#<!-- -->Simulation Environment</span><span class="page__taxonomy-item">#<!-- -->Scene Generation</span><span class="page__taxonomy-item">#<!-- -->Point-Goal Navigation</span><span class="page__taxonomy-item">#<!-- -->Realistic Layouts</span><span class="page__taxonomy-item">#<!-- -->Object Interaction</span><span class="page__taxonomy-item">#<!-- -->Real-to-Sim</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-16-GAPrune_Gradient-Alignment_Pruning_for_Domain-Aware_Embeddings/">[논문리뷰] GAPrune: Gradient-Alignment Pruning for Domain-Aware Embeddings</a></h2><div class="archive__item-excerpt">Yixuan Tang이 [arXiv]에 게시한 &#x27;GAPrune: Gradient-Alignment Pruning for Domain-Aware Embeddings&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-16 13:16:41+0900">2025년 9월 16일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Model Pruning</span><span class="page__taxonomy-item">#<!-- -->Domain Adaptation</span><span class="page__taxonomy-item">#<!-- -->Embedding Models</span><span class="page__taxonomy-item">#<!-- -->Gradient Alignment</span><span class="page__taxonomy-item">#<!-- -->Fisher Information</span><span class="page__taxonomy-item">#<!-- -->Model Compression</span><span class="page__taxonomy-item">#<!-- -->LLMs</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-16-EthicsMH_A_Pilot_Benchmark_for_Ethical_Reasoning_in_Mental_Health_AI/">[논문리뷰] EthicsMH: A Pilot Benchmark for Ethical Reasoning in Mental Health AI</a></h2><div class="archive__item-excerpt">UVSKKR이 [arXiv]에 게시한 &#x27;EthicsMH: A Pilot Benchmark for Ethical Reasoning in Mental Health AI&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-16 13:16:41+0900">2025년 9월 16일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Ethical Reasoning</span><span class="page__taxonomy-item">#<!-- -->Mental Health AI</span><span class="page__taxonomy-item">#<!-- -->Benchmark Dataset</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->AI Ethics</span><span class="page__taxonomy-item">#<!-- -->Clinical Decision Support</span><span class="page__taxonomy-item">#<!-- -->Human-in-the-loop</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-16-Dr.V_A_Hierarchical_Perception-Temporal-Cognition_Framework_to_Diagnose_Video_Hallucination_by_Fine-grained_Spatial-Temporal_Grounding">[논문리뷰] Dr.V: A Hierarchical Perception-Temporal-Cognition Framework to Diagnose Video Hallucination by Fine-grained Spatial-Temporal Grounding</a></h2><div class="archive__item-excerpt">Li Zheng이 [arXiv]에 게시한 &#x27;Dr.V: A Hierarchical Perception-Temporal-Cognition Framework to Diagnose Video Hallucination by Fine-grained Spatial-Temporal Grounding&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-16 13:16:41+0900">2025년 9월 16일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Video Hallucination</span><span class="page__taxonomy-item">#<!-- -->Large Video Models (LVMs)</span><span class="page__taxonomy-item">#<!-- -->Hierarchical Reasoning</span><span class="page__taxonomy-item">#<!-- -->Spatial-Temporal Grounding</span><span class="page__taxonomy-item">#<!-- -->Diagnostic Framework</span><span class="page__taxonomy-item">#<!-- -->Benchmark Dataset</span><span class="page__taxonomy-item">#<!-- -->Multimodal AI</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-16-CognitiveSky_Scalable_Sentiment_and_Narrative_Analysis_for_Decentralized_Social_Media/">[논문리뷰] CognitiveSky: Scalable Sentiment and Narrative Analysis for Decentralized Social Media</a></h2><div class="archive__item-excerpt">Subasish Das이 [arXiv]에 게시한 &#x27;CognitiveSky: Scalable Sentiment and Narrative Analysis for Decentralized Social Media&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-16 13:16:41+0900">2025년 9월 16일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Sentiment Analysis</span><span class="page__taxonomy-item">#<!-- -->Narrative Analysis</span><span class="page__taxonomy-item">#<!-- -->Decentralized Social Media</span><span class="page__taxonomy-item">#<!-- -->Bluesky</span><span class="page__taxonomy-item">#<!-- -->Transformer Models</span><span class="page__taxonomy-item">#<!-- -->Topic Modeling</span><span class="page__taxonomy-item">#<!-- -->Real-time Processing</span><span class="page__taxonomy-item">#<!-- -->Data Visualization</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-15-X-Part_high_fidelity_and_structure_coherent_shape_decomposition/">[논문리뷰] X-Part: high fidelity and structure coherent shape decomposition</a></h2><div class="archive__item-excerpt">Yunhan Yang이 [arXiv]에 게시한 &#x27;X-Part: high fidelity and structure coherent shape decomposition&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-15 13:12:08+0900">2025년 9월 15일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->3D Shape Decomposition</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->Part-level Generation</span><span class="page__taxonomy-item">#<!-- -->Controllable Generation</span><span class="page__taxonomy-item">#<!-- -->Bounding Box Prompts</span><span class="page__taxonomy-item">#<!-- -->Semantic Features</span><span class="page__taxonomy-item">#<!-- -->Interactive Editing</span><span class="page__taxonomy-item">#<!-- -->Generative AI</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-15-VStyle_A_Benchmark_for_Voice_Style_Adaptation_with_Spoken_Instructions/">[논문리뷰] VStyle: A Benchmark for Voice Style Adaptation with Spoken Instructions</a></h2><div class="archive__item-excerpt">Dong Zhang이 [arXiv]에 게시한 &#x27;VStyle: A Benchmark for Voice Style Adaptation with Spoken Instructions&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-15 13:12:08+0900">2025년 9월 15일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Voice Style Adaptation</span><span class="page__taxonomy-item">#<!-- -->Spoken Language Models</span><span class="page__taxonomy-item">#<!-- -->Benchmark</span><span class="page__taxonomy-item">#<!-- -->LALM-as-a-Judge</span><span class="page__taxonomy-item">#<!-- -->Speech Generation</span><span class="page__taxonomy-item">#<!-- -->Multilingual</span><span class="page__taxonomy-item">#<!-- -->Evaluation Framework</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-15-Virtual_Agent_Economies/">[논문리뷰] Virtual Agent Economies</a></h2><div class="archive__item-excerpt">William A. Cunningham이 [arXiv]에 게시한 &#x27;Virtual Agent Economies&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-15 13:12:08+0900">2025년 9월 15일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->AI Agents</span><span class="page__taxonomy-item">#<!-- -->Virtual Economy</span><span class="page__taxonomy-item">#<!-- -->Multi-Agent Systems</span><span class="page__taxonomy-item">#<!-- -->Economic Mechanisms</span><span class="page__taxonomy-item">#<!-- -->Governance</span><span class="page__taxonomy-item">#<!-- -->Blockchain</span><span class="page__taxonomy-item">#<!-- -->Resource Allocation</span><span class="page__taxonomy-item">#<!-- -->Agent Alignment</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-15-The_Illusion_of_Diminishing_Returns_Measuring_Long_Horizon_Execution_in_LLMs/">[논문리뷰] The Illusion of Diminishing Returns: Measuring Long Horizon Execution in LLMs</a></h2><div class="archive__item-excerpt">Jonas Geiping이 [arXiv]에 게시한 &#x27;The Illusion of Diminishing Returns: Measuring Long Horizon Execution in LLMs&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-15 13:12:08+0900">2025년 9월 15일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Long-Horizon Tasks</span><span class="page__taxonomy-item">#<!-- -->Execution Capability</span><span class="page__taxonomy-item">#<!-- -->Scaling Laws</span><span class="page__taxonomy-item">#<!-- -->Self-Conditioning</span><span class="page__taxonomy-item">#<!-- -->Thinking Models</span><span class="page__taxonomy-item">#<!-- -->Agentic AI</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-15-QuantAgent_Price-Driven_Multi-Agent_LLMs_for_High-Frequency_Trading/">[논문리뷰] QuantAgent: Price-Driven Multi-Agent LLMs for High-Frequency Trading</a></h2><div class="archive__item-excerpt">Chenyu You이 [arXiv]에 게시한 &#x27;QuantAgent: Price-Driven Multi-Agent LLMs for High-Frequency Trading&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-15 13:12:08+0900">2025년 9월 15일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->High-Frequency Trading</span><span class="page__taxonomy-item">#<!-- -->Multi-Agent Systems</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Technical Analysis</span><span class="page__taxonomy-item">#<!-- -->Algorithmic Trading</span><span class="page__taxonomy-item">#<!-- -->Financial Reasoning</span><span class="page__taxonomy-item">#<!-- -->Price-Driven Signals</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-15-MCP-AgentBench_Evaluating_Real-World_Language_Agent_Performance_with_MCP-Mediated_Tools/">[논문리뷰] MCP-AgentBench: Evaluating Real-World Language Agent Performance with MCP-Mediated Tools</a></h2><div class="archive__item-excerpt">Xiaorui Wang이 [arXiv]에 게시한 &#x27;MCP-AgentBench: Evaluating Real-World Language Agent Performance with MCP-Mediated Tools&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-15 13:12:08+0900">2025년 9월 15일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Language Agents</span><span class="page__taxonomy-item">#<!-- -->Tool Use</span><span class="page__taxonomy-item">#<!-- -->Benchmarks</span><span class="page__taxonomy-item">#<!-- -->Model Context Protocol (MCP)</span><span class="page__taxonomy-item">#<!-- -->LLM Evaluation</span><span class="page__taxonomy-item">#<!-- -->Agentic AI</span><span class="page__taxonomy-item">#<!-- -->Real-World Performance</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-15-LoFT_Parameter-Efficient_Fine-Tuning_for_Long-tailed_Semi-Supervised_Learning_in_Open-World_Scenarios/">[논문리뷰] LoFT: Parameter-Efficient Fine-Tuning for Long-tailed Semi-Supervised Learning in Open-World Scenarios</a></h2><div class="archive__item-excerpt">Bing Su이 [arXiv]에 게시한 &#x27;LoFT: Parameter-Efficient Fine-Tuning for Long-tailed Semi-Supervised Learning in Open-World Scenarios&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-15 13:12:08+0900">2025년 9월 15일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Long-tailed Learning</span><span class="page__taxonomy-item">#<!-- -->Semi-Supervised Learning</span><span class="page__taxonomy-item">#<!-- -->Parameter-Efficient Fine-Tuning</span><span class="page__taxonomy-item">#<!-- -->Foundation Models</span><span class="page__taxonomy-item">#<!-- -->Open-World Scenarios</span><span class="page__taxonomy-item">#<!-- -->OOD Detection</span><span class="page__taxonomy-item">#<!-- -->Confidence Calibration</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-15-IntrEx_A_Dataset_for_Modeling_Engagement_in_Educational_Conversations/">[논문리뷰] IntrEx: A Dataset for Modeling Engagement in Educational Conversations</a></h2><div class="archive__item-excerpt">Gabriele Pergola이 [arXiv]에 게시한 &#x27;IntrEx: A Dataset for Modeling Engagement in Educational Conversations&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-15 13:12:08+0900">2025년 9월 15일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Educational Dialogue</span><span class="page__taxonomy-item">#<!-- -->Engagement Modeling</span><span class="page__taxonomy-item">#<!-- -->Dataset Annotation</span><span class="page__taxonomy-item">#<!-- -->Second Language Learning</span><span class="page__taxonomy-item">#<!-- -->Human Feedback</span><span class="page__taxonomy-item">#<!-- -->LLM Alignment</span><span class="page__taxonomy-item">#<!-- -->Readability Metrics</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-15-Inpainting-Guided_Policy_Optimization_for_Diffusion_Large_Language_Models/">[논문리뷰] Inpainting-Guided Policy Optimization for Diffusion Large Language Models</a></h2><div class="archive__item-excerpt">Chenyu Wang이 [arXiv]에 게시한 &#x27;Inpainting-Guided Policy Optimization for Diffusion Large Language Models&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-15 13:12:08+0900">2025년 9월 15일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Diffusion LLMs</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Inpainting</span><span class="page__taxonomy-item">#<!-- -->Policy Optimization</span><span class="page__taxonomy-item">#<!-- -->Exploration</span><span class="page__taxonomy-item">#<!-- -->Mathematical Reasoning</span><span class="page__taxonomy-item">#<!-- -->GRPO</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-15-InfGen_A_Resolution-Agnostic_Paradigm_for_Scalable_Image_Synthesis/">[논문리뷰] InfGen: A Resolution-Agnostic Paradigm for Scalable Image Synthesis</a></h2><div class="archive__item-excerpt">Song Guo이 [arXiv]에 게시한 &#x27;InfGen: A Resolution-Agnostic Paradigm for Scalable Image Synthesis&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-15 13:12:08+0900">2025년 9월 15일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Image Synthesis</span><span class="page__taxonomy-item">#<!-- -->Resolution-Agnostic</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->Latent Space</span><span class="page__taxonomy-item">#<!-- -->VAE Decoder</span><span class="page__taxonomy-item">#<!-- -->High-Resolution Image Generation</span><span class="page__taxonomy-item">#<!-- -->Generative AI</span><span class="page__taxonomy-item">#<!-- -->Transformer Architecture</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-15-HANRAG_Heuristic_Accurate_Noise-resistant_Retrieval-Augmented_Generation_for_Multi-hop_Question_Answering/">[논문리뷰] HANRAG: Heuristic Accurate Noise-resistant Retrieval-Augmented Generation for Multi-hop Question Answering</a></h2><div class="archive__item-excerpt">Zhehao Tan이 [arXiv]에 게시한 &#x27;HANRAG: Heuristic Accurate Noise-resistant Retrieval-Augmented Generation for Multi-hop Question Answering&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-15 13:12:08+0900">2025년 9월 15일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Retrieval-Augmented Generation</span><span class="page__taxonomy-item">#<!-- -->Multi-hop QA</span><span class="page__taxonomy-item">#<!-- -->Noise Resistance</span><span class="page__taxonomy-item">#<!-- -->LLM</span><span class="page__taxonomy-item">#<!-- -->Query Decomposition</span><span class="page__taxonomy-item">#<!-- -->Adaptive Retrieval</span><span class="page__taxonomy-item">#<!-- -->Heuristic Framework</span><span class="page__taxonomy-item">#<!-- -->Revelator</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-15-FLOWER_Democratizing_Generalist_Robot_Policies_with_Efficient_Vision-Language-Action_Flow_Policies/">[논문리뷰] FLOWER: Democratizing Generalist Robot Policies with Efficient Vision-Language-Action Flow Policies</a></h2><div class="archive__item-excerpt">Fabian Otto이 [arXiv]에 게시한 &#x27;FLOWER: Democratizing Generalist Robot Policies with Efficient Vision-Language-Action Flow Policies&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-15 13:12:08+0900">2025년 9월 15일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Generalist Robot Policies</span><span class="page__taxonomy-item">#<!-- -->Vision-Language-Action Models</span><span class="page__taxonomy-item">#<!-- -->Efficient AI</span><span class="page__taxonomy-item">#<!-- -->Imitation Learning</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->Intermediate Fusion</span><span class="page__taxonomy-item">#<!-- -->Robotics</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-15-CMHG_A_Dataset_and_Benchmark_for_Headline_Generation_of_Minority_Languages_in_China/">[논문리뷰] CMHG: A Dataset and Benchmark for Headline Generation of Minority Languages in China</a></h2><div class="archive__item-excerpt">XU Han이 [arXiv]에 게시한 &#x27;CMHG: A Dataset and Benchmark for Headline Generation of Minority Languages in China&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-15 13:12:08+0900">2025년 9월 15일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Headline Generation</span><span class="page__taxonomy-item">#<!-- -->Minority Languages</span><span class="page__taxonomy-item">#<!-- -->Low-Resource NLP</span><span class="page__taxonomy-item">#<!-- -->Dataset</span><span class="page__taxonomy-item">#<!-- -->Benchmark</span><span class="page__taxonomy-item">#<!-- -->Natural Language Generation</span><span class="page__taxonomy-item">#<!-- -->Chinese Minority Languages</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-12-VLA-Adapter_An_Effective_Paradigm_for_Tiny-Scale_Vision-Language-Action_Model/">[논문리뷰] VLA-Adapter: An Effective Paradigm for Tiny-Scale Vision-Language-Action Model</a></h2><div class="archive__item-excerpt">Zirui Ge이 [arXiv]에 게시한 &#x27;VLA-Adapter: An Effective Paradigm for Tiny-Scale Vision-Language-Action Model&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-12 13:12:46+0900">2025년 9월 12일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Vision-Language-Action Models</span><span class="page__taxonomy-item">#<!-- -->Robotics</span><span class="page__taxonomy-item">#<!-- -->Multimodal Learning</span><span class="page__taxonomy-item">#<!-- -->Efficient AI</span><span class="page__taxonomy-item">#<!-- -->Model Adaptation</span><span class="page__taxonomy-item">#<!-- -->Bridge Attention</span><span class="page__taxonomy-item">#<!-- -->Low-resource Training</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-12-Visual_Programmability_A_Guide_for_Code-as-Thought_in_Chart_Understanding/">[논문리뷰] Visual Programmability: A Guide for Code-as-Thought in Chart Understanding</a></h2><div class="archive__item-excerpt">Ethan Chern이 [arXiv]에 게시한 &#x27;Visual Programmability: A Guide for Code-as-Thought in Chart Understanding&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-12 13:12:46+0900">2025년 9월 12일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Visual Programmability</span><span class="page__taxonomy-item">#<!-- -->Code-as-Thought (CaT)</span><span class="page__taxonomy-item">#<!-- -->Chart Understanding</span><span class="page__taxonomy-item">#<!-- -->Vision-Language Models (VLMs)</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning (RL)</span><span class="page__taxonomy-item">#<!-- -->Adaptive Reasoning</span><span class="page__taxonomy-item">#<!-- -->Dual-Reward System</span><span class="page__taxonomy-item">#<!-- -->Multimodal AI</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-12-The_Choice_of_Divergence_A_Neglected_Key_to_Mitigating_Diversity_Collapse_in_Reinforcement_Learning_with_Verifiable_Reward/">[논문리뷰] The Choice of Divergence: A Neglected Key to Mitigating Diversity Collapse in Reinforcement Learning with Verifiable Reward</a></h2><div class="archive__item-excerpt">Xiaoyu Tan이 [arXiv]에 게시한 &#x27;The Choice of Divergence: A Neglected Key to Mitigating Diversity Collapse in Reinforcement Learning with Verifiable Reward&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-12 13:12:46+0900">2025년 9월 12일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Large Language Models (LLMs)</span><span class="page__taxonomy-item">#<!-- -->Diversity Collapse</span><span class="page__taxonomy-item">#<!-- -->f-divergence</span><span class="page__taxonomy-item">#<!-- -->Forward-KL</span><span class="page__taxonomy-item">#<!-- -->JS-divergence</span><span class="page__taxonomy-item">#<!-- -->Pass@k</span><span class="page__taxonomy-item">#<!-- -->Catastrophic Forgetting</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-12-SpatialVID_A_Large-Scale_Video_Dataset_with_Spatial_Annotations/">[논문리뷰] SpatialVID: A Large-Scale Video Dataset with Spatial Annotations</a></h2><div class="archive__item-excerpt">Jian Gao이 [arXiv]에 게시한 &#x27;SpatialVID: A Large-Scale Video Dataset with Spatial Annotations&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-12 13:12:46+0900">2025년 9월 12일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Video Dataset</span><span class="page__taxonomy-item">#<!-- -->Spatial Annotation</span><span class="page__taxonomy-item">#<!-- -->Camera Pose Estimation</span><span class="page__taxonomy-item">#<!-- -->Depth Map</span><span class="page__taxonomy-item">#<!-- -->Structured Caption</span><span class="page__taxonomy-item">#<!-- -->Motion Instruction</span><span class="page__taxonomy-item">#<!-- -->3D Vision</span><span class="page__taxonomy-item">#<!-- -->World Modeling</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-12-SimpleVLA-RL_Scaling_VLA_Training_via_Reinforcement_Learning/">[논문리뷰] SimpleVLA-RL: Scaling VLA Training via Reinforcement Learning</a></h2><div class="archive__item-excerpt">Zhaohui Yang이 [arXiv]에 게시한 &#x27;SimpleVLA-RL: Scaling VLA Training via Reinforcement Learning&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-12 13:12:46+0900">2025년 9월 12일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning (RL)</span><span class="page__taxonomy-item">#<!-- -->Vision-Language-Action (VLA) Models</span><span class="page__taxonomy-item">#<!-- -->Robotic Manipulation</span><span class="page__taxonomy-item">#<!-- -->Data Scarcity</span><span class="page__taxonomy-item">#<!-- -->Generalization</span><span class="page__taxonomy-item">#<!-- -->Sim-to-Real Transfer</span><span class="page__taxonomy-item">#<!-- -->Online RL</span><span class="page__taxonomy-item">#<!-- -->Long-Horizon Planning</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-12-Reasoning_Introduces_New_Poisoning_Attacks_Yet_Makes_Them_More_Complicated/">[논문리뷰] Reasoning Introduces New Poisoning Attacks Yet Makes Them More Complicated</a></h2><div class="archive__item-excerpt">Jamie Hayes이 [arXiv]에 게시한 &#x27;Reasoning Introduces New Poisoning Attacks Yet Makes Them More Complicated&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-12 13:12:46+0900">2025년 9월 12일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLM Security</span><span class="page__taxonomy-item">#<!-- -->Data Poisoning</span><span class="page__taxonomy-item">#<!-- -->Chain-of-Thought</span><span class="page__taxonomy-item">#<!-- -->Reasoning Models</span><span class="page__taxonomy-item">#<!-- -->Backdoor Attacks</span><span class="page__taxonomy-item">#<!-- -->CoT Unfaithfulness</span><span class="page__taxonomy-item">#<!-- -->Emergent Robustness</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-12-OmniEVA_Embodied_Versatile_Planner_via_Task-Adaptive_3D-Grounded_and_Embodiment-aware_Reasoning/">[논문리뷰] OmniEVA: Embodied Versatile Planner via Task-Adaptive 3D-Grounded and Embodiment-aware Reasoning</a></h2><div class="archive__item-excerpt">Yuzheng Zhuang이 [arXiv]에 게시한 &#x27;OmniEVA: Embodied Versatile Planner via Task-Adaptive 3D-Grounded and Embodiment-aware Reasoning&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-12 13:12:46+0900">2025년 9월 12일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Embodied AI</span><span class="page__taxonomy-item">#<!-- -->Multimodal LLMs</span><span class="page__taxonomy-item">#<!-- -->3D Grounding</span><span class="page__taxonomy-item">#<!-- -->Task-Adaptive Reasoning</span><span class="page__taxonomy-item">#<!-- -->Embodiment-Aware Planning</span><span class="page__taxonomy-item">#<!-- -->Robotics</span><span class="page__taxonomy-item">#<!-- -->Spatial Reasoning</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-12-Modality_Alignment_with_Multi-scale_Bilateral_Attention_for_Multimodal_Recommendation/">[논문리뷰] Modality Alignment with Multi-scale Bilateral Attention for Multimodal Recommendation</a></h2><div class="archive__item-excerpt">Dong-Ho Lee이 [arXiv]에 게시한 &#x27;Modality Alignment with Multi-scale Bilateral Attention for Multimodal Recommendation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-12 13:12:46+0900">2025년 9월 12일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Multimodal Recommendation</span><span class="page__taxonomy-item">#<!-- -->Modality Alignment</span><span class="page__taxonomy-item">#<!-- -->Attention Mechanism</span><span class="page__taxonomy-item">#<!-- -->Dilated Convolution</span><span class="page__taxonomy-item">#<!-- -->Maximum Mean Discrepancy</span><span class="page__taxonomy-item">#<!-- -->Contrastive Learning</span><span class="page__taxonomy-item">#<!-- -->Dimensionality Reduction</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-12-LoCoBench_A_Benchmark_for_Long-Context_Large_Language_Models_in_Complex_Software_Engineering/">[논문리뷰] LoCoBench: A Benchmark for Long-Context Large Language Models in Complex Software Engineering</a></h2><div class="archive__item-excerpt">Jianguo Zhang이 [arXiv]에 게시한 &#x27;LoCoBench: A Benchmark for Long-Context Large Language Models in Complex Software Engineering&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-12 13:12:46+0900">2025년 9월 12일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Long-Context LLMs</span><span class="page__taxonomy-item">#<!-- -->Software Engineering</span><span class="page__taxonomy-item">#<!-- -->Code Evaluation</span><span class="page__taxonomy-item">#<!-- -->Benchmark</span><span class="page__taxonomy-item">#<!-- -->Multi-file Reasoning</span><span class="page__taxonomy-item">#<!-- -->Architectural Understanding</span><span class="page__taxonomy-item">#<!-- -->Context Length</span><span class="page__taxonomy-item">#<!-- -->Software Development Lifecycle</span><span class="page__taxonomy-item">#<!-- -->Metrics</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-12-Kling-Avatar_Grounding_Multimodal_Instructions_for_Cascaded_Long-Duration_Avatar_Animation_Synthesis/">[논문리뷰] Kling-Avatar: Grounding Multimodal Instructions for Cascaded Long-Duration Avatar Animation Synthesis</a></h2><div class="archive__item-excerpt">Wentao Hu이 [arXiv]에 게시한 &#x27;Kling-Avatar: Grounding Multimodal Instructions for Cascaded Long-Duration Avatar Animation Synthesis&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-12 13:12:46+0900">2025년 9월 12일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Avatar Animation</span><span class="page__taxonomy-item">#<!-- -->Multimodal Instructions</span><span class="page__taxonomy-item">#<!-- -->Long-Duration Video Generation</span><span class="page__taxonomy-item">#<!-- -->MLLM Director</span><span class="page__taxonomy-item">#<!-- -->Cascaded Framework</span><span class="page__taxonomy-item">#<!-- -->Lip Synchronization</span><span class="page__taxonomy-item">#<!-- -->Instruction Grounding</span><span class="page__taxonomy-item">#<!-- -->Video Diffusion Transformers</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-12-HuMo_Human-Centric_Video_Generation_via_Collaborative_Multi-Modal_Conditioning/">[논문리뷰] HuMo: Human-Centric Video Generation via Collaborative Multi-Modal Conditioning</a></h2><div class="archive__item-excerpt">Zhuowei Chen이 [arXiv]에 게시한 &#x27;HuMo: Human-Centric Video Generation via Collaborative Multi-Modal Conditioning&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-12 13:12:46+0900">2025년 9월 12일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Human-Centric Video Generation</span><span class="page__taxonomy-item">#<!-- -->Multimodal Conditioning</span><span class="page__taxonomy-item">#<!-- -->Text-to-Video</span><span class="page__taxonomy-item">#<!-- -->Image-to-Video</span><span class="page__taxonomy-item">#<!-- -->Audio-to-Video</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->Subject Preservation</span><span class="page__taxonomy-item">#<!-- -->Audio-Visual Synchronization</span><span class="page__taxonomy-item">#<!-- -->Progressive Training</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-12-Harnessing_Uncertainty_Entropy-Modulated_Policy_Gradients_for_Long-Horizon_LLM_Agents/">[논문리뷰] Harnessing Uncertainty: Entropy-Modulated Policy Gradients for Long-Horizon LLM Agents</a></h2><div class="archive__item-excerpt">Xintao Wang이 [arXiv]에 게시한 &#x27;Harnessing Uncertainty: Entropy-Modulated Policy Gradients for Long-Horizon LLM Agents&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-12 13:12:46+0900">2025년 9월 12일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLM Agents</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Policy Gradients</span><span class="page__taxonomy-item">#<!-- -->Entropy Modulation</span><span class="page__taxonomy-item">#<!-- -->Credit Assignment</span><span class="page__taxonomy-item">#<!-- -->Uncertainty</span><span class="page__taxonomy-item">#<!-- -->Long-Horizon Tasks</span><span class="page__taxonomy-item">#<!-- -->Self-Calibrating Gradient Scaling</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-12-Gradient-Attention_Guided_Dual-Masking_Synergetic_Framework_for_Robust_Text-based_Person_Retrieval/">[논문리뷰] Gradient-Attention Guided Dual-Masking Synergetic Framework for Robust Text-based Person Retrieval</a></h2><div class="archive__item-excerpt">Kaicheng Yang이 [arXiv]에 게시한 &#x27;Gradient-Attention Guided Dual-Masking Synergetic Framework for Robust Text-based Person Retrieval&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-12 13:12:46+0900">2025년 9월 12일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Text-based Person Retrieval</span><span class="page__taxonomy-item">#<!-- -->CLIP</span><span class="page__taxonomy-item">#<!-- -->MLLM</span><span class="page__taxonomy-item">#<!-- -->Data Curation</span><span class="page__taxonomy-item">#<!-- -->Dual-Masking</span><span class="page__taxonomy-item">#<!-- -->Gradient-Attention</span><span class="page__taxonomy-item">#<!-- -->WebPerson Dataset</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-12-FLUX-Reason-6M_PRISM-Bench_A_Million-Scale_Text-to-Image_Reasoning_Dataset_and_Comprehensive_Benchmark/">[논문리뷰] FLUX-Reason-6M &amp; PRISM-Bench: A Million-Scale Text-to-Image Reasoning Dataset and Comprehensive Benchmark</a></h2><div class="archive__item-excerpt">Shuai Bai이 [arXiv]에 게시한 &#x27;FLUX-Reason-6M &amp; PRISM-Bench: A Million-Scale Text-to-Image Reasoning Dataset and Comprehensive Benchmark&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-12 13:12:46+0900">2025년 9월 12일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Text-to-Image Generation</span><span class="page__taxonomy-item">#<!-- -->Reasoning Dataset</span><span class="page__taxonomy-item">#<!-- -->Benchmark</span><span class="page__taxonomy-item">#<!-- -->Generation Chain-of-Thought</span><span class="page__taxonomy-item">#<!-- -->Vision-Language Model</span><span class="page__taxonomy-item">#<!-- -->Image Aesthetics</span><span class="page__taxonomy-item">#<!-- -->Prompt Alignment</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-12-EchoX_Towards_Mitigating_Acoustic-Semantic_Gap_via_Echo_Training_for_Speech-to-Speech_LLMs/">[논문리뷰] EchoX: Towards Mitigating Acoustic-Semantic Gap via Echo Training for Speech-to-Speech LLMs</a></h2><div class="archive__item-excerpt">Kaiqi Kou이 [arXiv]에 게시한 &#x27;EchoX: Towards Mitigating Acoustic-Semantic Gap via Echo Training for Speech-to-Speech LLMs&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-12 13:12:46+0900">2025년 9월 12일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Speech-to-Speech LLMs</span><span class="page__taxonomy-item">#<!-- -->Acoustic-Semantic Gap</span><span class="page__taxonomy-item">#<!-- -->Echo Training</span><span class="page__taxonomy-item">#<!-- -->Unit Language</span><span class="page__taxonomy-item">#<!-- -->Streaming Inference</span><span class="page__taxonomy-item">#<!-- -->Knowledge-based QA</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-12-Can_Understanding_and_Generation_Truly_Benefit_Together_--_or_Just_Coexist/">[논문리뷰] Can Understanding and Generation Truly Benefit Together -- or Just Coexist?</a></h2><div class="archive__item-excerpt">Hui Han이 [arXiv]에 게시한 &#x27;Can Understanding and Generation Truly Benefit Together -- or Just Coexist?&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-12 13:12:46+0900">2025년 9월 12일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Multimodal Understanding</span><span class="page__taxonomy-item">#<!-- -->Multimodal Generation</span><span class="page__taxonomy-item">#<!-- -->Unified Models</span><span class="page__taxonomy-item">#<!-- -->Auto-Encoder</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Image-to-Text</span><span class="page__taxonomy-item">#<!-- -->Text-to-Image</span><span class="page__taxonomy-item">#<!-- -->Reconstruction Fidelity</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-12-2D_Gaussian_Splatting_with_Semantic_Alignment_for_Image_Inpainting/">[논문리뷰] 2D Gaussian Splatting with Semantic Alignment for Image Inpainting</a></h2><div class="archive__item-excerpt">Guangming Lu이 [arXiv]에 게시한 &#x27;2D Gaussian Splatting with Semantic Alignment for Image Inpainting&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-12 13:12:46+0900">2025년 9월 12일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Image Inpainting</span><span class="page__taxonomy-item">#<!-- -->2D Gaussian Splatting</span><span class="page__taxonomy-item">#<!-- -->Semantic Alignment</span><span class="page__taxonomy-item">#<!-- -->DINO Features</span><span class="page__taxonomy-item">#<!-- -->Patch-level Rasterization</span><span class="page__taxonomy-item">#<!-- -->Continuous Representation</span><span class="page__taxonomy-item">#<!-- -->Generative Models</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-11-think_So_lets_replace_this_phrase_with_insult..._think_Lessons_learned_from_generation_of_toxic_texts_with_LLMs">[논문리뷰] &lt;think&gt; So let&#x27;s replace this phrase with insult... &lt;/think&gt; Lessons learned from generation of toxic texts with LLMs</a></h2><div class="archive__item-excerpt">Alexander Panchenko이 [arXiv]에 게시한 &#x27;&lt;think&gt; So let&#x27;s replace this phrase with insult... &lt;/think&gt; Lessons learned from generation of toxic texts with LLMs&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-11 13:02:36+0900">2025년 9월 11일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Toxic Text Generation</span><span class="page__taxonomy-item">#<!-- -->LLMs</span><span class="page__taxonomy-item">#<!-- -->Text Detoxification</span><span class="page__taxonomy-item">#<!-- -->Lexical Diversity</span><span class="page__taxonomy-item">#<!-- -->Synthetic Data</span><span class="page__taxonomy-item">#<!-- -->Human Annotation</span><span class="page__taxonomy-item">#<!-- -->Style Transfer</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-11-RewardDance_Reward_Scaling_in_Visual_Generation/">[논문리뷰] RewardDance: Reward Scaling in Visual Generation</a></h2><div class="archive__item-excerpt">Liang Li이 [arXiv]에 게시한 &#x27;RewardDance: Reward Scaling in Visual Generation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-11 13:02:36+0900">2025년 9월 11일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Reward Model</span><span class="page__taxonomy-item">#<!-- -->Visual Generation</span><span class="page__taxonomy-item">#<!-- -->RLHF</span><span class="page__taxonomy-item">#<!-- -->VLM</span><span class="page__taxonomy-item">#<!-- -->Reward Scaling</span><span class="page__taxonomy-item">#<!-- -->Reward Hacking</span><span class="page__taxonomy-item">#<!-- -->Generative Paradigm</span><span class="page__taxonomy-item">#<!-- -->Context Scaling</span><span class="page__taxonomy-item">#<!-- -->Text-to-Image</span><span class="page__taxonomy-item">#<!-- -->Text-to-Video</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-11-P3-SAM_Native_3D_Part_Segmentation/">[논문리뷰] P3-SAM: Native 3D Part Segmentation</a></h2><div class="archive__item-excerpt">Yunhan Yang이 [arXiv]에 게시한 &#x27;P3-SAM: Native 3D Part Segmentation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-11 13:02:36+0900">2025년 9월 11일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->3D Part Segmentation</span><span class="page__taxonomy-item">#<!-- -->Point Cloud Segmentation</span><span class="page__taxonomy-item">#<!-- -->Prompt-based Segmentation</span><span class="page__taxonomy-item">#<!-- -->Deep Learning</span><span class="page__taxonomy-item">#<!-- -->Transformer</span><span class="page__taxonomy-item">#<!-- -->Interactive Segmentation</span><span class="page__taxonomy-item">#<!-- -->Automatic Segmentation</span><span class="page__taxonomy-item">#<!-- -->Native 3D</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-11-Hunyuan-MT_Technical_Report/">[논문리뷰] Hunyuan-MT Technical Report</a></h2><div class="archive__item-excerpt">Yang Du이 [arXiv]에 게시한 &#x27;Hunyuan-MT Technical Report&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-11 13:02:36+0900">2025년 9월 11일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Machine Translation</span><span class="page__taxonomy-item">#<!-- -->Large Language Model</span><span class="page__taxonomy-item">#<!-- -->Multilingual</span><span class="page__taxonomy-item">#<!-- -->Low-Resource Languages</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Weak-to-Strong Learning</span><span class="page__taxonomy-item">#<!-- -->Slow Thinking</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-11-HumanAgencyBench_Scalable_Evaluation_of_Human_Agency_Support_in_AI_Assistants/">[논문리뷰] HumanAgencyBench: Scalable Evaluation of Human Agency Support in AI Assistants</a></h2><div class="archive__item-excerpt">Jacy Reese Anthis이 [arXiv]에 게시한 &#x27;HumanAgencyBench: Scalable Evaluation of Human Agency Support in AI Assistants&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-11 13:02:36+0900">2025년 9월 11일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Human Agency</span><span class="page__taxonomy-item">#<!-- -->AI Assistants</span><span class="page__taxonomy-item">#<!-- -->LLM Evaluation</span><span class="page__taxonomy-item">#<!-- -->Benchmark</span><span class="page__taxonomy-item">#<!-- -->Sociotechnical AI</span><span class="page__taxonomy-item">#<!-- -->AI Alignment</span><span class="page__taxonomy-item">#<!-- -->Scalable Evaluation</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-11-EnvX_Agentize_Everything_with_Agentic_AI/">[논문리뷰] EnvX: Agentize Everything with Agentic AI</a></h2><div class="archive__item-excerpt">Wenzheng Tom Tang이 [arXiv]에 게시한 &#x27;EnvX: Agentize Everything with Agentic AI&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-11 13:02:36+0900">2025년 9월 11일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Agentic AI</span><span class="page__taxonomy-item">#<!-- -->Multi-Agent Systems</span><span class="page__taxonomy-item">#<!-- -->Code Repository</span><span class="page__taxonomy-item">#<!-- -->Agentization</span><span class="page__taxonomy-item">#<!-- -->Natural Language Interaction</span><span class="page__taxonomy-item">#<!-- -->Agent-to-Agent Protocol</span><span class="page__taxonomy-item">#<!-- -->LLM-based Agents</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-11-A_Survey_of_Reinforcement_Learning_for_Large_Reasoning_Models/">[논문리뷰] A Survey of Reinforcement Learning for Large Reasoning Models</a></h2><div class="archive__item-excerpt">Runze Liu이 [arXiv]에 게시한 &#x27;A Survey of Reinforcement Learning for Large Reasoning Models&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-11 13:02:36+0900">2025년 9월 11일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Large Reasoning Models</span><span class="page__taxonomy-item">#<!-- -->LLMs</span><span class="page__taxonomy-item">#<!-- -->Reward Design</span><span class="page__taxonomy-item">#<!-- -->Policy Optimization</span><span class="page__taxonomy-item">#<!-- -->Verifiable Rewards</span><span class="page__taxonomy-item">#<!-- -->Agentic AI</span><span class="page__taxonomy-item">#<!-- -->Multimodal AI</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-11-AgentGym-RL_Training_LLM_Agents_for_Long-Horizon_Decision_Making_through_Multi-Turn_Reinforcement_Learning/">[논문리뷰] AgentGym-RL: Training LLM Agents for Long-Horizon Decision Making through Multi-Turn Reinforcement Learning</a></h2><div class="archive__item-excerpt">Honglin Guo이 [arXiv]에 게시한 &#x27;AgentGym-RL: Training LLM Agents for Long-Horizon Decision Making through Multi-Turn Reinforcement Learning&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-11 13:02:36+0900">2025년 9월 11일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLM Agents</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Multi-Turn Interaction</span><span class="page__taxonomy-item">#<!-- -->Long-Horizon Decision Making</span><span class="page__taxonomy-item">#<!-- -->Agent Framework</span><span class="page__taxonomy-item">#<!-- -->Exploration-Exploitation</span><span class="page__taxonomy-item">#<!-- -->Progressive Scaling</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-11-3D_and_4D_World_Modeling_A_Survey/">[논문리뷰] 3D and 4D World Modeling: A Survey</a></h2><div class="archive__item-excerpt">Ao Liang이 [arXiv]에 게시한 &#x27;3D and 4D World Modeling: A Survey&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-11 13:02:36+0900">2025년 9월 11일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->3D World Modeling</span><span class="page__taxonomy-item">#<!-- -->4D World Modeling</span><span class="page__taxonomy-item">#<!-- -->Generative Models</span><span class="page__taxonomy-item">#<!-- -->Predictive Models</span><span class="page__taxonomy-item">#<!-- -->LiDAR</span><span class="page__taxonomy-item">#<!-- -->Occupancy Grids</span><span class="page__taxonomy-item">#<!-- -->Video Generation</span><span class="page__taxonomy-item">#<!-- -->Autonomous Driving</span><span class="page__taxonomy-item">#<!-- -->Robotics</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-10-ΔL_Normalization_Rethink_Loss_Aggregation_in_RLVR/">[논문리뷰] ΔL Normalization: Rethink Loss Aggregation in RLVR</a></h2><div class="archive__item-excerpt">Lili Qiu이 [arXiv]에 게시한 &#x27;ΔL Normalization: Rethink Loss Aggregation in RLVR&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-10 13:11:01+0900">2025년 9월 10일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->LLMs</span><span class="page__taxonomy-item">#<!-- -->Gradient Variance</span><span class="page__taxonomy-item">#<!-- -->Loss Aggregation</span><span class="page__taxonomy-item">#<!-- -->Unbiased Estimator</span><span class="page__taxonomy-item">#<!-- -->RLVR</span><span class="page__taxonomy-item">#<!-- -->Policy Gradient</span><span class="page__taxonomy-item">#<!-- -->Normalization</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-10-Visual_Representation_Alignment_for_Multimodal_Large_Language_Models/">[논문리뷰] Visual Representation Alignment for Multimodal Large Language Models</a></h2><div class="archive__item-excerpt">Heeseong Shin이 [arXiv]에 게시한 &#x27;Visual Representation Alignment for Multimodal Large Language Models&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-10 13:11:01+0900">2025년 9월 10일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Multimodal LLMs</span><span class="page__taxonomy-item">#<!-- -->Visual Representation Alignment</span><span class="page__taxonomy-item">#<!-- -->Foundation Models</span><span class="page__taxonomy-item">#<!-- -->Regularization</span><span class="page__taxonomy-item">#<!-- -->Fine-grained Visual Understanding</span><span class="page__taxonomy-item">#<!-- -->Spatial Reasoning</span><span class="page__taxonomy-item">#<!-- -->Object Counting</span><span class="page__taxonomy-item">#<!-- -->Vision-Language Models</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-10-UMO_Scaling_Multi-Identity_Consistency_for_Image_Customization_via_Matching_Reward/">[논문리뷰] UMO: Scaling Multi-Identity Consistency for Image Customization via Matching Reward</a></h2><div class="archive__item-excerpt">Fei Ding이 [arXiv]에 게시한 &#x27;UMO: Scaling Multi-Identity Consistency for Image Customization via Matching Reward&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-10 13:11:01+0900">2025년 9월 10일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Image Customization</span><span class="page__taxonomy-item">#<!-- -->Multi-Identity Generation</span><span class="page__taxonomy-item">#<!-- -->Identity Consistency</span><span class="page__taxonomy-item">#<!-- -->Identity Confusion</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->Matching Reward</span><span class="page__taxonomy-item">#<!-- -->Global Assignment</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-10-Staying_in_the_Sweet_Spot_Responsive_Reasoning_Evolution_via_Capability-Adaptive_Hint_Scaffolding/">[논문리뷰] Staying in the Sweet Spot: Responsive Reasoning Evolution via Capability-Adaptive Hint Scaffolding</a></h2><div class="archive__item-excerpt">Yongcheng Zeng이 [arXiv]에 게시한 &#x27;Staying in the Sweet Spot: Responsive Reasoning Evolution via Capability-Adaptive Hint Scaffolding&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-10 13:11:01+0900">2025년 9월 10일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->RLVR</span><span class="page__taxonomy-item">#<!-- -->LLM Reasoning</span><span class="page__taxonomy-item">#<!-- -->Adaptive Learning</span><span class="page__taxonomy-item">#<!-- -->Hint Scaffolding</span><span class="page__taxonomy-item">#<!-- -->Item Response Theory</span><span class="page__taxonomy-item">#<!-- -->Exploration Efficiency</span><span class="page__taxonomy-item">#<!-- -->Problem Difficulty</span><span class="page__taxonomy-item">#<!-- -->Policy Optimization</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-10-SimpleQA_Verified_A_Reliable_Factuality_Benchmark_to_Measure_Parametric_Knowledge/">[논문리뷰] SimpleQA Verified: A Reliable Factuality Benchmark to Measure Parametric Knowledge</a></h2><div class="archive__item-excerpt">Dipanjan Das이 [arXiv]에 게시한 &#x27;SimpleQA Verified: A Reliable Factuality Benchmark to Measure Parametric Knowledge&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-10 13:11:01+0900">2025년 9월 10일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLM Factuality</span><span class="page__taxonomy-item">#<!-- -->Parametric Knowledge</span><span class="page__taxonomy-item">#<!-- -->Benchmark</span><span class="page__taxonomy-item">#<!-- -->Question Answering</span><span class="page__taxonomy-item">#<!-- -->Data Curation</span><span class="page__taxonomy-item">#<!-- -->Evaluation Metrics</span><span class="page__taxonomy-item">#<!-- -->Hallucination Mitigation</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-10-Reconstruction_Alignment_Improves_Unified_Multimodal_Models/">[논문리뷰] Reconstruction Alignment Improves Unified Multimodal Models</a></h2><div class="archive__item-excerpt">XuDong Wang이 [arXiv]에 게시한 &#x27;Reconstruction Alignment Improves Unified Multimodal Models&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-10 13:11:01+0900">2025년 9월 10일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Unified Multimodal Models</span><span class="page__taxonomy-item">#<!-- -->Image Generation</span><span class="page__taxonomy-item">#<!-- -->Image Editing</span><span class="page__taxonomy-item">#<!-- -->Post-training</span><span class="page__taxonomy-item">#<!-- -->Self-supervised Learning</span><span class="page__taxonomy-item">#<!-- -->Reconstruction Alignment</span><span class="page__taxonomy-item">#<!-- -->Visual Embeddings</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-10-Q-Sched_Pushing_the_Boundaries_of_Few-Step_Diffusion_Models_with_Quantization-Aware_Scheduling/">[논문리뷰] Q-Sched: Pushing the Boundaries of Few-Step Diffusion Models with Quantization-Aware Scheduling</a></h2><div class="archive__item-excerpt">Diana Marculescu이 [arXiv]에 게시한 &#x27;Q-Sched: Pushing the Boundaries of Few-Step Diffusion Models with Quantization-Aware Scheduling&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-10 13:11:01+0900">2025년 9월 10일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->Quantization</span><span class="page__taxonomy-item">#<!-- -->Few-Step Generation</span><span class="page__taxonomy-item">#<!-- -->Model Compression</span><span class="page__taxonomy-item">#<!-- -->Noise Scheduling</span><span class="page__taxonomy-item">#<!-- -->Post-Training Quantization</span><span class="page__taxonomy-item">#<!-- -->Image Quality Metrics</span><span class="page__taxonomy-item">#<!-- -->Latent Consistency Models</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-10-Parallel-R1_Towards_Parallel_Thinking_via_Reinforcement_Learning/">[논문리뷰] Parallel-R1: Towards Parallel Thinking via Reinforcement Learning</a></h2><div class="archive__item-excerpt">Xinyu Yang이 [arXiv]에 게시한 &#x27;Parallel-R1: Towards Parallel Thinking via Reinforcement Learning&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-10 13:11:01+0900">2025년 9월 10일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Parallel Thinking</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Mathematical Reasoning</span><span class="page__taxonomy-item">#<!-- -->Progressive Curriculum</span><span class="page__taxonomy-item">#<!-- -->Reward Design</span><span class="page__taxonomy-item">#<!-- -->Exploration Scaffold</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-10-Mini-o3_Scaling_Up_Reasoning_Patterns_and_Interaction_Turns_for_Visual_Search/">[논문리뷰] Mini-o3: Scaling Up Reasoning Patterns and Interaction Turns for Visual Search</a></h2><div class="archive__item-excerpt">Tianjian Li이 [arXiv]에 게시한 &#x27;Mini-o3: Scaling Up Reasoning Patterns and Interaction Turns for Visual Search&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-10 13:11:01+0900">2025년 9월 10일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Visual Search</span><span class="page__taxonomy-item">#<!-- -->Multi-Turn Reasoning</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Tool-Integrated Agents</span><span class="page__taxonomy-item">#<!-- -->Exploratory Reasoning</span><span class="page__taxonomy-item">#<!-- -->Data Augmentation</span><span class="page__taxonomy-item">#<!-- -->Over-turn Masking</span><span class="page__taxonomy-item">#<!-- -->Visual Language Models</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-10-Language_Self-Play_For_Data-Free_Training/">[논문리뷰] Language Self-Play For Data-Free Training</a></h2><div class="archive__item-excerpt">Vijai Mohan이 [arXiv]에 게시한 &#x27;Language Self-Play For Data-Free Training&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-10 13:11:01+0900">2025년 9월 10일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Self-Play</span><span class="page__taxonomy-item">#<!-- -->Data-Free Training</span><span class="page__taxonomy-item">#<!-- -->Instruction Following</span><span class="page__taxonomy-item">#<!-- -->Adversarial Training</span><span class="page__taxonomy-item">#<!-- -->Reward Modeling</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-10-F1_A_Vision-Language-Action_Model_Bridging_Understanding_and_Generation_to_Actions/">[논문리뷰] F1: A Vision-Language-Action Model Bridging Understanding and Generation to Actions</a></h2><div class="archive__item-excerpt">Zherui Qiu이 [arXiv]에 게시한 &#x27;F1: A Vision-Language-Action Model Bridging Understanding and Generation to Actions&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-10 13:11:01+0900">2025년 9월 10일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Vision-Language-Action</span><span class="page__taxonomy-item">#<!-- -->Embodied AI</span><span class="page__taxonomy-item">#<!-- -->Visual Foresight</span><span class="page__taxonomy-item">#<!-- -->Predictive Inverse Dynamics</span><span class="page__taxonomy-item">#<!-- -->Mixture-of-Transformer</span><span class="page__taxonomy-item">#<!-- -->Robot Manipulation</span><span class="page__taxonomy-item">#<!-- -->Multi-stage Training</span><span class="page__taxonomy-item">#<!-- -->Generalization</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-10-Directly_Aligning_the_Full_Diffusion_Trajectory_with_Fine-Grained_Human_Preference/">[논문리뷰] Directly Aligning the Full Diffusion Trajectory with Fine-Grained Human Preference</a></h2><div class="archive__item-excerpt">Yingfang Zhang이 [arXiv]에 게시한 &#x27;Directly Aligning the Full Diffusion Trajectory with Fine-Grained Human Preference&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-10 13:11:01+0900">2025년 9월 10일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Human Preference</span><span class="page__taxonomy-item">#<!-- -->Text-to-Image Generation</span><span class="page__taxonomy-item">#<!-- -->Reward Hacking</span><span class="page__taxonomy-item">#<!-- -->Direct-Align</span><span class="page__taxonomy-item">#<!-- -->SRPO</span><span class="page__taxonomy-item">#<!-- -->Fine-Grained Control</span><span class="page__taxonomy-item">#<!-- -->Flow Matching Models</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-10-Curia_A_Multi-Modal_Foundation_Model_for_Radiology/">[논문리뷰] Curia: A Multi-Modal Foundation Model for Radiology</a></h2><div class="archive__item-excerpt">Elodie Ferreres이 [arXiv]에 게시한 &#x27;Curia: A Multi-Modal Foundation Model for Radiology&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-10 13:11:01+0900">2025년 9월 10일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Foundation Model</span><span class="page__taxonomy-item">#<!-- -->Radiology</span><span class="page__taxonomy-item">#<!-- -->Computed Tomography (CT)</span><span class="page__taxonomy-item">#<!-- -->Magnetic Resonance Imaging (MRI)</span><span class="page__taxonomy-item">#<!-- -->Self-supervised Learning</span><span class="page__taxonomy-item">#<!-- -->Vision Transformer</span><span class="page__taxonomy-item">#<!-- -->Cross-Modality Generalization</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-10-Causal_Attention_with_Lookahead_Keys/">[논문리뷰] Causal Attention with Lookahead Keys</a></h2><div class="archive__item-excerpt">Quanquan Gu이 [arXiv]에 게시한 &#x27;Causal Attention with Lookahead Keys&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-10 13:11:01+0900">2025년 9월 10일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Causal Attention</span><span class="page__taxonomy-item">#<!-- -->Lookahead Keys</span><span class="page__taxonomy-item">#<!-- -->Autoregressive Modeling</span><span class="page__taxonomy-item">#<!-- -->Language Models</span><span class="page__taxonomy-item">#<!-- -->Transformer</span><span class="page__taxonomy-item">#<!-- -->Perplexity Reduction</span><span class="page__taxonomy-item">#<!-- -->Parallel Training</span><span class="page__taxonomy-item">#<!-- -->Efficient Inference</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-9-WebExplorer_Explore_and_Evolve_for_Training_Long-Horizon_Web_Agents/">[논문리뷰] WebExplorer: Explore and Evolve for Training Long-Horizon Web Agents</a></h2><div class="archive__item-excerpt">Aili Chen이 [arXiv]에 게시한 &#x27;WebExplorer: Explore and Evolve for Training Long-Horizon Web Agents&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-09 13:19:09+0900">2025년 9월 9일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Web Agents</span><span class="page__taxonomy-item">#<!-- -->Long-Horizon Reasoning</span><span class="page__taxonomy-item">#<!-- -->Large Language Models (LLMs)</span><span class="page__taxonomy-item">#<!-- -->Data Generation</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning (RL)</span><span class="page__taxonomy-item">#<!-- -->Supervised Fine-tuning (SFT)</span><span class="page__taxonomy-item">#<!-- -->Web Navigation</span><span class="page__taxonomy-item">#<!-- -->Information Retrieval</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-9-UniVerse-1_Unified_Audio-Video_Generation_via_Stitching_of_Experts/">[논문리뷰] UniVerse-1: Unified Audio-Video Generation via Stitching of Experts</a></h2><div class="archive__item-excerpt">Xinyao Liao이 [arXiv]에 게시한 &#x27;UniVerse-1: Unified Audio-Video Generation via Stitching of Experts&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-09 13:19:09+0900">2025년 9월 9일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Unified Audio-Video Generation</span><span class="page__taxonomy-item">#<!-- -->Stitching of Experts (SoE)</span><span class="page__taxonomy-item">#<!-- -->Multimodal Diffusion</span><span class="page__taxonomy-item">#<!-- -->Online Annotation</span><span class="page__taxonomy-item">#<!-- -->Cross-modal Noise Correlation</span><span class="page__taxonomy-item">#<!-- -->Foundation Models</span><span class="page__taxonomy-item">#<!-- -->Verse-Bench</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-9-Test-Time_Scaling_in_Reasoning_Models_Is_Not_Effective_for_Knowledge-Intensive_Tasks_Yet/">[논문리뷰] Test-Time Scaling in Reasoning Models Is Not Effective for Knowledge-Intensive Tasks Yet</a></h2><div class="archive__item-excerpt">See-Kiong Ng이 [arXiv]에 게시한 &#x27;Test-Time Scaling in Reasoning Models Is Not Effective for Knowledge-Intensive Tasks Yet&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-09 13:19:09+0900">2025년 9월 9일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Test-Time Scaling</span><span class="page__taxonomy-item">#<!-- -->Reasoning Models</span><span class="page__taxonomy-item">#<!-- -->Knowledge-Intensive Tasks</span><span class="page__taxonomy-item">#<!-- -->Hallucinations</span><span class="page__taxonomy-item">#<!-- -->Factual Accuracy</span><span class="page__taxonomy-item">#<!-- -->Chain-of-Thought</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-9-Scaling_up_Multi-Turn_Off-Policy_RL_and_Multi-Agent_Tree_Search_for_LLM_Step-Provers/">[논문리뷰] Scaling up Multi-Turn Off-Policy RL and Multi-Agent Tree Search for LLM Step-Provers</a></h2><div class="archive__item-excerpt">Xia Xiao이 [arXiv]에 게시한 &#x27;Scaling up Multi-Turn Off-Policy RL and Multi-Agent Tree Search for LLM Step-Provers&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-09 13:19:09+0900">2025년 9월 9일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLM Step-Provers</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning (RL)</span><span class="page__taxonomy-item">#<!-- -->Off-Policy RL</span><span class="page__taxonomy-item">#<!-- -->Multi-Agent Systems</span><span class="page__taxonomy-item">#<!-- -->Tree Search</span><span class="page__taxonomy-item">#<!-- -->Automated Theorem Proving (ATP)</span><span class="page__taxonomy-item">#<!-- -->Formal Mathematics</span><span class="page__taxonomy-item">#<!-- -->AlphaZero</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-9-Saturation-Driven_Dataset_Generation_for_LLM_Mathematical_Reasoning_in_the_TPTP_Ecosystem/">[논문리뷰] Saturation-Driven Dataset Generation for LLM Mathematical Reasoning in the TPTP Ecosystem</a></h2><div class="archive__item-excerpt">Damien Sileo이 [arXiv]에 게시한 &#x27;Saturation-Driven Dataset Generation for LLM Mathematical Reasoning in the TPTP Ecosystem&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-09 13:19:09+0900">2025년 9월 9일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Automated Theorem Proving</span><span class="page__taxonomy-item">#<!-- -->LLM</span><span class="page__taxonomy-item">#<!-- -->Mathematical Reasoning</span><span class="page__taxonomy-item">#<!-- -->Synthetic Data Generation</span><span class="page__taxonomy-item">#<!-- -->TPTP Ecosystem</span><span class="page__taxonomy-item">#<!-- -->Saturation Proving</span><span class="page__taxonomy-item">#<!-- -->Proof Graph Reconstruction</span><span class="page__taxonomy-item">#<!-- -->Data Augmentation</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-9-Rtextbf2AI_Towards_Resistant_and_Resilient_AI_in_an_Evolving_World/">[논문리뷰] R^textbf{2AI}: Towards Resistant and Resilient AI in an Evolving World</a></h2><div class="archive__item-excerpt">Bowen Zhou이 [arXiv]에 게시한 &#x27;R^textbf{2AI}: Towards Resistant and Resilient AI in an Evolving World&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-09 13:19:09+0900">2025년 9월 9일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->AI Safety</span><span class="page__taxonomy-item">#<!-- -->Resistant AI</span><span class="page__taxonomy-item">#<!-- -->Resilient AI</span><span class="page__taxonomy-item">#<!-- -->Coevolution</span><span class="page__taxonomy-item">#<!-- -->Fast-Slow Models</span><span class="page__taxonomy-item">#<!-- -->Adversarial Training</span><span class="page__taxonomy-item">#<!-- -->Continual Learning</span><span class="page__taxonomy-item">#<!-- -->AGI Alignment</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-9-Revolutionizing_Reinforcement_Learning_Framework_for_Diffusion_Large_Language_Models/">[논문리뷰] Revolutionizing Reinforcement Learning Framework for Diffusion Large Language Models</a></h2><div class="archive__item-excerpt">Ke Shen이 [arXiv]에 게시한 &#x27;Revolutionizing Reinforcement Learning Framework for Diffusion Large Language Models&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-09 13:19:09+0900">2025년 9월 9일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Diffusion Language Models</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Trajectory-aware RL</span><span class="page__taxonomy-item">#<!-- -->Value Model</span><span class="page__taxonomy-item">#<!-- -->Masked Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Reasoning Tasks</span><span class="page__taxonomy-item">#<!-- -->Code Generation</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-9-Reverse-Engineered_Reasoning_for_Open-Ended_Generation/">[논문리뷰] Reverse-Engineered Reasoning for Open-Ended Generation</a></h2><div class="archive__item-excerpt">Wangchunshu Zhou이 [arXiv]에 게시한 &#x27;Reverse-Engineered Reasoning for Open-Ended Generation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-09 13:19:09+0900">2025년 9월 9일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Deep Reasoning</span><span class="page__taxonomy-item">#<!-- -->Open-Ended Generation</span><span class="page__taxonomy-item">#<!-- -->Reverse-Engineered Reasoning (REER)</span><span class="page__taxonomy-item">#<!-- -->LLMs</span><span class="page__taxonomy-item">#<!-- -->Synthetic Data</span><span class="page__taxonomy-item">#<!-- -->Iterative Refinement</span><span class="page__taxonomy-item">#<!-- -->Perplexity Minimization</span><span class="page__taxonomy-item">#<!-- -->DeepWriting-20K</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-9-Reinforcement_Learning_Foundations_for_Deep_Research_Systems_A_Survey/">[논문리뷰] Reinforcement Learning Foundations for Deep Research Systems: A Survey</a></h2><div class="archive__item-excerpt">Wei Han이 [arXiv]에 게시한 &#x27;Reinforcement Learning Foundations for Deep Research Systems: A Survey&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-09 13:19:09+0900">2025년 9월 9일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Deep Research Systems</span><span class="page__taxonomy-item">#<!-- -->Agentic AI</span><span class="page__taxonomy-item">#<!-- -->Tool Use</span><span class="page__taxonomy-item">#<!-- -->Hierarchical Agents</span><span class="page__taxonomy-item">#<!-- -->Reward Design</span><span class="page__taxonomy-item">#<!-- -->Multimodal AI</span><span class="page__taxonomy-item">#<!-- -->RL Frameworks</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-9-Reinforced_Visual_Perception_with_Tools/">[논문리뷰] Reinforced Visual Perception with Tools</a></h2><div class="archive__item-excerpt">Mingyang Fu이 [arXiv]에 게시한 &#x27;Reinforced Visual Perception with Tools&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-09 13:19:09+0900">2025년 9월 9일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Visual Reasoning</span><span class="page__taxonomy-item">#<!-- -->Multimodal LLMs</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Tool Usage</span><span class="page__taxonomy-item">#<!-- -->Perception-heavy Benchmarks</span><span class="page__taxonomy-item">#<!-- -->GRPO</span><span class="page__taxonomy-item">#<!-- -->Vision Tools</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-9-Paper2Agent_Reimagining_Research_Papers_As_Interactive_and_Reliable_AI_Agents/">[논문리뷰] Paper2Agent: Reimagining Research Papers As Interactive and Reliable AI Agents</a></h2><div class="archive__item-excerpt">James Zou이 [arXiv]에 게시한 &#x27;Paper2Agent: Reimagining Research Papers As Interactive and Reliable AI Agents&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-09 13:19:09+0900">2025년 9월 9일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->AI Agents</span><span class="page__taxonomy-item">#<!-- -->Research Reproducibility</span><span class="page__taxonomy-item">#<!-- -->Scientific Communication</span><span class="page__taxonomy-item">#<!-- -->Model Context Protocol (MCP)</span><span class="page__taxonomy-item">#<!-- -->Natural Language Interaction</span><span class="page__taxonomy-item">#<!-- -->Genomics</span><span class="page__taxonomy-item">#<!-- -->Single-Cell Analysis</span><span class="page__taxonomy-item">#<!-- -->Spatial Transcriptomics</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-9-MAS-Bench_A_Unified_Benchmark_for_Shortcut-Augmented_Hybrid_Mobile_GUI_Agents/">[논문리뷰] MAS-Bench: A Unified Benchmark for Shortcut-Augmented Hybrid Mobile GUI Agents</a></h2><div class="archive__item-excerpt">Zhengxi Lu이 [arXiv]에 게시한 &#x27;MAS-Bench: A Unified Benchmark for Shortcut-Augmented Hybrid Mobile GUI Agents&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-09 13:19:09+0900">2025년 9월 9일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Mobile GUI Agents</span><span class="page__taxonomy-item">#<!-- -->Hybrid Automation</span><span class="page__taxonomy-item">#<!-- -->Shortcut Generation</span><span class="page__taxonomy-item">#<!-- -->Benchmark</span><span class="page__taxonomy-item">#<!-- -->Task Efficiency</span><span class="page__taxonomy-item">#<!-- -->LLM-based Agents</span><span class="page__taxonomy-item">#<!-- -->Mobile Robotics</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-9-Llama-GENBA-10B_A_Trilingual_Large_Language_Model_for_German_English_and_Bavarian/">[논문리뷰] Llama-GENBA-10B: A Trilingual Large Language Model for German, English and Bavarian</a></h2><div class="archive__item-excerpt">Hoi-Fong Mak이 [arXiv]에 게시한 &#x27;Llama-GENBA-10B: A Trilingual Large Language Model for German, English and Bavarian&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-09 13:19:09+0900">2025년 9월 9일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Multilingual LLM</span><span class="page__taxonomy-item">#<!-- -->Low-Resource Language</span><span class="page__taxonomy-item">#<!-- -->German</span><span class="page__taxonomy-item">#<!-- -->Bavarian Dialect</span><span class="page__taxonomy-item">#<!-- -->Cross-Lingual Transfer</span><span class="page__taxonomy-item">#<!-- -->Continuous Pretraining</span><span class="page__taxonomy-item">#<!-- -->Llama-3.1</span><span class="page__taxonomy-item">#<!-- -->Model Expansion</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-9-Interleaving_Reasoning_for_Better_Text-to-Image_Generation/">[논문리뷰] Interleaving Reasoning for Better Text-to-Image Generation</a></h2><div class="archive__item-excerpt">Shixiang Tang이 [arXiv]에 게시한 &#x27;Interleaving Reasoning for Better Text-to-Image Generation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-09 13:19:09+0900">2025년 9월 9일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Text-to-Image Generation</span><span class="page__taxonomy-item">#<!-- -->Interleaving Reasoning</span><span class="page__taxonomy-item">#<!-- -->Multimodal Learning</span><span class="page__taxonomy-item">#<!-- -->Visual Quality</span><span class="page__taxonomy-item">#<!-- -->Fine-grained Detail</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->Self-Correction</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-9-Focusing_by_Contrastive_Attention_Enhancing_VLMs_Visual_Reasoning/">[논문리뷰] Focusing by Contrastive Attention: Enhancing VLMs&#x27; Visual Reasoning</a></h2><div class="archive__item-excerpt">Baolong Bi이 [arXiv]에 게시한 &#x27;Focusing by Contrastive Attention: Enhancing VLMs&#x27; Visual Reasoning&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-09 13:19:09+0900">2025년 9월 9일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Vision-Language Models (VLMs)</span><span class="page__taxonomy-item">#<!-- -->Visual Reasoning</span><span class="page__taxonomy-item">#<!-- -->Attention Mechanisms</span><span class="page__taxonomy-item">#<!-- -->Contrastive Learning</span><span class="page__taxonomy-item">#<!-- -->Noise Suppression</span><span class="page__taxonomy-item">#<!-- -->Visual Complexity</span><span class="page__taxonomy-item">#<!-- -->Training-Free</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-9-Easier_Painting_Than_Thinking_Can_Text-to-Image_Models_Set_the_Stage_but_Not_Direct_the_Play/">[논문리뷰] Easier Painting Than Thinking: Can Text-to-Image Models Set the Stage, but Not Direct the Play?</a></h2><div class="archive__item-excerpt">Rui Chen이 [arXiv]에 게시한 &#x27;Easier Painting Than Thinking: Can Text-to-Image Models Set the Stage, but Not Direct the Play?&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-09 13:19:09+0900">2025년 9월 9일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Text-to-Image Generation</span><span class="page__taxonomy-item">#<!-- -->T2I Benchmarking</span><span class="page__taxonomy-item">#<!-- -->Compositional Reasoning</span><span class="page__taxonomy-item">#<!-- -->Deductive Inference</span><span class="page__taxonomy-item">#<!-- -->Inductive Inference</span><span class="page__taxonomy-item">#<!-- -->Abductive Inference</span><span class="page__taxonomy-item">#<!-- -->MLLM Evaluation</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-9-Does_DINOv3_Set_a_New_Medical_Vision_Standard/">[논문리뷰] Does DINOv3 Set a New Medical Vision Standard?</a></h2><div class="archive__item-excerpt">Bailiang Jian이 [arXiv]에 게시한 &#x27;Does DINOv3 Set a New Medical Vision Standard?&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-09 13:19:09+0900">2025년 9월 9일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Medical Imaging</span><span class="page__taxonomy-item">#<!-- -->Foundation Models</span><span class="page__taxonomy-item">#<!-- -->DINOv3</span><span class="page__taxonomy-item">#<!-- -->Self-Supervised Learning</span><span class="page__taxonomy-item">#<!-- -->Vision Transformer</span><span class="page__taxonomy-item">#<!-- -->2D/3D Classification</span><span class="page__taxonomy-item">#<!-- -->Segmentation</span><span class="page__taxonomy-item">#<!-- -->Domain Adaptation</span><span class="page__taxonomy-item">#<!-- -->Scaling Laws</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-9-D-HUMOR_Dark_Humor_Understanding_via_Multimodal_Open-ended_Reasoning/">[논문리뷰] D-HUMOR: Dark Humor Understanding via Multimodal Open-ended Reasoning</a></h2><div class="archive__item-excerpt">Dhanvin Sanjay Namboodiri이 [arXiv]에 게시한 &#x27;D-HUMOR: Dark Humor Understanding via Multimodal Open-ended Reasoning&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-09 13:19:09+0900">2025년 9월 9일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Dark Humor Detection</span><span class="page__taxonomy-item">#<!-- -->Multimodal Reasoning</span><span class="page__taxonomy-item">#<!-- -->Vision-Language Models (VLMs)</span><span class="page__taxonomy-item">#<!-- -->Iterative Reasoning Refinement</span><span class="page__taxonomy-item">#<!-- -->Meme Analysis</span><span class="page__taxonomy-item">#<!-- -->Content Moderation</span><span class="page__taxonomy-item">#<!-- -->Cross-Modal Attention</span><span class="page__taxonomy-item">#<!-- -->Dataset Annotation</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-8-WinT3R_Window-Based_Streaming_Reconstruction_with_Camera_Token_Pool/">[논문리뷰] WinT3R: Window-Based Streaming Reconstruction with Camera Token Pool</a></h2><div class="archive__item-excerpt">Wenzheng Chang이 [arXiv]에 게시한 &#x27;WinT3R: Window-Based Streaming Reconstruction with Camera Token Pool&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-08 13:10:18+0900">2025년 9월 8일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Online 3D Reconstruction</span><span class="page__taxonomy-item">#<!-- -->Camera Pose Estimation</span><span class="page__taxonomy-item">#<!-- -->Streaming Reconstruction</span><span class="page__taxonomy-item">#<!-- -->Sliding Window</span><span class="page__taxonomy-item">#<!-- -->Camera Token Pool</span><span class="page__taxonomy-item">#<!-- -->Real-time Performance</span><span class="page__taxonomy-item">#<!-- -->Computer Vision</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-8-WildScore_Benchmarking_MLLMs_in-the-Wild_Symbolic_Music_Reasoning/">[논문리뷰] WildScore: Benchmarking MLLMs in-the-Wild Symbolic Music Reasoning</a></h2><div class="archive__item-excerpt">Amit Namburi이 [arXiv]에 게시한 &#x27;WildScore: Benchmarking MLLMs in-the-Wild Symbolic Music Reasoning&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-08 13:10:18+0900">2025년 9월 8일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Multimodal Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Symbolic Music Reasoning</span><span class="page__taxonomy-item">#<!-- -->Music Score Analysis</span><span class="page__taxonomy-item">#<!-- -->Benchmarking</span><span class="page__taxonomy-item">#<!-- -->Visual Question Answering</span><span class="page__taxonomy-item">#<!-- -->In-the-Wild Data</span><span class="page__taxonomy-item">#<!-- -->Music Theory</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-8-Why_Language_Models_Hallucinate/">[논문리뷰] Why Language Models Hallucinate</a></h2><div class="archive__item-excerpt">Edwin Zhang이 [arXiv]에 게시한 &#x27;Why Language Models Hallucinate&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-08 13:10:18+0900">2025년 9월 8일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Language Models</span><span class="page__taxonomy-item">#<!-- -->Hallucination</span><span class="page__taxonomy-item">#<!-- -->Pretraining</span><span class="page__taxonomy-item">#<!-- -->Post-training</span><span class="page__taxonomy-item">#<!-- -->Evaluation Metrics</span><span class="page__taxonomy-item">#<!-- -->Binary Classification</span><span class="page__taxonomy-item">#<!-- -->Uncertainty Quantification</span><span class="page__taxonomy-item">#<!-- -->Calibration</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-8-U-ARM_Ultra_low-cost_general_teleoperation_interface_for_robot_manipulation/">[논문리뷰] U-ARM : Ultra low-cost general teleoperation interface for robot manipulation</a></h2><div class="archive__item-excerpt">Junda Huang이 [arXiv]에 게시한 &#x27;U-ARM : Ultra low-cost general teleoperation interface for robot manipulation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-08 13:10:18+0900">2025년 9월 8일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Teleoperation</span><span class="page__taxonomy-item">#<!-- -->Robot Manipulation</span><span class="page__taxonomy-item">#<!-- -->Low-Cost Hardware</span><span class="page__taxonomy-item">#<!-- -->3D Printing</span><span class="page__taxonomy-item">#<!-- -->Leader-Follower System</span><span class="page__taxonomy-item">#<!-- -->Data Collection</span><span class="page__taxonomy-item">#<!-- -->Robotics Interface</span><span class="page__taxonomy-item">#<!-- -->Open Source</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-8-Symbolic_Graphics_Programming_with_Large_Language_Models/">[논문리뷰] Symbolic Graphics Programming with Large Language Models</a></h2><div class="archive__item-excerpt">Kaipeng Zhang이 [arXiv]에 게시한 &#x27;Symbolic Graphics Programming with Large Language Models&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-08 13:10:18+0900">2025년 9월 8일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Symbolic Graphics Programming</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->SVG Generation</span><span class="page__taxonomy-item">#<!-- -->Text-to-Image Synthesis</span><span class="page__taxonomy-item">#<!-- -->Cross-Modal Alignment</span><span class="page__taxonomy-item">#<!-- -->Program Synthesis</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-8-Set_Block_Decoding_is_a_Language_Model_Inference_Accelerator/">[논문리뷰] Set Block Decoding is a Language Model Inference Accelerator</a></h2><div class="archive__item-excerpt">Jeremy Reizenstein이 [arXiv]에 게시한 &#x27;Set Block Decoding is a Language Model Inference Accelerator&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-08 13:10:18+0900">2025년 9월 8일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Language Model Inference</span><span class="page__taxonomy-item">#<!-- -->Acceleration</span><span class="page__taxonomy-item">#<!-- -->Set Block Decoding</span><span class="page__taxonomy-item">#<!-- -->Next Token Prediction</span><span class="page__taxonomy-item">#<!-- -->Masked Token Prediction</span><span class="page__taxonomy-item">#<!-- -->Parallel Decoding</span><span class="page__taxonomy-item">#<!-- -->KV-caching</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-8-On_Robustness_and_Reliability_of_Benchmark-Based_Evaluation_of_LLMs/">[논문리뷰] On Robustness and Reliability of Benchmark-Based Evaluation of LLMs</a></h2><div class="archive__item-excerpt">Kevin Roitero이 [arXiv]에 게시한 &#x27;On Robustness and Reliability of Benchmark-Based Evaluation of LLMs&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-08 13:10:18+0900">2025년 9월 8일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLM Evaluation</span><span class="page__taxonomy-item">#<!-- -->Model Robustness</span><span class="page__taxonomy-item">#<!-- -->Benchmark Reliability</span><span class="page__taxonomy-item">#<!-- -->Paraphrasing</span><span class="page__taxonomy-item">#<!-- -->Linguistic Variability</span><span class="page__taxonomy-item">#<!-- -->Generalization</span><span class="page__taxonomy-item">#<!-- -->Question Answering</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-8-MedVista3D_Vision-Language_Modeling_for_Reducing_Diagnostic_Errors_in_3D_CT_Disease_Detection_Understanding_and_Reporting/">[논문리뷰] MedVista3D: Vision-Language Modeling for Reducing Diagnostic Errors in 3D CT Disease Detection, Understanding and Reporting</a></h2><div class="archive__item-excerpt">Vanessa Wildman이 [arXiv]에 게시한 &#x27;MedVista3D: Vision-Language Modeling for Reducing Diagnostic Errors in 3D CT Disease Detection, Understanding and Reporting&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-08 13:10:18+0900">2025년 9월 8일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->3D CT</span><span class="page__taxonomy-item">#<!-- -->Vision-Language Model</span><span class="page__taxonomy-item">#<!-- -->Medical Imaging</span><span class="page__taxonomy-item">#<!-- -->Diagnostic Error Reduction</span><span class="page__taxonomy-item">#<!-- -->Multi-scale Alignment</span><span class="page__taxonomy-item">#<!-- -->Semantic Enrichment</span><span class="page__taxonomy-item">#<!-- -->Radiology Reporting</span><span class="page__taxonomy-item">#<!-- -->Zero-shot Learning</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-8-LuxDiT_Lighting_Estimation_with_Video_Diffusion_Transformer/">[논문리뷰] LuxDiT: Lighting Estimation with Video Diffusion Transformer</a></h2><div class="archive__item-excerpt">Sanja Fidler이 [arXiv]에 게시한 &#x27;LuxDiT: Lighting Estimation with Video Diffusion Transformer&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-08 13:10:18+0900">2025년 9월 8일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Lighting Estimation</span><span class="page__taxonomy-item">#<!-- -->HDR Environment Map</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->Video Transformer</span><span class="page__taxonomy-item">#<!-- -->Low-Rank Adaptation</span><span class="page__taxonomy-item">#<!-- -->Generative Models</span><span class="page__taxonomy-item">#<!-- -->Synthetic Data</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-8-LatticeWorld_A_Multimodal_Large_Language_Model-Empowered_Framework_for_Interactive_Complex_World_Generation/">[논문리뷰] LatticeWorld: A Multimodal Large Language Model-Empowered Framework for Interactive Complex World Generation</a></h2><div class="archive__item-excerpt">Zhan Zhao이 [arXiv]에 게시한 &#x27;LatticeWorld: A Multimodal Large Language Model-Empowered Framework for Interactive Complex World Generation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-08 13:10:18+0900">2025년 9월 8일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Multimodal LLM</span><span class="page__taxonomy-item">#<!-- -->3D World Generation</span><span class="page__taxonomy-item">#<!-- -->Unreal Engine 5</span><span class="page__taxonomy-item">#<!-- -->Procedural Content Generation</span><span class="page__taxonomy-item">#<!-- -->Interactive Environments</span><span class="page__taxonomy-item">#<!-- -->Sim-to-Real</span><span class="page__taxonomy-item">#<!-- -->Spatial Understanding</span><span class="page__taxonomy-item">#<!-- -->Multimodal Input</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-8-Bootstrapping_Task_Spaces_for_Self-Improvement/">[논문리뷰] Bootstrapping Task Spaces for Self-Improvement</a></h2><div class="archive__item-excerpt">Yoram Bachrach이 [arXiv]에 게시한 &#x27;Bootstrapping Task Spaces for Self-Improvement&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-08 13:10:18+0900">2025년 9월 8일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning (RL)</span><span class="page__taxonomy-item">#<!-- -->Large Language Models (LLMs)</span><span class="page__taxonomy-item">#<!-- -->Self-Improvement</span><span class="page__taxonomy-item">#<!-- -->Autocurriculum</span><span class="page__taxonomy-item">#<!-- -->Task-Space Exploration</span><span class="page__taxonomy-item">#<!-- -->Inference-Time Iteration</span><span class="page__taxonomy-item">#<!-- -->Policy Optimization</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-8-Behavioral_Fingerprinting_of_Large_Language_Models/">[논문리뷰] Behavioral Fingerprinting of Large Language Models</a></h2><div class="archive__item-excerpt">Xing Li이 [arXiv]에 게시한 &#x27;Behavioral Fingerprinting of Large Language Models&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-08 13:10:18+0900">2025년 9월 8일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Behavioral Evaluation</span><span class="page__taxonomy-item">#<!-- -->Model Alignment</span><span class="page__taxonomy-item">#<!-- -->Sycophancy</span><span class="page__taxonomy-item">#<!-- -->World Model Brittleness</span><span class="page__taxonomy-item">#<!-- -->Metacognition</span><span class="page__taxonomy-item">#<!-- -->Personality Profiling</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-5-Video-MTR_Reinforced_Multi-Turn_Reasoning_for_Long_Video_Understanding/">[논문리뷰] Video-MTR: Reinforced Multi-Turn Reasoning for Long Video Understanding</a></h2><div class="archive__item-excerpt">Lionel Ni이 [arXiv]에 게시한 &#x27;Video-MTR: Reinforced Multi-Turn Reasoning for Long Video Understanding&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-05 13:07:20+0900">2025년 9월 5일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Long Video Understanding</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Multi-Turn Reasoning</span><span class="page__taxonomy-item">#<!-- -->MLLMs</span><span class="page__taxonomy-item">#<!-- -->Video Segment Selection</span><span class="page__taxonomy-item">#<!-- -->Bi-level Reward</span><span class="page__taxonomy-item">#<!-- -->Question Answering</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-5-Transition_Models_Rethinking_the_Generative_Learning_Objective/">[논문리뷰] Transition Models: Rethinking the Generative Learning Objective</a></h2><div class="archive__item-excerpt">Yangguang Li이 [arXiv]에 게시한 &#x27;Transition Models: Rethinking the Generative Learning Objective&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-05 13:07:20+0900">2025년 9월 5일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Generative Models</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->Training Objective</span><span class="page__taxonomy-item">#<!-- -->Continuous-Time Dynamics</span><span class="page__taxonomy-item">#<!-- -->State Transition</span><span class="page__taxonomy-item">#<!-- -->Few-Step Generation</span><span class="page__taxonomy-item">#<!-- -->Scalable Training</span><span class="page__taxonomy-item">#<!-- -->Image Generation</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-5-Towards_a_Unified_View_of_Large_Language_Model_Post-Training/">[논문리뷰] Towards a Unified View of Large Language Model Post-Training</a></h2><div class="archive__item-excerpt">Hongyi Liu이 [arXiv]에 게시한 &#x27;Towards a Unified View of Large Language Model Post-Training&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-05 13:07:20+0900">2025년 9월 5일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Large Language Models (LLMs)</span><span class="page__taxonomy-item">#<!-- -->Post-Training</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning (RL)</span><span class="page__taxonomy-item">#<!-- -->Supervised Fine-Tuning (SFT)</span><span class="page__taxonomy-item">#<!-- -->Policy Gradient</span><span class="page__taxonomy-item">#<!-- -->Unified Framework</span><span class="page__taxonomy-item">#<!-- -->Hybrid Algorithms</span><span class="page__taxonomy-item">#<!-- -->Bias-Variance Tradeoff</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-5-NER_Retriever_Zero-Shot_Named_Entity_Retrieval_with_Type-Aware_Embeddings/">[논문리뷰] NER Retriever: Zero-Shot Named Entity Retrieval with Type-Aware Embeddings</a></h2><div class="archive__item-excerpt">Oren Glickman이 [arXiv]에 게시한 &#x27;NER Retriever: Zero-Shot Named Entity Retrieval with Type-Aware Embeddings&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-05 13:07:20+0900">2025년 9월 5일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Named Entity Retrieval</span><span class="page__taxonomy-item">#<!-- -->Zero-Shot Learning</span><span class="page__taxonomy-item">#<!-- -->Type-Aware Embeddings</span><span class="page__taxonomy-item">#<!-- -->Large Language Models (LLMs)</span><span class="page__taxonomy-item">#<!-- -->Contrastive Learning</span><span class="page__taxonomy-item">#<!-- -->Internal Representations</span><span class="page__taxonomy-item">#<!-- -->Information Retrieval</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-5-Inverse_IFEval_Can_LLMs_Unlearn_Stubborn_Training_Conventions_to_Follow_Real_Instructions/">[논문리뷰] Inverse IFEval: Can LLMs Unlearn Stubborn Training Conventions to Follow Real Instructions?</a></h2><div class="archive__item-excerpt">Yu Fu이 [arXiv]에 게시한 &#x27;Inverse IFEval: Can LLMs Unlearn Stubborn Training Conventions to Follow Real Instructions?&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-05 13:07:20+0900">2025년 9월 5일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLMs</span><span class="page__taxonomy-item">#<!-- -->Instruction Following</span><span class="page__taxonomy-item">#<!-- -->Benchmark</span><span class="page__taxonomy-item">#<!-- -->Cognitive Inertia</span><span class="page__taxonomy-item">#<!-- -->Out-of-Distribution</span><span class="page__taxonomy-item">#<!-- -->Supervised Fine-Tuning</span><span class="page__taxonomy-item">#<!-- -->Evaluation</span><span class="page__taxonomy-item">#<!-- -->Robustness</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-5-From_Editor_to_Dense_Geometry_Estimator/">[논문리뷰] From Editor to Dense Geometry Estimator</a></h2><div class="archive__item-excerpt">Lang Nie이 [arXiv]에 게시한 &#x27;From Editor to Dense Geometry Estimator&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-05 13:07:20+0900">2025년 9월 5일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Dense Geometry Estimation</span><span class="page__taxonomy-item">#<!-- -->Diffusion Transformer</span><span class="page__taxonomy-item">#<!-- -->Image Editing</span><span class="page__taxonomy-item">#<!-- -->Zero-shot Learning</span><span class="page__taxonomy-item">#<!-- -->Depth Estimation</span><span class="page__taxonomy-item">#<!-- -->Normal Estimation</span><span class="page__taxonomy-item">#<!-- -->Flow Matching</span><span class="page__taxonomy-item">#<!-- -->Logarithmic Quantization</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-5-Few-step_Flow_for_3D_Generation_via_Marginal-Data_Transport_Distillation/">[논문리뷰] Few-step Flow for 3D Generation via Marginal-Data Transport Distillation</a></h2><div class="archive__item-excerpt">Lingxi Xie이 [arXiv]에 게시한 &#x27;Few-step Flow for 3D Generation via Marginal-Data Transport Distillation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-05 13:07:20+0900">2025년 9월 5일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->3D Generation</span><span class="page__taxonomy-item">#<!-- -->Flow-based Models</span><span class="page__taxonomy-item">#<!-- -->Model Distillation</span><span class="page__taxonomy-item">#<!-- -->Few-step Sampling</span><span class="page__taxonomy-item">#<!-- -->Marginal-Data Transport</span><span class="page__taxonomy-item">#<!-- -->Velocity Matching</span><span class="page__taxonomy-item">#<!-- -->Velocity Distillation</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-5-False_Sense_of_Security_Why_Probing-based_Malicious_Input_Detection_Fails_to_Generalize/">[논문리뷰] False Sense of Security: Why Probing-based Malicious Input Detection Fails to Generalize</a></h2><div class="archive__item-excerpt">Muhao Chen이 [arXiv]에 게시한 &#x27;False Sense of Security: Why Probing-based Malicious Input Detection Fails to Generalize&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-05 13:07:20+0900">2025년 9월 5일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLM Safety</span><span class="page__taxonomy-item">#<!-- -->Malicious Input Detection</span><span class="page__taxonomy-item">#<!-- -->Probing Classifiers</span><span class="page__taxonomy-item">#<!-- -->Out-of-Distribution Generalization</span><span class="page__taxonomy-item">#<!-- -->Superficial Patterns</span><span class="page__taxonomy-item">#<!-- -->Instructional Patterns</span><span class="page__taxonomy-item">#<!-- -->Trigger Words</span><span class="page__taxonomy-item">#<!-- -->AI Safety</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-5-Durian_Dual_Reference-guided_Portrait_Animation_with_Attribute_Transfer/">[논문리뷰] Durian: Dual Reference-guided Portrait Animation with Attribute Transfer</a></h2><div class="archive__item-excerpt">Hanbyul Joo이 [arXiv]에 게시한 &#x27;Durian: Dual Reference-guided Portrait Animation with Attribute Transfer&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-05 13:07:20+0900">2025년 9월 5일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Portrait Animation</span><span class="page__taxonomy-item">#<!-- -->Attribute Transfer</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->Dual Reference Networks</span><span class="page__taxonomy-item">#<!-- -->Zero-shot Learning</span><span class="page__taxonomy-item">#<!-- -->Self-Reconstruction</span><span class="page__taxonomy-item">#<!-- -->Facial Editing</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-5-Drivel-ology_Challenging_LLMs_with_Interpreting_Nonsense_with_Depth/">[논문리뷰] Drivel-ology: Challenging LLMs with Interpreting Nonsense with Depth</a></h2><div class="archive__item-excerpt">Chi-Li Chen이 [arXiv]에 게시한 &#x27;Drivel-ology: Challenging LLMs with Interpreting Nonsense with Depth&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-05 13:07:20+0900">2025년 9월 5일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Pragmatic Understanding</span><span class="page__taxonomy-item">#<!-- -->Drivelology</span><span class="page__taxonomy-item">#<!-- -->Benchmark Dataset</span><span class="page__taxonomy-item">#<!-- -->Multilingual NLP</span><span class="page__taxonomy-item">#<!-- -->Semantic Reasoning</span><span class="page__taxonomy-item">#<!-- -->Contextual Inference</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-5-Drawing2CAD_Sequence-to-Sequence_Learning_for_CAD_Generation_from_Vector_Drawings/">[논문리뷰] Drawing2CAD: Sequence-to-Sequence Learning for CAD Generation from Vector Drawings</a></h2><div class="archive__item-excerpt">Meie Fang이 [arXiv]에 게시한 &#x27;Drawing2CAD: Sequence-to-Sequence Learning for CAD Generation from Vector Drawings&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-05 13:07:20+0900">2025년 9월 5일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->CAD Generation</span><span class="page__taxonomy-item">#<!-- -->Vector Graphics</span><span class="page__taxonomy-item">#<!-- -->Sequence-to-Sequence Learning</span><span class="page__taxonomy-item">#<!-- -->Transformer Architecture</span><span class="page__taxonomy-item">#<!-- -->Engineering Drawings</span><span class="page__taxonomy-item">#<!-- -->Multi-modal Learning</span><span class="page__taxonomy-item">#<!-- -->Soft Target Loss</span><span class="page__taxonomy-item">#<!-- -->Dual Decoder</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-5-Delta_Activations_A_Representation_for_Finetuned_Large_Language_Models/">[논문리뷰] Delta Activations: A Representation for Finetuned Large Language Models</a></h2><div class="archive__item-excerpt">Ser-Nam Lim이 [arXiv]에 게시한 &#x27;Delta Activations: A Representation for Finetuned Large Language Models&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-05 13:07:20+0900">2025년 9월 5일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLM Embedding</span><span class="page__taxonomy-item">#<!-- -->Delta Activations</span><span class="page__taxonomy-item">#<!-- -->Finetuned Models</span><span class="page__taxonomy-item">#<!-- -->Model Representation</span><span class="page__taxonomy-item">#<!-- -->Model Clustering</span><span class="page__taxonomy-item">#<!-- -->Additive Property</span><span class="page__taxonomy-item">#<!-- -->Task Embedding</span><span class="page__taxonomy-item">#<!-- -->Model Merging</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-5-DeepResearch_Arena_The_First_Exam_of_LLMs_Research_Abilities_via_Seminar-Grounded_Tasks/">[논문리뷰] DeepResearch Arena: The First Exam of LLMs&#x27; Research Abilities via Seminar-Grounded Tasks</a></h2><div class="archive__item-excerpt">Jiaxuan Lu이 [arXiv]에 게시한 &#x27;DeepResearch Arena: The First Exam of LLMs&#x27; Research Abilities via Seminar-Grounded Tasks&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-05 13:07:20+0900">2025년 9월 5일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLM Evaluation</span><span class="page__taxonomy-item">#<!-- -->Research Agents</span><span class="page__taxonomy-item">#<!-- -->Benchmark</span><span class="page__taxonomy-item">#<!-- -->Multi-Agent System</span><span class="page__taxonomy-item">#<!-- -->Seminar-Grounded Tasks</span><span class="page__taxonomy-item">#<!-- -->Data Leakage Prevention</span><span class="page__taxonomy-item">#<!-- -->Ill-Structured Problems</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-4-Robix_A_Unified_Model_for_Robot_Interaction_Reasoning_and_Planning/">[논문리뷰] Robix: A Unified Model for Robot Interaction, Reasoning and Planning</a></h2><div class="archive__item-excerpt">Zixuan Wang이 [arXiv]에 게시한 &#x27;Robix: A Unified Model for Robot Interaction, Reasoning and Planning&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-04 12:56:15+0900">2025년 9월 4일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Robot Learning</span><span class="page__taxonomy-item">#<!-- -->Vision-Language Models (VLMs)</span><span class="page__taxonomy-item">#<!-- -->Embodied AI</span><span class="page__taxonomy-item">#<!-- -->Human-Robot Interaction (HRI)</span><span class="page__taxonomy-item">#<!-- -->Task Planning</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning (RL)</span><span class="page__taxonomy-item">#<!-- -->Chain-of-Thought (CoT) Reasoning</span><span class="page__taxonomy-item">#<!-- -->Robotics</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-4-Open_Data_Synthesis_For_Deep_Research/">[논문리뷰] Open Data Synthesis For Deep Research</a></h2><div class="archive__item-excerpt">Zheng Liu이 [arXiv]에 게시한 &#x27;Open Data Synthesis For Deep Research&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-04 12:56:15+0900">2025년 9월 4일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Data Synthesis</span><span class="page__taxonomy-item">#<!-- -->Deep Research</span><span class="page__taxonomy-item">#<!-- -->Hierarchical Constraint Satisfaction Problems</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Agentic AI</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Question Answering</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-4-MOSAIC_Multi-Subject_Personalized_Generation_via_Correspondence-Aware_Alignment_and_Disentanglement/">[논문리뷰] MOSAIC: Multi-Subject Personalized Generation via Correspondence-Aware Alignment and Disentanglement</a></h2><div class="archive__item-excerpt">Hualiang Wang이 [arXiv]에 게시한 &#x27;MOSAIC: Multi-Subject Personalized Generation via Correspondence-Aware Alignment and Disentanglement&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-04 12:56:15+0900">2025년 9월 4일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Multi-Subject Generation</span><span class="page__taxonomy-item">#<!-- -->Personalized Image Synthesis</span><span class="page__taxonomy-item">#<!-- -->Semantic Correspondence</span><span class="page__taxonomy-item">#<!-- -->Attention Disentanglement</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->Identity Preservation</span><span class="page__taxonomy-item">#<!-- -->Dataset</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-4-Mixture_of_Global_and_Local_Experts_with_Diffusion_Transformer_for_Controllable_Face_Generation/">[논문리뷰] Mixture of Global and Local Experts with Diffusion Transformer for Controllable Face Generation</a></h2><div class="archive__item-excerpt">Kai Li이 [arXiv]에 게시한 &#x27;Mixture of Global and Local Experts with Diffusion Transformer for Controllable Face Generation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-04 12:56:15+0900">2025년 9월 4일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Diffusion Transformer</span><span class="page__taxonomy-item">#<!-- -->Mixture of Experts</span><span class="page__taxonomy-item">#<!-- -->Controllable Generation</span><span class="page__taxonomy-item">#<!-- -->Face Generation</span><span class="page__taxonomy-item">#<!-- -->Multimodal Synthesis</span><span class="page__taxonomy-item">#<!-- -->Semantic Control</span><span class="page__taxonomy-item">#<!-- -->Image Generation</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-4-LMEnt_A_Suite_for_Analyzing_Knowledge_in_Language_Models_from_Pretraining_Data_to_Representations/">[논문리뷰] LMEnt: A Suite for Analyzing Knowledge in Language Models from Pretraining Data to Representations</a></h2><div class="archive__item-excerpt">Yoav Gur-Arieh이 [arXiv]에 게시한 &#x27;LMEnt: A Suite for Analyzing Knowledge in Language Models from Pretraining Data to Representations&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-04 12:56:15+0900">2025년 9월 4일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Language Models</span><span class="page__taxonomy-item">#<!-- -->Knowledge Acquisition</span><span class="page__taxonomy-item">#<!-- -->Pretraining Data</span><span class="page__taxonomy-item">#<!-- -->Entity Linking</span><span class="page__taxonomy-item">#<!-- -->Coreference Resolution</span><span class="page__taxonomy-item">#<!-- -->Information Retrieval</span><span class="page__taxonomy-item">#<!-- -->Model Analysis</span><span class="page__taxonomy-item">#<!-- -->Checkpoints</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-3-ViSTA-SLAM_Visual_SLAM_with_Symmetric_Two-view_Association/">[논문리뷰] ViSTA-SLAM: Visual SLAM with Symmetric Two-view Association</a></h2><div class="archive__item-excerpt">Daniel Cremers이 [arXiv]에 게시한 &#x27;ViSTA-SLAM: Visual SLAM with Symmetric Two-view Association&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-03 13:36:21+0900">2025년 9월 3일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Monocular SLAM</span><span class="page__taxonomy-item">#<!-- -->Dense Reconstruction</span><span class="page__taxonomy-item">#<!-- -->Neural Networks</span><span class="page__taxonomy-item">#<!-- -->Pose Graph Optimization</span><span class="page__taxonomy-item">#<!-- -->Intrinsics-free</span><span class="page__taxonomy-item">#<!-- -->Real-time</span><span class="page__taxonomy-item">#<!-- -->Two-view Association</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-3-VerlTool_Towards_Holistic_Agentic_Reinforcement_Learning_with_Tool_Use/">[논문리뷰] VerlTool: Towards Holistic Agentic Reinforcement Learning with Tool Use</a></h2><div class="archive__item-excerpt">Zhiheng Lyu이 [arXiv]에 게시한 &#x27;VerlTool: Towards Holistic Agentic Reinforcement Learning with Tool Use&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-03 13:36:21+0900">2025년 9월 3일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Agentic Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Tool Use</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning from Verifiable Rewards (RLVR)</span><span class="page__taxonomy-item">#<!-- -->Asynchronous Execution</span><span class="page__taxonomy-item">#<!-- -->Multi-modal AI</span><span class="page__taxonomy-item">#<!-- -->Framework</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-3-Universal_Deep_Research_Bring_Your_Own_Model_and_Strategy/">[논문리뷰] Universal Deep Research: Bring Your Own Model and Strategy</a></h2><div class="archive__item-excerpt">Pavlo Molchanov이 [arXiv]에 게시한 &#x27;Universal Deep Research: Bring Your Own Model and Strategy&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-03 13:36:21+0900">2025년 9월 3일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Agentic Systems</span><span class="page__taxonomy-item">#<!-- -->Language Models (LLMs)</span><span class="page__taxonomy-item">#<!-- -->Research Automation</span><span class="page__taxonomy-item">#<!-- -->Customizable Strategies</span><span class="page__taxonomy-item">#<!-- -->Code Generation</span><span class="page__taxonomy-item">#<!-- -->Deep Research</span><span class="page__taxonomy-item">#<!-- -->User-Defined Agents</span><span class="page__taxonomy-item">#<!-- -->Sandboxed Execution</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-3-UI-TARS-2_Technical_Report_Advancing_GUI_Agent_with_Multi-Turn_Reinforcement_Learning/">[논문리뷰] UI-TARS-2 Technical Report: Advancing GUI Agent with Multi-Turn Reinforcement Learning</a></h2><div class="archive__item-excerpt">Haoyang Zou이 [arXiv]에 게시한 &#x27;UI-TARS-2 Technical Report: Advancing GUI Agent with Multi-Turn Reinforcement Learning&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-03 13:36:21+0900">2025년 9월 3일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->GUI Agent</span><span class="page__taxonomy-item">#<!-- -->Multi-Turn RL</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Data Flywheel</span><span class="page__taxonomy-item">#<!-- -->Agent Framework</span><span class="page__taxonomy-item">#<!-- -->Hybrid Environments</span><span class="page__taxonomy-item">#<!-- -->Parameter Interpolation</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-3-Towards_More_Diverse_and_Challenging_Pre-training_for_Point_Cloud_Learning_Self-Supervised_Cross_Reconstruction_with_Decoupled_Views/">[논문리뷰] Towards More Diverse and Challenging Pre-training for Point Cloud Learning: Self-Supervised Cross Reconstruction with Decoupled Views</a></h2><div class="archive__item-excerpt">Junchi Yan이 [arXiv]에 게시한 &#x27;Towards More Diverse and Challenging Pre-training for Point Cloud Learning: Self-Supervised Cross Reconstruction with Decoupled Views&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-03 13:36:21+0900">2025년 9월 3일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Point Cloud Learning</span><span class="page__taxonomy-item">#<!-- -->Self-Supervised Learning</span><span class="page__taxonomy-item">#<!-- -->Cross Reconstruction</span><span class="page__taxonomy-item">#<!-- -->Decoupled Views</span><span class="page__taxonomy-item">#<!-- -->Generative Models</span><span class="page__taxonomy-item">#<!-- -->Positional Encoding</span><span class="page__taxonomy-item">#<!-- -->3D Vision</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-3-The_Landscape_of_Agentic_Reinforcement_Learning_for_LLMs_A_Survey/">[논문리뷰] The Landscape of Agentic Reinforcement Learning for LLMs: A Survey</a></h2><div class="archive__item-excerpt">Hejia Geng이 [arXiv]에 게시한 &#x27;The Landscape of Agentic Reinforcement Learning for LLMs: A Survey&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-03 13:36:21+0900">2025년 9월 3일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Agentic Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->LLM Agents</span><span class="page__taxonomy-item">#<!-- -->Sequential Decision Making</span><span class="page__taxonomy-item">#<!-- -->Policy Optimization</span><span class="page__taxonomy-item">#<!-- -->Tool Use</span><span class="page__taxonomy-item">#<!-- -->Dynamic Environments</span><span class="page__taxonomy-item">#<!-- -->Autonomous AI</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-3-The_Gold_Medals_in_an_Empty_Room_Diagnosing_Metalinguistic_Reasoning_in_LLMs_with_Camlang/">[논문리뷰] The Gold Medals in an Empty Room: Diagnosing Metalinguistic Reasoning in LLMs with Camlang</a></h2><div class="archive__item-excerpt">Solomon Tsai이 [arXiv]에 게시한 &#x27;The Gold Medals in an Empty Room: Diagnosing Metalinguistic Reasoning in LLMs with Camlang&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-03 13:36:21+0900">2025년 9월 3일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLMs</span><span class="page__taxonomy-item">#<!-- -->Metalinguistic Reasoning</span><span class="page__taxonomy-item">#<!-- -->Constructed Language</span><span class="page__taxonomy-item">#<!-- -->Camlang</span><span class="page__taxonomy-item">#<!-- -->Second Language Acquisition</span><span class="page__taxonomy-item">#<!-- -->Zero-shot Learning</span><span class="page__taxonomy-item">#<!-- -->Natural Language Understanding</span><span class="page__taxonomy-item">#<!-- -->Commonsense Reasoning</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-3-SQL-of-Thought_Multi-agentic_Text-to-SQL_with_Guided_Error_Correction/">[논문리뷰] SQL-of-Thought: Multi-agentic Text-to-SQL with Guided Error Correction</a></h2><div class="archive__item-excerpt">bindsch이 [arXiv]에 게시한 &#x27;SQL-of-Thought: Multi-agentic Text-to-SQL with Guided Error Correction&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-03 13:36:21+0900">2025년 9월 3일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Text-to-SQL</span><span class="page__taxonomy-item">#<!-- -->Multi-agent Systems</span><span class="page__taxonomy-item">#<!-- -->Chain-of-Thought</span><span class="page__taxonomy-item">#<!-- -->Error Correction</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Query Planning</span><span class="page__taxonomy-item">#<!-- -->Database Interaction</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-3-SimpleTIR_End-to-End_Reinforcement_Learning_for_Multi-Turn_Tool-Integrated_Reasoning/">[논문리뷰] SimpleTIR: End-to-End Reinforcement Learning for Multi-Turn Tool-Integrated Reasoning</a></h2><div class="archive__item-excerpt">Qian Liu이 [arXiv]에 게시한 &#x27;SimpleTIR: End-to-End Reinforcement Learning for Multi-Turn Tool-Integrated Reasoning&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-03 13:36:21+0900">2025년 9월 3일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Tool-Integrated Reasoning</span><span class="page__taxonomy-item">#<!-- -->Multi-turn Reasoning</span><span class="page__taxonomy-item">#<!-- -->Gradient Explosion</span><span class="page__taxonomy-item">#<!-- -->Training Stability</span><span class="page__taxonomy-item">#<!-- -->Trajectory Filtering</span><span class="page__taxonomy-item">#<!-- -->Zero RL</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-3-Reasoning_Vectors_Transferring_Chain-of-Thought_Capabilities_via_Task_Arithmetic/">[논문리뷰] Reasoning Vectors: Transferring Chain-of-Thought Capabilities via Task Arithmetic</a></h2><div class="archive__item-excerpt">Bernard Ghanem이 [arXiv]에 게시한 &#x27;Reasoning Vectors: Transferring Chain-of-Thought Capabilities via Task Arithmetic&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-03 13:36:21+0900">2025년 9월 3일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Reasoning Vectors</span><span class="page__taxonomy-item">#<!-- -->Task Arithmetic</span><span class="page__taxonomy-item">#<!-- -->Chain-of-Thought</span><span class="page__taxonomy-item">#<!-- -->LLMs</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Model Merging</span><span class="page__taxonomy-item">#<!-- -->Parameter Transfer</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-3-POINTS-Reader_Distillation-Free_Adaptation_of_Vision-Language_Models_for_Document_Conversion/">[논문리뷰] POINTS-Reader: Distillation-Free Adaptation of Vision-Language Models for Document Conversion</a></h2><div class="archive__item-excerpt">Haicheng Wang이 [arXiv]에 게시한 &#x27;POINTS-Reader: Distillation-Free Adaptation of Vision-Language Models for Document Conversion&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-03 13:36:21+0900">2025년 9월 3일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->문서 변환</span><span class="page__taxonomy-item">#<!-- -->시각-언어 모델</span><span class="page__taxonomy-item">#<!-- -->자가 개선</span><span class="page__taxonomy-item">#<!-- -->합성 데이터</span><span class="page__taxonomy-item">#<!-- -->증류 없는 학습</span><span class="page__taxonomy-item">#<!-- -->OCR</span><span class="page__taxonomy-item">#<!-- -->멀티모달 AI</span><span class="page__taxonomy-item">#<!-- -->데이터 필터링</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-3-OpenVision_2_A_Family_of_Generative_Pretrained_Visual_Encoders_for_Multimodal_Learning/">[논문리뷰] OpenVision 2: A Family of Generative Pretrained Visual Encoders for Multimodal Learning</a></h2><div class="archive__item-excerpt">Zirui Wang이 [arXiv]에 게시한 &#x27;OpenVision 2: A Family of Generative Pretrained Visual Encoders for Multimodal Learning&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-03 13:36:21+0900">2025년 9월 3일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Multimodal Learning</span><span class="page__taxonomy-item">#<!-- -->Vision Encoder</span><span class="page__taxonomy-item">#<!-- -->Generative Pretraining</span><span class="page__taxonomy-item">#<!-- -->Captioning Loss</span><span class="page__taxonomy-item">#<!-- -->Training Efficiency</span><span class="page__taxonomy-item">#<!-- -->Image-Text Models</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-3-MobiAgent_A_Systematic_Framework_for_Customizable_Mobile_Agents/">[논문리뷰] MobiAgent: A Systematic Framework for Customizable Mobile Agents</a></h2><div class="archive__item-excerpt">Wangbo Gong이 [arXiv]에 게시한 &#x27;MobiAgent: A Systematic Framework for Customizable Mobile Agents&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-03 13:36:21+0900">2025년 9월 3일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Mobile Agents</span><span class="page__taxonomy-item">#<!-- -->GUI Agents</span><span class="page__taxonomy-item">#<!-- -->Vision-Language Models</span><span class="page__taxonomy-item">#<!-- -->Agent Acceleration</span><span class="page__taxonomy-item">#<!-- -->Benchmarking</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Data Collection</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-3-Metis_Training_Large_Language_Models_with_Advanced_Low-Bit_Quantization/">[논문리뷰] Metis: Training Large Language Models with Advanced Low-Bit Quantization</a></h2><div class="archive__item-excerpt">Hengjie Cao이 [arXiv]에 게시한 &#x27;Metis: Training Large Language Models with Advanced Low-Bit Quantization&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-03 13:36:21+0900">2025년 9월 3일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Low-Bit Quantization</span><span class="page__taxonomy-item">#<!-- -->LLMs</span><span class="page__taxonomy-item">#<!-- -->Spectral Decomposition</span><span class="page__taxonomy-item">#<!-- -->Anisotropy</span><span class="page__taxonomy-item">#<!-- -->Adaptive Learning Rate</span><span class="page__taxonomy-item">#<!-- -->Regularization</span><span class="page__taxonomy-item">#<!-- -->FP8 Training</span><span class="page__taxonomy-item">#<!-- -->FP4 Training</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-3-MedDINOv3_How_to_adapt_vision_foundation_models_for_medical_image_segmentation/">[논문리뷰] MedDINOv3: How to adapt vision foundation models for medical image segmentation?</a></h2><div class="archive__item-excerpt">Xiaofeng Yang이 [arXiv]에 게시한 &#x27;MedDINOv3: How to adapt vision foundation models for medical image segmentation?&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-03 13:36:21+0900">2025년 9월 3일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Medical Image Segmentation</span><span class="page__taxonomy-item">#<!-- -->Vision Foundation Models</span><span class="page__taxonomy-item">#<!-- -->Self-supervised Learning</span><span class="page__taxonomy-item">#<!-- -->Vision Transformers (ViT)</span><span class="page__taxonomy-item">#<!-- -->Domain Adaptation</span><span class="page__taxonomy-item">#<!-- -->DINOv3</span><span class="page__taxonomy-item">#<!-- -->CT Imaging</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-3-M3Ret_Unleashing_Zero-shot_Multimodal_Medical_Image_Retrieval_via_Self-Supervision/">[논문리뷰] M3Ret: Unleashing Zero-shot Multimodal Medical Image Retrieval via Self-Supervision</a></h2><div class="archive__item-excerpt">Yan-Jie Zhou이 [arXiv]에 게시한 &#x27;M3Ret: Unleashing Zero-shot Multimodal Medical Image Retrieval via Self-Supervision&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-03 13:36:21+0900">2025년 9월 3일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Medical Image Retrieval</span><span class="page__taxonomy-item">#<!-- -->Self-Supervised Learning</span><span class="page__taxonomy-item">#<!-- -->Multimodal</span><span class="page__taxonomy-item">#<!-- -->Zero-shot</span><span class="page__taxonomy-item">#<!-- -->Foundation Models</span><span class="page__taxonomy-item">#<!-- -->MAE</span><span class="page__taxonomy-item">#<!-- -->SimDINO</span><span class="page__taxonomy-item">#<!-- -->Vision Transformer</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-3-LLaVA-Critic-R1_Your_Critic_Model_is_Secretly_a_Strong_Policy_Model/">[논문리뷰] LLaVA-Critic-R1: Your Critic Model is Secretly a Strong Policy Model</a></h2><div class="archive__item-excerpt">Jianwei Yang이 [arXiv]에 게시한 &#x27;LLaVA-Critic-R1: Your Critic Model is Secretly a Strong Policy Model&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-03 13:36:21+0900">2025년 9월 3일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Vision-Language Models (VLMs)</span><span class="page__taxonomy-item">#<!-- -->Critic Models</span><span class="page__taxonomy-item">#<!-- -->Policy Models</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning (RL)</span><span class="page__taxonomy-item">#<!-- -->Self-Criticism</span><span class="page__taxonomy-item">#<!-- -->Multimodal Reasoning</span><span class="page__taxonomy-item">#<!-- -->Preference Learning</span><span class="page__taxonomy-item">#<!-- -->Generative Models</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-3-Kwai_Keye-VL_1.5_Technical_Report">[논문리뷰] Kwai Keye-VL 1.5 Technical Report</a></h2><div class="archive__item-excerpt">SXxtyz이 [arXiv]에 게시한 &#x27;Kwai Keye-VL 1.5 Technical Report&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-03 13:36:21+0900">2025년 9월 3일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Multimodal LLMs</span><span class="page__taxonomy-item">#<!-- -->Video Understanding</span><span class="page__taxonomy-item">#<!-- -->Slow-Fast Encoding</span><span class="page__taxonomy-item">#<!-- -->Long Context</span><span class="page__taxonomy-item">#<!-- -->Chain-of-Thought</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Human Alignment</span><span class="page__taxonomy-item">#<!-- -->Native-Resolution Vision Encoder</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-3-Jointly_Reinforcing_Diversity_and_Quality_in_Language_Model_Generations/">[논문리뷰] Jointly Reinforcing Diversity and Quality in Language Model Generations</a></h2><div class="archive__item-excerpt">Tianlu이 [arXiv]에 게시한 &#x27;Jointly Reinforcing Diversity and Quality in Language Model Generations&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-03 13:36:21+0900">2025년 9월 3일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Language Models</span><span class="page__taxonomy-item">#<!-- -->Diversity Optimization</span><span class="page__taxonomy-item">#<!-- -->Quality Enhancement</span><span class="page__taxonomy-item">#<!-- -->Semantic Clustering</span><span class="page__taxonomy-item">#<!-- -->Post-training</span><span class="page__taxonomy-item">#<!-- -->Generative AI</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-3-Improving_Large_Vision_and_Language_Models_by_Learning_from_a_Panel_of_Peers/">[논문리뷰] Improving Large Vision and Language Models by Learning from a Panel of Peers</a></h2><div class="archive__item-excerpt">Simon Jenni이 [arXiv]에 게시한 &#x27;Improving Large Vision and Language Models by Learning from a Panel of Peers&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-03 13:36:21+0900">2025년 9월 3일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Large Vision and Language Models (LVLMs)</span><span class="page__taxonomy-item">#<!-- -->Self-Improvement</span><span class="page__taxonomy-item">#<!-- -->Peer Learning</span><span class="page__taxonomy-item">#<!-- -->Preference Alignment</span><span class="page__taxonomy-item">#<!-- -->Reward Modeling</span><span class="page__taxonomy-item">#<!-- -->Multimodal Learning</span><span class="page__taxonomy-item">#<!-- -->Knowledge Transfer</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-3-Implicit_Actor_Critic_Coupling_via_a_Supervised_Learning_Framework_for_RLVR/">[논문리뷰] Implicit Actor Critic Coupling via a Supervised Learning Framework for RLVR</a></h2><div class="archive__item-excerpt">Lu Wang이 [arXiv]에 게시한 &#x27;Implicit Actor Critic Coupling via a Supervised Learning Framework for RLVR&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-03 13:36:21+0900">2025년 9월 3일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->RLVR</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Actor-Critic</span><span class="page__taxonomy-item">#<!-- -->Supervised Learning</span><span class="page__taxonomy-item">#<!-- -->Mathematical Reasoning</span><span class="page__taxonomy-item">#<!-- -->Policy Optimization</span><span class="page__taxonomy-item">#<!-- -->Cross-Entropy Loss</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-3-GenCompositor_Generative_Video_Compositing_with_Diffusion_Transformer/">[논문리뷰] GenCompositor: Generative Video Compositing with Diffusion Transformer</a></h2><div class="archive__item-excerpt">Lingen Li이 [arXiv]에 게시한 &#x27;GenCompositor: Generative Video Compositing with Diffusion Transformer&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-03 13:36:21+0900">2025년 9월 3일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Video Compositing</span><span class="page__taxonomy-item">#<!-- -->Diffusion Transformer</span><span class="page__taxonomy-item">#<!-- -->Generative Models</span><span class="page__taxonomy-item">#<!-- -->Video Editing</span><span class="page__taxonomy-item">#<!-- -->Position Embedding</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->Masked Token Injection</span><span class="page__taxonomy-item">#<!-- -->Video Harmonization</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-3-FlashAdventure_A_Benchmark_for_GUI_Agents_Solving_Full_Story_Arcs_in_Diverse_Adventure_Games/">[논문리뷰] FlashAdventure: A Benchmark for GUI Agents Solving Full Story Arcs in Diverse Adventure Games</a></h2><div class="archive__item-excerpt">Dongmin Park이 [arXiv]에 게시한 &#x27;FlashAdventure: A Benchmark for GUI Agents Solving Full Story Arcs in Diverse Adventure Games&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-03 13:36:21+0900">2025년 9월 3일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->GUI Agents</span><span class="page__taxonomy-item">#<!-- -->Adventure Games</span><span class="page__taxonomy-item">#<!-- -->Benchmark</span><span class="page__taxonomy-item">#<!-- -->Full Story Arc</span><span class="page__taxonomy-item">#<!-- -->Observation-Behavior Gap</span><span class="page__taxonomy-item">#<!-- -->LLMs</span><span class="page__taxonomy-item">#<!-- -->Automated Evaluation</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-3-FastFit_Accelerating_Multi-Reference_Virtual_Try-On_via_Cacheable_Diffusion_Models/">[논문리뷰] FastFit: Accelerating Multi-Reference Virtual Try-On via Cacheable Diffusion Models</a></h2><div class="archive__item-excerpt">Zhen Wang이 [arXiv]에 게시한 &#x27;FastFit: Accelerating Multi-Reference Virtual Try-On via Cacheable Diffusion Models&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-03 13:36:21+0900">2025년 9월 3일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Virtual Try-On</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->Cacheable Architecture</span><span class="page__taxonomy-item">#<!-- -->Multi-Reference</span><span class="page__taxonomy-item">#<!-- -->Semi-Attention</span><span class="page__taxonomy-item">#<!-- -->Efficiency</span><span class="page__taxonomy-item">#<!-- -->Image Synthesis</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-3-Fantastic_Pretraining_Optimizers_and_Where_to_Find_Them/">[논문리뷰] Fantastic Pretraining Optimizers and Where to Find Them</a></h2><div class="archive__item-excerpt">Percy Liang이 [arXiv]에 게시한 &#x27;Fantastic Pretraining Optimizers and Where to Find Them&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-03 13:36:21+0900">2025년 9월 3일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Deep Learning Optimizers</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Hyperparameter Tuning</span><span class="page__taxonomy-item">#<!-- -->Pretraining Speedup</span><span class="page__taxonomy-item">#<!-- -->Scaling Laws</span><span class="page__taxonomy-item">#<!-- -->AdamW</span><span class="page__taxonomy-item">#<!-- -->Matrix-based Optimizers</span><span class="page__taxonomy-item">#<!-- -->Data-to-Model Ratio</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-3-ELV-Halluc_Benchmarking_Semantic_Aggregation_Hallucinations_in_Long_Video_Understanding/">[논문리뷰] ELV-Halluc: Benchmarking Semantic Aggregation Hallucinations in Long Video Understanding</a></h2><div class="archive__item-excerpt">Xuanyu Zheng이 [arXiv]에 게시한 &#x27;ELV-Halluc: Benchmarking Semantic Aggregation Hallucinations in Long Video Understanding&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-03 13:36:21+0900">2025년 9월 3일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Long Video Understanding</span><span class="page__taxonomy-item">#<!-- -->Hallucination</span><span class="page__taxonomy-item">#<!-- -->Semantic Aggregation</span><span class="page__taxonomy-item">#<!-- -->Video MLLM</span><span class="page__taxonomy-item">#<!-- -->Benchmark</span><span class="page__taxonomy-item">#<!-- -->DPO</span><span class="page__taxonomy-item">#<!-- -->Positional Encoding</span><span class="page__taxonomy-item">#<!-- -->VideoQA</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-3-Discrete_Noise_Inversion_for_Next-scale_Autoregressive_Text-based_Image_Editing/">[논문리뷰] Discrete Noise Inversion for Next-scale Autoregressive Text-based Image Editing</a></h2><div class="archive__item-excerpt">Amin Heyrani Nobar이 [arXiv]에 게시한 &#x27;Discrete Noise Inversion for Next-scale Autoregressive Text-based Image Editing&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-03 13:36:21+0900">2025년 9월 3일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Image Editing</span><span class="page__taxonomy-item">#<!-- -->Autoregressive Models</span><span class="page__taxonomy-item">#<!-- -->Noise Inversion</span><span class="page__taxonomy-item">#<!-- -->Text-to-Image</span><span class="page__taxonomy-item">#<!-- -->Gumbel-max Trick</span><span class="page__taxonomy-item">#<!-- -->Training-free</span><span class="page__taxonomy-item">#<!-- -->Location-aware Argmax Inversion</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-3-DCPO_Dynamic_Clipping_Policy_Optimization/">[논문리뷰] DCPO: Dynamic Clipping Policy Optimization</a></h2><div class="archive__item-excerpt">Kai Lu이 [arXiv]에 게시한 &#x27;DCPO: Dynamic Clipping Policy Optimization&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-03 13:36:21+0900">2025년 9월 3일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->LLM</span><span class="page__taxonomy-item">#<!-- -->Policy Optimization</span><span class="page__taxonomy-item">#<!-- -->Dynamic Clipping</span><span class="page__taxonomy-item">#<!-- -->Advantage Standardization</span><span class="page__taxonomy-item">#<!-- -->RLVR</span><span class="page__taxonomy-item">#<!-- -->Reasoning</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-3-C-DiffDet_Fusing_Global_Scene_Context_with_Generative_Denoising_for_High-Fidelity_Object_Detection/">[논문리뷰] C-DiffDet+: Fusing Global Scene Context with Generative Denoising for High-Fidelity Object Detection</a></h2><div class="archive__item-excerpt">Vito Renó이 [arXiv]에 게시한 &#x27;C-DiffDet+: Fusing Global Scene Context with Generative Denoising for High-Fidelity Object Detection&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-03 13:36:21+0900">2025년 9월 3일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Object Detection</span><span class="page__taxonomy-item">#<!-- -->Diffusion Model</span><span class="page__taxonomy-item">#<!-- -->Global Scene Context</span><span class="page__taxonomy-item">#<!-- -->Context-Aware Fusion</span><span class="page__taxonomy-item">#<!-- -->Fine-grained Detection</span><span class="page__taxonomy-item">#<!-- -->Automotive Damage Assessment</span><span class="page__taxonomy-item">#<!-- -->Generative Denoising</span><span class="page__taxonomy-item">#<!-- -->Cross-Attention</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-3-Benchmarking_Optimizers_for_Large_Language_Model_Pretraining/">[논문리뷰] Benchmarking Optimizers for Large Language Model Pretraining</a></h2><div class="archive__item-excerpt">mjaggi이 [arXiv]에 게시한 &#x27;Benchmarking Optimizers for Large Language Model Pretraining&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-03 13:36:21+0900">2025년 9월 3일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLM Optimizers</span><span class="page__taxonomy-item">#<!-- -->Benchmarking</span><span class="page__taxonomy-item">#<!-- -->Hyperparameter Tuning</span><span class="page__taxonomy-item">#<!-- -->AdamW</span><span class="page__taxonomy-item">#<!-- -->AdEMAMix</span><span class="page__taxonomy-item">#<!-- -->MARS</span><span class="page__taxonomy-item">#<!-- -->Mixture of Experts (MoE)</span><span class="page__taxonomy-item">#<!-- -->Weight Decay</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-3-Baichuan-M2_Scaling_Medical_Capability_with_Large_Verifier_System/">[논문리뷰] Baichuan-M2: Scaling Medical Capability with Large Verifier System</a></h2><div class="archive__item-excerpt">Jayok6이 [arXiv]에 게시한 &#x27;Baichuan-M2: Scaling Medical Capability with Large Verifier System&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-03 13:36:21+0900">2025년 9월 3일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Medical AI</span><span class="page__taxonomy-item">#<!-- -->LLM</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Verifier System</span><span class="page__taxonomy-item">#<!-- -->Patient Simulator</span><span class="page__taxonomy-item">#<!-- -->Clinical Rubrics</span><span class="page__taxonomy-item">#<!-- -->Baichuan-M2</span><span class="page__taxonomy-item">#<!-- -->HealthBench</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-3-Attributes_as_Textual_Genes_Leveraging_LLMs_as_Genetic_Algorithm_Simulators_for_Conditional_Synthetic_Data_Generation/">[논문리뷰] Attributes as Textual Genes: Leveraging LLMs as Genetic Algorithm Simulators for Conditional Synthetic Data Generation</a></h2><div class="archive__item-excerpt">Xiaolei Huang이 [arXiv]에 게시한 &#x27;Attributes as Textual Genes: Leveraging LLMs as Genetic Algorithm Simulators for Conditional Synthetic Data Generation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-03 13:36:21+0900">2025년 9월 3일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Synthetic Data Generation</span><span class="page__taxonomy-item">#<!-- -->Large Language Models (LLMs)</span><span class="page__taxonomy-item">#<!-- -->Genetic Algorithms</span><span class="page__taxonomy-item">#<!-- -->Textual Data Augmentation</span><span class="page__taxonomy-item">#<!-- -->Active Learning</span><span class="page__taxonomy-item">#<!-- -->NLP</span><span class="page__taxonomy-item">#<!-- -->Data Diversity</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-3-AMBEDKAR-A_Multi-level_Bias_Elimination_through_a_Decoding_Approach_with_Knowledge_Augmentation_for_Robust_Constitutional_Alignment_of_Language_Models/">[논문리뷰] AMBEDKAR-A Multi-level Bias Elimination through a Decoding Approach with Knowledge Augmentation for Robust Constitutional Alignment of Language Models</a></h2><div class="archive__item-excerpt">Rahul Karthikeyan이 [arXiv]에 게시한 &#x27;AMBEDKAR-A Multi-level Bias Elimination through a Decoding Approach with Knowledge Augmentation for Robust Constitutional Alignment of Language Models&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-03 13:36:21+0900">2025년 9월 3일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Bias Mitigation</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Speculative Decoding</span><span class="page__taxonomy-item">#<!-- -->Constitutional AI</span><span class="page__taxonomy-item">#<!-- -->Fairness</span><span class="page__taxonomy-item">#<!-- -->Inference-Time Control</span><span class="page__taxonomy-item">#<!-- -->Indian Sociocultural Context</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-2-UI-Level_Evaluation_of_ALLaM_34B_Measuring_an_Arabic-Centric_LLM_via_HUMAIN_Chat/">[논문리뷰] UI-Level Evaluation of ALLaM 34B: Measuring an Arabic-Centric LLM via HUMAIN Chat</a></h2><div class="archive__item-excerpt">Omartificial-Intelligence-Space이 [arXiv]에 게시한 &#x27;UI-Level Evaluation of ALLaM 34B: Measuring an Arabic-Centric LLM via HUMAIN Chat&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-02 13:01:41+0900">2025년 9월 2일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Arabic LLM</span><span class="page__taxonomy-item">#<!-- -->UI-level Evaluation</span><span class="page__taxonomy-item">#<!-- -->ALLaM 34B</span><span class="page__taxonomy-item">#<!-- -->HUMAIN Chat</span><span class="page__taxonomy-item">#<!-- -->Dialectal Arabic</span><span class="page__taxonomy-item">#<!-- -->LLM as a Judge</span><span class="page__taxonomy-item">#<!-- -->Safety Evaluation</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-2-T2R-bench_A_Benchmark_for_Generating_Article-Level_Reports_from_Real_World_Industrial_Tables/">[논문리뷰] T2R-bench: A Benchmark for Generating Article-Level Reports from Real World Industrial Tables</a></h2><div class="archive__item-excerpt">Yu Zhao이 [arXiv]에 게시한 &#x27;T2R-bench: A Benchmark for Generating Article-Level Reports from Real World Industrial Tables&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-02 13:01:41+0900">2025년 9월 2일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Table-to-Report Generation</span><span class="page__taxonomy-item">#<!-- -->Large Language Models (LLMs)</span><span class="page__taxonomy-item">#<!-- -->Benchmark Dataset</span><span class="page__taxonomy-item">#<!-- -->Industrial Applications</span><span class="page__taxonomy-item">#<!-- -->Table Reasoning</span><span class="page__taxonomy-item">#<!-- -->Evaluation Metrics</span><span class="page__taxonomy-item">#<!-- -->Real-world Data</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-2-PVPO_Pre-Estimated_Value-Based_Policy_Optimization_for_Agentic_Reasoning/">[논문리뷰] PVPO: Pre-Estimated Value-Based Policy Optimization for Agentic Reasoning</a></h2><div class="archive__item-excerpt">Yuewei Zhang이 [arXiv]에 게시한 &#x27;PVPO: Pre-Estimated Value-Based Policy Optimization for Agentic Reasoning&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-02 13:01:41+0900">2025년 9월 2일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Critic-Free RL</span><span class="page__taxonomy-item">#<!-- -->Agentic Reasoning</span><span class="page__taxonomy-item">#<!-- -->Policy Optimization</span><span class="page__taxonomy-item">#<!-- -->Large Language Models (LLMs)</span><span class="page__taxonomy-item">#<!-- -->Advantage Estimation</span><span class="page__taxonomy-item">#<!-- -->Group Sampling</span><span class="page__taxonomy-item">#<!-- -->Static Value Estimation</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-2-No_Label_Left_Behind_A_Unified_Surface_Defect_Detection_Model_for_all_Supervision_Regimes/">[논문리뷰] No Label Left Behind: A Unified Surface Defect Detection Model for all Supervision Regimes</a></h2><div class="archive__item-excerpt">Danijel Skočaj이 [arXiv]에 게시한 &#x27;No Label Left Behind: A Unified Surface Defect Detection Model for all Supervision Regimes&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-02 13:01:41+0900">2025년 9월 2일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Surface Defect Detection</span><span class="page__taxonomy-item">#<!-- -->Anomaly Detection</span><span class="page__taxonomy-item">#<!-- -->Mixed Supervision</span><span class="page__taxonomy-item">#<!-- -->Deep Learning</span><span class="page__taxonomy-item">#<!-- -->Industrial Inspection</span><span class="page__taxonomy-item">#<!-- -->Unified Model</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-2-How_Can_Input_Reformulation_Improve_Tool_Usage_Accuracy_in_a_Complex_Dynamic_Environment_A_Study_on_τ-bench/">[논문리뷰] How Can Input Reformulation Improve Tool Usage Accuracy in a Complex Dynamic Environment? A Study on τ-bench</a></h2><div class="archive__item-excerpt">Jayanth Srinivasa이 [arXiv]에 게시한 &#x27;How Can Input Reformulation Improve Tool Usage Accuracy in a Complex Dynamic Environment? A Study on τ-bench&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-02 13:01:41+0900">2025년 9월 2일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLM Agents</span><span class="page__taxonomy-item">#<!-- -->Tool Use</span><span class="page__taxonomy-item">#<!-- -->Function Calling</span><span class="page__taxonomy-item">#<!-- -->Input Reformulation</span><span class="page__taxonomy-item">#<!-- -->Dynamic Environments</span><span class="page__taxonomy-item">#<!-- -->τ-bench</span><span class="page__taxonomy-item">#<!-- -->Context Engineering</span><span class="page__taxonomy-item">#<!-- -->Multi-Agent Framework</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-2-From_reactive_to_cognitive_brain-inspired_spatial_intelligence_for_embodied_agents/">[논문리뷰] From reactive to cognitive: brain-inspired spatial intelligence for embodied agents</a></h2><div class="archive__item-excerpt">Songming Liu이 [arXiv]에 게시한 &#x27;From reactive to cognitive: brain-inspired spatial intelligence for embodied agents&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-02 13:01:41+0900">2025년 9월 2일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Spatial Cognition</span><span class="page__taxonomy-item">#<!-- -->Embodied Agents</span><span class="page__taxonomy-item">#<!-- -->Brain-inspired AI</span><span class="page__taxonomy-item">#<!-- -->Cognitive Map</span><span class="page__taxonomy-item">#<!-- -->Spatial Memory</span><span class="page__taxonomy-item">#<!-- -->MLLMs</span><span class="page__taxonomy-item">#<!-- -->Navigation</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-1-UItron_Foundational_GUI_Agent_with_Advanced_Perception_and_Planning/">[논문리뷰] UItron: Foundational GUI Agent with Advanced Perception and Planning</a></h2><div class="archive__item-excerpt">Yufeng Zhong이 [arXiv]에 게시한 &#x27;UItron: Foundational GUI Agent with Advanced Perception and Planning&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-01 13:14:34+0900">2025년 9월 1일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->GUI Agent</span><span class="page__taxonomy-item">#<!-- -->Foundational Model</span><span class="page__taxonomy-item">#<!-- -->Multimodal LLM</span><span class="page__taxonomy-item">#<!-- -->Perception</span><span class="page__taxonomy-item">#<!-- -->Planning</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Data Engineering</span><span class="page__taxonomy-item">#<!-- -->Chinese App Scenarios</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-1-TiKMiX_Take_Data_Influence_into_Dynamic_Mixture_for_Language_Model_Pre-training/">[논문리뷰] TiKMiX: Take Data Influence into Dynamic Mixture for Language Model Pre-training</a></h2><div class="archive__item-excerpt">Jiyao Deng이 [arXiv]에 게시한 &#x27;TiKMiX: Take Data Influence into Dynamic Mixture for Language Model Pre-training&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-01 13:14:34+0900">2025년 9월 1일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Language Model Pre-training</span><span class="page__taxonomy-item">#<!-- -->Dynamic Data Mixing</span><span class="page__taxonomy-item">#<!-- -->Data Influence</span><span class="page__taxonomy-item">#<!-- -->Group Influence</span><span class="page__taxonomy-item">#<!-- -->Optimization</span><span class="page__taxonomy-item">#<!-- -->Regression Model</span><span class="page__taxonomy-item">#<!-- -->LLM Training</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-1-Think_in_Games_Learning_to_Reason_in_Games_via_Reinforcement_Learning_with_Large_Language_Models/">[논문리뷰] Think in Games: Learning to Reason in Games via Reinforcement Learning with Large Language Models</a></h2><div class="archive__item-excerpt">Yifan Lu이 [arXiv]에 게시한 &#x27;Think in Games: Learning to Reason in Games via Reinforcement Learning with Large Language Models&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-01 13:14:34+0900">2025년 9월 1일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Game AI</span><span class="page__taxonomy-item">#<!-- -->Procedural Knowledge</span><span class="page__taxonomy-item">#<!-- -->Declarative Knowledge</span><span class="page__taxonomy-item">#<!-- -->Explainable AI</span><span class="page__taxonomy-item">#<!-- -->Strategic Decision-Making</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-1-TalkVid_A_Large-Scale_Diversified_Dataset_for_Audio-Driven_Talking_Head_Synthesis/">[논문리뷰] TalkVid: A Large-Scale Diversified Dataset for Audio-Driven Talking Head Synthesis</a></h2><div class="archive__item-excerpt">Pengcheng Chen이 [arXiv]에 게시한 &#x27;TalkVid: A Large-Scale Diversified Dataset for Audio-Driven Talking Head Synthesis&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-01 13:14:34+0900">2025년 9월 1일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Audio-Driven Talking Head Synthesis</span><span class="page__taxonomy-item">#<!-- -->Large-Scale Dataset</span><span class="page__taxonomy-item">#<!-- -->Data Diversity</span><span class="page__taxonomy-item">#<!-- -->Data Curation</span><span class="page__taxonomy-item">#<!-- -->Evaluation Benchmark</span><span class="page__taxonomy-item">#<!-- -->Generalization Gap</span><span class="page__taxonomy-item">#<!-- -->Algorithmic Fairness</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-1-R-4B_Incentivizing_General-Purpose_Auto-Thinking_Capability_in_MLLMs_via_Bi-Mode_Annealing_and_Reinforce_Learning/">[논문리뷰] R-4B: Incentivizing General-Purpose Auto-Thinking Capability in MLLMs via Bi-Mode Annealing and Reinforce Learning</a></h2><div class="archive__item-excerpt">Han Hu이 [arXiv]에 게시한 &#x27;R-4B: Incentivizing General-Purpose Auto-Thinking Capability in MLLMs via Bi-Mode Annealing and Reinforce Learning&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-01 13:14:34+0900">2025년 9월 1일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Multimodal Large Language Models (MLLMs)</span><span class="page__taxonomy-item">#<!-- -->Auto-Thinking</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning (RL)</span><span class="page__taxonomy-item">#<!-- -->Bi-mode Annealing</span><span class="page__taxonomy-item">#<!-- -->Bi-mode Policy Optimization (BPO)</span><span class="page__taxonomy-item">#<!-- -->General-Purpose AI</span><span class="page__taxonomy-item">#<!-- -->Reasoning</span><span class="page__taxonomy-item">#<!-- -->Efficiency</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-1-Morae_Proactively_Pausing_UI_Agents_for_User_Choices/">[논문리뷰] Morae: Proactively Pausing UI Agents for User Choices</a></h2><div class="archive__item-excerpt">Amy Pavel이 [arXiv]에 게시한 &#x27;Morae: Proactively Pausing UI Agents for User Choices&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-01 13:14:34+0900">2025년 9월 1일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->UI Agents</span><span class="page__taxonomy-item">#<!-- -->Accessibility</span><span class="page__taxonomy-item">#<!-- -->Human-Agent Interaction</span><span class="page__taxonomy-item">#<!-- -->Mixed-Initiative AI</span><span class="page__taxonomy-item">#<!-- -->Large Multimodal Models</span><span class="page__taxonomy-item">#<!-- -->Proactive AI</span><span class="page__taxonomy-item">#<!-- -->User Choice</span><span class="page__taxonomy-item">#<!-- -->Blind and Low-Vision Users</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-1-Mimicking_the_Physicists_EyeA_VLM-centric_Approach_for_Physics_Formula_Discovery/">[논문리뷰] Mimicking the Physicist&#x27;s Eye:A VLM-centric Approach for Physics Formula Discovery</a></h2><div class="archive__item-excerpt">Wenjie Zhou이 [arXiv]에 게시한 &#x27;Mimicking the Physicist&#x27;s Eye:A VLM-centric Approach for Physics Formula Discovery&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-01 13:14:34+0900">2025년 9월 1일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Physics Formula Discovery</span><span class="page__taxonomy-item">#<!-- -->Multimodal AI</span><span class="page__taxonomy-item">#<!-- -->Vision-Language Models</span><span class="page__taxonomy-item">#<!-- -->Symbolic Regression</span><span class="page__taxonomy-item">#<!-- -->Causal Chain of Thought</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Agentic AI</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-1-HERMES_Human-to-Robot_Embodied_Learning_from_Multi-Source_Motion_Data_for_Mobile_Dexterous_Manipulation/">[논문리뷰] HERMES: Human-to-Robot Embodied Learning from Multi-Source Motion Data for Mobile Dexterous Manipulation</a></h2><div class="archive__item-excerpt">Tianhai Liang이 [arXiv]에 게시한 &#x27;HERMES: Human-to-Robot Embodied Learning from Multi-Source Motion Data for Mobile Dexterous Manipulation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-01 13:14:34+0900">2025년 9월 1일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Dexterous Manipulation</span><span class="page__taxonomy-item">#<!-- -->Mobile Manipulation</span><span class="page__taxonomy-item">#<!-- -->Human-to-Robot Learning</span><span class="page__taxonomy-item">#<!-- -->Sim2Real</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Depth Image</span><span class="page__taxonomy-item">#<!-- -->Visual Localization</span><span class="page__taxonomy-item">#<!-- -->Bimanual Control</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-1-EmbodiedOneVision_Interleaved_Vision-Text-Action_Pretraining_for_General_Robot_Control/">[논문리뷰] EmbodiedOneVision: Interleaved Vision-Text-Action Pretraining for General Robot Control</a></h2><div class="archive__item-excerpt">Zhaoqing Chen이 [arXiv]에 게시한 &#x27;EmbodiedOneVision: Interleaved Vision-Text-Action Pretraining for General Robot Control&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-01 13:14:34+0900">2025년 9월 1일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Embodied AI</span><span class="page__taxonomy-item">#<!-- -->Robot Control</span><span class="page__taxonomy-item">#<!-- -->Vision-Language-Action Models</span><span class="page__taxonomy-item">#<!-- -->Multimodal Pretraining</span><span class="page__taxonomy-item">#<!-- -->Flow Matching</span><span class="page__taxonomy-item">#<!-- -->Foundation Models</span><span class="page__taxonomy-item">#<!-- -->Generalization</span><span class="page__taxonomy-item">#<!-- -->Real-world Robotics</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-1-Efficient_Code_Embeddings_from_Code_Generation_Models/">[논문리뷰] Efficient Code Embeddings from Code Generation Models</a></h2><div class="archive__item-excerpt">Han Xiao이 [arXiv]에 게시한 &#x27;Efficient Code Embeddings from Code Generation Models&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-01 13:14:34+0900">2025년 9월 1일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Code Embeddings</span><span class="page__taxonomy-item">#<!-- -->Code Generation Models</span><span class="page__taxonomy-item">#<!-- -->Autoregressive Backbones</span><span class="page__taxonomy-item">#<!-- -->Last-Token Pooling</span><span class="page__taxonomy-item">#<!-- -->Instruction Tuning</span><span class="page__taxonomy-item">#<!-- -->Contrastive Learning</span><span class="page__taxonomy-item">#<!-- -->Retrieval-Augmented Generation</span><span class="page__taxonomy-item">#<!-- -->MTEB Benchmark</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-1-Droplet3D_Commonsense_Priors_from_Videos_Facilitate_3D_Generation/">[논문리뷰] Droplet3D: Commonsense Priors from Videos Facilitate 3D Generation</a></h2><div class="archive__item-excerpt">Qi Jia이 [arXiv]에 게시한 &#x27;Droplet3D: Commonsense Priors from Videos Facilitate 3D Generation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-01 13:14:34+0900">2025년 9월 1일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->3D Generation</span><span class="page__taxonomy-item">#<!-- -->Video Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->Spatial Consistency</span><span class="page__taxonomy-item">#<!-- -->Semantic Knowledge</span><span class="page__taxonomy-item">#<!-- -->Multi-view Synthesis</span><span class="page__taxonomy-item">#<!-- -->Large-scale Dataset</span><span class="page__taxonomy-item">#<!-- -->Image-to-3D</span><span class="page__taxonomy-item">#<!-- -->Text-to-3D</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-1-CLIPSym_Delving_into_Symmetry_Detection_with_CLIP/">[논문리뷰] CLIPSym: Delving into Symmetry Detection with CLIP</a></h2><div class="archive__item-excerpt">Raymond A. Yeh이 [arXiv]에 게시한 &#x27;CLIPSym: Delving into Symmetry Detection with CLIP&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-01 13:14:34+0900">2025년 9월 1일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Symmetry Detection</span><span class="page__taxonomy-item">#<!-- -->Vision-Language Models</span><span class="page__taxonomy-item">#<!-- -->CLIP</span><span class="page__taxonomy-item">#<!-- -->Equivariant Networks</span><span class="page__taxonomy-item">#<!-- -->Prompt Engineering</span><span class="page__taxonomy-item">#<!-- -->Geometric Deep Learning</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-1-A_Survey_of_Scientific_Large_Language_Models_From_Data_Foundations_to_Agent_Frontiers/">[논문리뷰] A Survey of Scientific Large Language Models: From Data Foundations to Agent Frontiers</a></h2><div class="archive__item-excerpt">Jiamin Wu이 [arXiv]에 게시한 &#x27;A Survey of Scientific Large Language Models: From Data Foundations to Agent Frontiers&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-01 13:14:34+0900">2025년 9월 1일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Scientific LLMs</span><span class="page__taxonomy-item">#<!-- -->AI for Science</span><span class="page__taxonomy-item">#<!-- -->Scientific Data</span><span class="page__taxonomy-item">#<!-- -->Agentic AI</span><span class="page__taxonomy-item">#<!-- -->Multimodal Integration</span><span class="page__taxonomy-item">#<!-- -->Knowledge Representation</span><span class="page__taxonomy-item">#<!-- -->Autonomous Discovery</span><span class="page__taxonomy-item">#<!-- -->Data Ecosystems</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-1-AHELM_A_Holistic_Evaluation_of_Audio-Language_Models/">[논문리뷰] AHELM: A Holistic Evaluation of Audio-Language Models</a></h2><div class="archive__item-excerpt">Siwei Yang이 [arXiv]에 게시한 &#x27;AHELM: A Holistic Evaluation of Audio-Language Models&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-01 13:14:34+0900">2025년 9월 1일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Audio-Language Models</span><span class="page__taxonomy-item">#<!-- -->Holistic Evaluation</span><span class="page__taxonomy-item">#<!-- -->Benchmarking</span><span class="page__taxonomy-item">#<!-- -->Multimodality</span><span class="page__taxonomy-item">#<!-- -->Fairness</span><span class="page__taxonomy-item">#<!-- -->Robustness</span><span class="page__taxonomy-item">#<!-- -->Reasoning</span><span class="page__taxonomy-item">#<!-- -->Bias Detection</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-9-1-A.S.E_A_Repository-Level_Benchmark_for_Evaluating_Security_in_AI-Generated_Code">[논문리뷰] A.S.E: A Repository-Level Benchmark for Evaluating Security in AI-Generated Code</a></h2><div class="archive__item-excerpt">Libo Chen이 [arXiv]에 게시한 &#x27;A.S.E: A Repository-Level Benchmark for Evaluating Security in AI-Generated Code&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-09-01 13:14:34+0900">2025년 9월 1일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->AI-Generated Code Security</span><span class="page__taxonomy-item">#<!-- -->LLM Evaluation</span><span class="page__taxonomy-item">#<!-- -->Repository-Level Benchmark</span><span class="page__taxonomy-item">#<!-- -->Code Security</span><span class="page__taxonomy-item">#<!-- -->Vulnerability Detection</span><span class="page__taxonomy-item">#<!-- -->Static Analysis</span><span class="page__taxonomy-item">#<!-- -->Reproducibility</span><span class="page__taxonomy-item">#<!-- -->Context-Awareness</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-29-USO_Unified_Style_and_Subject-Driven_Generation_via_Disentangled_and_Reward_Learning/">[논문리뷰] USO: Unified Style and Subject-Driven Generation via Disentangled and Reward Learning</a></h2><div class="archive__item-excerpt">Jiahe Tian이 [arXiv]에 게시한 &#x27;USO: Unified Style and Subject-Driven Generation via Disentangled and Reward Learning&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-29 13:14:44+0900">2025년 8월 29일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Style-Driven Generation</span><span class="page__taxonomy-item">#<!-- -->Subject-Driven Generation</span><span class="page__taxonomy-item">#<!-- -->Disentangled Representation</span><span class="page__taxonomy-item">#<!-- -->Reward Learning</span><span class="page__taxonomy-item">#<!-- -->Cross-Task Learning</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->Image Customization</span><span class="page__taxonomy-item">#<!-- -->Unified Framework</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-29-Turning_the_Spell_Around_Lightweight_Alignment_Amplification_via_Rank-One_Safety_Injection/">[논문리뷰] Turning the Spell Around: Lightweight Alignment Amplification via Rank-One Safety Injection</a></h2><div class="archive__item-excerpt">Bernard Ghanem이 [arXiv]에 게시한 &#x27;Turning the Spell Around: Lightweight Alignment Amplification via Rank-One Safety Injection&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-29 13:14:44+0900">2025년 8월 29일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLM Safety</span><span class="page__taxonomy-item">#<!-- -->Alignment Amplification</span><span class="page__taxonomy-item">#<!-- -->Rank-One Update</span><span class="page__taxonomy-item">#<!-- -->Mechanistic Interpretability</span><span class="page__taxonomy-item">#<!-- -->Weight Steering</span><span class="page__taxonomy-item">#<!-- -->Jailbreak Robustness</span><span class="page__taxonomy-item">#<!-- -->Fine-tuning-free</span><span class="page__taxonomy-item">#<!-- -->Safety Injection</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-29-TCIA_A_Task-Centric_Instruction_Augmentation_Method_for_Instruction_Finetuning/">[논문리뷰] TCIA: A Task-Centric Instruction Augmentation Method for Instruction Finetuning</a></h2><div class="archive__item-excerpt">Simin Ma이 [arXiv]에 게시한 &#x27;TCIA: A Task-Centric Instruction Augmentation Method for Instruction Finetuning&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-29 13:14:44+0900">2025년 8월 29일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Instruction Augmentation</span><span class="page__taxonomy-item">#<!-- -->Fine-tuning</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Task-Centric</span><span class="page__taxonomy-item">#<!-- -->Data Diversity</span><span class="page__taxonomy-item">#<!-- -->Task Alignment</span><span class="page__taxonomy-item">#<!-- -->Breadth-First Search</span><span class="page__taxonomy-item">#<!-- -->Constraint Generation</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-29-rStar2-Agent_Agentic_Reasoning_Technical_Report/">[논문리뷰] rStar2-Agent: Agentic Reasoning Technical Report</a></h2><div class="archive__item-excerpt">Weijiang Xu이 [arXiv]에 게시한 &#x27;rStar2-Agent: Agentic Reasoning Technical Report&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-29 13:14:44+0900">2025년 8월 29일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Agentic Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Math Reasoning</span><span class="page__taxonomy-item">#<!-- -->Code Interpreter</span><span class="page__taxonomy-item">#<!-- -->Tool Use</span><span class="page__taxonomy-item">#<!-- -->GRPO-RoC</span><span class="page__taxonomy-item">#<!-- -->LLM Training Efficiency</span><span class="page__taxonomy-item">#<!-- -->Self-Reflection</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-29-ROSE_Remove_Objects_with_Side_Effects_in_Videos/">[논문리뷰] ROSE: Remove Objects with Side Effects in Videos</a></h2><div class="archive__item-excerpt">Hantang Liu이 [arXiv]에 게시한 &#x27;ROSE: Remove Objects with Side Effects in Videos&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-29 13:14:44+0900">2025년 8월 29일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Video Object Removal</span><span class="page__taxonomy-item">#<!-- -->Side Effects</span><span class="page__taxonomy-item">#<!-- -->3D Rendering</span><span class="page__taxonomy-item">#<!-- -->Diffusion Transformer</span><span class="page__taxonomy-item">#<!-- -->Video Inpainting</span><span class="page__taxonomy-item">#<!-- -->Synthetic Data</span><span class="page__taxonomy-item">#<!-- -->Difference Mask</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-29-Provable_Benefits_of_In-Tool_Learning_for_Large_Language_Models/">[논문리뷰] Provable Benefits of In-Tool Learning for Large Language Models</a></h2><div class="archive__item-excerpt">Vivien Cabannes이 [arXiv]에 게시한 &#x27;Provable Benefits of In-Tool Learning for Large Language Models&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-29 13:14:44+0900">2025년 8월 29일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->In-Tool Learning</span><span class="page__taxonomy-item">#<!-- -->In-Weight Learning</span><span class="page__taxonomy-item">#<!-- -->Factual Recall</span><span class="page__taxonomy-item">#<!-- -->Retrieval-Augmented Generation</span><span class="page__taxonomy-item">#<!-- -->Scaling Laws</span><span class="page__taxonomy-item">#<!-- -->Parameter Efficiency</span><span class="page__taxonomy-item">#<!-- -->Catastrophic Forgetting</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-29-Pref-GRPO_Pairwise_Preference_Reward-based_GRPO_for_Stable_Text-to-Image_Reinforcement_Learning/">[논문리뷰] Pref-GRPO: Pairwise Preference Reward-based GRPO for Stable Text-to-Image Reinforcement Learning</a></h2><div class="archive__item-excerpt">Jiazi Bu이 [arXiv]에 게시한 &#x27;Pref-GRPO: Pairwise Preference Reward-based GRPO for Stable Text-to-Image Reinforcement Learning&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-29 13:14:44+0900">2025년 8월 29일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Text-to-Image Generation</span><span class="page__taxonomy-item">#<!-- -->GRPO</span><span class="page__taxonomy-item">#<!-- -->Reward Hacking</span><span class="page__taxonomy-item">#<!-- -->Pairwise Preference</span><span class="page__taxonomy-item">#<!-- -->Reward Model</span><span class="page__taxonomy-item">#<!-- -->Stable Optimization</span><span class="page__taxonomy-item">#<!-- -->UniGenBench</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-29-Persuasion_Dynamics_in_LLMs_Investigating_Robustness_and_Adaptability_in_Knowledge_and_Safety_with_DuET-PD/">[논문리뷰] Persuasion Dynamics in LLMs: Investigating Robustness and Adaptability in Knowledge and Safety with DuET-PD</a></h2><div class="archive__item-excerpt">Roy Ka-Wei Lee이 [arXiv]에 게시한 &#x27;Persuasion Dynamics in LLMs: Investigating Robustness and Adaptability in Knowledge and Safety with DuET-PD&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-29 13:14:44+0900">2025년 8월 29일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Persuasion Dynamics</span><span class="page__taxonomy-item">#<!-- -->Large Language Models (LLMs)</span><span class="page__taxonomy-item">#<!-- -->Robustness</span><span class="page__taxonomy-item">#<!-- -->Gullibility</span><span class="page__taxonomy-item">#<!-- -->Receptiveness</span><span class="page__taxonomy-item">#<!-- -->Direct Preference Optimization (DPO)</span><span class="page__taxonomy-item">#<!-- -->Safety Alignment</span><span class="page__taxonomy-item">#<!-- -->Multi-turn Dialogue</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-29-OnGoal_Tracking_and_Visualizing_Conversational_Goals_in_Multi-Turn_Dialogue_with_Large_Language_Models/">[논문리뷰] OnGoal: Tracking and Visualizing Conversational Goals in Multi-Turn Dialogue with Large Language Models</a></h2><div class="archive__item-excerpt">Alex Endert이 [arXiv]에 게시한 &#x27;OnGoal: Tracking and Visualizing Conversational Goals in Multi-Turn Dialogue with Large Language Models&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-29 13:14:44+0900">2025년 8월 29일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Large Language Models (LLMs)</span><span class="page__taxonomy-item">#<!-- -->Human-Computer Interaction (HCI)</span><span class="page__taxonomy-item">#<!-- -->Conversational AI</span><span class="page__taxonomy-item">#<!-- -->Goal Tracking</span><span class="page__taxonomy-item">#<!-- -->Visualization</span><span class="page__taxonomy-item">#<!-- -->Multi-Turn Dialogue</span><span class="page__taxonomy-item">#<!-- -->User Interface Design</span><span class="page__taxonomy-item">#<!-- -->Sensemaking</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-29-OneReward_Unified_Mask-Guided_Image_Generation_via_Multi-Task_Human_Preference_Learning/">[논문리뷰] OneReward: Unified Mask-Guided Image Generation via Multi-Task Human Preference Learning</a></h2><div class="archive__item-excerpt">Yitong Wang이 [arXiv]에 게시한 &#x27;OneReward: Unified Mask-Guided Image Generation via Multi-Task Human Preference Learning&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-29 13:14:44+0900">2025년 8월 29일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Image Generation</span><span class="page__taxonomy-item">#<!-- -->Mask-Guided Editing</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Human Preference Learning</span><span class="page__taxonomy-item">#<!-- -->Vision-Language Models</span><span class="page__taxonomy-item">#<!-- -->Multi-Task Learning</span><span class="page__taxonomy-item">#<!-- -->Flow Matching</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-29-Multi-View_3D_Point_Tracking/">[논문리뷰] Multi-View 3D Point Tracking</a></h2><div class="archive__item-excerpt">Irem Demir이 [arXiv]에 게시한 &#x27;Multi-View 3D Point Tracking&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-29 13:14:44+0900">2025년 8월 29일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->3D Point Tracking</span><span class="page__taxonomy-item">#<!-- -->Multi-View</span><span class="page__taxonomy-item">#<!-- -->Transformer</span><span class="page__taxonomy-item">#<!-- -->kNN Correlation</span><span class="page__taxonomy-item">#<!-- -->Depth Estimation</span><span class="page__taxonomy-item">#<!-- -->Dynamic Scenes</span><span class="page__taxonomy-item">#<!-- -->Occlusion Handling</span><span class="page__taxonomy-item">#<!-- -->Feature Fusion</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-29-Mixture_of_Contexts_for_Long_Video_Generation/">[논문리뷰] Mixture of Contexts for Long Video Generation</a></h2><div class="archive__item-excerpt">Junfei Xiao이 [arXiv]에 게시한 &#x27;Mixture of Contexts for Long Video Generation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-29 13:14:44+0900">2025년 8월 29일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Long Video Generation</span><span class="page__taxonomy-item">#<!-- -->Diffusion Transformers (DiT)</span><span class="page__taxonomy-item">#<!-- -->Sparse Attention</span><span class="page__taxonomy-item">#<!-- -->Context Routing</span><span class="page__taxonomy-item">#<!-- -->Memory Management</span><span class="page__taxonomy-item">#<!-- -->Generative Models</span><span class="page__taxonomy-item">#<!-- -->Video Synthesis</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-29-MCP-Bench_Benchmarking_Tool-Using_LLM_Agents_with_Complex_Real-World_Tasks_via_MCP_Servers/">[논문리뷰] MCP-Bench: Benchmarking Tool-Using LLM Agents with Complex Real-World Tasks via MCP Servers</a></h2><div class="archive__item-excerpt">Shashank Biju이 [arXiv]에 게시한 &#x27;MCP-Bench: Benchmarking Tool-Using LLM Agents with Complex Real-World Tasks via MCP Servers&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-29 13:14:44+0900">2025년 8월 29일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLM Agents</span><span class="page__taxonomy-item">#<!-- -->Tool Use</span><span class="page__taxonomy-item">#<!-- -->Benchmarking</span><span class="page__taxonomy-item">#<!-- -->Model Context Protocol (MCP)</span><span class="page__taxonomy-item">#<!-- -->Cross-Domain Orchestration</span><span class="page__taxonomy-item">#<!-- -->Fuzzy Instructions</span><span class="page__taxonomy-item">#<!-- -->Multi-Step Tasks</span><span class="page__taxonomy-item">#<!-- -->Real-World Scenarios</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-29-FakeParts_a_New_Family_of_AI-Generated_DeepFakes/">[논문리뷰] FakeParts: a New Family of AI-Generated DeepFakes</a></h2><div class="archive__item-excerpt">Xi Wang이 [arXiv]에 게시한 &#x27;FakeParts: a New Family of AI-Generated DeepFakes&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-29 13:14:44+0900">2025년 8월 29일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Deepfake Detection</span><span class="page__taxonomy-item">#<!-- -->Partial Deepfakes</span><span class="page__taxonomy-item">#<!-- -->AI-Generated Video</span><span class="page__taxonomy-item">#<!-- -->Benchmark Dataset</span><span class="page__taxonomy-item">#<!-- -->Video Forensics</span><span class="page__taxonomy-item">#<!-- -->Generative Models</span><span class="page__taxonomy-item">#<!-- -->Manipulation Detection</span><span class="page__taxonomy-item">#<!-- -->Human Perception</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-29-DressDance_Dress_up_and_Dance_as_You_Like_It_-_Technical_Preview/">[논문리뷰] Dress&amp;Dance: Dress up and Dance as You Like It - Technical Preview</a></h2><div class="archive__item-excerpt">Yu-Xiong Wang이 [arXiv]에 게시한 &#x27;Dress&amp;Dance: Dress up and Dance as You Like It - Technical Preview&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-29 13:14:44+0900">2025년 8월 29일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Virtual Try-On</span><span class="page__taxonomy-item">#<!-- -->Video Diffusion</span><span class="page__taxonomy-item">#<!-- -->Multi-modal Conditioning</span><span class="page__taxonomy-item">#<!-- -->Garment Transfer</span><span class="page__taxonomy-item">#<!-- -->Pose Animation</span><span class="page__taxonomy-item">#<!-- -->Generative AI</span><span class="page__taxonomy-item">#<!-- -->Fashion Tech</span><span class="page__taxonomy-item">#<!-- -->CondNet</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-29-Collaborative_Multi-Modal_Coding_for_High-Quality_3D_Generation/">[논문리뷰] Collaborative Multi-Modal Coding for High-Quality 3D Generation</a></h2><div class="archive__item-excerpt">Ziwei Liu이 [arXiv]에 게시한 &#x27;Collaborative Multi-Modal Coding for High-Quality 3D Generation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-29 13:14:44+0900">2025년 8월 29일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->3D Generation</span><span class="page__taxonomy-item">#<!-- -->Multi-modal Learning</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->Triplane Representation</span><span class="page__taxonomy-item">#<!-- -->Collaborative Coding</span><span class="page__taxonomy-item">#<!-- -->Image-to-3D</span><span class="page__taxonomy-item">#<!-- -->Latent Space</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-29-CogVLA_Cognition-Aligned_Vision-Language-Action_Model_via_Instruction-Driven_Routing_Sparsification/">[논문리뷰] CogVLA: Cognition-Aligned Vision-Language-Action Model via Instruction-Driven Routing &amp; Sparsification</a></h2><div class="archive__item-excerpt">Liqiang Nie이 [arXiv]에 게시한 &#x27;CogVLA: Cognition-Aligned Vision-Language-Action Model via Instruction-Driven Routing &amp; Sparsification&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-29 13:14:44+0900">2025년 8월 29일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Vision-Language-Action Model</span><span class="page__taxonomy-item">#<!-- -->Sparsification</span><span class="page__taxonomy-item">#<!-- -->Instruction-Driven Routing</span><span class="page__taxonomy-item">#<!-- -->Cognition-Aligned AI</span><span class="page__taxonomy-item">#<!-- -->Robotics</span><span class="page__taxonomy-item">#<!-- -->Computational Efficiency</span><span class="page__taxonomy-item">#<!-- -->Multimodal AI</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-29-AWorld_Orchestrating_the_Training_Recipe_for_Agentic_AI/">[논문리뷰] AWorld: Orchestrating the Training Recipe for Agentic AI</a></h2><div class="archive__item-excerpt">Qintong Wu이 [arXiv]에 게시한 &#x27;AWorld: Orchestrating the Training Recipe for Agentic AI&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-29 13:14:44+0900">2025년 8월 29일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Agentic AI</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Distributed Systems</span><span class="page__taxonomy-item">#<!-- -->Experience Generation</span><span class="page__taxonomy-item">#<!-- -->LLM Fine-tuning</span><span class="page__taxonomy-item">#<!-- -->GAIA Benchmark</span><span class="page__taxonomy-item">#<!-- -->Scalability</span><span class="page__taxonomy-item">#<!-- -->AWORLD Framework</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-28-Taming_the_Chaos_Coordinated_Autoscaling_for_Heterogeneous_and_Disaggregated_LLM_Inference/">[논문리뷰] Taming the Chaos: Coordinated Autoscaling for Heterogeneous and Disaggregated LLM Inference</a></h2><div class="archive__item-excerpt">Chunlei Han이 [arXiv]에 게시한 &#x27;Taming the Chaos: Coordinated Autoscaling for Heterogeneous and Disaggregated LLM Inference&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-28 13:10:39+0900">2025년 8월 28일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLM Inference</span><span class="page__taxonomy-item">#<!-- -->Autoscaling</span><span class="page__taxonomy-item">#<!-- -->Disaggregated Architecture</span><span class="page__taxonomy-item">#<!-- -->Heterogeneous Hardware</span><span class="page__taxonomy-item">#<!-- -->Resource Management</span><span class="page__taxonomy-item">#<!-- -->Topology-aware Scheduling</span><span class="page__taxonomy-item">#<!-- -->GPU Utilization</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-28-StepWiser_Stepwise_Generative_Judges_for_Wiser_Reasoning/">[논문리뷰] StepWiser: Stepwise Generative Judges for Wiser Reasoning</a></h2><div class="archive__item-excerpt">Olga Golovneva이 [arXiv]에 게시한 &#x27;StepWiser: Stepwise Generative Judges for Wiser Reasoning&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-28 13:10:39+0900">2025년 8월 28일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLM Reasoning</span><span class="page__taxonomy-item">#<!-- -->Process Reward Models</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Generative Judges</span><span class="page__taxonomy-item">#<!-- -->Stepwise Feedback</span><span class="page__taxonomy-item">#<!-- -->Chain-of-Thought</span><span class="page__taxonomy-item">#<!-- -->Meta-Reasoning</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-28-Self-Rewarding_Vision-Language_Model_via_Reasoning_Decomposition/">[논문리뷰] Self-Rewarding Vision-Language Model via Reasoning Decomposition</a></h2><div class="archive__item-excerpt">Zhenwen Liang이 [arXiv]에 게시한 &#x27;Self-Rewarding Vision-Language Model via Reasoning Decomposition&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-28 13:10:39+0900">2025년 8월 28일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Vision-Language Models</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Self-Rewarding</span><span class="page__taxonomy-item">#<!-- -->Reasoning Decomposition</span><span class="page__taxonomy-item">#<!-- -->Visual Perception</span><span class="page__taxonomy-item">#<!-- -->Language Reasoning</span><span class="page__taxonomy-item">#<!-- -->Hallucinations</span><span class="page__taxonomy-item">#<!-- -->Language Shortcuts</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-28-Predicting_the_Order_of_Upcoming_Tokens_Improves_Language_Modeling/">[논문리뷰] Predicting the Order of Upcoming Tokens Improves Language Modeling</a></h2><div class="archive__item-excerpt">Alham Fikri Aji이 [arXiv]에 게시한 &#x27;Predicting the Order of Upcoming Tokens Improves Language Modeling&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-28 13:10:39+0900">2025년 8월 28일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Language Modeling</span><span class="page__taxonomy-item">#<!-- -->Next-Token Prediction</span><span class="page__taxonomy-item">#<!-- -->Multi-Token Prediction</span><span class="page__taxonomy-item">#<!-- -->Token Order Prediction</span><span class="page__taxonomy-item">#<!-- -->Auxiliary Objective</span><span class="page__taxonomy-item">#<!-- -->Learning-to-Rank</span><span class="page__taxonomy-item">#<!-- -->Transformer</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-28-MotionFlux_Efficient_Text-Guided_Motion_Generation_through_Rectified_Flow_Matching_and_Preference_Alignment/">[논문리뷰] MotionFlux: Efficient Text-Guided Motion Generation through Rectified Flow Matching and Preference Alignment</a></h2><div class="archive__item-excerpt">An-An Liu이 [arXiv]에 게시한 &#x27;MotionFlux: Efficient Text-Guided Motion Generation through Rectified Flow Matching and Preference Alignment&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-28 13:10:39+0900">2025년 8월 28일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Text-Guided Motion Generation</span><span class="page__taxonomy-item">#<!-- -->Rectified Flow Matching</span><span class="page__taxonomy-item">#<!-- -->Preference Alignment</span><span class="page__taxonomy-item">#<!-- -->Human Motion Synthesis</span><span class="page__taxonomy-item">#<!-- -->Real-time AI</span><span class="page__taxonomy-item">#<!-- -->Transformer Architecture</span><span class="page__taxonomy-item">#<!-- -->Self-supervised Learning</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-28-Mind_the_Third_Eye_Benchmarking_Privacy_Awareness_in_MLLM-powered_Smartphone_Agents/">[논문리뷰] Mind the Third Eye! Benchmarking Privacy Awareness in MLLM-powered Smartphone Agents</a></h2><div class="archive__item-excerpt">Yue Yao이 [arXiv]에 게시한 &#x27;Mind the Third Eye! Benchmarking Privacy Awareness in MLLM-powered Smartphone Agents&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-28 13:10:39+0900">2025년 8월 28일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Multimodal LLMs (MLLMs)</span><span class="page__taxonomy-item">#<!-- -->Smartphone Agents</span><span class="page__taxonomy-item">#<!-- -->Privacy Awareness</span><span class="page__taxonomy-item">#<!-- -->Benchmarking</span><span class="page__taxonomy-item">#<!-- -->Sensitive Data Detection</span><span class="page__taxonomy-item">#<!-- -->Risk Assessment</span><span class="page__taxonomy-item">#<!-- -->UI Automation</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-28-MIDAS_Multimodal_Interactive_Digital-human_Synthesis_via_Real-time_Autoregressive_Video_Generation/">[논문리뷰] MIDAS: Multimodal Interactive Digital-human Synthesis via Real-time Autoregressive Video Generation</a></h2><div class="archive__item-excerpt">Yan Zhou이 [arXiv]에 게시한 &#x27;MIDAS: Multimodal Interactive Digital-human Synthesis via Real-time Autoregressive Video Generation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-28 13:10:39+0900">2025년 8월 28일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Multimodal Generation</span><span class="page__taxonomy-item">#<!-- -->Digital Human Synthesis</span><span class="page__taxonomy-item">#<!-- -->Real-time Video Generation</span><span class="page__taxonomy-item">#<!-- -->Autoregressive LLM</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->Deep Compression Autoencoder</span><span class="page__taxonomy-item">#<!-- -->Exposure Bias Mitigation</span><span class="page__taxonomy-item">#<!-- -->Streaming Inference</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-28-Gaze_into_the_Heart_A_Multi-View_Video_Dataset_for_rPPG_and_Health_Biomarkers_Estimation/">[논문리뷰] Gaze into the Heart: A Multi-View Video Dataset for rPPG and Health Biomarkers Estimation</a></h2><div class="archive__item-excerpt">Anton Ivaschenko이 [arXiv]에 게시한 &#x27;Gaze into the Heart: A Multi-View Video Dataset for rPPG and Health Biomarkers Estimation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-28 13:10:39+0900">2025년 8월 28일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->rPPG</span><span class="page__taxonomy-item">#<!-- -->Multi-View Video Dataset</span><span class="page__taxonomy-item">#<!-- -->Health Biomarkers</span><span class="page__taxonomy-item">#<!-- -->Physiological Monitoring</span><span class="page__taxonomy-item">#<!-- -->Deep Learning</span><span class="page__taxonomy-item">#<!-- -->Telemedicine</span><span class="page__taxonomy-item">#<!-- -->Biosignals</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-28-Discrete_Diffusion_VLA_Bringing_Discrete_Diffusion_to_Action_Decoding_in_Vision-Language-Action_Policies/">[논문리뷰] Discrete Diffusion VLA: Bringing Discrete Diffusion to Action Decoding in Vision-Language-Action Policies</a></h2><div class="archive__item-excerpt">Sitong Mao이 [arXiv]에 게시한 &#x27;Discrete Diffusion VLA: Bringing Discrete Diffusion to Action Decoding in Vision-Language-Action Policies&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-28 13:10:39+0900">2025년 8월 28일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Vision-Language-Action (VLA)</span><span class="page__taxonomy-item">#<!-- -->Discrete Diffusion</span><span class="page__taxonomy-item">#<!-- -->Action Decoding</span><span class="page__taxonomy-item">#<!-- -->Transformer</span><span class="page__taxonomy-item">#<!-- -->Robot Control</span><span class="page__taxonomy-item">#<!-- -->Masked Modeling</span><span class="page__taxonomy-item">#<!-- -->Adaptive Decoding</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-28-Diffusion_Language_Models_Know_the_Answer_Before_Decoding/">[논문리뷰] Diffusion Language Models Know the Answer Before Decoding</a></h2><div class="archive__item-excerpt">Shilin Yan이 [arXiv]에 게시한 &#x27;Diffusion Language Models Know the Answer Before Decoding&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-28 13:10:39+0900">2025년 8월 28일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Diffusion Language Models</span><span class="page__taxonomy-item">#<!-- -->DLM Acceleration</span><span class="page__taxonomy-item">#<!-- -->Early Answer Convergence</span><span class="page__taxonomy-item">#<!-- -->Early Commit Decoding</span><span class="page__taxonomy-item">#<!-- -->Confidence Gap</span><span class="page__taxonomy-item">#<!-- -->Inference Speedup</span><span class="page__taxonomy-item">#<!-- -->Training-Free</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-28-DeepScholar-Bench_A_Live_Benchmark_and_Automated_Evaluation_for_Generative_Research_Synthesis/">[논문리뷰] DeepScholar-Bench: A Live Benchmark and Automated Evaluation for Generative Research Synthesis</a></h2><div class="archive__item-excerpt">Ion Stoica이 [arXiv]에 게시한 &#x27;DeepScholar-Bench: A Live Benchmark and Automated Evaluation for Generative Research Synthesis&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-28 13:10:39+0900">2025년 8월 28일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Generative Research Synthesis</span><span class="page__taxonomy-item">#<!-- -->Live Benchmark</span><span class="page__taxonomy-item">#<!-- -->Automated Evaluation</span><span class="page__taxonomy-item">#<!-- -->LLM-as-a-judge</span><span class="page__taxonomy-item">#<!-- -->Related Work Generation</span><span class="page__taxonomy-item">#<!-- -->Retrieval-Augmented Generation</span><span class="page__taxonomy-item">#<!-- -->Verifiability</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-28-CODA_Coordinating_the_Cerebrum_and_Cerebellum_for_a_Dual-Brain_Computer_Use_Agent_with_Decoupled_Reinforcement_Learning/">[논문리뷰] CODA: Coordinating the Cerebrum and Cerebellum for a Dual-Brain Computer Use Agent with Decoupled Reinforcement Learning</a></h2><div class="archive__item-excerpt">Jianze Liang이 [arXiv]에 게시한 &#x27;CODA: Coordinating the Cerebrum and Cerebellum for a Dual-Brain Computer Use Agent with Decoupled Reinforcement Learning&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-28 13:10:39+0900">2025년 8월 28일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->GUI Agents</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Planner-Executor Architecture</span><span class="page__taxonomy-item">#<!-- -->Decoupled Training</span><span class="page__taxonomy-item">#<!-- -->Large Vision-Language Models</span><span class="page__taxonomy-item">#<!-- -->Specialization</span><span class="page__taxonomy-item">#<!-- -->Generalization</span><span class="page__taxonomy-item">#<!-- -->Computer Use Agent</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-28-Beyond_Transcription_Mechanistic_Interpretability_in_ASR/">[논문리뷰] Beyond Transcription: Mechanistic Interpretability in ASR</a></h2><div class="archive__item-excerpt">Aviv Shamsian이 [arXiv]에 게시한 &#x27;Beyond Transcription: Mechanistic Interpretability in ASR&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-28 13:10:39+0900">2025년 8월 28일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->ASR</span><span class="page__taxonomy-item">#<!-- -->Mechanistic Interpretability</span><span class="page__taxonomy-item">#<!-- -->Logit Lens</span><span class="page__taxonomy-item">#<!-- -->Linear Probing</span><span class="page__taxonomy-item">#<!-- -->Activation Patching</span><span class="page__taxonomy-item">#<!-- -->Hallucinations</span><span class="page__taxonomy-item">#<!-- -->Repetitions</span><span class="page__taxonomy-item">#<!-- -->Encoder-Decoder</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-28-AudioStory_Generating_Long-Form_Narrative_Audio_with_Large_Language_Models/">[논문리뷰] AudioStory: Generating Long-Form Narrative Audio with Large Language Models</a></h2><div class="archive__item-excerpt">Yixiao Ge이 [arXiv]에 게시한 &#x27;AudioStory: Generating Long-Form Narrative Audio with Large Language Models&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-28 13:10:39+0900">2025년 8월 28일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Text-to-Audio</span><span class="page__taxonomy-item">#<!-- -->Long-Form Audio Generation</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Narrative Reasoning</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->Multimodal AI</span><span class="page__taxonomy-item">#<!-- -->Progressive Training</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-27-Wan-S2V_Audio-Driven_Cinematic_Video_Generation/">[논문리뷰] Wan-S2V: Audio-Driven Cinematic Video Generation</a></h2><div class="archive__item-excerpt">Chaonan Ji이 [arXiv]에 게시한 &#x27;Wan-S2V: Audio-Driven Cinematic Video Generation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-27 13:22:18+0900">2025년 8월 27일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Audio-Driven Video Generation</span><span class="page__taxonomy-item">#<!-- -->Cinematic Video</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->Transformer Architecture</span><span class="page__taxonomy-item">#<!-- -->Long Video Consistency</span><span class="page__taxonomy-item">#<!-- -->Human Animation</span><span class="page__taxonomy-item">#<!-- -->Multimodal Control</span><span class="page__taxonomy-item">#<!-- -->Data Curation</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-27-VoxHammer_Training-Free_Precise_and_Coherent_3D_Editing_in_Native_3D_Space/">[논문리뷰] VoxHammer: Training-Free Precise and Coherent 3D Editing in Native 3D Space</a></h2><div class="archive__item-excerpt">Rui Chen이 [arXiv]에 게시한 &#x27;VoxHammer: Training-Free Precise and Coherent 3D Editing in Native 3D Space&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-27 13:22:18+0900">2025년 8월 27일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->3D Editing</span><span class="page__taxonomy-item">#<!-- -->Training-Free</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->Latent Space</span><span class="page__taxonomy-item">#<!-- -->3D Inversion</span><span class="page__taxonomy-item">#<!-- -->Contextual Feature Replacement</span><span class="page__taxonomy-item">#<!-- -->3D Consistency</span><span class="page__taxonomy-item">#<!-- -->Edit3D-Bench</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-27-VibeVoice_Technical_Report/">[논문리뷰] VibeVoice Technical Report</a></h2><div class="archive__item-excerpt">Yaoyao Chang이 [arXiv]에 게시한 &#x27;VibeVoice Technical Report&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-27 13:22:18+0900">2025년 8월 27일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Speech Synthesis</span><span class="page__taxonomy-item">#<!-- -->Long-form Audio</span><span class="page__taxonomy-item">#<!-- -->Multi-speaker</span><span class="page__taxonomy-item">#<!-- -->Next-token Diffusion</span><span class="page__taxonomy-item">#<!-- -->Speech Tokenizer</span><span class="page__taxonomy-item">#<!-- -->Large Language Model</span><span class="page__taxonomy-item">#<!-- -->Variational Autoencoder</span><span class="page__taxonomy-item">#<!-- -->Audio Compression</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-27-Unraveling_the_cognitive_patterns_of_Large_Language_Models_through_module_communities/">[논문리뷰] Unraveling the cognitive patterns of Large Language Models through module communities</a></h2><div class="archive__item-excerpt">Jianxi Gao이 [arXiv]에 게시한 &#x27;Unraveling the cognitive patterns of Large Language Models through module communities&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-27 13:22:18+0900">2025년 8월 27일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Network Community Structure</span><span class="page__taxonomy-item">#<!-- -->Cognitive Skills</span><span class="page__taxonomy-item">#<!-- -->AI Interpretability</span><span class="page__taxonomy-item">#<!-- -->Module Communities</span><span class="page__taxonomy-item">#<!-- -->Fine-tuning</span><span class="page__taxonomy-item">#<!-- -->Neural Plasticity</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-27-UltraMemV2_Memory_Networks_Scaling_to_120B_Parameters_with_Superior_Long-Context_Learning/">[논문리뷰] UltraMemV2: Memory Networks Scaling to 120B Parameters with Superior Long-Context Learning</a></h2><div class="archive__item-excerpt">Ran Guo이 [arXiv]에 게시한 &#x27;UltraMemV2: Memory Networks Scaling to 120B Parameters with Superior Long-Context Learning&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-27 13:22:18+0900">2025년 8월 27일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Memory Networks</span><span class="page__taxonomy-item">#<!-- -->Mixture of Experts (MoE)</span><span class="page__taxonomy-item">#<!-- -->Long-Context Learning</span><span class="page__taxonomy-item">#<!-- -->Sparse Models</span><span class="page__taxonomy-item">#<!-- -->Transformer Architecture</span><span class="page__taxonomy-item">#<!-- -->LLMs</span><span class="page__taxonomy-item">#<!-- -->Efficient Inference</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-27-TreePO_Bridging_the_Gap_of_Policy_Optimization_and_Efficacy_and_Inference_Efficiency_with_Heuristic_Tree-based_Modeling/">[논문리뷰] TreePO: Bridging the Gap of Policy Optimization and Efficacy and Inference Efficiency with Heuristic Tree-based Modeling</a></h2><div class="archive__item-excerpt">Zhoufutu Wen이 [arXiv]에 게시한 &#x27;TreePO: Bridging the Gap of Policy Optimization and Efficacy and Inference Efficiency with Heuristic Tree-based Modeling&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-27 13:22:18+0900">2025년 8월 27일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Policy Optimization</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Inference Efficiency</span><span class="page__taxonomy-item">#<!-- -->Tree Search</span><span class="page__taxonomy-item">#<!-- -->Segment-level Decoding</span><span class="page__taxonomy-item">#<!-- -->Advantage Estimation</span><span class="page__taxonomy-item">#<!-- -->Reasoning</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-27-Training_Language_Model_Agents_to_Find_Vulnerabilities_with_CTF-Dojo/">[논문리뷰] Training Language Model Agents to Find Vulnerabilities with CTF-Dojo</a></h2><div class="archive__item-excerpt">Zijian Wang이 [arXiv]에 게시한 &#x27;Training Language Model Agents to Find Vulnerabilities with CTF-Dojo&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-27 13:22:18+0900">2025년 8월 27일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLM Agents</span><span class="page__taxonomy-item">#<!-- -->Cybersecurity</span><span class="page__taxonomy-item">#<!-- -->CTF Challenges</span><span class="page__taxonomy-item">#<!-- -->Vulnerability Detection</span><span class="page__taxonomy-item">#<!-- -->Execution Environments</span><span class="page__taxonomy-item">#<!-- -->Docker</span><span class="page__taxonomy-item">#<!-- -->Automated Training</span><span class="page__taxonomy-item">#<!-- -->Verifiable Feedback</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-27-ThinkDial_An_Open_Recipe_for_Controlling_Reasoning_Effort_in_Large_Language_Models/">[논문리뷰] ThinkDial: An Open Recipe for Controlling Reasoning Effort in Large Language Models</a></h2><div class="archive__item-excerpt">Jiangjie Chen이 [arXiv]에 게시한 &#x27;ThinkDial: An Open Recipe for Controlling Reasoning Effort in Large Language Models&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-27 13:22:18+0900">2025년 8월 27일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLMs</span><span class="page__taxonomy-item">#<!-- -->Controllable Reasoning</span><span class="page__taxonomy-item">#<!-- -->Computational Efficiency</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Supervised Fine-tuning</span><span class="page__taxonomy-item">#<!-- -->Reasoning Compression</span><span class="page__taxonomy-item">#<!-- -->Budget-Aware Training</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-27-Spacer_Towards_Engineered_Scientific_Inspiration/">[논문리뷰] Spacer: Towards Engineered Scientific Inspiration</a></h2><div class="archive__item-excerpt">zerojun48이 [arXiv]에 게시한 &#x27;Spacer: Towards Engineered Scientific Inspiration&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-27 13:22:18+0900">2025년 8월 27일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Scientific Discovery</span><span class="page__taxonomy-item">#<!-- -->Large Language Models (LLMs)</span><span class="page__taxonomy-item">#<!-- -->Decontextualization</span><span class="page__taxonomy-item">#<!-- -->Keyword Graph</span><span class="page__taxonomy-item">#<!-- -->Multi-Agent System</span><span class="page__taxonomy-item">#<!-- -->Scientific Ideation</span><span class="page__taxonomy-item">#<!-- -->Research Automation</span><span class="page__taxonomy-item">#<!-- -->Inspiration Engine</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-27-ReportBench_Evaluating_Deep_Research_Agents_via_Academic_Survey_Tasks/">[논문리뷰] ReportBench: Evaluating Deep Research Agents via Academic Survey Tasks</a></h2><div class="archive__item-excerpt">Kai Jia이 [arXiv]에 게시한 &#x27;ReportBench: Evaluating Deep Research Agents via Academic Survey Tasks&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-27 13:22:18+0900">2025년 8월 27일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Deep Research Agents</span><span class="page__taxonomy-item">#<!-- -->LLM Evaluation</span><span class="page__taxonomy-item">#<!-- -->Academic Survey</span><span class="page__taxonomy-item">#<!-- -->Factual Accuracy</span><span class="page__taxonomy-item">#<!-- -->Citation Verification</span><span class="page__taxonomy-item">#<!-- -->Report Generation</span><span class="page__taxonomy-item">#<!-- -->Benchmark</span><span class="page__taxonomy-item">#<!-- -->Hallucination</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-27-QueryBandits_for_Hallucination_Mitigation_Exploiting_Semantic_Features_for_No-Regret_Rewriting/">[논문리뷰] QueryBandits for Hallucination Mitigation: Exploiting Semantic Features for No-Regret Rewriting</a></h2><div class="archive__item-excerpt">Manuela Veloso이 [arXiv]에 게시한 &#x27;QueryBandits for Hallucination Mitigation: Exploiting Semantic Features for No-Regret Rewriting&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-27 13:22:18+0900">2025년 8월 27일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Hallucination Mitigation</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Contextual Bandits</span><span class="page__taxonomy-item">#<!-- -->Query Rewriting</span><span class="page__taxonomy-item">#<!-- -->Semantic Features</span><span class="page__taxonomy-item">#<!-- -->No-Regret Learning</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-27-Pixie_Fast_and_Generalizable_Supervised_Learning_of_3D_Physics_from_Pixels/">[논문리뷰] Pixie: Fast and Generalizable Supervised Learning of 3D Physics from Pixels</a></h2><div class="archive__item-excerpt">Dinesh Jayaraman이 [arXiv]에 게시한 &#x27;Pixie: Fast and Generalizable Supervised Learning of 3D Physics from Pixels&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-27 13:22:18+0900">2025년 8월 27일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->3D Physics Prediction</span><span class="page__taxonomy-item">#<!-- -->Supervised Learning</span><span class="page__taxonomy-item">#<!-- -->CLIP Features</span><span class="page__taxonomy-item">#<!-- -->Neural Radiance Fields</span><span class="page__taxonomy-item">#<!-- -->Material Point Method</span><span class="page__taxonomy-item">#<!-- -->PIXIEVERSE Dataset</span><span class="page__taxonomy-item">#<!-- -->Zero-Shot Generalization</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-27-Optimal_Sparsity_of_Mixture-of-Experts_Language_Models_for_Reasoning_Tasks/">[논문리뷰] Optimal Sparsity of Mixture-of-Experts Language Models for Reasoning Tasks</a></h2><div class="archive__item-excerpt">Daisuke Nohara이 [arXiv]에 게시한 &#x27;Optimal Sparsity of Mixture-of-Experts Language Models for Reasoning Tasks&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-27 13:22:18+0900">2025년 8월 27일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Mixture-of-Experts (MoE)</span><span class="page__taxonomy-item">#<!-- -->Sparsity</span><span class="page__taxonomy-item">#<!-- -->Scaling Laws</span><span class="page__taxonomy-item">#<!-- -->Reasoning Tasks</span><span class="page__taxonomy-item">#<!-- -->Memorization</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Generalization Gap</span><span class="page__taxonomy-item">#<!-- -->Top-k Routing</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-27-OmniHuman-1.5_Instilling_an_Active_Mind_in_Avatars_via_Cognitive_Simulation">[논문리뷰] OmniHuman-1.5: Instilling an Active Mind in Avatars via Cognitive Simulation</a></h2><div class="archive__item-excerpt">Jiaqi Yang이 [arXiv]에 게시한 &#x27;OmniHuman-1.5: Instilling an Active Mind in Avatars via Cognitive Simulation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-27 13:22:18+0900">2025년 8월 27일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Video Avatar Generation</span><span class="page__taxonomy-item">#<!-- -->Cognitive Simulation</span><span class="page__taxonomy-item">#<!-- -->Multimodal Large Language Models (MLLMs)</span><span class="page__taxonomy-item">#<!-- -->Diffusion Transformers (DiT)</span><span class="page__taxonomy-item">#<!-- -->Multimodal Fusion</span><span class="page__taxonomy-item">#<!-- -->Human Motion Synthesis</span><span class="page__taxonomy-item">#<!-- -->Contextual Animation</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-27-ObjFiller-3D_Consistent_Multi-view_3D_Inpainting_via_Video_Diffusion_Models/">[논문리뷰] ObjFiller-3D: Consistent Multi-view 3D Inpainting via Video Diffusion Models</a></h2><div class="archive__item-excerpt">Beiqi Chen이 [arXiv]에 게시한 &#x27;ObjFiller-3D: Consistent Multi-view 3D Inpainting via Video Diffusion Models&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-27 13:22:18+0900">2025년 8월 27일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->3D Inpainting</span><span class="page__taxonomy-item">#<!-- -->Multi-view Consistency</span><span class="page__taxonomy-item">#<!-- -->Video Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->3D Object Completion</span><span class="page__taxonomy-item">#<!-- -->Generative Models</span><span class="page__taxonomy-item">#<!-- -->LoRA</span><span class="page__taxonomy-item">#<!-- -->3D Gaussian Splatting</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-27-MovieCORE_COgnitive_REasoning_in_Movies/">[논문리뷰] MovieCORE: COgnitive REasoning in Movies</a></h2><div class="archive__item-excerpt">Hung-Ting Su이 [arXiv]에 게시한 &#x27;MovieCORE: COgnitive REasoning in Movies&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-27 13:22:18+0900">2025년 8월 27일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Video Question Answering (VQA)</span><span class="page__taxonomy-item">#<!-- -->Cognitive Reasoning</span><span class="page__taxonomy-item">#<!-- -->System-2 Thinking</span><span class="page__taxonomy-item">#<!-- -->Multi-agent LLMs</span><span class="page__taxonomy-item">#<!-- -->Dataset Creation</span><span class="page__taxonomy-item">#<!-- -->Movie Understanding</span><span class="page__taxonomy-item">#<!-- -->Cinematic Content</span><span class="page__taxonomy-item">#<!-- -->Agentic Enhancement</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-27-FastMeshEfficient_Artistic_Mesh_Generation_via_Component_Decoupling/">[논문리뷰] FastMesh:Efficient Artistic Mesh Generation via Component Decoupling</a></h2><div class="archive__item-excerpt">Xingang Pan이 [arXiv]에 게시한 &#x27;FastMesh:Efficient Artistic Mesh Generation via Component Decoupling&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-27 13:22:18+0900">2025년 8월 27일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->3D Mesh Generation</span><span class="page__taxonomy-item">#<!-- -->Component Decoupling</span><span class="page__taxonomy-item">#<!-- -->Autoregressive Models</span><span class="page__taxonomy-item">#<!-- -->Bidirectional Transformer</span><span class="page__taxonomy-item">#<!-- -->Fidelity Enhancement</span><span class="page__taxonomy-item">#<!-- -->Prediction Filtering</span><span class="page__taxonomy-item">#<!-- -->Token Efficiency</span><span class="page__taxonomy-item">#<!-- -->Artistic Meshes</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-27-Demystifying_Scientific_Problem-Solving_in_LLMs_by_Probing_Knowledge_and_Reasoning/">[논문리뷰] Demystifying Scientific Problem-Solving in LLMs by Probing Knowledge and Reasoning</a></h2><div class="archive__item-excerpt">Arman Cohan이 [arXiv]에 게시한 &#x27;Demystifying Scientific Problem-Solving in LLMs by Probing Knowledge and Reasoning&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-27 13:22:18+0900">2025년 8월 27일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Scientific Reasoning</span><span class="page__taxonomy-item">#<!-- -->Knowledge Retrieval</span><span class="page__taxonomy-item">#<!-- -->Reasoning Probing</span><span class="page__taxonomy-item">#<!-- -->Benchmarks</span><span class="page__taxonomy-item">#<!-- -->Chain-of-Thought</span><span class="page__taxonomy-item">#<!-- -->Fine-tuning</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-27-CMPhysBench_A_Benchmark_for_Evaluating_Large_Language_Models_in_Condensed_Matter_Physics/">[논문리뷰] CMPhysBench: A Benchmark for Evaluating Large Language Models in Condensed Matter Physics</a></h2><div class="archive__item-excerpt">Dongchen Huang이 [arXiv]에 게시한 &#x27;CMPhysBench: A Benchmark for Evaluating Large Language Models in Condensed Matter Physics&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-27 13:22:18+0900">2025년 8월 27일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Condensed Matter Physics</span><span class="page__taxonomy-item">#<!-- -->Benchmark</span><span class="page__taxonomy-item">#<!-- -->Scientific Reasoning</span><span class="page__taxonomy-item">#<!-- -->Evaluation Metric</span><span class="page__taxonomy-item">#<!-- -->Expression Edit Distance</span><span class="page__taxonomy-item">#<!-- -->Problem Solving</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-27-ClaimGen-CN_A_Large-scale_Chinese_Dataset_for_Legal_Claim_Generation/">[논문리뷰] ClaimGen-CN: A Large-scale Chinese Dataset for Legal Claim Generation</a></h2><div class="archive__item-excerpt">Kun Kuang이 [arXiv]에 게시한 &#x27;ClaimGen-CN: A Large-scale Chinese Dataset for Legal Claim Generation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-27 13:22:18+0900">2025년 8월 27일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Legal AI</span><span class="page__taxonomy-item">#<!-- -->Natural Language Processing</span><span class="page__taxonomy-item">#<!-- -->Claim Generation</span><span class="page__taxonomy-item">#<!-- -->Chinese Legal Dataset</span><span class="page__taxonomy-item">#<!-- -->Factuality</span><span class="page__taxonomy-item">#<!-- -->Clarity</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Zero-shot Evaluation</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-27-CineScale_Free_Lunch_in_High-Resolution_Cinematic_Visual_Generation/">[논문리뷰] CineScale: Free Lunch in High-Resolution Cinematic Visual Generation</a></h2><div class="archive__item-excerpt">Ziwei Liu이 [arXiv]에 게시한 &#x27;CineScale: Free Lunch in High-Resolution Cinematic Visual Generation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-27 13:22:18+0900">2025년 8월 27일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->High-Resolution Generation</span><span class="page__taxonomy-item">#<!-- -->Image Generation</span><span class="page__taxonomy-item">#<!-- -->Video Generation</span><span class="page__taxonomy-item">#<!-- -->UNet Architecture</span><span class="page__taxonomy-item">#<!-- -->DiT Architecture</span><span class="page__taxonomy-item">#<!-- -->Scale Fusion</span><span class="page__taxonomy-item">#<!-- -->LoRA Fine-tuning</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-27-Autoregressive_Universal_Video_Segmentation_Model/">[논문리뷰] Autoregressive Universal Video Segmentation Model</a></h2><div class="archive__item-excerpt">Albert Gu이 [arXiv]에 게시한 &#x27;Autoregressive Universal Video Segmentation Model&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-27 13:22:18+0900">2025년 8월 27일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Video Segmentation</span><span class="page__taxonomy-item">#<!-- -->Autoregressive Model</span><span class="page__taxonomy-item">#<!-- -->Universal Model</span><span class="page__taxonomy-item">#<!-- -->State Space Models</span><span class="page__taxonomy-item">#<!-- -->Mamba</span><span class="page__taxonomy-item">#<!-- -->Parallel Training</span><span class="page__taxonomy-item">#<!-- -->Streaming Video</span><span class="page__taxonomy-item">#<!-- -->Deep Learning</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-26-Visual-CoG_Stage-Aware_Reinforcement_Learning_with_Chain_of_Guidance_for_Text-to-Image_Generation/">[논문리뷰] Visual-CoG: Stage-Aware Reinforcement Learning with Chain of Guidance for Text-to-Image Generation</a></h2><div class="archive__item-excerpt">Haoxiang Shi이 [arXiv]에 게시한 &#x27;Visual-CoG: Stage-Aware Reinforcement Learning with Chain of Guidance for Text-to-Image Generation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-26 13:21:57+0900">2025년 8월 26일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Text-to-Image Generation</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Chain of Thought</span><span class="page__taxonomy-item">#<!-- -->Multimodal LLMs</span><span class="page__taxonomy-item">#<!-- -->Stage-Aware Rewards</span><span class="page__taxonomy-item">#<!-- -->Semantic Reasoning</span><span class="page__taxonomy-item">#<!-- -->Generative AI</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-26-UQ_Assessing_Language_Models_on_Unsolved_Questions/">[논문리뷰] UQ: Assessing Language Models on Unsolved Questions</a></h2><div class="archive__item-excerpt">Wei Liu이 [arXiv]에 게시한 &#x27;UQ: Assessing Language Models on Unsolved Questions&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-26 13:21:57+0900">2025년 8월 26일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLM Evaluation</span><span class="page__taxonomy-item">#<!-- -->Unsolved Questions</span><span class="page__taxonomy-item">#<!-- -->AI Benchmark</span><span class="page__taxonomy-item">#<!-- -->Oracle-Free Validation</span><span class="page__taxonomy-item">#<!-- -->Generator-Validator Gap</span><span class="page__taxonomy-item">#<!-- -->Community Evaluation</span><span class="page__taxonomy-item">#<!-- -->Stack Exchange</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-26-TaDiCodec_Text-aware_Diffusion_Speech_Tokenizer_for_Speech_Language_Modeling/">[논문리뷰] TaDiCodec: Text-aware Diffusion Speech Tokenizer for Speech Language Modeling</a></h2><div class="archive__item-excerpt">Jiaqi Li이 [arXiv]에 게시한 &#x27;TaDiCodec: Text-aware Diffusion Speech Tokenizer for Speech Language Modeling&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-26 13:21:57+0900">2025년 8월 26일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Speech Tokenizer</span><span class="page__taxonomy-item">#<!-- -->Diffusion Model</span><span class="page__taxonomy-item">#<!-- -->Text-to-Speech</span><span class="page__taxonomy-item">#<!-- -->Speech Language Modeling</span><span class="page__taxonomy-item">#<!-- -->Low Bitrate Codec</span><span class="page__taxonomy-item">#<!-- -->End-to-End Training</span><span class="page__taxonomy-item">#<!-- -->Binary Spherical Quantization</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-26-T2I-ReasonBench_Benchmarking_Reasoning-Informed_Text-to-Image_Generation/">[논문리뷰] T2I-ReasonBench: Benchmarking Reasoning-Informed Text-to-Image Generation</a></h2><div class="archive__item-excerpt">Xihui Liu이 [arXiv]에 게시한 &#x27;T2I-ReasonBench: Benchmarking Reasoning-Informed Text-to-Image Generation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-26 13:21:57+0900">2025년 8월 26일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Text-to-Image Generation</span><span class="page__taxonomy-item">#<!-- -->Reasoning Benchmark</span><span class="page__taxonomy-item">#<!-- -->Idiom Interpretation</span><span class="page__taxonomy-item">#<!-- -->Textual Image Design</span><span class="page__taxonomy-item">#<!-- -->Entity Reasoning</span><span class="page__taxonomy-item">#<!-- -->Scientific Reasoning</span><span class="page__taxonomy-item">#<!-- -->Multimodal LLM Evaluation</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-26-ST-Raptor_LLM-Powered_Semi-Structured_Table_Question_Answering/">[논문리뷰] ST-Raptor: LLM-Powered Semi-Structured Table Question Answering</a></h2><div class="archive__item-excerpt">Wei Zhou이 [arXiv]에 게시한 &#x27;ST-Raptor: LLM-Powered Semi-Structured Table Question Answering&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-26 13:21:57+0900">2025년 8월 26일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Semi-structured Tables</span><span class="page__taxonomy-item">#<!-- -->Question Answering</span><span class="page__taxonomy-item">#<!-- -->LLMs</span><span class="page__taxonomy-item">#<!-- -->Hierarchical Orthogonal Tree</span><span class="page__taxonomy-item">#<!-- -->Table Layout Understanding</span><span class="page__taxonomy-item">#<!-- -->Pipeline Generation</span><span class="page__taxonomy-item">#<!-- -->Verification Mechanism</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-26-SpotEdit_Evaluating_Visually-Guided_Image_Editing_Methods/">[논문리뷰] SpotEdit: Evaluating Visually-Guided Image Editing Methods</a></h2><div class="archive__item-excerpt">Ersin Yumer이 [arXiv]에 게시한 &#x27;SpotEdit: Evaluating Visually-Guided Image Editing Methods&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-26 13:21:57+0900">2025년 8월 26일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Visually-Guided Image Editing</span><span class="page__taxonomy-item">#<!-- -->Multimodal Models</span><span class="page__taxonomy-item">#<!-- -->Benchmark</span><span class="page__taxonomy-item">#<!-- -->Hallucination</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->Autoregressive Models</span><span class="page__taxonomy-item">#<!-- -->Evaluation Metrics</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-26-PosterGen_Aesthetic-Aware_Paper-to-Poster_Generation_via_Multi-Agent_LLMs/">[논문리뷰] PosterGen: Aesthetic-Aware Paper-to-Poster Generation via Multi-Agent LLMs</a></h2><div class="archive__item-excerpt">Chenyu You이 [arXiv]에 게시한 &#x27;PosterGen: Aesthetic-Aware Paper-to-Poster Generation via Multi-Agent LLMs&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-26 13:21:57+0900">2025년 8월 26일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Multi-Agent LLMs</span><span class="page__taxonomy-item">#<!-- -->Academic Poster Generation</span><span class="page__taxonomy-item">#<!-- -->Aesthetic Design</span><span class="page__taxonomy-item">#<!-- -->Layout Optimization</span><span class="page__taxonomy-item">#<!-- -->Typography</span><span class="page__taxonomy-item">#<!-- -->Color Palette</span><span class="page__taxonomy-item">#<!-- -->VLM-as-Judge</span><span class="page__taxonomy-item">#<!-- -->Content Fidelity</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-26-Neither_Valid_nor_Reliable_Investigating_the_Use_of_LLMs_as_Judges/">[논문리뷰] Neither Valid nor Reliable? Investigating the Use of LLMs as Judges</a></h2><div class="archive__item-excerpt">Golnoosh Farnadi이 [arXiv]에 게시한 &#x27;Neither Valid nor Reliable? Investigating the Use of LLMs as Judges&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-26 13:21:57+0900">2025년 8월 26일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLMs as Judges</span><span class="page__taxonomy-item">#<!-- -->NLG Evaluation</span><span class="page__taxonomy-item">#<!-- -->Measurement Theory</span><span class="page__taxonomy-item">#<!-- -->Validity</span><span class="page__taxonomy-item">#<!-- -->Reliability</span><span class="page__taxonomy-item">#<!-- -->Evaluation Bias</span><span class="page__taxonomy-item">#<!-- -->Scalability</span><span class="page__taxonomy-item">#<!-- -->Responsible AI</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-26-MV-RAG_Retrieval_Augmented_Multiview_Diffusion/">[논문리뷰] MV-RAG: Retrieval Augmented Multiview Diffusion</a></h2><div class="archive__item-excerpt">sagiebenaim이 [arXiv]에 게시한 &#x27;MV-RAG: Retrieval Augmented Multiview Diffusion&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-26 13:21:57+0900">2025년 8월 26일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Retrieval Augmented Generation</span><span class="page__taxonomy-item">#<!-- -->Multiview Diffusion</span><span class="page__taxonomy-item">#<!-- -->Text-to-3D Generation</span><span class="page__taxonomy-item">#<!-- -->Out-of-Domain</span><span class="page__taxonomy-item">#<!-- -->Image Retrieval</span><span class="page__taxonomy-item">#<!-- -->3D Consistency</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->Hybrid Training</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-26-MeshSplat_Generalizable_Sparse-View_Surface_Reconstruction_via_Gaussian_Splatting/">[논문리뷰] MeshSplat: Generalizable Sparse-View Surface Reconstruction via Gaussian Splatting</a></h2><div class="archive__item-excerpt">Yanzhe Liang이 [arXiv]에 게시한 &#x27;MeshSplat: Generalizable Sparse-View Surface Reconstruction via Gaussian Splatting&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-26 13:21:57+0900">2025년 8월 26일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Sparse-View</span><span class="page__taxonomy-item">#<!-- -->Surface Reconstruction</span><span class="page__taxonomy-item">#<!-- -->Gaussian Splatting</span><span class="page__taxonomy-item">#<!-- -->2DGS</span><span class="page__taxonomy-item">#<!-- -->Novel View Synthesis</span><span class="page__taxonomy-item">#<!-- -->Generalizable</span><span class="page__taxonomy-item">#<!-- -->Mesh Extraction</span><span class="page__taxonomy-item">#<!-- -->3D Vision</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-26-MEENA_PersianMMMU_Multimodal-Multilingual_Educational_Exams_for_N-level_Assessment/">[논문리뷰] MEENA (PersianMMMU): Multimodal-Multilingual Educational Exams for N-level Assessment</a></h2><div class="archive__item-excerpt">Doratossadat Dastgheib이 [arXiv]에 게시한 &#x27;MEENA (PersianMMMU): Multimodal-Multilingual Educational Exams for N-level Assessment&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-26 13:21:57+0900">2025년 8월 26일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Multimodal Language Models</span><span class="page__taxonomy-item">#<!-- -->Multilingual Benchmarking</span><span class="page__taxonomy-item">#<!-- -->Persian Language</span><span class="page__taxonomy-item">#<!-- -->Educational Assessment</span><span class="page__taxonomy-item">#<!-- -->Vision-Language Models</span><span class="page__taxonomy-item">#<!-- -->Cultural Nuance</span><span class="page__taxonomy-item">#<!-- -->Reasoning Tasks</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-26-Limitations_of_Normalization_in_Attention_Mechanism/">[논문리뷰] Limitations of Normalization in Attention Mechanism</a></h2><div class="archive__item-excerpt">Radu State이 [arXiv]에 게시한 &#x27;Limitations of Normalization in Attention Mechanism&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-26 13:21:57+0900">2025년 8월 26일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Attention Mechanism</span><span class="page__taxonomy-item">#<!-- -->Normalization</span><span class="page__taxonomy-item">#<!-- -->Softmax</span><span class="page__taxonomy-item">#<!-- -->Transformer Models</span><span class="page__taxonomy-item">#<!-- -->Gradient Sensitivity</span><span class="page__taxonomy-item">#<!-- -->Token Separability</span><span class="page__taxonomy-item">#<!-- -->Context Length</span><span class="page__taxonomy-item">#<!-- -->GPT-2</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-26-InternVL3.5_Advancing_Open-Source_Multimodal_Models_in_Versatility_Reasoning_and_Efficiency">[논문리뷰] InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency</a></h2><div class="archive__item-excerpt">jinglinglin이 [arXiv]에 게시한 &#x27;InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-26 13:21:57+0900">2025년 8월 26일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Multimodal Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Inference Efficiency</span><span class="page__taxonomy-item">#<!-- -->Vision-Language Models</span><span class="page__taxonomy-item">#<!-- -->Open-Source</span><span class="page__taxonomy-item">#<!-- -->Versatility</span><span class="page__taxonomy-item">#<!-- -->Reasoning</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-26-German4All_-_A_Dataset_and_Model_for_Readability-Controlled_Paraphrasing_in_German/">[논문리뷰] German4All - A Dataset and Model for Readability-Controlled Paraphrasing in German</a></h2><div class="archive__item-excerpt">Cristian-George Craciun이 [arXiv]에 게시한 &#x27;German4All - A Dataset and Model for Readability-Controlled Paraphrasing in German&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-26 13:21:57+0900">2025년 8월 26일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Text Simplification</span><span class="page__taxonomy-item">#<!-- -->Paraphrasing</span><span class="page__taxonomy-item">#<!-- -->Readability Control</span><span class="page__taxonomy-item">#<!-- -->German NLP</span><span class="page__taxonomy-item">#<!-- -->Dataset Generation</span><span class="page__taxonomy-item">#<!-- -->LLM Distillation</span><span class="page__taxonomy-item">#<!-- -->Multi-level Text Generation</span><span class="page__taxonomy-item">#<!-- -->Accessibility</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-26-Explain_Before_You_Answer_A_Survey_on_Compositional_Visual_Reasoning/">[논문리뷰] Explain Before You Answer: A Survey on Compositional Visual Reasoning</a></h2><div class="archive__item-excerpt">Xin Zheng이 [arXiv]에 게시한 &#x27;Explain Before You Answer: A Survey on Compositional Visual Reasoning&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-26 13:21:57+0900">2025년 8월 26일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Compositional Visual Reasoning</span><span class="page__taxonomy-item">#<!-- -->Multimodal AI</span><span class="page__taxonomy-item">#<!-- -->Vision-Language Models</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Chain-of-Thought</span><span class="page__taxonomy-item">#<!-- -->Tool Learning</span><span class="page__taxonomy-item">#<!-- -->Agentic AI</span><span class="page__taxonomy-item">#<!-- -->Survey</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-26-Breaking_the_Exploration_Bottleneck_Rubric-Scaffolded_Reinforcement_Learning_for_General_LLM_Reasoning/">[논문리뷰] Breaking the Exploration Bottleneck: Rubric-Scaffolded Reinforcement Learning for General LLM Reasoning</a></h2><div class="archive__item-excerpt">Jiale Zhao이 [arXiv]에 게시한 &#x27;Breaking the Exploration Bottleneck: Rubric-Scaffolded Reinforcement Learning for General LLM Reasoning&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-26 13:21:57+0900">2025년 8월 26일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Exploration Bottleneck</span><span class="page__taxonomy-item">#<!-- -->Instructional Scaffolding</span><span class="page__taxonomy-item">#<!-- -->Rubric-based Rewards</span><span class="page__taxonomy-item">#<!-- -->General Reasoning</span><span class="page__taxonomy-item">#<!-- -->RL with Verifiable Rewards</span><span class="page__taxonomy-item">#<!-- -->Policy Optimization</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-26-Beyond_Memorization_Extending_Reasoning_Depth_with_Recurrence_Memory_and_Test-Time_Compute_Scaling/">[논문리뷰] Beyond Memorization: Extending Reasoning Depth with Recurrence, Memory and Test-Time Compute Scaling</a></h2><div class="archive__item-excerpt">Daniil Orel이 [arXiv]에 게시한 &#x27;Beyond Memorization: Extending Reasoning Depth with Recurrence, Memory and Test-Time Compute Scaling&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-26 13:21:57+0900">2025년 8월 26일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Reasoning Depth</span><span class="page__taxonomy-item">#<!-- -->Cellular Automata</span><span class="page__taxonomy-item">#<!-- -->Transformer Architectures</span><span class="page__taxonomy-item">#<!-- -->Recurrence</span><span class="page__taxonomy-item">#<!-- -->Adaptive Computation Time</span><span class="page__taxonomy-item">#<!-- -->Chain-of-Thought</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Generalization</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-25-TPLA_Tensor_Parallel_Latent_Attention_for_Efficient_Disaggregated_Prefill_Decode_Inference/">[논문리뷰] TPLA: Tensor Parallel Latent Attention for Efficient Disaggregated Prefill &amp; Decode Inference</a></h2><div class="archive__item-excerpt">Di Yin이 [arXiv]에 게시한 &#x27;TPLA: Tensor Parallel Latent Attention for Efficient Disaggregated Prefill &amp; Decode Inference&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-25 13:13:07+0900">2025년 8월 25일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLM Inference</span><span class="page__taxonomy-item">#<!-- -->Tensor Parallelism</span><span class="page__taxonomy-item">#<!-- -->KV Cache Optimization</span><span class="page__taxonomy-item">#<!-- -->Latent Attention</span><span class="page__taxonomy-item">#<!-- -->Memory Efficiency</span><span class="page__taxonomy-item">#<!-- -->Decoding Speedup</span><span class="page__taxonomy-item">#<!-- -->Prefill/Decode Separation</span><span class="page__taxonomy-item">#<!-- -->Reparameterization</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-25-Selective_Contrastive_Learning_for_Weakly_Supervised_Affordance_Grounding/">[논문리뷰] Selective Contrastive Learning for Weakly Supervised Affordance Grounding</a></h2><div class="archive__item-excerpt">Jae-Pil Heo이 [arXiv]에 게시한 &#x27;Selective Contrastive Learning for Weakly Supervised Affordance Grounding&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-25 13:13:07+0900">2025년 8월 25일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Weakly Supervised Learning</span><span class="page__taxonomy-item">#<!-- -->Affordance Grounding</span><span class="page__taxonomy-item">#<!-- -->Contrastive Learning</span><span class="page__taxonomy-item">#<!-- -->CLIP</span><span class="page__taxonomy-item">#<!-- -->Part Discovery</span><span class="page__taxonomy-item">#<!-- -->Object Localization</span><span class="page__taxonomy-item">#<!-- -->DINO</span><span class="page__taxonomy-item">#<!-- -->Generative Models</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-25-Learnable_SMPLify_A_Neural_Solution_for_Optimization-Free_Human_Pose_Inverse_Kinematics/">[논문리뷰] Learnable SMPLify: A Neural Solution for Optimization-Free Human Pose Inverse Kinematics</a></h2><div class="archive__item-excerpt">Xiao Sun이 [arXiv]에 게시한 &#x27;Learnable SMPLify: A Neural Solution for Optimization-Free Human Pose Inverse Kinematics&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-25 13:13:07+0900">2025년 8월 25일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Inverse Kinematics</span><span class="page__taxonomy-item">#<!-- -->Human Pose Estimation</span><span class="page__taxonomy-item">#<!-- -->SMPL Model</span><span class="page__taxonomy-item">#<!-- -->Neural Networks</span><span class="page__taxonomy-item">#<!-- -->Optimization-Free</span><span class="page__taxonomy-item">#<!-- -->Residual Learning</span><span class="page__taxonomy-item">#<!-- -->Data-Driven</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-25-Jailbreaking_Commercial_Black-Box_LLMs_with_Explicitly_Harmful_Prompts/">[논문리뷰] Jailbreaking Commercial Black-Box LLMs with Explicitly Harmful Prompts</a></h2><div class="archive__item-excerpt">Liming Fang이 [arXiv]에 게시한 &#x27;Jailbreaking Commercial Black-Box LLMs with Explicitly Harmful Prompts&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-25 13:13:07+0900">2025년 8월 25일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLM Jailbreaking</span><span class="page__taxonomy-item">#<!-- -->Red Teaming</span><span class="page__taxonomy-item">#<!-- -->Malicious Content Detection</span><span class="page__taxonomy-item">#<!-- -->Developer Messages</span><span class="page__taxonomy-item">#<!-- -->D-Attack</span><span class="page__taxonomy-item">#<!-- -->DH-CoT</span><span class="page__taxonomy-item">#<!-- -->Adversarial Attacks</span><span class="page__taxonomy-item">#<!-- -->Dataset Cleaning</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-25-InMind_Evaluating_LLMs_in_Capturing_and_Applying_Individual_Human_Reasoning_Styles/">[논문리뷰] InMind: Evaluating LLMs in Capturing and Applying Individual Human Reasoning Styles</a></h2><div class="archive__item-excerpt">Diping Song이 [arXiv]에 게시한 &#x27;InMind: Evaluating LLMs in Capturing and Applying Individual Human Reasoning Styles&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-25 13:13:07+0900">2025년 8월 25일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLM Evaluation</span><span class="page__taxonomy-item">#<!-- -->Human Reasoning Styles</span><span class="page__taxonomy-item">#<!-- -->Social Deduction Games</span><span class="page__taxonomy-item">#<!-- -->Theory of Mind</span><span class="page__taxonomy-item">#<!-- -->Adaptive Reasoning</span><span class="page__taxonomy-item">#<!-- -->Avalon Game</span><span class="page__taxonomy-item">#<!-- -->Cognitive Grounding</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-25-End-to-End_Agentic_RAG_System_Training_for_Traceable_Diagnostic_Reasoning/">[논문리뷰] End-to-End Agentic RAG System Training for Traceable Diagnostic Reasoning</a></h2><div class="archive__item-excerpt">Pengcheng Qiu이 [arXiv]에 게시한 &#x27;End-to-End Agentic RAG System Training for Traceable Diagnostic Reasoning&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-25 13:13:07+0900">2025년 8월 25일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Agentic RAG</span><span class="page__taxonomy-item">#<!-- -->Medical Diagnosis</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Traceable AI</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Clinical Decision Support</span><span class="page__taxonomy-item">#<!-- -->Out-of-Distribution Generalization</span><span class="page__taxonomy-item">#<!-- -->Reward Design</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-25-EgoTwin_Dreaming_Body_and_View_in_First_Person/">[논문리뷰] EgoTwin: Dreaming Body and View in First Person</a></h2><div class="archive__item-excerpt">Wentao Wang이 [arXiv]에 게시한 &#x27;EgoTwin: Dreaming Body and View in First Person&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-25 13:13:07+0900">2025년 8월 25일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Egocentric Video Generation</span><span class="page__taxonomy-item">#<!-- -->Human Motion Synthesis</span><span class="page__taxonomy-item">#<!-- -->Diffusion Transformers</span><span class="page__taxonomy-item">#<!-- -->Multimodal Generation</span><span class="page__taxonomy-item">#<!-- -->Viewpoint Alignment</span><span class="page__taxonomy-item">#<!-- -->Causal Interplay</span><span class="page__taxonomy-item">#<!-- -->First-Person Vision</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-25-Do_What_Teaching_Vision-Language-Action_Models_to_Reject_the_Impossible/">[논문리뷰] Do What? Teaching Vision-Language-Action Models to Reject the Impossible</a></h2><div class="archive__item-excerpt">Roei Herzig이 [arXiv]에 게시한 &#x27;Do What? Teaching Vision-Language-Action Models to Reject the Impossible&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-25 13:13:07+0900">2025년 8월 25일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Vision-Language-Action Models</span><span class="page__taxonomy-item">#<!-- -->Robotics</span><span class="page__taxonomy-item">#<!-- -->False Premise Detection</span><span class="page__taxonomy-item">#<!-- -->Instruction Following</span><span class="page__taxonomy-item">#<!-- -->Human-Robot Interaction</span><span class="page__taxonomy-item">#<!-- -->Clarification</span><span class="page__taxonomy-item">#<!-- -->Instruction Tuning</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-25-CRISP_Persistent_Concept_Unlearning_via_Sparse_Autoencoders/">[논문리뷰] CRISP: Persistent Concept Unlearning via Sparse Autoencoders</a></h2><div class="archive__item-excerpt">Yonatan Belinkov이 [arXiv]에 게시한 &#x27;CRISP: Persistent Concept Unlearning via Sparse Autoencoders&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-25 13:13:07+0900">2025년 8월 25일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Concept Unlearning</span><span class="page__taxonomy-item">#<!-- -->Sparse Autoencoders (SAEs)</span><span class="page__taxonomy-item">#<!-- -->LLMs</span><span class="page__taxonomy-item">#<!-- -->Parameter-Efficient Fine-Tuning</span><span class="page__taxonomy-item">#<!-- -->Model Interpretability</span><span class="page__taxonomy-item">#<!-- -->Safety-Critical AI</span><span class="page__taxonomy-item">#<!-- -->Feature Suppression</span><span class="page__taxonomy-item">#<!-- -->WMDP Benchmark</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-25-CARFT_Boosting_LLM_Reasoning_via_Contrastive_Learning_with_Annotated_Chain-of-Thought-based_Reinforced_Fine-Tuning/">[논문리뷰] CARFT: Boosting LLM Reasoning via Contrastive Learning with Annotated Chain-of-Thought-based Reinforced Fine-Tuning</a></h2><div class="archive__item-excerpt">Yulun Zhang이 [arXiv]에 게시한 &#x27;CARFT: Boosting LLM Reasoning via Contrastive Learning with Annotated Chain-of-Thought-based Reinforced Fine-Tuning&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-25 13:13:07+0900">2025년 8월 25일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLM Reasoning</span><span class="page__taxonomy-item">#<!-- -->Contrastive Learning</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Fine-tuning</span><span class="page__taxonomy-item">#<!-- -->Chain-of-Thought (CoT)</span><span class="page__taxonomy-item">#<!-- -->Annotated Data</span><span class="page__taxonomy-item">#<!-- -->Model Stability</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-25-Beyond_Pass1_Self-Play_with_Variational_Problem_Synthesis_Sustains_RLVR/">[논문리뷰] Beyond Pass@1: Self-Play with Variational Problem Synthesis Sustains RLVR</a></h2><div class="archive__item-excerpt">Ying Nian Wu이 [arXiv]에 게시한 &#x27;Beyond Pass@1: Self-Play with Variational Problem Synthesis Sustains RLVR&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-25 13:13:07+0900">2025년 8월 25일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Self-Play</span><span class="page__taxonomy-item">#<!-- -->Variational Problem Synthesis</span><span class="page__taxonomy-item">#<!-- -->Policy Entropy</span><span class="page__taxonomy-item">#<!-- -->Pass@k</span><span class="page__taxonomy-item">#<!-- -->Reasoning Benchmarks</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-25-AgentScope_1.0_A_Developer-Centric_Framework_for_Building_Agentic_Applications">[논문리뷰] AgentScope 1.0: A Developer-Centric Framework for Building Agentic Applications</a></h2><div class="archive__item-excerpt">Liuyi Yao이 [arXiv]에 게시한 &#x27;AgentScope 1.0: A Developer-Centric Framework for Building Agentic Applications&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-25 13:13:07+0900">2025년 8월 25일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLM Agents</span><span class="page__taxonomy-item">#<!-- -->Agentic Applications</span><span class="page__taxonomy-item">#<!-- -->ReAct Paradigm</span><span class="page__taxonomy-item">#<!-- -->Framework</span><span class="page__taxonomy-item">#<!-- -->Tool Use</span><span class="page__taxonomy-item">#<!-- -->Multi-Agent Systems</span><span class="page__taxonomy-item">#<!-- -->Developer Experience</span><span class="page__taxonomy-item">#<!-- -->Evaluation</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-25-AetherCode_Evaluating_LLMs_Ability_to_Win_In_Premier_Programming_Competitions/">[논문리뷰] AetherCode: Evaluating LLMs&#x27; Ability to Win In Premier Programming Competitions</a></h2><div class="archive__item-excerpt">Yidi Du이 [arXiv]에 게시한 &#x27;AetherCode: Evaluating LLMs&#x27; Ability to Win In Premier Programming Competitions&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-25 13:13:07+0900">2025년 8월 25일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Competitive Programming</span><span class="page__taxonomy-item">#<!-- -->LLM Evaluation</span><span class="page__taxonomy-item">#<!-- -->Code Reasoning</span><span class="page__taxonomy-item">#<!-- -->Benchmark</span><span class="page__taxonomy-item">#<!-- -->Test Case Generation</span><span class="page__taxonomy-item">#<!-- -->Programming Competitions</span><span class="page__taxonomy-item">#<!-- -->Algorithmic Problems</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-22-When_and_What_Diffusion-Grounded_VideoLLM_with_Entity_Aware_Segmentation_for_Long_Video_Understanding/">[논문리뷰] When and What: Diffusion-Grounded VideoLLM with Entity Aware Segmentation for Long Video Understanding</a></h2><div class="archive__item-excerpt">Rui Guo이 [arXiv]에 게시한 &#x27;When and What: Diffusion-Grounded VideoLLM with Entity Aware Segmentation for Long Video Understanding&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-22 13:10:52+0900">2025년 8월 22일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Video-LLM</span><span class="page__taxonomy-item">#<!-- -->Diffusion Model</span><span class="page__taxonomy-item">#<!-- -->Temporal Grounding</span><span class="page__taxonomy-item">#<!-- -->Object Segmentation</span><span class="page__taxonomy-item">#<!-- -->Long Video Understanding</span><span class="page__taxonomy-item">#<!-- -->Multimodal AI</span><span class="page__taxonomy-item">#<!-- -->Video Question Answering</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-22-Waver_Wave_Your_Way_to_Lifelike_Video_Generation/">[논문리뷰] Waver: Wave Your Way to Lifelike Video Generation</a></h2><div class="archive__item-excerpt">Yifu Zhang이 [arXiv]에 게시한 &#x27;Waver: Wave Your Way to Lifelike Video Generation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-22 13:10:52+0900">2025년 8월 22일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Video Generation</span><span class="page__taxonomy-item">#<!-- -->Foundation Model</span><span class="page__taxonomy-item">#<!-- -->Diffusion Model</span><span class="page__taxonomy-item">#<!-- -->Transformer</span><span class="page__taxonomy-item">#<!-- -->Text-to-Video</span><span class="page__taxonomy-item">#<!-- -->Image-to-Video</span><span class="page__taxonomy-item">#<!-- -->Super-Resolution</span><span class="page__taxonomy-item">#<!-- -->Data Curation</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-22-Snap-Snap_Taking_Two_Images_to_Reconstruct_3D_Human_Gaussians_in_Milliseconds/">[논문리뷰] Snap-Snap: Taking Two Images to Reconstruct 3D Human Gaussians in Milliseconds</a></h2><div class="archive__item-excerpt">Chuiyun Wu이 [arXiv]에 게시한 &#x27;Snap-Snap: Taking Two Images to Reconstruct 3D Human Gaussians in Milliseconds&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-22 13:10:52+0900">2025년 8월 22일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->3D Human Reconstruction</span><span class="page__taxonomy-item">#<!-- -->Gaussian Splatting</span><span class="page__taxonomy-item">#<!-- -->Sparse View</span><span class="page__taxonomy-item">#<!-- -->Two-Image Input</span><span class="page__taxonomy-item">#<!-- -->Real-time Inference</span><span class="page__taxonomy-item">#<!-- -->Point Cloud Prediction</span><span class="page__taxonomy-item">#<!-- -->Feed-forward Network</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-22-SceneGen_Single-Image_3D_Scene_Generation_in_One_Feedforward_Pass/">[논문리뷰] SceneGen: Single-Image 3D Scene Generation in One Feedforward Pass</a></h2><div class="archive__item-excerpt">Ya Zhang이 [arXiv]에 게시한 &#x27;SceneGen: Single-Image 3D Scene Generation in One Feedforward Pass&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-22 13:10:52+0900">2025년 8월 22일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->3D Scene Generation</span><span class="page__taxonomy-item">#<!-- -->Single-Image Input</span><span class="page__taxonomy-item">#<!-- -->Feedforward Networks</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->Geometric Modeling</span><span class="page__taxonomy-item">#<!-- -->Texture Synthesis</span><span class="page__taxonomy-item">#<!-- -->Transformer</span><span class="page__taxonomy-item">#<!-- -->Feature Aggregation</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-22-Mobile-Agent-v3_Foundamental_Agents_for_GUI_Automation/">[논문리뷰] Mobile-Agent-v3: Foundamental Agents for GUI Automation</a></h2><div class="archive__item-excerpt">Haowei Liu이 [arXiv]에 게시한 &#x27;Mobile-Agent-v3: Foundamental Agents for GUI Automation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-22 13:10:52+0900">2025년 8월 22일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->GUI Automation</span><span class="page__taxonomy-item">#<!-- -->Multimodal Agents</span><span class="page__taxonomy-item">#<!-- -->Foundational Models</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Cross-Platform</span><span class="page__taxonomy-item">#<!-- -->Self-Supervised Learning</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-22-LiveMCP-101_Stress_Testing_and_Diagnosing_MCP-enabled_Agents_on_Challenging_Queries/">[논문리뷰] LiveMCP-101: Stress Testing and Diagnosing MCP-enabled Agents on Challenging Queries</a></h2><div class="archive__item-excerpt">huuuyeah이 [arXiv]에 게시한 &#x27;LiveMCP-101: Stress Testing and Diagnosing MCP-enabled Agents on Challenging Queries&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-22 13:10:52+0900">2025년 8월 22일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->AI Agents</span><span class="page__taxonomy-item">#<!-- -->Tool Use</span><span class="page__taxonomy-item">#<!-- -->Model Context Protocol (MCP)</span><span class="page__taxonomy-item">#<!-- -->Benchmarking</span><span class="page__taxonomy-item">#<!-- -->Large Language Models (LLMs)</span><span class="page__taxonomy-item">#<!-- -->Real-world Tasks</span><span class="page__taxonomy-item">#<!-- -->Evaluation</span><span class="page__taxonomy-item">#<!-- -->Error Analysis</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-22-INTIMA_A_Benchmark_for_Human-AI_Companionship_Behavior/">[논문리뷰] INTIMA: A Benchmark for Human-AI Companionship Behavior</a></h2><div class="archive__item-excerpt">Yacine Jernite이 [arXiv]에 게시한 &#x27;INTIMA: A Benchmark for Human-AI Companionship Behavior&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-22 13:10:52+0900">2025년 8월 22일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->AI Companionship</span><span class="page__taxonomy-item">#<!-- -->Benchmark</span><span class="page__taxonomy-item">#<!-- -->Language Models (LLMs)</span><span class="page__taxonomy-item">#<!-- -->Human-AI Interaction</span><span class="page__taxonomy-item">#<!-- -->Emotional AI</span><span class="page__taxonomy-item">#<!-- -->Boundary Setting</span><span class="page__taxonomy-item">#<!-- -->Psychological Frameworks</span><span class="page__taxonomy-item">#<!-- -->Evaluation Metrics</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-22-Intern-S1_A_Scientific_Multimodal_Foundation_Model/">[논문리뷰] Intern-S1: A Scientific Multimodal Foundation Model</a></h2><div class="archive__item-excerpt">xuhuang87이 [arXiv]에 게시한 &#x27;Intern-S1: A Scientific Multimodal Foundation Model&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-22 13:10:52+0900">2025년 8월 22일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Multimodal Foundation Model</span><span class="page__taxonomy-item">#<!-- -->Scientific AI</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Mixture-of-Experts (MoE)</span><span class="page__taxonomy-item">#<!-- -->Dynamic Tokenizer</span><span class="page__taxonomy-item">#<!-- -->Data Curation</span><span class="page__taxonomy-item">#<!-- -->Low-Resource Learning</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-22-Fin-PRM_A_Domain-Specialized_Process_Reward_Model_for_Financial_Reasoning_in_Large_Language_Models/">[논문리뷰] Fin-PRM: A Domain-Specialized Process Reward Model for Financial Reasoning in Large Language Models</a></h2><div class="archive__item-excerpt">Lifan Guo이 [arXiv]에 게시한 &#x27;Fin-PRM: A Domain-Specialized Process Reward Model for Financial Reasoning in Large Language Models&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-22 13:10:52+0900">2025년 8월 22일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Process Reward Models</span><span class="page__taxonomy-item">#<!-- -->Financial Reasoning</span><span class="page__taxonomy-item">#<!-- -->Domain Specialization</span><span class="page__taxonomy-item">#<!-- -->RLHF</span><span class="page__taxonomy-item">#<!-- -->Best-of-N Selection</span><span class="page__taxonomy-item">#<!-- -->Data Curation</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-22-Does_the_cafe_entrance_look_accessible_Where_is_the_door_Towards_Geospatial_AI_Agents_for_Visual_Inquiries/">[논문리뷰] &#x27;Does the cafe entrance look accessible? Where is the door?&#x27; Towards Geospatial AI Agents for Visual Inquiries</a></h2><div class="archive__item-excerpt">Xia Su이 [arXiv]에 게시한 &#x27;Does the cafe entrance look accessible? Where is the door? Towards Geospatial AI Agents for Visual Inquiries&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-22 13:10:52+0900">2025년 8월 22일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Geospatial AI</span><span class="page__taxonomy-item">#<!-- -->Multimodal AI Agents</span><span class="page__taxonomy-item">#<!-- -->Visual Question Answering</span><span class="page__taxonomy-item">#<!-- -->Accessibility</span><span class="page__taxonomy-item">#<!-- -->Street View Imagery</span><span class="page__taxonomy-item">#<!-- -->Spatial Reasoning</span><span class="page__taxonomy-item">#<!-- -->Human-Computer Interaction</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-22-Deep_Think_with_Confidence/">[논문리뷰] Deep Think with Confidence</a></h2><div class="archive__item-excerpt">Xuewei Wang이 [arXiv]에 게시한 &#x27;Deep Think with Confidence&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-22 13:10:52+0900">2025년 8월 22일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLM Reasoning</span><span class="page__taxonomy-item">#<!-- -->Confidence Filtering</span><span class="page__taxonomy-item">#<!-- -->Self-Consistency</span><span class="page__taxonomy-item">#<!-- -->Test-Time Optimization</span><span class="page__taxonomy-item">#<!-- -->Computational Efficiency</span><span class="page__taxonomy-item">#<!-- -->Adaptive Sampling</span><span class="page__taxonomy-item">#<!-- -->Early Stopping</span><span class="page__taxonomy-item">#<!-- -->Majority Voting</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-22-A_Survey_on_Large_Language_Model_Benchmarks/">[논문리뷰] A Survey on Large Language Model Benchmarks</a></h2><div class="archive__item-excerpt">Siyi Li이 [arXiv]에 게시한 &#x27;A Survey on Large Language Model Benchmarks&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-22 13:10:52+0900">2025년 8월 22일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLM Benchmarks</span><span class="page__taxonomy-item">#<!-- -->Evaluation</span><span class="page__taxonomy-item">#<!-- -->Systematic Review</span><span class="page__taxonomy-item">#<!-- -->General Capabilities</span><span class="page__taxonomy-item">#<!-- -->Domain-Specific Benchmarks</span><span class="page__taxonomy-item">#<!-- -->Target-Specific Benchmarks</span><span class="page__taxonomy-item">#<!-- -->Data Contamination</span><span class="page__taxonomy-item">#<!-- -->AI Ethics</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-22-ATLAS_Decoupling_Skeletal_and_Shape_Parameters_for_Expressive_Parametric_Human_Modeling/">[논문리뷰] ATLAS: Decoupling Skeletal and Shape Parameters for Expressive Parametric Human Modeling</a></h2><div class="archive__item-excerpt">Shunsuke Saito이 [arXiv]에 게시한 &#x27;ATLAS: Decoupling Skeletal and Shape Parameters for Expressive Parametric Human Modeling&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-22 13:10:52+0900">2025년 8월 22일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Parametric Human Model</span><span class="page__taxonomy-item">#<!-- -->3D Human Modeling</span><span class="page__taxonomy-item">#<!-- -->Shape-Skeleton Decoupling</span><span class="page__taxonomy-item">#<!-- -->Pose Correctives</span><span class="page__taxonomy-item">#<!-- -->Single Image Mesh Fitting</span><span class="page__taxonomy-item">#<!-- -->Expressive Modeling</span><span class="page__taxonomy-item">#<!-- -->Goliath Dataset</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-22-aiXiv_A_Next-Generation_Open_Access_Ecosystem_for_Scientific_Discovery_Generated_by_AI_Scientists/">[논문리뷰] aiXiv: A Next-Generation Open Access Ecosystem for Scientific Discovery Generated by AI Scientists</a></h2><div class="archive__item-excerpt">Heng Zhang이 [arXiv]에 게시한 &#x27;aiXiv: A Next-Generation Open Access Ecosystem for Scientific Discovery Generated by AI Scientists&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-22 13:10:52+0900">2025년 8월 22일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->AI Agents</span><span class="page__taxonomy-item">#<!-- -->Open Access</span><span class="page__taxonomy-item">#<!-- -->Scientific Discovery</span><span class="page__taxonomy-item">#<!-- -->Peer Review</span><span class="page__taxonomy-item">#<!-- -->LLMs</span><span class="page__taxonomy-item">#<!-- -->Multi-agent Systems</span><span class="page__taxonomy-item">#<!-- -->Prompt Injection</span><span class="page__taxonomy-item">#<!-- -->Iterative Refinement</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-21-ViExam_Are_Vision_Language_Models_Better_than_Humans_on_Vietnamese_Multimodal_Exam_Questions/">[논문리뷰] ViExam: Are Vision Language Models Better than Humans on Vietnamese Multimodal Exam Questions?</a></h2><div class="archive__item-excerpt">Daeyoung Kim이 [arXiv]에 게시한 &#x27;ViExam: Are Vision Language Models Better than Humans on Vietnamese Multimodal Exam Questions?&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-21 13:15:28+0900">2025년 8월 21일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Vision Language Models</span><span class="page__taxonomy-item">#<!-- -->Multimodal AI</span><span class="page__taxonomy-item">#<!-- -->Vietnamese Language</span><span class="page__taxonomy-item">#<!-- -->Educational Assessment</span><span class="page__taxonomy-item">#<!-- -->Low-Resource Languages</span><span class="page__taxonomy-item">#<!-- -->Cross-Lingual Reasoning</span><span class="page__taxonomy-item">#<!-- -->ViExam</span><span class="page__taxonomy-item">#<!-- -->Human-in-the-Loop</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-21-Tinker_Diffusions_Gift_to_3D--Multi-View_Consistent_Editing_From_Sparse_Inputs_without_Per-Scene_Optimization/">[논문리뷰] Tinker: Diffusion&#x27;s Gift to 3D--Multi-View Consistent Editing From Sparse Inputs without Per-Scene Optimization</a></h2><div class="archive__item-excerpt">Hao Chen이 [arXiv]에 게시한 &#x27;Tinker: Diffusion&#x27;s Gift to 3D--Multi-View Consistent Editing From Sparse Inputs without Per-Scene Optimization&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-21 13:15:28+0900">2025년 8월 21일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->3D Editing</span><span class="page__taxonomy-item">#<!-- -->Multi-View Consistency</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->Sparse Input</span><span class="page__taxonomy-item">#<!-- -->Zero-Shot Learning</span><span class="page__taxonomy-item">#<!-- -->Scene Completion</span><span class="page__taxonomy-item">#<!-- -->Gaussian Splatting</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-21-RynnEC_Bringing_MLLMs_into_Embodied_World/">[논문리뷰] RynnEC: Bringing MLLMs into Embodied World</a></h2><div class="archive__item-excerpt">jiangpinliu이 [arXiv]에 게시한 &#x27;RynnEC: Bringing MLLMs into Embodied World&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-21 13:15:28+0900">2025년 8월 21일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Multi-modal Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Embodied AI</span><span class="page__taxonomy-item">#<!-- -->Embodied Cognition</span><span class="page__taxonomy-item">#<!-- -->Video Understanding</span><span class="page__taxonomy-item">#<!-- -->Instance Segmentation</span><span class="page__taxonomy-item">#<!-- -->Spatial Reasoning</span><span class="page__taxonomy-item">#<!-- -->Robotics</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-21-Refining_Contrastive_Learning_and_Homography_Relations_for_Multi-Modal_Recommendation/">[논문리뷰] Refining Contrastive Learning and Homography Relations for Multi-Modal Recommendation</a></h2><div class="archive__item-excerpt">Shiqing Wu이 [arXiv]에 게시한 &#x27;Refining Contrastive Learning and Homography Relations for Multi-Modal Recommendation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-21 13:15:28+0900">2025년 8월 21일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Multi-modal Recommendation</span><span class="page__taxonomy-item">#<!-- -->Contrastive Learning</span><span class="page__taxonomy-item">#<!-- -->Graph Neural Network</span><span class="page__taxonomy-item">#<!-- -->Homography Relations</span><span class="page__taxonomy-item">#<!-- -->Meta-network</span><span class="page__taxonomy-item">#<!-- -->Orthogonal Constraint</span><span class="page__taxonomy-item">#<!-- -->Data Sparsity</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-21-Quantization_Meets_dLLMs_A_Systematic_Study_of_Post-training_Quantization_for_Diffusion_LLMs/">[논문리뷰] Quantization Meets dLLMs: A Systematic Study of Post-training Quantization for Diffusion LLMs</a></h2><div class="archive__item-excerpt">Haobo Xu이 [arXiv]에 게시한 &#x27;Quantization Meets dLLMs: A Systematic Study of Post-training Quantization for Diffusion LLMs&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-21 13:15:28+0900">2025년 8월 21일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Diffusion LLMs</span><span class="page__taxonomy-item">#<!-- -->Post-training Quantization (PTQ)</span><span class="page__taxonomy-item">#<!-- -->Model Compression</span><span class="page__taxonomy-item">#<!-- -->Activation Outliers</span><span class="page__taxonomy-item">#<!-- -->Quantization Methods</span><span class="page__taxonomy-item">#<!-- -->Efficient Deployment</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-21-On-Policy_RL_Meets_Off-Policy_Experts_Harmonizing_Supervised_Fine-Tuning_and_Reinforcement_Learning_via_Dynamic_Weighting/">[논문리뷰] On-Policy RL Meets Off-Policy Experts: Harmonizing Supervised Fine-Tuning and Reinforcement Learning via Dynamic Weighting</a></h2><div class="archive__item-excerpt">Guoyin Wang이 [arXiv]에 게시한 &#x27;On-Policy RL Meets Off-Policy Experts: Harmonizing Supervised Fine-Tuning and Reinforcement Learning via Dynamic Weighting&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-21 13:15:28+0900">2025년 8월 21일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Supervised Fine-Tuning</span><span class="page__taxonomy-item">#<!-- -->On-Policy RL</span><span class="page__taxonomy-item">#<!-- -->Off-Policy Experts</span><span class="page__taxonomy-item">#<!-- -->Dynamic Weighting</span><span class="page__taxonomy-item">#<!-- -->LLM Alignment</span><span class="page__taxonomy-item">#<!-- -->Reasoning</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-21-NVIDIA_Nemotron_Nano_2_An_Accurate_and_Efficient_Hybrid_Mamba-Transformer_Reasoning_Model/">[논문리뷰] NVIDIA Nemotron Nano 2: An Accurate and Efficient Hybrid Mamba-Transformer Reasoning Model</a></h2><div class="archive__item-excerpt">abercovich이 [arXiv]에 게시한 &#x27;NVIDIA Nemotron Nano 2: An Accurate and Efficient Hybrid Mamba-Transformer Reasoning Model&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-21 13:15:28+0900">2025년 8월 21일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Hybrid Architecture</span><span class="page__taxonomy-item">#<!-- -->Mamba-Transformer</span><span class="page__taxonomy-item">#<!-- -->Reasoning LLM</span><span class="page__taxonomy-item">#<!-- -->Model Compression</span><span class="page__taxonomy-item">#<!-- -->Knowledge Distillation</span><span class="page__taxonomy-item">#<!-- -->Long Context</span><span class="page__taxonomy-item">#<!-- -->High Throughput</span><span class="page__taxonomy-item">#<!-- -->FP8 Training</span><span class="page__taxonomy-item">#<!-- -->Instruction Following</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-21-mSCoRe_a_Multilingual_and_Scalable_Benchmark_for_Skill-based_Commonsense_Reasoning/">[논문리뷰] mSCoRe: a Multilingual and Scalable Benchmark for Skill-based Commonsense Reasoning</a></h2><div class="archive__item-excerpt">anoperson이 [arXiv]에 게시한 &#x27;mSCoRe: a Multilingual and Scalable Benchmark for Skill-based Commonsense Reasoning&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-21 13:15:28+0900">2025년 8월 21일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Multilingual Benchmark</span><span class="page__taxonomy-item">#<!-- -->Commonsense Reasoning</span><span class="page__taxonomy-item">#<!-- -->LLM Evaluation</span><span class="page__taxonomy-item">#<!-- -->Reasoning Taxonomy</span><span class="page__taxonomy-item">#<!-- -->Benchmark Scaling</span><span class="page__taxonomy-item">#<!-- -->Data Synthesis</span><span class="page__taxonomy-item">#<!-- -->Cultural Nuances</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-21-MeshCoder_LLM-Powered_Structured_Mesh_Code_Generation_from_Point_Clouds/">[논문리뷰] MeshCoder: LLM-Powered Structured Mesh Code Generation from Point Clouds</a></h2><div class="archive__item-excerpt">Jiangmiao이 [arXiv]에 게시한 &#x27;MeshCoder: LLM-Powered Structured Mesh Code Generation from Point Clouds&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-21 13:15:28+0900">2025년 8월 21일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLM</span><span class="page__taxonomy-item">#<!-- -->Point Clouds</span><span class="page__taxonomy-item">#<!-- -->3D Reconstruction</span><span class="page__taxonomy-item">#<!-- -->Structured Mesh</span><span class="page__taxonomy-item">#<!-- -->Blender Python</span><span class="page__taxonomy-item">#<!-- -->Shape Editing</span><span class="page__taxonomy-item">#<!-- -->Part-based Representation</span><span class="page__taxonomy-item">#<!-- -->Large Language Model</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-21-MCP-Universe_Benchmarking_Large_Language_Models_with_Real-World_Model_Context_Protocol_Servers/">[논문리뷰] MCP-Universe: Benchmarking Large Language Models with Real-World Model Context Protocol Servers</a></h2><div class="archive__item-excerpt">Prathyusha Jwalapuram이 [arXiv]에 게시한 &#x27;MCP-Universe: Benchmarking Large Language Models with Real-World Model Context Protocol Servers&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-21 13:15:28+0900">2025년 8월 21일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Benchmarking</span><span class="page__taxonomy-item">#<!-- -->Model Context Protocol</span><span class="page__taxonomy-item">#<!-- -->Tool Use</span><span class="page__taxonomy-item">#<!-- -->Real-World Applications</span><span class="page__taxonomy-item">#<!-- -->Agent Evaluation</span><span class="page__taxonomy-item">#<!-- -->Long Context</span><span class="page__taxonomy-item">#<!-- -->Unknown Tools</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-21-Local_Scale_Equivariance_with_Latent_Deep_Equilibrium_Canonicalizer/">[논문리뷰] Local Scale Equivariance with Latent Deep Equilibrium Canonicalizer</a></h2><div class="archive__item-excerpt">Jeremiah Jiang이 [arXiv]에 게시한 &#x27;Local Scale Equivariance with Latent Deep Equilibrium Canonicalizer&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-21 13:15:28+0900">2025년 8월 21일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Scale Equivariance</span><span class="page__taxonomy-item">#<!-- -->Deep Equilibrium Models</span><span class="page__taxonomy-item">#<!-- -->Canonicalization</span><span class="page__taxonomy-item">#<!-- -->Computer Vision</span><span class="page__taxonomy-item">#<!-- -->Image Classification</span><span class="page__taxonomy-item">#<!-- -->Semantic Segmentation</span><span class="page__taxonomy-item">#<!-- -->Latent Representation</span><span class="page__taxonomy-item">#<!-- -->Monotone Scaling</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-21-Leuvenshtein_Efficient_FHE-based_Edit_Distance_Computation_with_Single_Bootstrap_per_Cell/">[논문리뷰] Leuvenshtein: Efficient FHE-based Edit Distance Computation with Single Bootstrap per Cell</a></h2><div class="archive__item-excerpt">Ingrid Verbauwhede이 [arXiv]에 게시한 &#x27;Leuvenshtein: Efficient FHE-based Edit Distance Computation with Single Bootstrap per Cell&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-21 13:15:28+0900">2025년 8월 21일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Fully Homomorphic Encryption (FHE)</span><span class="page__taxonomy-item">#<!-- -->TFHE</span><span class="page__taxonomy-item">#<!-- -->Levenshtein Distance</span><span class="page__taxonomy-item">#<!-- -->Programmable Bootstrapping (PBS)</span><span class="page__taxonomy-item">#<!-- -->Privacy-Preserving Computation</span><span class="page__taxonomy-item">#<!-- -->String Similarity</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-21-FutureX_An_Advanced_Live_Benchmark_for_LLM_Agents_in_Future_Prediction/">[논문리뷰] FutureX: An Advanced Live Benchmark for LLM Agents in Future Prediction</a></h2><div class="archive__item-excerpt">tianlecai이 [arXiv]에 게시한 &#x27;FutureX: An Advanced Live Benchmark for LLM Agents in Future Prediction&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-21 13:15:28+0900">2025년 8월 21일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLM Agents</span><span class="page__taxonomy-item">#<!-- -->Future Prediction</span><span class="page__taxonomy-item">#<!-- -->Live Benchmark</span><span class="page__taxonomy-item">#<!-- -->Dynamic Evaluation</span><span class="page__taxonomy-item">#<!-- -->Data Contamination</span><span class="page__taxonomy-item">#<!-- -->Tool Use</span><span class="page__taxonomy-item">#<!-- -->Web Search</span><span class="page__taxonomy-item">#<!-- -->Financial Forecasting</span><span class="page__taxonomy-item">#<!-- -->Misinformation</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-21-From_Scores_to_Skills_A_Cognitive_Diagnosis_Framework_for_Evaluating_Financial_Large_Language_Models/">[논문리뷰] From Scores to Skills: A Cognitive Diagnosis Framework for Evaluating Financial Large Language Models</a></h2><div class="archive__item-excerpt">Ziyan Kuang이 [arXiv]에 게시한 &#x27;From Scores to Skills: A Cognitive Diagnosis Framework for Evaluating Financial Large Language Models&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-21 13:15:28+0900">2025년 8월 21일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Financial LLMs</span><span class="page__taxonomy-item">#<!-- -->Cognitive Diagnosis Model</span><span class="page__taxonomy-item">#<!-- -->LLM Evaluation</span><span class="page__taxonomy-item">#<!-- -->Knowledge Assessment</span><span class="page__taxonomy-item">#<!-- -->Matrix Factorization</span><span class="page__taxonomy-item">#<!-- -->CPA-QKA</span><span class="page__taxonomy-item">#<!-- -->Interpretability</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-21-From_AI_for_Science_to_Agentic_Science_A_Survey_on_Autonomous_Scientific_Discovery/">[논문리뷰] From AI for Science to Agentic Science: A Survey on Autonomous Scientific Discovery</a></h2><div class="archive__item-excerpt">zijieqiu이 [arXiv]에 게시한 &#x27;From AI for Science to Agentic Science: A Survey on Autonomous Scientific Discovery&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-21 13:15:28+0900">2025년 8월 21일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Agentic AI</span><span class="page__taxonomy-item">#<!-- -->Autonomous Scientific Discovery</span><span class="page__taxonomy-item">#<!-- -->AI for Science</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Multi-agent Systems</span><span class="page__taxonomy-item">#<!-- -->Scientific Workflow Automation</span><span class="page__taxonomy-item">#<!-- -->Natural Sciences</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-21-DuPO_Enabling_Reliable_LLM_Self-Verification_via_Dual_Preference_Optimization/">[논문리뷰] DuPO: Enabling Reliable LLM Self-Verification via Dual Preference Optimization</a></h2><div class="archive__item-excerpt">Yu Lu이 [arXiv]에 게시한 &#x27;DuPO: Enabling Reliable LLM Self-Verification via Dual Preference Optimization&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-21 13:15:28+0900">2025년 8월 21일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLM Optimization</span><span class="page__taxonomy-item">#<!-- -->Self-Verification</span><span class="page__taxonomy-item">#<!-- -->Dual Learning</span><span class="page__taxonomy-item">#<!-- -->Preference Optimization</span><span class="page__taxonomy-item">#<!-- -->Self-Supervised Learning</span><span class="page__taxonomy-item">#<!-- -->Mathematical Reasoning</span><span class="page__taxonomy-item">#<!-- -->Multilingual Translation</span><span class="page__taxonomy-item">#<!-- -->RLHF</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-20-ZARA_Zero-shot_Motion_Time-Series_Analysis_via_Knowledge_and_Retrieval_Driven_LLM_Agents/">[논문리뷰] ZARA: Zero-shot Motion Time-Series Analysis via Knowledge and Retrieval Driven LLM Agents</a></h2><div class="archive__item-excerpt">Flora D. Salim이 [arXiv]에 게시한 &#x27;ZARA: Zero-shot Motion Time-Series Analysis via Knowledge and Retrieval Driven LLM Agents&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-20 13:26:54+0900">2025년 8월 20일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Zero-shot HAR</span><span class="page__taxonomy-item">#<!-- -->LLM Agents</span><span class="page__taxonomy-item">#<!-- -->Time-Series Analysis</span><span class="page__taxonomy-item">#<!-- -->Knowledge Base</span><span class="page__taxonomy-item">#<!-- -->Retrieval-Augmented Generation</span><span class="page__taxonomy-item">#<!-- -->Multi-sensor Fusion</span><span class="page__taxonomy-item">#<!-- -->Interpretability</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-20-Training-Free_Text-Guided_Color_Editing_with_Multi-Modal_Diffusion_Transformer/">[논문리뷰] Training-Free Text-Guided Color Editing with Multi-Modal Diffusion Transformer</a></h2><div class="archive__item-excerpt">Deyu Zhou이 [arXiv]에 게시한 &#x27;Training-Free Text-Guided Color Editing with Multi-Modal Diffusion Transformer&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-20 13:26:54+0900">2025년 8월 20일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Text-Guided Editing</span><span class="page__taxonomy-item">#<!-- -->Color Editing</span><span class="page__taxonomy-item">#<!-- -->Diffusion Transformers</span><span class="page__taxonomy-item">#<!-- -->Training-Free</span><span class="page__taxonomy-item">#<!-- -->Multi-Modal AI</span><span class="page__taxonomy-item">#<!-- -->Attention Control</span><span class="page__taxonomy-item">#<!-- -->Image Manipulation</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-20-TempFlow-GRPO_When_Timing_Matters_for_GRPO_in_Flow_Models/">[논문리뷰] TempFlow-GRPO: When Timing Matters for GRPO in Flow Models</a></h2><div class="archive__item-excerpt">Jian Yang이 [arXiv]에 게시한 &#x27;TempFlow-GRPO: When Timing Matters for GRPO in Flow Models&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-20 13:26:54+0900">2025년 8월 20일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Flow Matching</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Human Preference Alignment</span><span class="page__taxonomy-item">#<!-- -->GRPO</span><span class="page__taxonomy-item">#<!-- -->Temporal Credit Assignment</span><span class="page__taxonomy-item">#<!-- -->Generative AI</span><span class="page__taxonomy-item">#<!-- -->Text-to-Image</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-20-Semantic_IDs_for_Joint_Generative_Search_and_Recommendation/">[논문리뷰] Semantic IDs for Joint Generative Search and Recommendation</a></h2><div class="archive__item-excerpt">Enrico Palumbo이 [arXiv]에 게시한 &#x27;Semantic IDs for Joint Generative Search and Recommendation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-20 13:26:54+0900">2025년 8월 20일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Generative Models</span><span class="page__taxonomy-item">#<!-- -->Search and Recommendation</span><span class="page__taxonomy-item">#<!-- -->Semantic IDs</span><span class="page__taxonomy-item">#<!-- -->Bi-Encoder</span><span class="page__taxonomy-item">#<!-- -->Quantization</span><span class="page__taxonomy-item">#<!-- -->Multi-Task Learning</span><span class="page__taxonomy-item">#<!-- -->Retrieval Augmented Generation</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-20-Radiance_Fields_in_XR_A_Survey_on_How_Radiance_Fields_are_Envisioned_and_Addressed_for_XR_Research/">[논문리뷰] Radiance Fields in XR: A Survey on How Radiance Fields are Envisioned and Addressed for XR Research</a></h2><div class="archive__item-excerpt">Susanne Schmidt이 [arXiv]에 게시한 &#x27;Radiance Fields in XR: A Survey on How Radiance Fields are Envisioned and Addressed for XR Research&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-20 13:26:54+0900">2025년 8월 20일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Radiance Fields</span><span class="page__taxonomy-item">#<!-- -->XR</span><span class="page__taxonomy-item">#<!-- -->NeRF</span><span class="page__taxonomy-item">#<!-- -->3D Gaussian Splatting</span><span class="page__taxonomy-item">#<!-- -->View Synthesis</span><span class="page__taxonomy-item">#<!-- -->Systematic Review</span><span class="page__taxonomy-item">#<!-- -->Immersive Technology</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-20-Prompt_Orchestration_Markup_Language/">[논문리뷰] Prompt Orchestration Markup Language</a></h2><div class="archive__item-excerpt">Yuqing Yang이 [arXiv]에 게시한 &#x27;Prompt Orchestration Markup Language&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-20 13:26:54+0900">2025년 8월 20일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Prompt Engineering</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Markup Language</span><span class="page__taxonomy-item">#<!-- -->Structured Prompting</span><span class="page__taxonomy-item">#<!-- -->IDE Support</span><span class="page__taxonomy-item">#<!-- -->Multimodal Data</span><span class="page__taxonomy-item">#<!-- -->Styling System</span><span class="page__taxonomy-item">#<!-- -->Development Toolkit</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-20-OmniTry_Virtual_Try-On_Anything_without_Masks/">[논문리뷰] OmniTry: Virtual Try-On Anything without Masks</a></h2><div class="archive__item-excerpt">Xiaoduan Feng이 [arXiv]에 게시한 &#x27;OmniTry: Virtual Try-On Anything without Masks&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-20 13:26:54+0900">2025년 8월 20일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Virtual Try-On</span><span class="page__taxonomy-item">#<!-- -->Diffusion Model</span><span class="page__taxonomy-item">#<!-- -->Mask-Free</span><span class="page__taxonomy-item">#<!-- -->Image Inpainting</span><span class="page__taxonomy-item">#<!-- -->ID Consistency</span><span class="page__taxonomy-item">#<!-- -->Wearable Objects</span><span class="page__taxonomy-item">#<!-- -->Generative AI</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-20-MultiRef_Controllable_Image_Generation_with_Multiple_Visual_References/">[논문리뷰] MultiRef: Controllable Image Generation with Multiple Visual References</a></h2><div class="archive__item-excerpt">Shiyun Lang이 [arXiv]에 게시한 &#x27;MultiRef: Controllable Image Generation with Multiple Visual References&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-20 13:26:54+0900">2025년 8월 20일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Controllable Image Generation</span><span class="page__taxonomy-item">#<!-- -->Multi-modal Generation</span><span class="page__taxonomy-item">#<!-- -->Visual References</span><span class="page__taxonomy-item">#<!-- -->Image-to-Image</span><span class="page__taxonomy-item">#<!-- -->Benchmark</span><span class="page__taxonomy-item">#<!-- -->Dataset</span><span class="page__taxonomy-item">#<!-- -->MLLM-as-a-Judge</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-20-Motion2Motion_Cross-topology_Motion_Transfer_with_Sparse_Correspondence/">[논문리뷰] Motion2Motion: Cross-topology Motion Transfer with Sparse Correspondence</a></h2><div class="archive__item-excerpt">Xin Chen이 [arXiv]에 게시한 &#x27;Motion2Motion: Cross-topology Motion Transfer with Sparse Correspondence&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-20 13:26:54+0900">2025년 8월 20일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Motion Transfer</span><span class="page__taxonomy-item">#<!-- -->Cross-topology</span><span class="page__taxonomy-item">#<!-- -->Sparse Correspondence</span><span class="page__taxonomy-item">#<!-- -->Motion Matching</span><span class="page__taxonomy-item">#<!-- -->Animation</span><span class="page__taxonomy-item">#<!-- -->Training-free</span><span class="page__taxonomy-item">#<!-- -->Few-shot Learning</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-20-MMAU-Pro_A_Challenging_and_Comprehensive_Benchmark_for_Holistic_Evaluation_of_Audio_General_Intelligence/">[논문리뷰] MMAU-Pro: A Challenging and Comprehensive Benchmark for Holistic Evaluation of Audio General Intelligence</a></h2><div class="archive__item-excerpt">Fernando López이 [arXiv]에 게시한 &#x27;MMAU-Pro: A Challenging and Comprehensive Benchmark for Holistic Evaluation of Audio General Intelligence&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-20 13:26:54+0900">2025년 8월 20일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Audio Intelligence</span><span class="page__taxonomy-item">#<!-- -->Multimodal AI</span><span class="page__taxonomy-item">#<!-- -->Benchmark</span><span class="page__taxonomy-item">#<!-- -->Audio-Language Models</span><span class="page__taxonomy-item">#<!-- -->Holistic Evaluation</span><span class="page__taxonomy-item">#<!-- -->Reasoning</span><span class="page__taxonomy-item">#<!-- -->Long-Form Audio</span><span class="page__taxonomy-item">#<!-- -->Multicultural Music</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-20-MM-BrowseComp_A_Comprehensive_Benchmark_for_Multimodal_Browsing_Agents/">[논문리뷰] MM-BrowseComp: A Comprehensive Benchmark for Multimodal Browsing Agents</a></h2><div class="archive__item-excerpt">Jun Dong이 [arXiv]에 게시한 &#x27;MM-BrowseComp: A Comprehensive Benchmark for Multimodal Browsing Agents&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-20 13:26:54+0900">2025년 8월 20일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Multimodal Browsing</span><span class="page__taxonomy-item">#<!-- -->AI Agents</span><span class="page__taxonomy-item">#<!-- -->Benchmark</span><span class="page__taxonomy-item">#<!-- -->Vision-Language Models</span><span class="page__taxonomy-item">#<!-- -->Reasoning</span><span class="page__taxonomy-item">#<!-- -->Tool Use</span><span class="page__taxonomy-item">#<!-- -->Deep Search</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-20-Mind_the_Generation_Process_Fine-Grained_Confidence_Estimation_During_LLM_Generation/">[논문리뷰] Mind the Generation Process: Fine-Grained Confidence Estimation During LLM Generation</a></h2><div class="archive__item-excerpt">Xinyi Wang이 [arXiv]에 게시한 &#x27;Mind the Generation Process: Fine-Grained Confidence Estimation During LLM Generation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-20 13:26:54+0900">2025년 8월 20일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLMs</span><span class="page__taxonomy-item">#<!-- -->Confidence Estimation</span><span class="page__taxonomy-item">#<!-- -->Fine-Grained</span><span class="page__taxonomy-item">#<!-- -->Generation Process</span><span class="page__taxonomy-item">#<!-- -->Calibration</span><span class="page__taxonomy-item">#<!-- -->Monte Carlo Sampling</span><span class="page__taxonomy-item">#<!-- -->Backward Confidence Integration</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-20-MedSAMix_A_Training-Free_Model_Merging_Approach_for_Medical_Image_Segmentation/">[논문리뷰] MedSAMix: A Training-Free Model Merging Approach for Medical Image Segmentation</a></h2><div class="archive__item-excerpt">Jonas Geiping이 [arXiv]에 게시한 &#x27;MedSAMix: A Training-Free Model Merging Approach for Medical Image Segmentation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-20 13:26:54+0900">2025년 8월 20일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Medical Image Segmentation</span><span class="page__taxonomy-item">#<!-- -->Model Merging</span><span class="page__taxonomy-item">#<!-- -->Training-Free</span><span class="page__taxonomy-item">#<!-- -->SAM</span><span class="page__taxonomy-item">#<!-- -->Generalization</span><span class="page__taxonomy-item">#<!-- -->Zero-Order Optimization</span><span class="page__taxonomy-item">#<!-- -->Bayesian Optimization</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-20-LongSplat_Robust_Unposed_3D_Gaussian_Splatting_for_Casual_Long_Videos/">[논문리뷰] LongSplat: Robust Unposed 3D Gaussian Splatting for Casual Long Videos</a></h2><div class="archive__item-excerpt">Yen-Yu Lin이 [arXiv]에 게시한 &#x27;LongSplat: Robust Unposed 3D Gaussian Splatting for Casual Long Videos&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-20 13:26:54+0900">2025년 8월 20일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Novel View Synthesis</span><span class="page__taxonomy-item">#<!-- -->3D Gaussian Splatting</span><span class="page__taxonomy-item">#<!-- -->Unposed Reconstruction</span><span class="page__taxonomy-item">#<!-- -->Camera Pose Estimation</span><span class="page__taxonomy-item">#<!-- -->Incremental Optimization</span><span class="page__taxonomy-item">#<!-- -->Octree</span><span class="page__taxonomy-item">#<!-- -->Long Videos</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-20-Leveraging_Large_Language_Models_for_Predictive_Analysis_of_Human_Misery/">[논문리뷰] Leveraging Large Language Models for Predictive Analysis of Human Misery</a></h2><div class="archive__item-excerpt">Abhilash Nandy이 [arXiv]에 게시한 &#x27;Leveraging Large Language Models for Predictive Analysis of Human Misery&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-20 13:26:54+0900">2025년 8월 20일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Large Language Models (LLMs)</span><span class="page__taxonomy-item">#<!-- -->Affective Computing</span><span class="page__taxonomy-item">#<!-- -->Misery Score Prediction</span><span class="page__taxonomy-item">#<!-- -->Prompt Engineering</span><span class="page__taxonomy-item">#<!-- -->Few-shot Learning</span><span class="page__taxonomy-item">#<!-- -->Gamified Evaluation</span><span class="page__taxonomy-item">#<!-- -->Feedback-driven Adaptation</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-20-Evaluating_Podcast_Recommendations_with_Profile-Aware_LLM-as-a-Judge/">[논문리뷰] Evaluating Podcast Recommendations with Profile-Aware LLM-as-a-Judge</a></h2><div class="archive__item-excerpt">Alice Wang이 [arXiv]에 게시한 &#x27;Evaluating Podcast Recommendations with Profile-Aware LLM-as-a-Judge&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-20 13:26:54+0900">2025년 8월 20일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Podcast Recommendation</span><span class="page__taxonomy-item">#<!-- -->LLM-as-a-Judge</span><span class="page__taxonomy-item">#<!-- -->Offline Evaluation</span><span class="page__taxonomy-item">#<!-- -->User Profiling</span><span class="page__taxonomy-item">#<!-- -->Recommender Systems</span><span class="page__taxonomy-item">#<!-- -->Natural Language Processing</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-20-Embodied-R1_Reinforced_Embodied_Reasoning_for_General_Robotic_Manipulation/">[논문리뷰] Embodied-R1: Reinforced Embodied Reasoning for General Robotic Manipulation</a></h2><div class="archive__item-excerpt">Fei Ni이 [arXiv]에 게시한 &#x27;Embodied-R1: Reinforced Embodied Reasoning for General Robotic Manipulation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-20 13:26:54+0900">2025년 8월 20일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Embodied AI</span><span class="page__taxonomy-item">#<!-- -->Robotic Manipulation</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Vision-Language Model</span><span class="page__taxonomy-item">#<!-- -->Pointing</span><span class="page__taxonomy-item">#<!-- -->Zero-shot Generalization</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-20-Describe_What_You_See_with_Multimodal_Large_Language_Models_to_Enhance_Video_Recommendations/">[논문리뷰] Describe What You See with Multimodal Large Language Models to Enhance Video Recommendations</a></h2><div class="archive__item-excerpt">Mounia Lalmas이 [arXiv]에 게시한 &#x27;Describe What You See with Multimodal Large Language Models to Enhance Video Recommendations&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-20 13:26:54+0900">2025년 8월 20일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Multimodal Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Video Recommendation</span><span class="page__taxonomy-item">#<!-- -->Zero-Shot Learning</span><span class="page__taxonomy-item">#<!-- -->Content-Based Filtering</span><span class="page__taxonomy-item">#<!-- -->Natural Language Processing</span><span class="page__taxonomy-item">#<!-- -->Foundation Models</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-20-CorrSteer_Steering_Improves_Task_Performance_and_Safety_in_LLMs_through_Correlation-based_Sparse_Autoencoder_Feature_Selection/">[논문리뷰] CorrSteer: Steering Improves Task Performance and Safety in LLMs through Correlation-based Sparse Autoencoder Feature Selection</a></h2><div class="archive__item-excerpt">Adriano Koshiyama이 [arXiv]에 게시한 &#x27;CorrSteer: Steering Improves Task Performance and Safety in LLMs through Correlation-based Sparse Autoencoder Feature Selection&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-20 13:26:54+0900">2025년 8월 20일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Sparse Autoencoders</span><span class="page__taxonomy-item">#<!-- -->LLM Steering</span><span class="page__taxonomy-item">#<!-- -->Feature Selection</span><span class="page__taxonomy-item">#<!-- -->Correlation Analysis</span><span class="page__taxonomy-item">#<!-- -->AI Safety</span><span class="page__taxonomy-item">#<!-- -->Bias Mitigation</span><span class="page__taxonomy-item">#<!-- -->Mechanistic Interpretability</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-20-Copyright_Protection_for_Large_Language_Models_A_Survey_of_Methods_Challenges_and_Trends/">[논문리뷰] Copyright Protection for Large Language Models: A Survey of Methods, Challenges, and Trends</a></h2><div class="archive__item-excerpt">Xixiang Zhao이 [arXiv]에 게시한 &#x27;Copyright Protection for Large Language Models: A Survey of Methods, Challenges, and Trends&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-20 13:26:54+0900">2025년 8월 20일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLM Copyright Protection</span><span class="page__taxonomy-item">#<!-- -->Model Fingerprinting</span><span class="page__taxonomy-item">#<!-- -->Text Watermarking</span><span class="page__taxonomy-item">#<!-- -->Invasive Fingerprinting</span><span class="page__taxonomy-item">#<!-- -->Intrinsic Fingerprinting</span><span class="page__taxonomy-item">#<!-- -->Intellectual Property</span><span class="page__taxonomy-item">#<!-- -->Digital Rights Management</span><span class="page__taxonomy-item">#<!-- -->Backdoor Watermarking</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-20-Chain-of-Agents_End-to-End_Agent_Foundation_Models_via_Multi-Agent_Distillation_and_Agentic_RL/">[논문리뷰] Chain-of-Agents: End-to-End Agent Foundation Models via Multi-Agent Distillation and Agentic RL</a></h2><div class="archive__item-excerpt">Liam-Liu이 [arXiv]에 게시한 &#x27;Chain-of-Agents: End-to-End Agent Foundation Models via Multi-Agent Distillation and Agentic RL&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-20 13:26:54+0900">2025년 8월 20일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Chain-of-Agents</span><span class="page__taxonomy-item">#<!-- -->Agent Foundation Models</span><span class="page__taxonomy-item">#<!-- -->Multi-Agent Systems</span><span class="page__taxonomy-item">#<!-- -->Tool-Integrated Reasoning</span><span class="page__taxonomy-item">#<!-- -->Multi-agent Distillation</span><span class="page__taxonomy-item">#<!-- -->Agentic Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->LLMs</span><span class="page__taxonomy-item">#<!-- -->End-to-End Learning</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-20-CAMAR_Continuous_Actions_Multi-Agent_Routing/">[논문리뷰] CAMAR: Continuous Actions Multi-Agent Routing</a></h2><div class="archive__item-excerpt">Alexey Skrynnik이 [arXiv]에 게시한 &#x27;CAMAR: Continuous Actions Multi-Agent Routing&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-20 13:26:54+0900">2025년 8월 20일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Multi-Agent Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Continuous Control</span><span class="page__taxonomy-item">#<!-- -->Pathfinding</span><span class="page__taxonomy-item">#<!-- -->MARL Benchmark</span><span class="page__taxonomy-item">#<!-- -->GPU Acceleration</span><span class="page__taxonomy-item">#<!-- -->Robotics Simulation</span><span class="page__taxonomy-item">#<!-- -->Scalability</span><span class="page__taxonomy-item">#<!-- -->Heterogeneous Agents</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-20-Beyond_Human_Judgment_A_Bayesian_Evaluation_of_LLMs_Moral_Values_Understanding/">[논문리뷰] Beyond Human Judgment: A Bayesian Evaluation of LLMs&#x27; Moral Values Understanding</a></h2><div class="archive__item-excerpt">Alina Landowska이 [arXiv]에 게시한 &#x27;Beyond Human Judgment: A Bayesian Evaluation of LLMs&#x27; Moral Values Understanding&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-20 13:26:54+0900">2025년 8월 20일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Moral Reasoning</span><span class="page__taxonomy-item">#<!-- -->Bayesian Evaluation</span><span class="page__taxonomy-item">#<!-- -->Uncertainty Quantification</span><span class="page__taxonomy-item">#<!-- -->Natural Language Processing</span><span class="page__taxonomy-item">#<!-- -->Soft Labels</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-20-A_Stitch_in_Time_Saves_Nine_Proactive_Self-Refinement_for_Language_Models/">[논문리뷰] A Stitch in Time Saves Nine: Proactive Self-Refinement for Language Models</a></h2><div class="archive__item-excerpt">Zishang Jiang이 [arXiv]에 게시한 &#x27;A Stitch in Time Saves Nine: Proactive Self-Refinement for Language Models&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-20 13:26:54+0900">2025년 8월 20일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Self-Refinement</span><span class="page__taxonomy-item">#<!-- -->Language Models</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Proactive AI</span><span class="page__taxonomy-item">#<!-- -->Generation Process</span><span class="page__taxonomy-item">#<!-- -->Markov Decision Process</span><span class="page__taxonomy-item">#<!-- -->Adaptive Learning</span><span class="page__taxonomy-item">#<!-- -->LLM Efficiency</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-20-Advances_in_Speech_Separation_Techniques_Challenges_and_Future_Trends/">[논문리뷰] Advances in Speech Separation: Techniques, Challenges, and Future Trends</a></h2><div class="archive__item-excerpt">Zhuo Chen이 [arXiv]에 게시한 &#x27;Advances in Speech Separation: Techniques, Challenges, and Future Trends&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-20 13:26:54+0900">2025년 8월 20일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Speech Separation</span><span class="page__taxonomy-item">#<!-- -->Deep Neural Networks</span><span class="page__taxonomy-item">#<!-- -->Cocktail Party Problem</span><span class="page__taxonomy-item">#<!-- -->Transformer Architecture</span><span class="page__taxonomy-item">#<!-- -->Unsupervised Learning</span><span class="page__taxonomy-item">#<!-- -->Supervised Learning</span><span class="page__taxonomy-item">#<!-- -->Evaluation Metrics</span><span class="page__taxonomy-item">#<!-- -->Datasets</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-19-When_Punctuation_Matters_A_Large-Scale_Comparison_of_Prompt_Robustness_Methods_for_LLMs/">[논문리뷰] When Punctuation Matters: A Large-Scale Comparison of Prompt Robustness Methods for LLMs</a></h2><div class="archive__item-excerpt">Elena Tutubalina이 [arXiv]에 게시한 &#x27;When Punctuation Matters: A Large-Scale Comparison of Prompt Robustness Methods for LLMs&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-19 13:15:01+0900">2025년 8월 19일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLM Robustness</span><span class="page__taxonomy-item">#<!-- -->Prompt Sensitivity</span><span class="page__taxonomy-item">#<!-- -->In-Context Learning</span><span class="page__taxonomy-item">#<!-- -->Fine-Tuning</span><span class="page__taxonomy-item">#<!-- -->Batch Calibration</span><span class="page__taxonomy-item">#<!-- -->Template Ensembles</span><span class="page__taxonomy-item">#<!-- -->Distribution Shift</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-19-Speed_Always_Wins_A_Survey_on_Efficient_Architectures_for_Large_Language_Models/">[논문리뷰] Speed Always Wins: A Survey on Efficient Architectures for Large Language Models</a></h2><div class="archive__item-excerpt">Jusen Du이 [arXiv]에 게시한 &#x27;Speed Always Wins: A Survey on Efficient Architectures for Large Language Models&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-19 13:15:01+0900">2025년 8월 19일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Efficient Architectures</span><span class="page__taxonomy-item">#<!-- -->Transformer Optimization</span><span class="page__taxonomy-item">#<!-- -->Linear Attention</span><span class="page__taxonomy-item">#<!-- -->State Space Models</span><span class="page__taxonomy-item">#<!-- -->Mixture-of-Experts</span><span class="page__taxonomy-item">#<!-- -->Sparse Attention</span><span class="page__taxonomy-item">#<!-- -->Diffusion LLMs</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-19-S2-Guidance_Stochastic_Self_Guidance_for_Training-Free_Enhancement_of_Diffusion_Models/">[논문리뷰] S^2-Guidance: Stochastic Self Guidance for Training-Free Enhancement of Diffusion Models</a></h2><div class="archive__item-excerpt">Meiqi Wu이 [arXiv]에 게시한 &#x27;S^2-Guidance: Stochastic Self Guidance for Training-Free Enhancement of Diffusion Models&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-19 13:15:01+0900">2025년 8월 19일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->Classifier-free Guidance</span><span class="page__taxonomy-item">#<!-- -->Self-Guidance</span><span class="page__taxonomy-item">#<!-- -->Training-Free</span><span class="page__taxonomy-item">#<!-- -->Stochastic Block-Dropping</span><span class="page__taxonomy-item">#<!-- -->Generative Models</span><span class="page__taxonomy-item">#<!-- -->Text-to-Image</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-19-Representing_Speech_Through_Autoregressive_Prediction_of_Cochlear_Tokens/">[논문리뷰] Representing Speech Through Autoregressive Prediction of Cochlear Tokens</a></h2><div class="archive__item-excerpt">Daniel L. K. Yamins이 [arXiv]에 게시한 &#x27;Representing Speech Through Autoregressive Prediction of Cochlear Tokens&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-19 13:15:01+0900">2025년 8월 19일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Speech Representation Learning</span><span class="page__taxonomy-item">#<!-- -->Autoregressive Models</span><span class="page__taxonomy-item">#<!-- -->Cochlear Tokens</span><span class="page__taxonomy-item">#<!-- -->Biologically Inspired AI</span><span class="page__taxonomy-item">#<!-- -->Self-Supervised Learning</span><span class="page__taxonomy-item">#<!-- -->Audio Processing</span><span class="page__taxonomy-item">#<!-- -->Transformer Networks</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-19-Reinforcement_Learning_with_Rubric_Anchors/">[논문리뷰] Reinforcement Learning with Rubric Anchors</a></h2><div class="archive__item-excerpt">Haokai Xu이 [arXiv]에 게시한 &#x27;Reinforcement Learning with Rubric Anchors&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-19 13:15:01+0900">2025년 8월 19일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Rubric-based Reward</span><span class="page__taxonomy-item">#<!-- -->RLVR Extension</span><span class="page__taxonomy-item">#<!-- -->Human-centric AI</span><span class="page__taxonomy-item">#<!-- -->Controllable Generation</span><span class="page__taxonomy-item">#<!-- -->Reward Hacking Mitigation</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-19-Precise_Action-to-Video_Generation_Through_Visual_Action_Prompts/">[논문리뷰] Precise Action-to-Video Generation Through Visual Action Prompts</a></h2><div class="archive__item-excerpt">Minghan Qin이 [arXiv]에 게시한 &#x27;Precise Action-to-Video Generation Through Visual Action Prompts&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-19 13:15:01+0900">2025년 8월 19일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Action-to-Video Generation</span><span class="page__taxonomy-item">#<!-- -->Visual Action Prompts</span><span class="page__taxonomy-item">#<!-- -->Skeleton Representation</span><span class="page__taxonomy-item">#<!-- -->Human-Object Interaction</span><span class="page__taxonomy-item">#<!-- -->Robotic Manipulation</span><span class="page__taxonomy-item">#<!-- -->Cross-Domain Transfer</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-19-Ovis2.5_Technical_Report">[논문리뷰] Ovis2.5 Technical Report</a></h2><div class="archive__item-excerpt">Yang Li이 [arXiv]에 게시한 &#x27;Ovis2.5 Technical Report&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-19 13:15:01+0900">2025년 8월 19일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Multimodal LLMs</span><span class="page__taxonomy-item">#<!-- -->Native Resolution Vision</span><span class="page__taxonomy-item">#<!-- -->Deep Reasoning</span><span class="page__taxonomy-item">#<!-- -->Chart Analysis</span><span class="page__taxonomy-item">#<!-- -->OCR</span><span class="page__taxonomy-item">#<!-- -->Visual Grounding</span><span class="page__taxonomy-item">#<!-- -->Training Efficiency</span><span class="page__taxonomy-item">#<!-- -->Preference Optimization</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-19-Next_Visual_Granularity_Generation/">[논문리뷰] Next Visual Granularity Generation</a></h2><div class="archive__item-excerpt">Kang Liao이 [arXiv]에 게시한 &#x27;Next Visual Granularity Generation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-19 13:15:01+0900">2025년 8월 19일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Image Generation</span><span class="page__taxonomy-item">#<!-- -->Granularity Control</span><span class="page__taxonomy-item">#<!-- -->Structured Representation</span><span class="page__taxonomy-item">#<!-- -->Hierarchical Generation</span><span class="page__taxonomy-item">#<!-- -->Coarse-to-fine</span><span class="page__taxonomy-item">#<!-- -->Visual Tokenization</span><span class="page__taxonomy-item">#<!-- -->Latent Space</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-19-Matrix-Game_2.0_An_Open-Source_Real-Time_and_Streaming_Interactive_World_Model">[논문리뷰] Matrix-Game 2.0: An Open-Source, Real-Time, and Streaming Interactive World Model</a></h2><div class="archive__item-excerpt">Yifan Zhang이 [arXiv]에 게시한 &#x27;Matrix-Game 2.0: An Open-Source, Real-Time, and Streaming Interactive World Model&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-19 13:15:01+0900">2025년 8월 19일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->World Model</span><span class="page__taxonomy-item">#<!-- -->Interactive Video Generation</span><span class="page__taxonomy-item">#<!-- -->Real-Time AI</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->Auto-Regressive Generation</span><span class="page__taxonomy-item">#<!-- -->Data Pipeline</span><span class="page__taxonomy-item">#<!-- -->Self-Forcing</span><span class="page__taxonomy-item">#<!-- -->KV Caching</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-19-Lumen_Consistent_Video_Relighting_and_Harmonious_Background_Replacement_with_Video_Generative_Models/">[논문리뷰] Lumen: Consistent Video Relighting and Harmonious Background Replacement with Video Generative Models</a></h2><div class="archive__item-excerpt">Zixiang Gao이 [arXiv]에 게시한 &#x27;Lumen: Consistent Video Relighting and Harmonious Background Replacement with Video Generative Models&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-19 13:15:01+0900">2025년 8월 19일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Video Relighting</span><span class="page__taxonomy-item">#<!-- -->Background Replacement</span><span class="page__taxonomy-item">#<!-- -->Generative Models</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->Temporal Consistency</span><span class="page__taxonomy-item">#<!-- -->Dataset Generation</span><span class="page__taxonomy-item">#<!-- -->Video Editing</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-19-Inverse-LLaVA_Eliminating_Alignment_Pre-training_Through_Text-to-Vision_Mapping/">[논문리뷰] Inverse-LLaVA: Eliminating Alignment Pre-training Through Text-to-Vision Mapping</a></h2><div class="archive__item-excerpt">Tyler Derr이 [arXiv]에 게시한 &#x27;Inverse-LLaVA: Eliminating Alignment Pre-training Through Text-to-Vision Mapping&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-19 13:15:01+0900">2025년 8월 19일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Multimodal Learning</span><span class="page__taxonomy-item">#<!-- -->Vision-Language Models</span><span class="page__taxonomy-item">#<!-- -->Alignment Pre-training</span><span class="page__taxonomy-item">#<!-- -->Text-to-Vision Mapping</span><span class="page__taxonomy-item">#<!-- -->Continuous Representations</span><span class="page__taxonomy-item">#<!-- -->Computational Efficiency</span><span class="page__taxonomy-item">#<!-- -->LLM</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-19-HeroBench_A_Benchmark_for_Long-Horizon_Planning_and_Structured_Reasoning_in_Virtual_Worlds/">[논문리뷰] HeroBench: A Benchmark for Long-Horizon Planning and Structured Reasoning in Virtual Worlds</a></h2><div class="archive__item-excerpt">Artyom Sorokin이 [arXiv]에 게시한 &#x27;HeroBench: A Benchmark for Long-Horizon Planning and Structured Reasoning in Virtual Worlds&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-19 13:15:01+0900">2025년 8월 19일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Long-Horizon Planning</span><span class="page__taxonomy-item">#<!-- -->Structured Reasoning</span><span class="page__taxonomy-item">#<!-- -->LLM Evaluation</span><span class="page__taxonomy-item">#<!-- -->Virtual Worlds</span><span class="page__taxonomy-item">#<!-- -->RPG</span><span class="page__taxonomy-item">#<!-- -->Benchmark</span><span class="page__taxonomy-item">#<!-- -->Agent Systems</span><span class="page__taxonomy-item">#<!-- -->Combat Simulation</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-19-Has_GPT-5_Achieved_Spatial_Intelligence_An_Empirical_Study/">[논문리뷰] Has GPT-5 Achieved Spatial Intelligence? An Empirical Study</a></h2><div class="archive__item-excerpt">Ruisi Wang이 [arXiv]에 게시한 &#x27;Has GPT-5 Achieved Spatial Intelligence? An Empirical Study&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-19 13:15:01+0900">2025년 8월 19일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Spatial Intelligence</span><span class="page__taxonomy-item">#<!-- -->Multimodal LLMs</span><span class="page__taxonomy-item">#<!-- -->Benchmark Evaluation</span><span class="page__taxonomy-item">#<!-- -->GPT-5</span><span class="page__taxonomy-item">#<!-- -->Cognitive AI</span><span class="page__taxonomy-item">#<!-- -->AGI</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-19-G-CUT3R_Guided_3D_Reconstruction_with_Camera_and_Depth_Prior_Integration/">[논문리뷰] G-CUT3R: Guided 3D Reconstruction with Camera and Depth Prior Integration</a></h2><div class="archive__item-excerpt">Evgeny Burnaev이 [arXiv]에 게시한 &#x27;G-CUT3R: Guided 3D Reconstruction with Camera and Depth Prior Integration&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-19 13:15:01+0900">2025년 8월 19일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->3D Reconstruction</span><span class="page__taxonomy-item">#<!-- -->Deep Learning</span><span class="page__taxonomy-item">#<!-- -->Multi-Modal Fusion</span><span class="page__taxonomy-item">#<!-- -->Camera Pose Estimation</span><span class="page__taxonomy-item">#<!-- -->Depth Estimation</span><span class="page__taxonomy-item">#<!-- -->Transformer Networks</span><span class="page__taxonomy-item">#<!-- -->Prior Information</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-19-ComoRAG_A_Cognitive-Inspired_Memory-Organized_RAG_for_Stateful_Long_Narrative_Reasoning/">[논문리뷰] ComoRAG: A Cognitive-Inspired Memory-Organized RAG for Stateful Long Narrative Reasoning</a></h2><div class="archive__item-excerpt">Yufeng Wang이 [arXiv]에 게시한 &#x27;ComoRAG: A Cognitive-Inspired Memory-Organized RAG for Stateful Long Narrative Reasoning&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-19 13:15:01+0900">2025년 8월 19일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Cognitive-Inspired RAG</span><span class="page__taxonomy-item">#<!-- -->Stateful Reasoning</span><span class="page__taxonomy-item">#<!-- -->Long Narrative Comprehension</span><span class="page__taxonomy-item">#<!-- -->Dynamic Memory</span><span class="page__taxonomy-item">#<!-- -->Metacognitive Regulation</span><span class="page__taxonomy-item">#<!-- -->Multi-step Retrieval</span><span class="page__taxonomy-item">#<!-- -->Hierarchical Knowledge Source</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-19-Beyond_Solving_Math_Quiz_Evaluating_the_Ability_of_Large_Reasoning_Models_to_Ask_for_Information/">[논문리뷰] Beyond Solving Math Quiz: Evaluating the Ability of Large Reasoning Models to Ask for Information</a></h2><div class="archive__item-excerpt">Xi Yang이 [arXiv]에 게시한 &#x27;Beyond Solving Math Quiz: Evaluating the Ability of Large Reasoning Models to Ask for Information&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-19 13:15:01+0900">2025년 8월 19일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Large Reasoning Models (LRMs)</span><span class="page__taxonomy-item">#<!-- -->Information Seeking</span><span class="page__taxonomy-item">#<!-- -->Incomplete Problems</span><span class="page__taxonomy-item">#<!-- -->Mathematical Reasoning</span><span class="page__taxonomy-item">#<!-- -->Supervised Fine-tuning (SFT)</span><span class="page__taxonomy-item">#<!-- -->Overthinking</span><span class="page__taxonomy-item">#<!-- -->Hallucination</span><span class="page__taxonomy-item">#<!-- -->CRITIC-math</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-19-4DNeX_Feed-Forward_4D_Generative_Modeling_Made_Easy/">[논문리뷰] 4DNeX: Feed-Forward 4D Generative Modeling Made Easy</a></h2><div class="archive__item-excerpt">Zeng Tao이 [arXiv]에 게시한 &#x27;4DNeX: Feed-Forward 4D Generative Modeling Made Easy&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-19 13:15:01+0900">2025년 8월 19일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->4D Generation</span><span class="page__taxonomy-item">#<!-- -->Dynamic 3D</span><span class="page__taxonomy-item">#<!-- -->Generative Models</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->Single Image Input</span><span class="page__taxonomy-item">#<!-- -->Video Synthesis</span><span class="page__taxonomy-item">#<!-- -->Point Clouds</span><span class="page__taxonomy-item">#<!-- -->Dataset</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-18-X-Node_Self-Explanation_is_All_We_Need/">[논문리뷰] X-Node: Self-Explanation is All We Need</a></h2><div class="archive__item-excerpt">Islem Rekik이 [arXiv]에 게시한 &#x27;X-Node: Self-Explanation is All We Need&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-18 13:14:38+0900">2025년 8월 18일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Graph Neural Networks</span><span class="page__taxonomy-item">#<!-- -->Explainable AI</span><span class="page__taxonomy-item">#<!-- -->Self-Explanation</span><span class="page__taxonomy-item">#<!-- -->Node Classification</span><span class="page__taxonomy-item">#<!-- -->Medical Imaging</span><span class="page__taxonomy-item">#<!-- -->Natural Language Processing</span><span class="page__taxonomy-item">#<!-- -->Interpretability</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-18-Thyme_Think_Beyond_Images/">[논문리뷰] Thyme: Think Beyond Images</a></h2><div class="archive__item-excerpt">Wei Chen이 [arXiv]에 게시한 &#x27;Thyme: Think Beyond Images&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-18 13:14:38+0900">2025년 8월 18일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Multimodal LLMs</span><span class="page__taxonomy-item">#<!-- -->Code Generation</span><span class="page__taxonomy-item">#<!-- -->Image Processing</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Supervised Fine-Tuning</span><span class="page__taxonomy-item">#<!-- -->Visual Reasoning</span><span class="page__taxonomy-item">#<!-- -->Sandbox</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-18-TexVerse_A_Universe_of_3D_Objects_with_High-Resolution_Textures/">[논문리뷰] TexVerse: A Universe of 3D Objects with High-Resolution Textures</a></h2><div class="archive__item-excerpt">Nan Cao이 [arXiv]에 게시한 &#x27;TexVerse: A Universe of 3D Objects with High-Resolution Textures&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-18 13:14:38+0900">2025년 8월 18일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->3D Dataset</span><span class="page__taxonomy-item">#<!-- -->High-Resolution Textures</span><span class="page__taxonomy-item">#<!-- -->Physically Based Rendering (PBR)</span><span class="page__taxonomy-item">#<!-- -->3D Animation</span><span class="page__taxonomy-item">#<!-- -->Data Curation</span><span class="page__taxonomy-item">#<!-- -->GPT-5 Annotations</span><span class="page__taxonomy-item">#<!-- -->Sketchfab</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-18-StyleMM_Stylized_3D_Morphable_Face_Model_via_Text-Driven_Aligned_Image_Translation/">[논문리뷰] StyleMM: Stylized 3D Morphable Face Model via Text-Driven Aligned Image Translation</a></h2><div class="archive__item-excerpt">Junyong Noh이 [arXiv]에 게시한 &#x27;StyleMM: Stylized 3D Morphable Face Model via Text-Driven Aligned Image Translation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-18 13:14:38+0900">2025년 8월 18일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->3D Morphable Model</span><span class="page__taxonomy-item">#<!-- -->Face Stylization</span><span class="page__taxonomy-item">#<!-- -->Text-to-Image Translation</span><span class="page__taxonomy-item">#<!-- -->Diffusion Model</span><span class="page__taxonomy-item">#<!-- -->Attribute Preservation</span><span class="page__taxonomy-item">#<!-- -->Generative AI</span><span class="page__taxonomy-item">#<!-- -->Computer Graphics</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-18-SSRL_Self-Search_Reinforcement_Learning/">[논문리뷰] SSRL: Self-Search Reinforcement Learning</a></h2><div class="archive__item-excerpt">Yanxu Chen이 [arXiv]에 게시한 &#x27;SSRL: Self-Search Reinforcement Learning&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-18 13:14:38+0900">2025년 8월 18일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Self-Search</span><span class="page__taxonomy-item">#<!-- -->Sim-to-Real Transfer</span><span class="page__taxonomy-item">#<!-- -->Agentic AI</span><span class="page__taxonomy-item">#<!-- -->Knowledge Retrieval</span><span class="page__taxonomy-item">#<!-- -->Reward Modeling</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-18-SPARSE_Data_Rich_Results_Few-Shot_Semi-Supervised_Learning_via_Class-Conditioned_Image_Translation/">[논문리뷰] SPARSE Data, Rich Results: Few-Shot Semi-Supervised Learning via Class-Conditioned Image Translation</a></h2><div class="archive__item-excerpt">Paolo Soda이 [arXiv]에 게시한 &#x27;SPARSE Data, Rich Results: Few-Shot Semi-Supervised Learning via Class-Conditioned Image Translation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-18 13:14:38+0900">2025년 8월 18일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Semi-supervised Learning</span><span class="page__taxonomy-item">#<!-- -->Few-shot Learning</span><span class="page__taxonomy-item">#<!-- -->Medical Imaging</span><span class="page__taxonomy-item">#<!-- -->GAN-based Methods</span><span class="page__taxonomy-item">#<!-- -->Image-to-image Translation</span><span class="page__taxonomy-item">#<!-- -->Pseudo-labeling</span><span class="page__taxonomy-item">#<!-- -->Ensemble Learning</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-18-PaperRegister_Boosting_Flexible-grained_Paper_Search_via_Hierarchical_Register_Indexing/">[논문리뷰] PaperRegister: Boosting Flexible-grained Paper Search via Hierarchical Register Indexing</a></h2><div class="archive__item-excerpt">Xianpei Han이 [arXiv]에 게시한 &#x27;PaperRegister: Boosting Flexible-grained Paper Search via Hierarchical Register Indexing&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-18 13:14:38+0900">2025년 8월 18일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->논문 검색</span><span class="page__taxonomy-item">#<!-- -->계층적 인덱싱</span><span class="page__taxonomy-item">#<!-- -->유연한 검색</span><span class="page__taxonomy-item">#<!-- -->대규모 언어 모델</span><span class="page__taxonomy-item">#<!-- -->정보 추출</span><span class="page__taxonomy-item">#<!-- -->뷰 인식</span><span class="page__taxonomy-item">#<!-- -->강화 학습</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-18-MAESTRO_Masked_AutoEncoders_for_Multimodal_Multitemporal_and_Multispectral_Earth_Observation_Data/">[논문리뷰] MAESTRO: Masked AutoEncoders for Multimodal, Multitemporal, and Multispectral Earth Observation Data</a></h2><div class="archive__item-excerpt">Nicolas Gonthier이 [arXiv]에 게시한 &#x27;MAESTRO: Masked AutoEncoders for Multimodal, Multitemporal, and Multispectral Earth Observation Data&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-18 13:14:38+0900">2025년 8월 18일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Self-supervised Learning</span><span class="page__taxonomy-item">#<!-- -->Masked Autoencoder</span><span class="page__taxonomy-item">#<!-- -->Earth Observation</span><span class="page__taxonomy-item">#<!-- -->Multimodal</span><span class="page__taxonomy-item">#<!-- -->Multitemporal</span><span class="page__taxonomy-item">#<!-- -->Multispectral</span><span class="page__taxonomy-item">#<!-- -->Fusion Strategies</span><span class="page__taxonomy-item">#<!-- -->Target Normalization</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-18-FantasyTalking2_Timestep-Layer_Adaptive_Preference_Optimization_for_Audio-Driven_Portrait_Animation/">[논문리뷰] FantasyTalking2: Timestep-Layer Adaptive Preference Optimization for Audio-Driven Portrait Animation</a></h2><div class="archive__item-excerpt">Mu Xu이 [arXiv]에 게시한 &#x27;FantasyTalking2: Timestep-Layer Adaptive Preference Optimization for Audio-Driven Portrait Animation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-18 13:14:38+0900">2025년 8월 18일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Audio-Driven Animation</span><span class="page__taxonomy-item">#<!-- -->Preference Optimization</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->Reward Modeling</span><span class="page__taxonomy-item">#<!-- -->Human Feedback</span><span class="page__taxonomy-item">#<!-- -->Multi-Objective Optimization</span><span class="page__taxonomy-item">#<!-- -->Timestep-Layer Adaptive</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-18-DINOv3/">[논문리뷰] DINOv3</a></h2><div class="archive__item-excerpt">Maxime Oquab이 [arXiv]에 게시한 &#x27;DINOv3&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-18 13:14:38+0900">2025년 8월 18일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Self-supervised Learning</span><span class="page__taxonomy-item">#<!-- -->Foundation Models</span><span class="page__taxonomy-item">#<!-- -->Vision Transformer</span><span class="page__taxonomy-item">#<!-- -->Dense Feature Maps</span><span class="page__taxonomy-item">#<!-- -->Gram Anchoring</span><span class="page__taxonomy-item">#<!-- -->Model Distillation</span><span class="page__taxonomy-item">#<!-- -->Geospatial AI</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-18-Controlling_Multimodal_LLMs_via_Reward-guided_Decoding/">[논문리뷰] Controlling Multimodal LLMs via Reward-guided Decoding</a></h2><div class="archive__item-excerpt">Michal Drozdzal이 [arXiv]에 게시한 &#x27;Controlling Multimodal LLMs via Reward-guided Decoding&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-18 13:14:38+0900">2025년 8월 18일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Multimodal LLMs</span><span class="page__taxonomy-item">#<!-- -->Reward Models</span><span class="page__taxonomy-item">#<!-- -->Guided Decoding</span><span class="page__taxonomy-item">#<!-- -->Visual Grounding</span><span class="page__taxonomy-item">#<!-- -->Hallucination Mitigation</span><span class="page__taxonomy-item">#<!-- -->Object Precision</span><span class="page__taxonomy-item">#<!-- -->Object Recall</span><span class="page__taxonomy-item">#<!-- -->Inference-time Control</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-15-We-Math_2.0_A_Versatile_MathBook_System_for_Incentivizing_Visual_Mathematical_Reasoning">[논문리뷰] We-Math 2.0: A Versatile MathBook System for Incentivizing Visual Mathematical Reasoning</a></h2><div class="archive__item-excerpt">Xiaowan Wang이 [arXiv]에 게시한 &#x27;We-Math 2.0: A Versatile MathBook System for Incentivizing Visual Mathematical Reasoning&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-15 13:09:31+0900">2025년 8월 15일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Visual Mathematical Reasoning</span><span class="page__taxonomy-item">#<!-- -->MLLMs</span><span class="page__taxonomy-item">#<!-- -->Knowledge System</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Curriculum Learning</span><span class="page__taxonomy-item">#<!-- -->Dataset Construction</span><span class="page__taxonomy-item">#<!-- -->Mathematical Benchmark</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-15-UI-Venus_Technical_Report_Building_High-performance_UI_Agents_with_RFT/">[논문리뷰] UI-Venus Technical Report: Building High-performance UI Agents with RFT</a></h2><div class="archive__item-excerpt">Shuheng Shen이 [arXiv]에 게시한 &#x27;UI-Venus Technical Report: Building High-performance UI Agents with RFT&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-15 13:09:31+0900">2025년 8월 15일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->UI Agent</span><span class="page__taxonomy-item">#<!-- -->MLLM</span><span class="page__taxonomy-item">#<!-- -->RFT</span><span class="page__taxonomy-item">#<!-- -->UI Grounding</span><span class="page__taxonomy-item">#<!-- -->UI Navigation</span><span class="page__taxonomy-item">#<!-- -->GRPO</span><span class="page__taxonomy-item">#<!-- -->Data Cleaning</span><span class="page__taxonomy-item">#<!-- -->Self-Evolving Trajectory</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-15-ToonComposer_Streamlining_Cartoon_Production_with_Generative_Post-Keyframing/">[논문리뷰] ToonComposer: Streamlining Cartoon Production with Generative Post-Keyframing</a></h2><div class="archive__item-excerpt">Xiaoyu Li이 [arXiv]에 게시한 &#x27;ToonComposer: Streamlining Cartoon Production with Generative Post-Keyframing&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-15 13:09:31+0900">2025년 8월 15일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Cartoon Generation</span><span class="page__taxonomy-item">#<!-- -->Video Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->DiT</span><span class="page__taxonomy-item">#<!-- -->Post-Keyframing</span><span class="page__taxonomy-item">#<!-- -->Low-Rank Adaptation</span><span class="page__taxonomy-item">#<!-- -->Sparse Control</span><span class="page__taxonomy-item">#<!-- -->Generative AI</span><span class="page__taxonomy-item">#<!-- -->Animation</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-15-STream3R_Scalable_Sequential_3D_Reconstruction_with_Causal_Transformer/">[논문리뷰] STream3R: Scalable Sequential 3D Reconstruction with Causal Transformer</a></h2><div class="archive__item-excerpt">Honghua Chen이 [arXiv]에 게시한 &#x27;STream3R: Scalable Sequential 3D Reconstruction with Causal Transformer&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-15 13:09:31+0900">2025년 8월 15일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->3D Reconstruction</span><span class="page__taxonomy-item">#<!-- -->Causal Transformer</span><span class="page__taxonomy-item">#<!-- -->Sequential Modeling</span><span class="page__taxonomy-item">#<!-- -->Streaming Data</span><span class="page__taxonomy-item">#<!-- -->Pointmap Prediction</span><span class="page__taxonomy-item">#<!-- -->Online Perception</span><span class="page__taxonomy-item">#<!-- -->KVCache</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-15-Processing_and_acquisition_traces_in_visual_encoders_What_does_CLIP_know_about_your_camera/">[논문리뷰] Processing and acquisition traces in visual encoders: What does CLIP know about your camera?</a></h2><div class="archive__item-excerpt">Giorgos Tolias이 [arXiv]에 게시한 &#x27;Processing and acquisition traces in visual encoders: What does CLIP know about your camera?&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-15 13:09:31+0900">2025년 8월 15일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Visual Encoders</span><span class="page__taxonomy-item">#<!-- -->Metadata</span><span class="page__taxonomy-item">#<!-- -->Image Processing</span><span class="page__taxonomy-item">#<!-- -->Image Acquisition</span><span class="page__taxonomy-item">#<!-- -->Robustness</span><span class="page__taxonomy-item">#<!-- -->CLIP</span><span class="page__taxonomy-item">#<!-- -->Foundation Models</span><span class="page__taxonomy-item">#<!-- -->Distribution Shift</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-15-PRELUDE_A_Benchmark_Designed_to_Require_Global_Comprehension_and_Reasoning_over_Long_Contexts/">[논문리뷰] PRELUDE: A Benchmark Designed to Require Global Comprehension and Reasoning over Long Contexts</a></h2><div class="archive__item-excerpt">Rui Lu이 [arXiv]에 게시한 &#x27;PRELUDE: A Benchmark Designed to Require Global Comprehension and Reasoning over Long Contexts&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-15 13:09:31+0900">2025년 8월 15일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Long-Context Understanding</span><span class="page__taxonomy-item">#<!-- -->Reasoning Benchmark</span><span class="page__taxonomy-item">#<!-- -->LLMs Evaluation</span><span class="page__taxonomy-item">#<!-- -->Natural Language Processing</span><span class="page__taxonomy-item">#<!-- -->Global Comprehension</span><span class="page__taxonomy-item">#<!-- -->Fluid Intelligence</span><span class="page__taxonomy-item">#<!-- -->Prequel Entailment</span><span class="page__taxonomy-item">#<!-- -->RAG</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-15-Passk_Training_for_Adaptively_Balancing_Exploration_and_Exploitation_of_Large_Reasoning_Models/">[논문리뷰] Pass@k Training for Adaptively Balancing Exploration and Exploitation of Large Reasoning Models</a></h2><div class="archive__item-excerpt">Qinghao Ye이 [arXiv]에 게시한 &#x27;Pass@k Training for Adaptively Balancing Exploration and Exploitation of Large Reasoning Models&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-15 13:09:31+0900">2025년 8월 15일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Exploration-Exploitation</span><span class="page__taxonomy-item">#<!-- -->Reward Design</span><span class="page__taxonomy-item">#<!-- -->Reasoning Tasks</span><span class="page__taxonomy-item">#<!-- -->Pass@k</span><span class="page__taxonomy-item">#<!-- -->Policy Optimization</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-15-NextStep-1_Toward_Autoregressive_Image_Generation_with_Continuous_Tokens_at_Scale/">[논문리뷰] NextStep-1: Toward Autoregressive Image Generation with Continuous Tokens at Scale</a></h2><div class="archive__item-excerpt">Quan Sun이 [arXiv]에 게시한 &#x27;NextStep-1: Toward Autoregressive Image Generation with Continuous Tokens at Scale&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-15 13:09:31+0900">2025년 8월 15일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Autoregressive Models</span><span class="page__taxonomy-item">#<!-- -->Text-to-Image Generation</span><span class="page__taxonomy-item">#<!-- -->Continuous Latent Tokens</span><span class="page__taxonomy-item">#<!-- -->Flow Matching</span><span class="page__taxonomy-item">#<!-- -->Image Editing</span><span class="page__taxonomy-item">#<!-- -->Multimodal Learning</span><span class="page__taxonomy-item">#<!-- -->Transformer Architecture</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-15-HumanSense_From_Multimodal_Perception_to_Empathetic_Context-Aware_Responses_through_Reasoning_MLLMs/">[논문리뷰] HumanSense: From Multimodal Perception to Empathetic Context-Aware Responses through Reasoning MLLMs</a></h2><div class="archive__item-excerpt">Yi Yuan이 [arXiv]에 게시한 &#x27;HumanSense: From Multimodal Perception to Empathetic Context-Aware Responses through Reasoning MLLMs&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-15 13:09:31+0900">2025년 8월 15일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Multimodal LLMs</span><span class="page__taxonomy-item">#<!-- -->Human-Centered AI</span><span class="page__taxonomy-item">#<!-- -->Empathy</span><span class="page__taxonomy-item">#<!-- -->Context-Awareness</span><span class="page__taxonomy-item">#<!-- -->MLLM Benchmark</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Reasoning</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-15-From_Black_Box_to_Transparency_Enhancing_Automated_Interpreting_Assessment_with_Explainable_AI_in_College_Classrooms/">[논문리뷰] From Black Box to Transparency: Enhancing Automated Interpreting Assessment with Explainable AI in College Classrooms</a></h2><div class="archive__item-excerpt">Ziyin Zhang이 [arXiv]에 게시한 &#x27;From Black Box to Transparency: Enhancing Automated Interpreting Assessment with Explainable AI in College Classrooms&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-15 13:09:31+0900">2025년 8월 15일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Automated Interpreting Assessment</span><span class="page__taxonomy-item">#<!-- -->Explainable AI</span><span class="page__taxonomy-item">#<!-- -->Data Augmentation</span><span class="page__taxonomy-item">#<!-- -->Variational Autoencoder</span><span class="page__taxonomy-item">#<!-- -->SHAP</span><span class="page__taxonomy-item">#<!-- -->Interpreting Quality</span><span class="page__taxonomy-item">#<!-- -->Natural Language Processing</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-15-A_Survey_on_Diffusion_Language_Models/">[논문리뷰] A Survey on Diffusion Language Models</a></h2><div class="archive__item-excerpt">Zhiqiang Shen이 [arXiv]에 게시한 &#x27;A Survey on Diffusion Language Models&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-15 13:09:31+0900">2025년 8월 15일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Diffusion Language Models</span><span class="page__taxonomy-item">#<!-- -->Generative AI</span><span class="page__taxonomy-item">#<!-- -->Parallel Decoding</span><span class="page__taxonomy-item">#<!-- -->Text Generation</span><span class="page__taxonomy-item">#<!-- -->Multimodal AI</span><span class="page__taxonomy-item">#<!-- -->Model Compression</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning from Human Feedback</span><span class="page__taxonomy-item">#<!-- -->Inference Optimization</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-15-2025-8-15-Explainability_and_Privacy_in_NLP/">[논문리뷰] When Explainability Meets Privacy: An Investigation at the Intersection of Post-hoc Explainability and Differential Privacy in the Context of Natural Language Processing</a></h2><div class="archive__item-excerpt">Gjergji Kasneci이 [arXiv]에 게시한 &#x27;When Explainability Meets Privacy: An Investigation at the Intersection of Post-hoc Explainability and Differential Privacy in the Context of Natural Language Processing&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-15 13:09:31+0900">2025년 8월 15일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Natural Language Processing (NLP)</span><span class="page__taxonomy-item">#<!-- -->Explainable AI (XAI)</span><span class="page__taxonomy-item">#<!-- -->Post-hoc Explainability</span><span class="page__taxonomy-item">#<!-- -->Differential Privacy (DP)</span><span class="page__taxonomy-item">#<!-- -->Privacy-Utility Trade-off</span><span class="page__taxonomy-item">#<!-- -->Model Faithfulness</span><span class="page__taxonomy-item">#<!-- -->Text Privatization</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-14-VisCodex_Unified_Multimodal_Code_Generation_via_Merging_Vision_and_Coding_Models/">[논문리뷰] VisCodex: Unified Multimodal Code Generation via Merging Vision and Coding Models</a></h2><div class="archive__item-excerpt">Dongdong Zhang이 [arXiv]에 게시한 &#x27;VisCodex: Unified Multimodal Code Generation via Merging Vision and Coding Models&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-14 13:19:02+0900">2025년 8월 14일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Multimodal LLM</span><span class="page__taxonomy-item">#<!-- -->Code Generation</span><span class="page__taxonomy-item">#<!-- -->Model Merging</span><span class="page__taxonomy-item">#<!-- -->Task Vectors</span><span class="page__taxonomy-item">#<!-- -->Vision-Language Model</span><span class="page__taxonomy-item">#<!-- -->Coding LLM</span><span class="page__taxonomy-item">#<!-- -->Instruction Tuning</span><span class="page__taxonomy-item">#<!-- -->Benchmark</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-14-Story2Board_A_Training-Free_Approach_for_Expressive_Storyboard_Generation/">[논문리뷰] Story2Board: A Training-Free Approach for Expressive Storyboard Generation</a></h2><div class="archive__item-excerpt">Dani Lischinski이 [arXiv]에 게시한 &#x27;Story2Board: A Training-Free Approach for Expressive Storyboard Generation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-14 13:19:02+0900">2025년 8월 14일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Storyboard Generation</span><span class="page__taxonomy-item">#<!-- -->Text-to-Image</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->Training-Free</span><span class="page__taxonomy-item">#<!-- -->Character Consistency</span><span class="page__taxonomy-item">#<!-- -->Scene Diversity</span><span class="page__taxonomy-item">#<!-- -->Visual Storytelling</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-14-Stand-In_A_Lightweight_and_Plug-and-Play_Identity_Control_for_Video_Generation/">[논문리뷰] Stand-In: A Lightweight and Plug-and-Play Identity Control for Video Generation</a></h2><div class="archive__item-excerpt">Chen Li이 [arXiv]에 게시한 &#x27;Stand-In: A Lightweight and Plug-and-Play Identity Control for Video Generation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-14 13:19:02+0900">2025년 8월 14일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Video Generation</span><span class="page__taxonomy-item">#<!-- -->Identity Preservation</span><span class="page__taxonomy-item">#<!-- -->Plug-and-Play</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->Self-Attention</span><span class="page__taxonomy-item">#<!-- -->Lightweight AI</span><span class="page__taxonomy-item">#<!-- -->Conditional Image Branch</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-14-Seeing_Listening_Remembering_and_Reasoning_A_Multimodal_Agent_with_Long-Term_Memory/">[논문리뷰] Seeing, Listening, Remembering, and Reasoning: A Multimodal Agent with Long-Term Memory</a></h2><div class="archive__item-excerpt">Yuan Lin이 [arXiv]에 게시한 &#x27;Seeing, Listening, Remembering, and Reasoning: A Multimodal Agent with Long-Term Memory&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-14 13:19:02+0900">2025년 8월 14일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Multimodal Agent</span><span class="page__taxonomy-item">#<!-- -->Long-Term Memory</span><span class="page__taxonomy-item">#<!-- -->Episodic Memory</span><span class="page__taxonomy-item">#<!-- -->Semantic Memory</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Video Question Answering</span><span class="page__taxonomy-item">#<!-- -->Entity-Centric Memory</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-14-Noise_Hypernetworks_Amortizing_Test-Time_Compute_in_Diffusion_Models/">[논문리뷰] Noise Hypernetworks: Amortizing Test-Time Compute in Diffusion Models</a></h2><div class="archive__item-excerpt">Zeynep Akata이 [arXiv]에 게시한 &#x27;Noise Hypernetworks: Amortizing Test-Time Compute in Diffusion Models&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-14 13:19:02+0900">2025년 8월 14일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->Hypernetworks</span><span class="page__taxonomy-item">#<!-- -->Test-Time Optimization</span><span class="page__taxonomy-item">#<!-- -->Reward-Guided Generation</span><span class="page__taxonomy-item">#<!-- -->Latent Space Optimization</span><span class="page__taxonomy-item">#<!-- -->LoRA</span><span class="page__taxonomy-item">#<!-- -->Generative AI</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-14-Mol-R1_Towards_Explicit_Long-CoT_Reasoning_in_Molecule_Discovery/">[논문리뷰] Mol-R1: Towards Explicit Long-CoT Reasoning in Molecule Discovery</a></h2><div class="archive__item-excerpt">Di Zhang이 [arXiv]에 게시한 &#x27;Mol-R1: Towards Explicit Long-CoT Reasoning in Molecule Discovery&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-14 13:19:02+0900">2025년 8월 14일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Molecule Discovery</span><span class="page__taxonomy-item">#<!-- -->Chain-of-Thought</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Supervised Fine-tuning</span><span class="page__taxonomy-item">#<!-- -->Molecular Generation</span><span class="page__taxonomy-item">#<!-- -->Explainable AI</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-14-MathReal_We_Keep_It_Real_A_Real_Scene_Benchmark_for_Evaluating_Math_Reasoning_in_Multimodal_Large_Language_Models/">[논문리뷰] MathReal: We Keep It Real! A Real Scene Benchmark for Evaluating Math Reasoning in Multimodal Large Language Models</a></h2><div class="archive__item-excerpt">Zhihan Zhou이 [arXiv]에 게시한 &#x27;MathReal: We Keep It Real! A Real Scene Benchmark for Evaluating Math Reasoning in Multimodal Large Language Models&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-14 13:19:02+0900">2025년 8월 14일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Multimodal Large Language Models (MLLMs)</span><span class="page__taxonomy-item">#<!-- -->Math Reasoning</span><span class="page__taxonomy-item">#<!-- -->Real-World Benchmark</span><span class="page__taxonomy-item">#<!-- -->Visual Perception</span><span class="page__taxonomy-item">#<!-- -->Robustness</span><span class="page__taxonomy-item">#<!-- -->K-12 Education</span><span class="page__taxonomy-item">#<!-- -->Dataset</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-14-Learning_to_Align_Aligning_to_Learn_A_Unified_Approach_for_Self-Optimized_Alignment/">[논문리뷰] Learning to Align, Aligning to Learn: A Unified Approach for Self-Optimized Alignment</a></h2><div class="archive__item-excerpt">Lei Fan이 [arXiv]에 게시한 &#x27;Learning to Align, Aligning to Learn: A Unified Approach for Self-Optimized Alignment&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-14 13:19:02+0900">2025년 8월 14일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLM Alignment</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning from Human Feedback</span><span class="page__taxonomy-item">#<!-- -->Preference Learning</span><span class="page__taxonomy-item">#<!-- -->Group Relative Alignment Optimization</span><span class="page__taxonomy-item">#<!-- -->Self-Optimization</span><span class="page__taxonomy-item">#<!-- -->Mixture-of-Experts</span><span class="page__taxonomy-item">#<!-- -->Imitation Learning</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-14-IAG_Input-aware_Backdoor_Attack_on_VLMs_for_Visual_Grounding/">[논문리뷰] IAG: Input-aware Backdoor Attack on VLMs for Visual Grounding</a></h2><div class="archive__item-excerpt">Di Zhang이 [arXiv]에 게시한 &#x27;IAG: Input-aware Backdoor Attack on VLMs for Visual Grounding&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-14 13:19:02+0900">2025년 8월 14일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Backdoor Attack</span><span class="page__taxonomy-item">#<!-- -->Vision-Language Models (VLMs)</span><span class="page__taxonomy-item">#<!-- -->Visual Grounding</span><span class="page__taxonomy-item">#<!-- -->Input-aware Trigger</span><span class="page__taxonomy-item">#<!-- -->Adversarial Attack</span><span class="page__taxonomy-item">#<!-- -->Security</span><span class="page__taxonomy-item">#<!-- -->U-Net</span><span class="page__taxonomy-item">#<!-- -->Open-vocabulary</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-14-GSFixer_Improving_3D_Gaussian_Splatting_with_Reference-Guided_Video_Diffusion_Priors/">[논문리뷰] GSFixer: Improving 3D Gaussian Splatting with Reference-Guided Video Diffusion Priors</a></h2><div class="archive__item-excerpt">Qingnan Fan이 [arXiv]에 게시한 &#x27;GSFixer: Improving 3D Gaussian Splatting with Reference-Guided Video Diffusion Priors&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-14 13:19:02+0900">2025년 8월 14일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->3D Gaussian Splatting</span><span class="page__taxonomy-item">#<!-- -->Novel View Synthesis</span><span class="page__taxonomy-item">#<!-- -->Diffusion Model</span><span class="page__taxonomy-item">#<!-- -->Artifact Restoration</span><span class="page__taxonomy-item">#<!-- -->Sparse-view 3D Reconstruction</span><span class="page__taxonomy-item">#<!-- -->Reference-Guided</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-14-Echo-4o_Harnessing_the_Power_of_GPT-4o_Synthetic_Images_for_Improved_Image_Generation/">[논문리뷰] Echo-4o: Harnessing the Power of GPT-4o Synthetic Images for Improved Image Generation</a></h2><div class="archive__item-excerpt">Zhenghao Hu이 [arXiv]에 게시한 &#x27;Echo-4o: Harnessing the Power of GPT-4o Synthetic Images for Improved Image Generation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-14 13:19:02+0900">2025년 8월 14일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Synthetic Data</span><span class="page__taxonomy-item">#<!-- -->Image Generation</span><span class="page__taxonomy-item">#<!-- -->GPT-4o</span><span class="page__taxonomy-item">#<!-- -->Multimodal Models</span><span class="page__taxonomy-item">#<!-- -->Instruction Following</span><span class="page__taxonomy-item">#<!-- -->Surreal Image Generation</span><span class="page__taxonomy-item">#<!-- -->Dataset</span><span class="page__taxonomy-item">#<!-- -->Benchmarking</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-14-Diffusion_LLMs_Can_Do_Faster-Than-AR_Inference_via_Discrete_Diffusion_Forcing/">[논문리뷰] Diffusion LLMs Can Do Faster-Than-AR Inference via Discrete Diffusion Forcing</a></h2><div class="archive__item-excerpt">Hao Zhang이 [arXiv]에 게시한 &#x27;Diffusion LLMs Can Do Faster-Than-AR Inference via Discrete Diffusion Forcing&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-14 13:19:02+0900">2025년 8월 14일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Diffusion LLMs</span><span class="page__taxonomy-item">#<!-- -->Faster Inference</span><span class="page__taxonomy-item">#<!-- -->Discrete Diffusion Forcing (D2F)</span><span class="page__taxonomy-item">#<!-- -->Autoregressive Generation</span><span class="page__taxonomy-item">#<!-- -->KV Cache Optimization</span><span class="page__taxonomy-item">#<!-- -->Parallel Decoding</span><span class="page__taxonomy-item">#<!-- -->Text Generation</span><span class="page__taxonomy-item">#<!-- -->Model Distillation</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-14-Cooper_Co-Optimizing_Policy_and_Reward_Models_in_Reinforcement_Learning_for_Large_Language_Models/">[논문리뷰] Cooper: Co-Optimizing Policy and Reward Models in Reinforcement Learning for Large Language Models</a></h2><div class="archive__item-excerpt">Guiyang Hou이 [arXiv]에 게시한 &#x27;Cooper: Co-Optimizing Policy and Reward Models in Reinforcement Learning for Large Language Models&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-14 13:19:02+0900">2025년 8월 14일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Reward Model</span><span class="page__taxonomy-item">#<!-- -->Policy Optimization</span><span class="page__taxonomy-item">#<!-- -->Reward Hacking</span><span class="page__taxonomy-item">#<!-- -->Hybrid Annotation</span><span class="page__taxonomy-item">#<!-- -->Mathematical Reasoning</span><span class="page__taxonomy-item">#<!-- -->Verifiable Rewards</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-14-Can_LLM-Generated_Textual_Explanations_Enhance_Model_Classification_Performance_An_Empirical_Study/">[논문리뷰] Can LLM-Generated Textual Explanations Enhance Model Classification Performance? An Empirical Study</a></h2><div class="archive__item-excerpt">Gjergji Kasneci이 [arXiv]에 게시한 &#x27;Can LLM-Generated Textual Explanations Enhance Model Classification Performance? An Empirical Study&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-14 13:19:02+0900">2025년 8월 14일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Explainable NLP</span><span class="page__taxonomy-item">#<!-- -->Natural Language Explanations</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Pre-trained Language Models</span><span class="page__taxonomy-item">#<!-- -->Natural Language Inference</span><span class="page__taxonomy-item">#<!-- -->Model Performance Enhancement</span><span class="page__taxonomy-item">#<!-- -->Text Generation</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-14-AWorld_Dynamic_Multi-Agent_System_with_Stable_Maneuvering_for_Robust_GAIA_Problem_Solving/">[논문리뷰] AWorld: Dynamic Multi-Agent System with Stable Maneuvering for Robust GAIA Problem Solving</a></h2><div class="archive__item-excerpt">Jinjie Gu이 [arXiv]에 게시한 &#x27;AWorld: Dynamic Multi-Agent System with Stable Maneuvering for Robust GAIA Problem Solving&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-14 13:19:02+0900">2025년 8월 14일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Multi-Agent System</span><span class="page__taxonomy-item">#<!-- -->Agent Stability</span><span class="page__taxonomy-item">#<!-- -->LLM</span><span class="page__taxonomy-item">#<!-- -->Tool Use</span><span class="page__taxonomy-item">#<!-- -->GAIA Benchmark</span><span class="page__taxonomy-item">#<!-- -->Robustness</span><span class="page__taxonomy-item">#<!-- -->Dynamic Supervision</span><span class="page__taxonomy-item">#<!-- -->Maneuvering</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-14-AMFT_Aligning_LLM_Reasoners_by_Meta-Learning_the_Optimal_Imitation-Exploration_Balance/">[논문리뷰] AMFT: Aligning LLM Reasoners by Meta-Learning the Optimal Imitation-Exploration Balance</a></h2><div class="archive__item-excerpt">Yong Li이 [arXiv]에 게시한 &#x27;AMFT: Aligning LLM Reasoners by Meta-Learning the Optimal Imitation-Exploration Balance&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-14 13:19:02+0900">2025년 8월 14일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Fine-tuning</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Meta-learning</span><span class="page__taxonomy-item">#<!-- -->Adaptive Control</span><span class="page__taxonomy-item">#<!-- -->Imitation Learning</span><span class="page__taxonomy-item">#<!-- -->Exploration</span><span class="page__taxonomy-item">#<!-- -->Reasoning</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-13-WGAST_Weakly-Supervised_Generative_Network_for_Daily_10_m_Land_Surface_Temperature_Estimation_via_Spatio-Temporal_Fusion/">[논문리뷰] WGAST: Weakly-Supervised Generative Network for Daily 10 m Land Surface Temperature Estimation via Spatio-Temporal Fusion</a></h2><div class="archive__item-excerpt">Rachid Nedjai이 [arXiv]에 게시한 &#x27;WGAST: Weakly-Supervised Generative Network for Daily 10 m Land Surface Temperature Estimation via Spatio-Temporal Fusion&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-13 13:29:23+0900">2025년 8월 13일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Spatio-Temporal Fusion</span><span class="page__taxonomy-item">#<!-- -->Land Surface Temperature</span><span class="page__taxonomy-item">#<!-- -->Generative Adversarial Network</span><span class="page__taxonomy-item">#<!-- -->Weakly-Supervised Learning</span><span class="page__taxonomy-item">#<!-- -->Remote Sensing</span><span class="page__taxonomy-item">#<!-- -->Deep Learning</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-13-VertexRegen_Mesh_Generation_with_Continuous_Level_of_Detail/">[논문리뷰] VertexRegen: Mesh Generation with Continuous Level of Detail</a></h2><div class="archive__item-excerpt">Jakob Engel이 [arXiv]에 게시한 &#x27;VertexRegen: Mesh Generation with Continuous Level of Detail&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-13 13:29:23+0900">2025년 8월 13일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Mesh Generation</span><span class="page__taxonomy-item">#<!-- -->Level of Detail (LOD)</span><span class="page__taxonomy-item">#<!-- -->Progressive Meshes</span><span class="page__taxonomy-item">#<!-- -->Vertex Split</span><span class="page__taxonomy-item">#<!-- -->Autoregressive Models</span><span class="page__taxonomy-item">#<!-- -->Transformer</span><span class="page__taxonomy-item">#<!-- -->3D Graphics</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-13-UNCAGE_Contrastive_Attention_Guidance_for_Masked_Generative_Transformers_in_Text-to-Image_Generation/">[논문리뷰] UNCAGE: Contrastive Attention Guidance for Masked Generative Transformers in Text-to-Image Generation</a></h2><div class="archive__item-excerpt">Kevin Galim이 [arXiv]에 게시한 &#x27;UNCAGE: Contrastive Attention Guidance for Masked Generative Transformers in Text-to-Image Generation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-13 13:29:23+0900">2025년 8월 13일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Text-to-Image Generation</span><span class="page__taxonomy-item">#<!-- -->Masked Generative Transformers</span><span class="page__taxonomy-item">#<!-- -->Compositional Generation</span><span class="page__taxonomy-item">#<!-- -->Attention Guidance</span><span class="page__taxonomy-item">#<!-- -->Unmasking Strategy</span><span class="page__taxonomy-item">#<!-- -->Contrastive Learning</span><span class="page__taxonomy-item">#<!-- -->Training-Free</span><span class="page__taxonomy-item">#<!-- -->Attribute Binding</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-13-Train_Long_Think_Short_Curriculum_Learning_for_Efficient_Reasoning/">[논문리뷰] Train Long, Think Short: Curriculum Learning for Efficient Reasoning</a></h2><div class="archive__item-excerpt">Marzyeh Ghassemi이 [arXiv]에 게시한 &#x27;Train Long, Think Short: Curriculum Learning for Efficient Reasoning&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-13 13:29:23+0900">2025년 8월 13일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Curriculum Learning</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Reasoning Efficiency</span><span class="page__taxonomy-item">#<!-- -->Token Budget Control</span><span class="page__taxonomy-item">#<!-- -->Group Relative Policy Optimization</span><span class="page__taxonomy-item">#<!-- -->Chain-of-Thought</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-13-Towards_Affordance-Aware_Robotic_Dexterous_Grasping_with_Human-like_Priors/">[논문리뷰] Towards Affordance-Aware Robotic Dexterous Grasping with Human-like Priors</a></h2><div class="archive__item-excerpt">Haoran Xu이 [arXiv]에 게시한 &#x27;Towards Affordance-Aware Robotic Dexterous Grasping with Human-like Priors&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-13 13:29:23+0900">2025년 8월 13일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Robotic Dexterous Grasping</span><span class="page__taxonomy-item">#<!-- -->Affordance-Aware</span><span class="page__taxonomy-item">#<!-- -->Human-like Priors</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Vision-Language Models</span><span class="page__taxonomy-item">#<!-- -->Two-Stage Training</span><span class="page__taxonomy-item">#<!-- -->Manipulation</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-13-TopXGen_Topic-Diverse_Parallel_Data_Generation_for_Low-Resource_Machine_Translation/">[논문리뷰] TopXGen: Topic-Diverse Parallel Data Generation for Low-Resource Machine Translation</a></h2><div class="archive__item-excerpt">Rachel Bawden이 [arXiv]에 게시한 &#x27;TopXGen: Topic-Diverse Parallel Data Generation for Low-Resource Machine Translation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-13 13:29:23+0900">2025년 8월 13일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Low-Resource MT</span><span class="page__taxonomy-item">#<!-- -->Data Augmentation</span><span class="page__taxonomy-item">#<!-- -->Large Language Models (LLMs)</span><span class="page__taxonomy-item">#<!-- -->Back-Translation</span><span class="page__taxonomy-item">#<!-- -->In-Context Learning (ICL)</span><span class="page__taxonomy-item">#<!-- -->Fine-Tuning</span><span class="page__taxonomy-item">#<!-- -->Topic-Guided Generation</span><span class="page__taxonomy-item">#<!-- -->Parallel Data Synthesis</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-13-Time_Is_a_Feature_Exploiting_Temporal_Dynamics_in_Diffusion_Language_Models/">[논문리뷰] Time Is a Feature: Exploiting Temporal Dynamics in Diffusion Language Models</a></h2><div class="archive__item-excerpt">Chenchen Jing이 [arXiv]에 게시한 &#x27;Time Is a Feature: Exploiting Temporal Dynamics in Diffusion Language Models&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-13 13:29:23+0900">2025년 8월 13일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Diffusion Language Models</span><span class="page__taxonomy-item">#<!-- -->Temporal Oscillation</span><span class="page__taxonomy-item">#<!-- -->Self-Consistency Voting</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Temporal Semantic Entropy</span><span class="page__taxonomy-item">#<!-- -->Text Generation</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-13-Test-Time_Reinforcement_Learning_for_GUI_Grounding_via_Region_Consistency/">[논문리뷰] Test-Time Reinforcement Learning for GUI Grounding via Region Consistency</a></h2><div class="archive__item-excerpt">Zhengxi Lu이 [arXiv]에 게시한 &#x27;Test-Time Reinforcement Learning for GUI Grounding via Region Consistency&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-13 13:29:23+0900">2025년 8월 13일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->GUI Grounding</span><span class="page__taxonomy-item">#<!-- -->Test-Time Scaling</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Region Consistency</span><span class="page__taxonomy-item">#<!-- -->Spatial Voting</span><span class="page__taxonomy-item">#<!-- -->Self-Supervised Learning</span><span class="page__taxonomy-item">#<!-- -->Vision-Language Models</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-13-OpenCUA_Open_Foundations_for_Computer-Use_Agents/">[논문리뷰] OpenCUA: Open Foundations for Computer-Use Agents</a></h2><div class="archive__item-excerpt">Tianbao Xie이 [arXiv]에 게시한 &#x27;OpenCUA: Open Foundations for Computer-Use Agents&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-13 13:29:23+0900">2025년 8월 13일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Computer-Use Agents</span><span class="page__taxonomy-item">#<!-- -->Vision-Language Models</span><span class="page__taxonomy-item">#<!-- -->Chain-of-Thought Reasoning</span><span class="page__taxonomy-item">#<!-- -->Large-scale Dataset</span><span class="page__taxonomy-item">#<!-- -->Open-source Framework</span><span class="page__taxonomy-item">#<!-- -->Desktop Automation</span><span class="page__taxonomy-item">#<!-- -->Agent Evaluation</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-13-NVSpeech_An_Integrated_and_Scalable_Pipeline_for_Human-Like_Speech_Modeling_with_Paralinguistic_Vocalizations/">[논문리뷰] NVSpeech: An Integrated and Scalable Pipeline for Human-Like Speech Modeling with Paralinguistic Vocalizations</a></h2><div class="archive__item-excerpt">Haoyue Zhan이 [arXiv]에 게시한 &#x27;NVSpeech: An Integrated and Scalable Pipeline for Human-Like Speech Modeling with Paralinguistic Vocalizations&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-13 13:29:23+0900">2025년 8월 13일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Paralinguistic Vocalizations</span><span class="page__taxonomy-item">#<!-- -->Speech Recognition</span><span class="page__taxonomy-item">#<!-- -->Text-to-Speech</span><span class="page__taxonomy-item">#<!-- -->Speech Synthesis</span><span class="page__taxonomy-item">#<!-- -->Data Annotation</span><span class="page__taxonomy-item">#<!-- -->Mandarin Speech</span><span class="page__taxonomy-item">#<!-- -->Expressive Speech</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-13-Matrix-3D_Omnidirectional_Explorable_3D_World_Generation/">[논문리뷰] Matrix-3D: Omnidirectional Explorable 3D World Generation</a></h2><div class="archive__item-excerpt">Yuqi Li이 [arXiv]에 게시한 &#x27;Matrix-3D: Omnidirectional Explorable 3D World Generation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-13 13:29:23+0900">2025년 8월 13일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->3D World Generation</span><span class="page__taxonomy-item">#<!-- -->Panoramic Video Generation</span><span class="page__taxonomy-item">#<!-- -->3D Reconstruction</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->Gaussian Splatting</span><span class="page__taxonomy-item">#<!-- -->Dataset</span><span class="page__taxonomy-item">#<!-- -->Camera Control</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-13-HierSearch_A_Hierarchical_Enterprise_Deep_Search_Framework_Integrating_Local_and_Web_Searches/">[논문리뷰] HierSearch: A Hierarchical Enterprise Deep Search Framework Integrating Local and Web Searches</a></h2><div class="archive__item-excerpt">Qiang Ju이 [arXiv]에 게시한 &#x27;HierSearch: A Hierarchical Enterprise Deep Search Framework Integrating Local and Web Searches&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-13 13:29:23+0900">2025년 8월 13일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Hierarchical Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Deep Search</span><span class="page__taxonomy-item">#<!-- -->Multi-source RAG</span><span class="page__taxonomy-item">#<!-- -->Agentic AI</span><span class="page__taxonomy-item">#<!-- -->Knowledge Integration</span><span class="page__taxonomy-item">#<!-- -->Enterprise Search</span><span class="page__taxonomy-item">#<!-- -->Large Reasoning Models</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-13-GeRe_Towards_Efficient_Anti-Forgetting_in_Continual_Learning_of_LLM_via_General_Samples_Replay/">[논문리뷰] GeRe: Towards Efficient Anti-Forgetting in Continual Learning of LLM via General Samples Replay</a></h2><div class="archive__item-excerpt">Yang Fan이 [arXiv]에 게시한 &#x27;GeRe: Towards Efficient Anti-Forgetting in Continual Learning of LLM via General Samples Replay&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-13 13:29:23+0900">2025년 8월 13일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Continual Learning</span><span class="page__taxonomy-item">#<!-- -->Large Language Models (LLMs)</span><span class="page__taxonomy-item">#<!-- -->Catastrophic Forgetting</span><span class="page__taxonomy-item">#<!-- -->Replay</span><span class="page__taxonomy-item">#<!-- -->Knowledge Distillation</span><span class="page__taxonomy-item">#<!-- -->Activation States</span><span class="page__taxonomy-item">#<!-- -->Anti-forgetting</span><span class="page__taxonomy-item">#<!-- -->Threshold-based Margin Loss</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-13-Feedback-Driven_Tool-Use_Improvements_in_Large_Language_Models_via_Automated_Build_Environments/">[논문리뷰] Feedback-Driven Tool-Use Improvements in Large Language Models via Automated Build Environments</a></h2><div class="archive__item-excerpt">Xuesong Yao이 [arXiv]에 게시한 &#x27;Feedback-Driven Tool-Use Improvements in Large Language Models via Automated Build Environments&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-13 13:29:23+0900">2025년 8월 13일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Large Language Models (LLMs)</span><span class="page__taxonomy-item">#<!-- -->Tool Use</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning (RL)</span><span class="page__taxonomy-item">#<!-- -->Automated Environment Generation</span><span class="page__taxonomy-item">#<!-- -->Feedback-Driven Training</span><span class="page__taxonomy-item">#<!-- -->Reward Mechanism</span><span class="page__taxonomy-item">#<!-- -->Contextual Understanding</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-13-Democratizing_Diplomacy_A_Harness_for_Evaluating_Any_Large_Language_Model_on_Full-Press_Diplomacy/">[논문리뷰] Democratizing Diplomacy: A Harness for Evaluating Any Large Language Model on Full-Press Diplomacy</a></h2><div class="archive__item-excerpt">Elizabeth Karpinski이 [arXiv]에 게시한 &#x27;Democratizing Diplomacy: A Harness for Evaluating Any Large Language Model on Full-Press Diplomacy&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-13 13:29:23+0900">2025년 8월 13일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Diplomacy Game</span><span class="page__taxonomy-item">#<!-- -->Multi-agent Systems</span><span class="page__taxonomy-item">#<!-- -->Strategic Reasoning</span><span class="page__taxonomy-item">#<!-- -->LLM Evaluation</span><span class="page__taxonomy-item">#<!-- -->Prompt Engineering</span><span class="page__taxonomy-item">#<!-- -->Behavioral Analysis</span><span class="page__taxonomy-item">#<!-- -->Game AI</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-13-DeCRED_Decoder-Centric_Regularization_for_Encoder-Decoder_Based_Speech_Recognition/">[논문리뷰] DeCRED: Decoder-Centric Regularization for Encoder-Decoder Based Speech Recognition</a></h2><div class="archive__item-excerpt">Lukáš Burget이 [arXiv]에 게시한 &#x27;DeCRED: Decoder-Centric Regularization for Encoder-Decoder Based Speech Recognition&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-13 13:29:23+0900">2025년 8월 13일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Speech Recognition</span><span class="page__taxonomy-item">#<!-- -->Encoder-Decoder</span><span class="page__taxonomy-item">#<!-- -->Regularization</span><span class="page__taxonomy-item">#<!-- -->Decoder-Centric</span><span class="page__taxonomy-item">#<!-- -->Intermediate Supervision</span><span class="page__taxonomy-item">#<!-- -->Out-of-Domain Generalization</span><span class="page__taxonomy-item">#<!-- -->Internal Language Model</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-13-Cut2Next_Generating_Next_Shot_via_In-Context_Tuning/">[논문리뷰] Cut2Next: Generating Next Shot via In-Context Tuning</a></h2><div class="archive__item-excerpt">Yu Qiao이 [arXiv]에 게시한 &#x27;Cut2Next: Generating Next Shot via In-Context Tuning&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-13 13:29:23+0900">2025년 8월 13일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Next Shot Generation</span><span class="page__taxonomy-item">#<!-- -->In-Context Tuning</span><span class="page__taxonomy-item">#<!-- -->Diffusion Transformer</span><span class="page__taxonomy-item">#<!-- -->Cinematic Continuity</span><span class="page__taxonomy-item">#<!-- -->Hierarchical Prompting</span><span class="page__taxonomy-item">#<!-- -->Video Generation</span><span class="page__taxonomy-item">#<!-- -->Shot Editing</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-13-CharacterShot_Controllable_and_Consistent_4D_Character_Animation/">[논문리뷰] CharacterShot: Controllable and Consistent 4D Character Animation</a></h2><div class="archive__item-excerpt">Fei Shen이 [arXiv]에 게시한 &#x27;CharacterShot: Controllable and Consistent 4D Character Animation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-13 13:29:23+0900">2025년 8월 13일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->4D Character Animation</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->Gaussian Splatting</span><span class="page__taxonomy-item">#<!-- -->Pose Control</span><span class="page__taxonomy-item">#<!-- -->Multi-view Synthesis</span><span class="page__taxonomy-item">#<!-- -->Temporal Consistency</span><span class="page__taxonomy-item">#<!-- -->Character Dataset</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-13-Bridging_Theory_and_Practice_in_Quantum_Game_Theory_Optimized_Implementation_of_the_Battle_of_the_Sexes_with_Error_Mitigation_on_NISQ_Hardware/">[논문리뷰] Bridging Theory and Practice in Quantum Game Theory: Optimized Implementation of the Battle of the Sexes with Error Mitigation on NISQ Hardware</a></h2><div class="archive__item-excerpt">Jhon Alejandro Andrade이 [arXiv]에 게시한 &#x27;Bridging Theory and Practice in Quantum Game Theory: Optimized Implementation of the Battle of the Sexes with Error Mitigation on NISQ Hardware&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-13 13:29:23+0900">2025년 8월 13일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Quantum Game Theory</span><span class="page__taxonomy-item">#<!-- -->NISQ Hardware</span><span class="page__taxonomy-item">#<!-- -->Error Mitigation</span><span class="page__taxonomy-item">#<!-- -->Battle of the Sexes</span><span class="page__taxonomy-item">#<!-- -->Qiskit</span><span class="page__taxonomy-item">#<!-- -->Quantum Computing</span><span class="page__taxonomy-item">#<!-- -->Strategic Coordination</span><span class="page__taxonomy-item">#<!-- -->Payoff Maximization</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-13-BiasGym_Fantastic_Biases_and_How_to_Find_and_Remove_Them/">[논문리뷰] BiasGym: Fantastic Biases and How to Find (and Remove) Them</a></h2><div class="archive__item-excerpt">Arnav Arora이 [arXiv]에 게시한 &#x27;BiasGym: Fantastic Biases and How to Find (and Remove) Them&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-13 13:29:23+0900">2025년 8월 13일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Bias Mitigation</span><span class="page__taxonomy-item">#<!-- -->LLMs</span><span class="page__taxonomy-item">#<!-- -->Mechanistic Interpretability</span><span class="page__taxonomy-item">#<!-- -->Fine-tuning</span><span class="page__taxonomy-item">#<!-- -->Attention Steering</span><span class="page__taxonomy-item">#<!-- -->Stereotype Analysis</span><span class="page__taxonomy-item">#<!-- -->Safety Alignment</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-13-Beyond_Ten_Turns_Unlocking_Long-Horizon_Agentic_Search_with_Large-Scale_Asynchronous_RL/">[논문리뷰] Beyond Ten Turns: Unlocking Long-Horizon Agentic Search with Large-Scale Asynchronous RL</a></h2><div class="archive__item-excerpt">Chuyi He이 [arXiv]에 게시한 &#x27;Beyond Ten Turns: Unlocking Long-Horizon Agentic Search with Large-Scale Asynchronous RL&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-13 13:29:23+0900">2025년 8월 13일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->LLM Agents</span><span class="page__taxonomy-item">#<!-- -->Agentic Search</span><span class="page__taxonomy-item">#<!-- -->Asynchronous RL</span><span class="page__taxonomy-item">#<!-- -->Long-Horizon Planning</span><span class="page__taxonomy-item">#<!-- -->Tool Use</span><span class="page__taxonomy-item">#<!-- -->Data Synthesis</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-13-AutoCodeBench_Large_Language_Models_are_Automatic_Code_Benchmark_Generators/">[논문리뷰] AutoCodeBench: Large Language Models are Automatic Code Benchmark Generators</a></h2><div class="archive__item-excerpt">Tao Zhang이 [arXiv]에 게시한 &#x27;AutoCodeBench: Large Language Models are Automatic Code Benchmark Generators&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-13 13:29:23+0900">2025년 8월 13일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->코드 생성</span><span class="page__taxonomy-item">#<!-- -->대규모 언어 모델</span><span class="page__taxonomy-item">#<!-- -->코드 벤치마크</span><span class="page__taxonomy-item">#<!-- -->다국어 프로그래밍</span><span class="page__taxonomy-item">#<!-- -->자동화된 데이터 생성</span><span class="page__taxonomy-item">#<!-- -->샌드박스 평가</span><span class="page__taxonomy-item">#<!-- -->멀티모달 AI</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-13-Aryabhata_An_exam-focused_language_model_for_JEE_Math/">[논문리뷰] Aryabhata: An exam-focused language model for JEE Math</a></h2><div class="archive__item-excerpt">Sandeep Varma이 [arXiv]에 게시한 &#x27;Aryabhata: An exam-focused language model for JEE Math&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-13 13:29:23+0900">2025년 8월 13일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Language Model</span><span class="page__taxonomy-item">#<!-- -->Math Reasoning</span><span class="page__taxonomy-item">#<!-- -->JEE</span><span class="page__taxonomy-item">#<!-- -->Supervised Fine-Tuning</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Model Merging</span><span class="page__taxonomy-item">#<!-- -->Chain-of-Thought</span><span class="page__taxonomy-item">#<!-- -->Curriculum Learning</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-13-Adversarial_Video_Promotion_Against_Text-to-Video_Retrieval/">[논문리뷰] Adversarial Video Promotion Against Text-to-Video Retrieval</a></h2><div class="archive__item-excerpt">Shuai Liu이 [arXiv]에 게시한 &#x27;Adversarial Video Promotion Against Text-to-Video Retrieval&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-13 13:29:23+0900">2025년 8월 13일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Adversarial Attack</span><span class="page__taxonomy-item">#<!-- -->Video Promotion</span><span class="page__taxonomy-item">#<!-- -->Text-to-Video Retrieval</span><span class="page__taxonomy-item">#<!-- -->Modality Refinement</span><span class="page__taxonomy-item">#<!-- -->Black-box Attack</span><span class="page__taxonomy-item">#<!-- -->Video Manipulation</span><span class="page__taxonomy-item">#<!-- -->Transferability</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-12-WideSearch_Benchmarking_Agentic_Broad_Info-Seeking/">[논문리뷰] WideSearch: Benchmarking Agentic Broad Info-Seeking</a></h2><div class="archive__item-excerpt">Yan Gao이 [arXiv]에 게시한 &#x27;WideSearch: Benchmarking Agentic Broad Info-Seeking&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-12 13:29:09+0900">2025년 8월 12일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Agentic Search</span><span class="page__taxonomy-item">#<!-- -->LLM</span><span class="page__taxonomy-item">#<!-- -->Benchmark</span><span class="page__taxonomy-item">#<!-- -->Information Seeking</span><span class="page__taxonomy-item">#<!-- -->Structured Output</span><span class="page__taxonomy-item">#<!-- -->Evaluation Metrics</span><span class="page__taxonomy-item">#<!-- -->Multi-agent Systems</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-12-When_Good_Sounds_Go_Adversarial_Jailbreaking_Audio-Language_Models_with_Benign_Inputs/">[논문리뷰] When Good Sounds Go Adversarial: Jailbreaking Audio-Language Models with Benign Inputs</a></h2><div class="archive__item-excerpt">Dasol Choi이 [arXiv]에 게시한 &#x27;When Good Sounds Go Adversarial: Jailbreaking Audio-Language Models with Benign Inputs&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-12 13:29:09+0900">2025년 8월 12일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Audio-Language Models</span><span class="page__taxonomy-item">#<!-- -->Jailbreak Attack</span><span class="page__taxonomy-item">#<!-- -->Adversarial Audio</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Projected Gradient Descent</span><span class="page__taxonomy-item">#<!-- -->Native Payload Discovery</span><span class="page__taxonomy-item">#<!-- -->Multimodal AI Safety</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-12-VisR-Bench_An_Empirical_Study_on_Visual_Retrieval-Augmented_Generation_for_Multilingual_Long_Document_Understanding/">[논문리뷰] VisR-Bench: An Empirical Study on Visual Retrieval-Augmented Generation for Multilingual Long Document Understanding</a></h2><div class="archive__item-excerpt">Tong Yu이 [arXiv]에 게시한 &#x27;VisR-Bench: An Empirical Study on Visual Retrieval-Augmented Generation for Multilingual Long Document Understanding&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-12 13:29:09+0900">2025년 8월 12일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Multimodal Retrieval</span><span class="page__taxonomy-item">#<!-- -->Retrieval-Augmented Generation</span><span class="page__taxonomy-item">#<!-- -->Long Document Understanding</span><span class="page__taxonomy-item">#<!-- -->Multilingual NLP</span><span class="page__taxonomy-item">#<!-- -->Visual QA</span><span class="page__taxonomy-item">#<!-- -->Benchmark</span><span class="page__taxonomy-item">#<!-- -->MLLMs</span><span class="page__taxonomy-item">#<!-- -->Table Understanding</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-12-UserBench_An_Interactive_Gym_Environment_for_User-Centric_Agents/">[논문리뷰] UserBench: An Interactive Gym Environment for User-Centric Agents</a></h2><div class="archive__item-excerpt">Jianguo Zhang이 [arXiv]에 게시한 &#x27;UserBench: An Interactive Gym Environment for User-Centric Agents&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-12 13:29:09+0900">2025년 8월 12일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->User-Centric AI</span><span class="page__taxonomy-item">#<!-- -->LLM Evaluation</span><span class="page__taxonomy-item">#<!-- -->Interactive Agents</span><span class="page__taxonomy-item">#<!-- -->Gym Environment</span><span class="page__taxonomy-item">#<!-- -->Preference Elicitation</span><span class="page__taxonomy-item">#<!-- -->Multi-turn Dialogue</span><span class="page__taxonomy-item">#<!-- -->Tool Use</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-12-Temporal_Self-Rewarding_Language_Models_Decoupling_Chosen-Rejected_via_Past-Future/">[논문리뷰] Temporal Self-Rewarding Language Models: Decoupling Chosen-Rejected via Past-Future</a></h2><div class="archive__item-excerpt">Qiufeng Wang이 [arXiv]에 게시한 &#x27;Temporal Self-Rewarding Language Models: Decoupling Chosen-Rejected via Past-Future&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-12 13:29:09+0900">2025년 8월 12일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Self-Rewarding LLMs</span><span class="page__taxonomy-item">#<!-- -->Direct Preference Optimization (DPO)</span><span class="page__taxonomy-item">#<!-- -->Preference Learning</span><span class="page__taxonomy-item">#<!-- -->Generative AI</span><span class="page__taxonomy-item">#<!-- -->Gradient Collapse</span><span class="page__taxonomy-item">#<!-- -->LLM Alignment</span><span class="page__taxonomy-item">#<!-- -->Iterative Optimization</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-12-Speech-to-LaTeX_New_Models_and_Datasets_for_Converting_Spoken_Equations_and_Sentences/">[논문리뷰] Speech-to-LaTeX: New Models and Datasets for Converting Spoken Equations and Sentences</a></h2><div class="archive__item-excerpt">Matvey Skripkin이 [arXiv]에 게시한 &#x27;Speech-to-LaTeX: New Models and Datasets for Converting Spoken Equations and Sentences&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-12 13:29:09+0900">2025년 8월 12일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Speech-to-LaTeX</span><span class="page__taxonomy-item">#<!-- -->ASR</span><span class="page__taxonomy-item">#<!-- -->Language Models</span><span class="page__taxonomy-item">#<!-- -->Multimodal AI</span><span class="page__taxonomy-item">#<!-- -->Dataset Creation</span><span class="page__taxonomy-item">#<!-- -->Mathematical Expression Recognition</span><span class="page__taxonomy-item">#<!-- -->LaTeX Generation</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-12-Shortcut_Learning_in_Generalist_Robot_Policies_The_Role_of_Dataset_Diversity_and_Fragmentation/">[논문리뷰] Shortcut Learning in Generalist Robot Policies: The Role of Dataset Diversity and Fragmentation</a></h2><div class="archive__item-excerpt">Hengtao Shen이 [arXiv]에 게시한 &#x27;Shortcut Learning in Generalist Robot Policies: The Role of Dataset Diversity and Fragmentation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-12 13:29:09+0900">2025년 8월 12일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Robot Learning</span><span class="page__taxonomy-item">#<!-- -->Generalization</span><span class="page__taxonomy-item">#<!-- -->Shortcut Learning</span><span class="page__taxonomy-item">#<!-- -->Dataset Diversity</span><span class="page__taxonomy-item">#<!-- -->Dataset Fragmentation</span><span class="page__taxonomy-item">#<!-- -->Data Augmentation</span><span class="page__taxonomy-item">#<!-- -->Imitation Learning</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-12-Reinforcement_Learning_in_Vision_A_Survey/">[논문리뷰] Reinforcement Learning in Vision: A Survey</a></h2><div class="archive__item-excerpt">Qingwei Meng이 [arXiv]에 게시한 &#x27;Reinforcement Learning in Vision: A Survey&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-12 13:29:09+0900">2025년 8월 12일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning (RL)</span><span class="page__taxonomy-item">#<!-- -->Computer Vision (CV)</span><span class="page__taxonomy-item">#<!-- -->Multimodal Large Language Models (MLLMs)</span><span class="page__taxonomy-item">#<!-- -->Visual Generation</span><span class="page__taxonomy-item">#<!-- -->Vision-Language-Action (VLA) Models</span><span class="page__taxonomy-item">#<!-- -->Policy Optimization</span><span class="page__taxonomy-item">#<!-- -->Reward Modeling</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-12-ReasonRank_Empowering_Passage_Ranking_with_Strong_Reasoning_Ability/">[논문리뷰] ReasonRank: Empowering Passage Ranking with Strong Reasoning Ability</a></h2><div class="archive__item-excerpt">Yuchen Li이 [arXiv]에 게시한 &#x27;ReasonRank: Empowering Passage Ranking with Strong Reasoning Ability&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-12 13:29:09+0900">2025년 8월 12일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Passage Ranking</span><span class="page__taxonomy-item">#<!-- -->Reasoning Models</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Data Synthesis</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Listwise Reranking</span><span class="page__taxonomy-item">#<!-- -->Information Retrieval</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-12-Part_I_Tricks_or_Traps_A_Deep_Dive_into_RL_for_LLM_Reasoning/">[논문리뷰] Part I: Tricks or Traps? A Deep Dive into RL for LLM Reasoning</a></h2><div class="archive__item-excerpt">Jiaheng Liu이 [arXiv]에 게시한 &#x27;Part I: Tricks or Traps? A Deep Dive into RL for LLM Reasoning&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-12 13:29:09+0900">2025년 8월 12일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->LLM Reasoning</span><span class="page__taxonomy-item">#<!-- -->Policy Optimization</span><span class="page__taxonomy-item">#<!-- -->Normalization</span><span class="page__taxonomy-item">#<!-- -->Clipping</span><span class="page__taxonomy-item">#<!-- -->Loss Aggregation</span><span class="page__taxonomy-item">#<!-- -->Overlong Filtering</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-12-OmniEAR_Benchmarking_Agent_Reasoning_in_Embodied_Tasks/">[논문리뷰] OmniEAR: Benchmarking Agent Reasoning in Embodied Tasks</a></h2><div class="archive__item-excerpt">Hongxing Li이 [arXiv]에 게시한 &#x27;OmniEAR: Benchmarking Agent Reasoning in Embodied Tasks&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-12 13:29:09+0900">2025년 8월 12일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Embodied AI</span><span class="page__taxonomy-item">#<!-- -->Agent Reasoning</span><span class="page__taxonomy-item">#<!-- -->LLM</span><span class="page__taxonomy-item">#<!-- -->Benchmarking</span><span class="page__taxonomy-item">#<!-- -->Tool Use</span><span class="page__taxonomy-item">#<!-- -->Multi-Agent Systems</span><span class="page__taxonomy-item">#<!-- -->Physical Interaction</span><span class="page__taxonomy-item">#<!-- -->Constraint Reasoning</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-12-Omni-Effects_Unified_and_Spatially-Controllable_Visual_Effects_Generation/">[논문리뷰] Omni-Effects: Unified and Spatially-Controllable Visual Effects Generation</a></h2><div class="archive__item-excerpt">Xiaokun Feng이 [arXiv]에 게시한 &#x27;Omni-Effects: Unified and Spatially-Controllable Visual Effects Generation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-12 13:29:09+0900">2025년 8월 12일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Visual Effects</span><span class="page__taxonomy-item">#<!-- -->Video Generation</span><span class="page__taxonomy-item">#<!-- -->LoRA</span><span class="page__taxonomy-item">#<!-- -->Mixture of Experts</span><span class="page__taxonomy-item">#<!-- -->Spatial Control</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->Multi-VFX</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-12-MolmoAct_Action_Reasoning_Models_that_can_Reason_in_Space/">[논문리뷰] MolmoAct: Action Reasoning Models that can Reason in Space</a></h2><div class="archive__item-excerpt">Shuo Liu이 [arXiv]에 게시한 &#x27;MolmoAct: Action Reasoning Models that can Reason in Space&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-12 13:29:09+0900">2025년 8월 12일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Robotics</span><span class="page__taxonomy-item">#<!-- -->Action Reasoning</span><span class="page__taxonomy-item">#<!-- -->Vision-Language Models</span><span class="page__taxonomy-item">#<!-- -->Spatial Planning</span><span class="page__taxonomy-item">#<!-- -->Depth Perception</span><span class="page__taxonomy-item">#<!-- -->Trajectory Generation</span><span class="page__taxonomy-item">#<!-- -->Explainable AI</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-12-MoBE_Mixture-of-Basis-Experts_for_Compressing_MoE-based_LLMs/">[논문리뷰] MoBE: Mixture-of-Basis-Experts for Compressing MoE-based LLMs</a></h2><div class="archive__item-excerpt">Jianguo Li이 [arXiv]에 게시한 &#x27;MoBE: Mixture-of-Basis-Experts for Compressing MoE-based LLMs&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-12 13:29:09+0900">2025년 8월 12일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Mixture-of-Experts (MoE)</span><span class="page__taxonomy-item">#<!-- -->LLM Compression</span><span class="page__taxonomy-item">#<!-- -->Matrix Decomposition</span><span class="page__taxonomy-item">#<!-- -->Parameter Efficiency</span><span class="page__taxonomy-item">#<!-- -->Deep Learning</span><span class="page__taxonomy-item">#<!-- -->Memory Optimization</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-12-Less_Is_More_Training-Free_Sparse_Attention_with_Global_Locality_for_Efficient_Reasoning/">[논문리뷰] Less Is More: Training-Free Sparse Attention with Global Locality for Efficient Reasoning</a></h2><div class="archive__item-excerpt">Baihong Yuan이 [arXiv]에 게시한 &#x27;Less Is More: Training-Free Sparse Attention with Global Locality for Efficient Reasoning&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-12 13:29:09+0900">2025년 8월 12일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Sparse Attention</span><span class="page__taxonomy-item">#<!-- -->LLMs</span><span class="page__taxonomy-item">#<!-- -->Reasoning Tasks</span><span class="page__taxonomy-item">#<!-- -->Efficiency</span><span class="page__taxonomy-item">#<!-- -->Training-Free</span><span class="page__taxonomy-item">#<!-- -->Global Locality</span><span class="page__taxonomy-item">#<!-- -->KV Cache Optimization</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-12-Klear-Reasoner_Advancing_Reasoning_Capability_via_Gradient-Preserving_Clipping_Policy_Optimization/">[논문리뷰] Klear-Reasoner: Advancing Reasoning Capability via Gradient-Preserving Clipping Policy Optimization</a></h2><div class="archive__item-excerpt">Guanting Dong이 [arXiv]에 게시한 &#x27;Klear-Reasoner: Advancing Reasoning Capability via Gradient-Preserving Clipping Policy Optimization&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-12 13:29:09+0900">2025년 8월 12일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Reasoning LLMs</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->PPO</span><span class="page__taxonomy-item">#<!-- -->Gradient Clipping</span><span class="page__taxonomy-item">#<!-- -->Supervised Fine-tuning</span><span class="page__taxonomy-item">#<!-- -->Math Reasoning</span><span class="page__taxonomy-item">#<!-- -->Code Generation</span><span class="page__taxonomy-item">#<!-- -->Policy Optimization</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-12-Grove_MoE_Towards_Efficient_and_Superior_MoE_LLMs_with_Adjugate_Experts/">[논문리뷰] Grove MoE: Towards Efficient and Superior MoE LLMs with Adjugate Experts</a></h2><div class="archive__item-excerpt">Tieyuan Chen이 [arXiv]에 게시한 &#x27;Grove MoE: Towards Efficient and Superior MoE LLMs with Adjugate Experts&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-12 13:29:09+0900">2025년 8월 12일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Mixture of Experts</span><span class="page__taxonomy-item">#<!-- -->LLMs</span><span class="page__taxonomy-item">#<!-- -->MoE Architecture</span><span class="page__taxonomy-item">#<!-- -->Dynamic Activation</span><span class="page__taxonomy-item">#<!-- -->Adjugate Experts</span><span class="page__taxonomy-item">#<!-- -->Upcycling Strategy</span><span class="page__taxonomy-item">#<!-- -->Load Balancing</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-12-GLiClass_Generalist_Lightweight_Model_for_Sequence_Classification_Tasks/">[논문리뷰] GLiClass: Generalist Lightweight Model for Sequence Classification Tasks</a></h2><div class="archive__item-excerpt">Alexander Yavorskyi이 [arXiv]에 게시한 &#x27;GLiClass: Generalist Lightweight Model for Sequence Classification Tasks&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-12 13:29:09+0900">2025년 8월 12일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Sequence Classification</span><span class="page__taxonomy-item">#<!-- -->Zero-shot Learning</span><span class="page__taxonomy-item">#<!-- -->Few-shot Learning</span><span class="page__taxonomy-item">#<!-- -->Transformer</span><span class="page__taxonomy-item">#<!-- -->Multi-label Classification</span><span class="page__taxonomy-item">#<!-- -->PPO</span><span class="page__taxonomy-item">#<!-- -->GLiNER</span><span class="page__taxonomy-item">#<!-- -->Computational Efficiency</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-12-Follow-Your-Shape_Shape-Aware_Image_Editing_via_Trajectory-Guided_Region_Control/">[논문리뷰] Follow-Your-Shape: Shape-Aware Image Editing via Trajectory-Guided Region Control</a></h2><div class="archive__item-excerpt">Hongyu Liu이 [arXiv]에 게시한 &#x27;Follow-Your-Shape: Shape-Aware Image Editing via Trajectory-Guided Region Control&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-12 13:29:09+0900">2025년 8월 12일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Image Editing</span><span class="page__taxonomy-item">#<!-- -->Shape Transformation</span><span class="page__taxonomy-item">#<!-- -->Rectified Flow</span><span class="page__taxonomy-item">#<!-- -->Trajectory Divergence Map</span><span class="page__taxonomy-item">#<!-- -->Region Control</span><span class="page__taxonomy-item">#<!-- -->Generative Models</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-12-Fact2Fiction_Targeted_Poisoning_Attack_to_Agentic_Fact-checking_System/">[논문리뷰] Fact2Fiction: Targeted Poisoning Attack to Agentic Fact-checking System</a></h2><div class="archive__item-excerpt">Reynold Cheng이 [arXiv]에 게시한 &#x27;Fact2Fiction: Targeted Poisoning Attack to Agentic Fact-checking System&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-12 13:29:09+0900">2025년 8월 12일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Adversarial Attack</span><span class="page__taxonomy-item">#<!-- -->Poisoning Attack</span><span class="page__taxonomy-item">#<!-- -->Fact-checking</span><span class="page__taxonomy-item">#<!-- -->LLM Agent</span><span class="page__taxonomy-item">#<!-- -->Retrieval Augmented Generation</span><span class="page__taxonomy-item">#<!-- -->Misinformation</span><span class="page__taxonomy-item">#<!-- -->System Security</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-12-Deep_Ignorance_Filtering_Pretraining_Data_Builds_Tamper-Resistant_Safeguards_into_Open-Weight_LLMs/">[논문리뷰] Deep Ignorance: Filtering Pretraining Data Builds Tamper-Resistant Safeguards into Open-Weight LLMs</a></h2><div class="archive__item-excerpt">Robert Kirk이 [arXiv]에 게시한 &#x27;Deep Ignorance: Filtering Pretraining Data Builds Tamper-Resistant Safeguards into Open-Weight LLMs&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-12 13:29:09+0900">2025년 8월 12일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLMs</span><span class="page__taxonomy-item">#<!-- -->데이터 필터링</span><span class="page__taxonomy-item">#<!-- -->사전 학습</span><span class="page__taxonomy-item">#<!-- -->변조 저항성</span><span class="page__taxonomy-item">#<!-- -->바이오위협</span><span class="page__taxonomy-item">#<!-- -->AI 안전</span><span class="page__taxonomy-item">#<!-- -->서킷 브레이킹</span><span class="page__taxonomy-item">#<!-- -->머신 언러닝</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-12-Compressing_Chain-of-Thought_in_LLMs_via_Step_Entropy/">[논문리뷰] Compressing Chain-of-Thought in LLMs via Step Entropy</a></h2><div class="archive__item-excerpt">Zhijian Xu이 [arXiv]에 게시한 &#x27;Compressing Chain-of-Thought in LLMs via Step Entropy&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-12 13:29:09+0900">2025년 8월 12일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLM</span><span class="page__taxonomy-item">#<!-- -->Chain-of-Thought</span><span class="page__taxonomy-item">#<!-- -->CoT Compression</span><span class="page__taxonomy-item">#<!-- -->Step Entropy</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->SFT</span><span class="page__taxonomy-item">#<!-- -->GRPO</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-12-BrowseComp-Plus_A_More_Fair_and_Transparent_Evaluation_Benchmark_of_Deep-Research_Agent/">[논문리뷰] BrowseComp-Plus: A More Fair and Transparent Evaluation Benchmark of Deep-Research Agent</a></h2><div class="archive__item-excerpt">Kai Zou이 [arXiv]에 게시한 &#x27;BrowseComp-Plus: A More Fair and Transparent Evaluation Benchmark of Deep-Research Agent&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-12 13:29:09+0900">2025년 8월 12일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Benchmarking</span><span class="page__taxonomy-item">#<!-- -->Deep-Research Agents</span><span class="page__taxonomy-item">#<!-- -->LLMs</span><span class="page__taxonomy-item">#<!-- -->Retrieval</span><span class="page__taxonomy-item">#<!-- -->Curated Corpus</span><span class="page__taxonomy-item">#<!-- -->Evaluation</span><span class="page__taxonomy-item">#<!-- -->Fairness</span><span class="page__taxonomy-item">#<!-- -->Transparency</span><span class="page__taxonomy-item">#<!-- -->Reproducibility</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-12-Bifrost-1_Bridging_Multimodal_LLMs_and_Diffusion_Models_with_Patch-level_CLIP_Latents/">[논문리뷰] Bifrost-1: Bridging Multimodal LLMs and Diffusion Models with Patch-level CLIP Latents</a></h2><div class="archive__item-excerpt">Mohit Bansal이 [arXiv]에 게시한 &#x27;Bifrost-1: Bridging Multimodal LLMs and Diffusion Models with Patch-level CLIP Latents&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-12 13:29:09+0900">2025년 8월 12일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Multimodal LLM</span><span class="page__taxonomy-item">#<!-- -->Diffusion Model</span><span class="page__taxonomy-item">#<!-- -->CLIP Latent</span><span class="page__taxonomy-item">#<!-- -->Image Generation</span><span class="page__taxonomy-item">#<!-- -->Multimodal Understanding</span><span class="page__taxonomy-item">#<!-- -->ControlNet</span><span class="page__taxonomy-item">#<!-- -->Training Efficiency</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-12-A_Comprehensive_Survey_of_Self-Evolving_AI_Agents_A_New_Paradigm_Bridging_Foundation_Models_and_Lifelong_Agentic_Systems/">[논문리뷰] A Comprehensive Survey of Self-Evolving AI Agents: A New Paradigm Bridging Foundation Models and Lifelong Agentic Systems</a></h2><div class="archive__item-excerpt">Xinhao Yi이 [arXiv]에 게시한 &#x27;A Comprehensive Survey of Self-Evolving AI Agents: A New Paradigm Bridging Foundation Models and Lifelong Agentic Systems&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-12 13:29:09+0900">2025년 8월 12일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Self-Evolving AI Agents</span><span class="page__taxonomy-item">#<!-- -->Lifelong Learning</span><span class="page__taxonomy-item">#<!-- -->Foundation Models</span><span class="page__taxonomy-item">#<!-- -->Multi-Agent Systems</span><span class="page__taxonomy-item">#<!-- -->Agent Optimization</span><span class="page__taxonomy-item">#<!-- -->Prompt Engineering</span><span class="page__taxonomy-item">#<!-- -->Tool Use</span><span class="page__taxonomy-item">#<!-- -->AI Safety</span><span class="page__taxonomy-item">#<!-- -->Survey</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-11-Voost_A_Unified_and_Scalable_Diffusion_Transformer_for_Bidirectional_Virtual_Try-On_and_Try-Off/">[논문리뷰] Voost: A Unified and Scalable Diffusion Transformer for Bidirectional Virtual Try-On and Try-Off</a></h2><div class="archive__item-excerpt">jgkwak이 [arXiv]에 게시한 &#x27;Voost: A Unified and Scalable Diffusion Transformer for Bidirectional Virtual Try-On and Try-Off&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-11 13:13:28+0900">2025년 8월 11일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Virtual Try-On</span><span class="page__taxonomy-item">#<!-- -->Virtual Try-Off</span><span class="page__taxonomy-item">#<!-- -->Diffusion Transformer</span><span class="page__taxonomy-item">#<!-- -->Bidirectional Learning</span><span class="page__taxonomy-item">#<!-- -->Generative AI</span><span class="page__taxonomy-item">#<!-- -->Fashion Synthesis</span><span class="page__taxonomy-item">#<!-- -->Attention Mechanism</span><span class="page__taxonomy-item">#<!-- -->Self-Correction</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-11-UI-AGILE_Advancing_GUI_Agents_with_Effective_Reinforcement_Learning_and_Precise_Inference-Time_Grounding/">[논문리뷰] UI-AGILE: Advancing GUI Agents with Effective Reinforcement Learning and Precise Inference-Time Grounding</a></h2><div class="archive__item-excerpt">Bingqi Chen이 [arXiv]에 게시한 &#x27;UI-AGILE: Advancing GUI Agents with Effective Reinforcement Learning and Precise Inference-Time Grounding&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-11 13:13:28+0900">2025년 8월 11일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->GUI Agents</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Grounding</span><span class="page__taxonomy-item">#<!-- -->MLLMs</span><span class="page__taxonomy-item">#<!-- -->Reward Function</span><span class="page__taxonomy-item">#<!-- -->Resampling</span><span class="page__taxonomy-item">#<!-- -->Visual Noise Reduction</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-11-Pruning_the_Unsurprising_Efficient_Code_Reasoning_via_First-Token_Surprisal/">[논문리뷰] Pruning the Unsurprising: Efficient Code Reasoning via First-Token Surprisal</a></h2><div class="archive__item-excerpt">Chengcheng Wan이 [arXiv]에 게시한 &#x27;Pruning the Unsurprising: Efficient Code Reasoning via First-Token Surprisal&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-11 13:13:28+0900">2025년 8월 11일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Code Reasoning</span><span class="page__taxonomy-item">#<!-- -->CoT Compression</span><span class="page__taxonomy-item">#<!-- -->LLMs</span><span class="page__taxonomy-item">#<!-- -->Efficiency</span><span class="page__taxonomy-item">#<!-- -->Surprisal</span><span class="page__taxonomy-item">#<!-- -->Pruning</span><span class="page__taxonomy-item">#<!-- -->Fine-tuning</span><span class="page__taxonomy-item">#<!-- -->Large Reasoning Models</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-11-MeshLLM_Empowering_Large_Language_Models_to_Progressively_Understand_and_Generate_3D_Mesh/">[논문리뷰] MeshLLM: Empowering Large Language Models to Progressively Understand and Generate 3D Mesh</a></h2><div class="archive__item-excerpt">Yi Yang이 [arXiv]에 게시한 &#x27;MeshLLM: Empowering Large Language Models to Progressively Understand and Generate 3D Mesh&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-11 13:13:28+0900">2025년 8월 11일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->3D Mesh Generation</span><span class="page__taxonomy-item">#<!-- -->LLMs</span><span class="page__taxonomy-item">#<!-- -->Mesh Understanding</span><span class="page__taxonomy-item">#<!-- -->Text-to-3D</span><span class="page__taxonomy-item">#<!-- -->Primitive-Mesh Decomposition</span><span class="page__taxonomy-item">#<!-- -->Progressive Training</span><span class="page__taxonomy-item">#<!-- -->Multimodal AI</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-11-Memp_Exploring_Agent_Procedural_Memory/">[논문리뷰] Memp: Exploring Agent Procedural Memory</a></h2><div class="archive__item-excerpt">Shuofei Qiao이 [arXiv]에 게시한 &#x27;Memp: Exploring Agent Procedural Memory&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-11 13:13:28+0900">2025년 8월 11일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Procedural Memory</span><span class="page__taxonomy-item">#<!-- -->LLM Agents</span><span class="page__taxonomy-item">#<!-- -->Memory Management</span><span class="page__taxonomy-item">#<!-- -->Task Automation</span><span class="page__taxonomy-item">#<!-- -->Lifelong Learning</span><span class="page__taxonomy-item">#<!-- -->Experience Replay</span><span class="page__taxonomy-item">#<!-- -->Agent Learning</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-11-MELLA_Bridging_Linguistic_Capability_and_Cultural_Groundedness_for_Low-Resource_Language_MLLMs/">[논문리뷰] MELLA: Bridging Linguistic Capability and Cultural Groundedness for Low-Resource Language MLLMs</a></h2><div class="archive__item-excerpt">Guohang Yan이 [arXiv]에 게시한 &#x27;MELLA: Bridging Linguistic Capability and Cultural Groundedness for Low-Resource Language MLLMs&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-11 13:13:28+0900">2025년 8월 11일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Multimodal Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Low-Resource Languages</span><span class="page__taxonomy-item">#<!-- -->Cultural Groundedness</span><span class="page__taxonomy-item">#<!-- -->Linguistic Capability</span><span class="page__taxonomy-item">#<!-- -->Dataset Creation</span><span class="page__taxonomy-item">#<!-- -->Multilingual AI</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-11-LightSwitch_Multi-view_Relighting_with_Material-guided_Diffusion/">[논문리뷰] LightSwitch: Multi-view Relighting with Material-guided Diffusion</a></h2><div class="archive__item-excerpt">Shubham Tulsiani이 [arXiv]에 게시한 &#x27;LightSwitch: Multi-view Relighting with Material-guided Diffusion&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-11 13:13:28+0900">2025년 8월 11일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Multi-view Relighting</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->Material-guided</span><span class="page__taxonomy-item">#<!-- -->Inverse Rendering</span><span class="page__taxonomy-item">#<!-- -->3D Scene Reconstruction</span><span class="page__taxonomy-item">#<!-- -->Image Synthesis</span><span class="page__taxonomy-item">#<!-- -->Consistent Relighting</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-11-InfiGUI-G1_Advancing_GUI_Grounding_with_Adaptive_Exploration_Policy_Optimization/">[논문리뷰] InfiGUI-G1: Advancing GUI Grounding with Adaptive Exploration Policy Optimization</a></h2><div class="archive__item-excerpt">Pengxiang Li이 [arXiv]에 게시한 &#x27;InfiGUI-G1: Advancing GUI Grounding with Adaptive Exploration Policy Optimization&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-11 13:13:28+0900">2025년 8월 11일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->GUI Grounding</span><span class="page__taxonomy-item">#<!-- -->MLLMs</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Policy Optimization</span><span class="page__taxonomy-item">#<!-- -->Exploration Strategy</span><span class="page__taxonomy-item">#<!-- -->Semantic Alignment</span><span class="page__taxonomy-item">#<!-- -->Adaptive Exploration Reward</span><span class="page__taxonomy-item">#<!-- -->Human-Computer Interaction</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-11-GLM-4.5_Agentic_Reasoning_and_Coding_ARC_Foundation_Models">[논문리뷰] GLM-4.5: Agentic, Reasoning, and Coding (ARC) Foundation Models</a></h2><div class="archive__item-excerpt">GLM-4. 5 Team이 [arXiv]에 게시한 &#x27;GLM-4.5: Agentic, Reasoning, and Coding (ARC) Foundation Models&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-11 13:13:28+0900">2025년 8월 11일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Large Language Model</span><span class="page__taxonomy-item">#<!-- -->Mixture-of-Experts</span><span class="page__taxonomy-item">#<!-- -->Agentic AI</span><span class="page__taxonomy-item">#<!-- -->Reasoning</span><span class="page__taxonomy-item">#<!-- -->Code Generation</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Foundation Model</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-11-GENIE_Gaussian_Encoding_for_Neural_Radiance_Fields_Interactive_Editing/">[논문리뷰] GENIE: Gaussian Encoding for Neural Radiance Fields Interactive Editing</a></h2><div class="archive__item-excerpt">Przemysław Spurek이 [arXiv]에 게시한 &#x27;GENIE: Gaussian Encoding for Neural Radiance Fields Interactive Editing&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-11 13:13:28+0900">2025년 8월 11일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Neural Radiance Fields (NeRF)</span><span class="page__taxonomy-item">#<!-- -->Gaussian Splatting (GS)</span><span class="page__taxonomy-item">#<!-- -->Interactive Editing</span><span class="page__taxonomy-item">#<!-- -->3D Scene Representation</span><span class="page__taxonomy-item">#<!-- -->Physics Simulation</span><span class="page__taxonomy-item">#<!-- -->Hybrid Model</span><span class="page__taxonomy-item">#<!-- -->Real-time Rendering</span><span class="page__taxonomy-item">#<!-- -->Ray Tracing</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-11-Adapting_Vision-Language_Models_Without_Labels_A_Comprehensive_Survey/">[논문리뷰] Adapting Vision-Language Models Without Labels: A Comprehensive Survey</a></h2><div class="archive__item-excerpt">Eleni Chatzi이 [arXiv]에 게시한 &#x27;Adapting Vision-Language Models Without Labels: A Comprehensive Survey&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-11 13:13:28+0900">2025년 8월 11일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Vision-Language Models (VLMs)</span><span class="page__taxonomy-item">#<!-- -->Unsupervised Adaptation</span><span class="page__taxonomy-item">#<!-- -->Test-Time Adaptation (TTA)</span><span class="page__taxonomy-item">#<!-- -->Domain Transfer</span><span class="page__taxonomy-item">#<!-- -->Multimodal Learning</span><span class="page__taxonomy-item">#<!-- -->Label-Free Learning</span><span class="page__taxonomy-item">#<!-- -->Zero-Shot Learning</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-8-Visual_Document_Understanding_and_Question_Answering_A_Multi-Agent_Collaboration_Framework_with_Test-Time_Scaling/">[논문리뷰] Visual Document Understanding and Question Answering: A Multi-Agent Collaboration Framework with Test-Time Scaling</a></h2><div class="archive__item-excerpt">Ruolin Shen이 [arXiv]에 게시한 &#x27;Visual Document Understanding and Question Answering: A Multi-Agent Collaboration Framework with Test-Time Scaling&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-08 13:32:22+0900">2025년 8월 8일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Visual Document Understanding</span><span class="page__taxonomy-item">#<!-- -->Visual Question Answering</span><span class="page__taxonomy-item">#<!-- -->Multi-Agent System</span><span class="page__taxonomy-item">#<!-- -->Test-Time Scaling</span><span class="page__taxonomy-item">#<!-- -->Self-Correction</span><span class="page__taxonomy-item">#<!-- -->Mixed Reward Modeling</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-8-StrandDesigner_Towards_Practical_Strand_Generation_with_Sketch_Guidance/">[논문리뷰] StrandDesigner: Towards Practical Strand Generation with Sketch Guidance</a></h2><div class="archive__item-excerpt">Xiaobin Hu이 [arXiv]에 게시한 &#x27;StrandDesigner: Towards Practical Strand Generation with Sketch Guidance&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-08 13:32:22+0900">2025년 8월 8일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Strand Generation</span><span class="page__taxonomy-item">#<!-- -->Sketch Guidance</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->Multi-scale Learning</span><span class="page__taxonomy-item">#<!-- -->Adaptive Conditioning</span><span class="page__taxonomy-item">#<!-- -->3D Hair Modeling</span><span class="page__taxonomy-item">#<!-- -->Computer Graphics</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-8-Steering_One-Step_Diffusion_Model_with_Fidelity-Rich_Decoder_for_Fast_Image_Compression/">[논문리뷰] Steering One-Step Diffusion Model with Fidelity-Rich Decoder for Fast Image Compression</a></h2><div class="archive__item-excerpt">Yifei Ji이 [arXiv]에 게시한 &#x27;Steering One-Step Diffusion Model with Fidelity-Rich Decoder for Fast Image Compression&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-08 13:32:22+0900">2025년 8월 8일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Image Compression</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->One-Step Decoding</span><span class="page__taxonomy-item">#<!-- -->Fidelity Guidance</span><span class="page__taxonomy-item">#<!-- -->Rate Annealing</span><span class="page__taxonomy-item">#<!-- -->VAE</span><span class="page__taxonomy-item">#<!-- -->Perceptual Quality</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-8-RPCANet_Deep_Interpretable_Robust_PCA_for_Sparse_Object_Segmentation/">[논문리뷰] RPCANet++: Deep Interpretable Robust PCA for Sparse Object Segmentation</a></h2><div class="archive__item-excerpt">Jian Yang이 [arXiv]에 게시한 &#x27;RPCANet++: Deep Interpretable Robust PCA for Sparse Object Segmentation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-08 13:32:22+0900">2025년 8월 8일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Robust PCA</span><span class="page__taxonomy-item">#<!-- -->Deep Unfolding</span><span class="page__taxonomy-item">#<!-- -->Sparse Segmentation</span><span class="page__taxonomy-item">#<!-- -->Interpretability</span><span class="page__taxonomy-item">#<!-- -->Image Decomposition</span><span class="page__taxonomy-item">#<!-- -->Computer Vision</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-8-REINA_Regularized_Entropy_Information-Based_Loss_for_Efficient_Simultaneous_Speech_Translation/">[논문리뷰] REINA: Regularized Entropy Information-Based Loss for Efficient Simultaneous Speech Translation</a></h2><div class="archive__item-excerpt">Xiao Yu이 [arXiv]에 게시한 &#x27;REINA: Regularized Entropy Information-Based Loss for Efficient Simultaneous Speech Translation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-08 13:32:22+0900">2025년 8월 8일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Simultaneous Speech Translation</span><span class="page__taxonomy-item">#<!-- -->Adaptive Policy</span><span class="page__taxonomy-item">#<!-- -->Entropy-based Loss</span><span class="page__taxonomy-item">#<!-- -->Mutual Information</span><span class="page__taxonomy-item">#<!-- -->Latency-Quality Trade-off</span><span class="page__taxonomy-item">#<!-- -->Speech-to-Text Translation</span><span class="page__taxonomy-item">#<!-- -->REINA</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-8-R-Zero_Self-Evolving_Reasoning_LLM_from_Zero_Data/">[논문리뷰] R-Zero: Self-Evolving Reasoning LLM from Zero Data</a></h2><div class="archive__item-excerpt">Zongxia Li이 [arXiv]에 게시한 &#x27;R-Zero: Self-Evolving Reasoning LLM from Zero Data&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-08 13:32:22+0900">2025년 8월 8일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Self-Evolving LLM</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Curriculum Learning</span><span class="page__taxonomy-item">#<!-- -->Reasoning</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Self-Play</span><span class="page__taxonomy-item">#<!-- -->Zero-Data Training</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-8-PRvL_Quantifying_the_Capabilities_and_Risks_of_Large_Language_Models_for_PII_Redaction/">[논문리뷰] PRvL: Quantifying the Capabilities and Risks of Large Language Models for PII Redaction</a></h2><div class="archive__item-excerpt">Prajit Das이 [arXiv]에 게시한 &#x27;PRvL: Quantifying the Capabilities and Risks of Large Language Models for PII Redaction&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-08 13:32:22+0900">2025년 8월 8일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->PII Redaction</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Instruction Tuning</span><span class="page__taxonomy-item">#<!-- -->Retrieval-Augmented Generation</span><span class="page__taxonomy-item">#<!-- -->Privacy Preservation</span><span class="page__taxonomy-item">#<!-- -->Model Evaluation</span><span class="page__taxonomy-item">#<!-- -->Cross-Domain Generalization</span><span class="page__taxonomy-item">#<!-- -->Open-Source LLMs</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-8-On_the_Generalization_of_SFT_A_Reinforcement_Learning_Perspective_with_Reward_Rectification/">[논문리뷰] On the Generalization of SFT: A Reinforcement Learning Perspective with Reward Rectification</a></h2><div class="archive__item-excerpt">Xinyu Ye이 [arXiv]에 게시한 &#x27;On the Generalization of SFT: A Reinforcement Learning Perspective with Reward Rectification&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-08 13:32:22+0900">2025년 8월 8일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Supervised Fine-Tuning (SFT)</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning (RL)</span><span class="page__taxonomy-item">#<!-- -->Generalization</span><span class="page__taxonomy-item">#<!-- -->Reward Rectification</span><span class="page__taxonomy-item">#<!-- -->Dynamic Fine-Tuning (DFT)</span><span class="page__taxonomy-item">#<!-- -->LLM</span><span class="page__taxonomy-item">#<!-- -->Policy Gradient</span><span class="page__taxonomy-item">#<!-- -->Mathematical Reasoning</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-8-MOSEv2_A_More_Challenging_Dataset_for_Video_Object_Segmentation_in_Complex_Scenes/">[논문리뷰] MOSEv2: A More Challenging Dataset for Video Object Segmentation in Complex Scenes</a></h2><div class="archive__item-excerpt">Xudong Jiang이 [arXiv]에 게시한 &#x27;MOSEv2: A More Challenging Dataset for Video Object Segmentation in Complex Scenes&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-08 13:32:22+0900">2025년 8월 8일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Video Object Segmentation</span><span class="page__taxonomy-item">#<!-- -->Dataset</span><span class="page__taxonomy-item">#<!-- -->Complex Scenes</span><span class="page__taxonomy-item">#<!-- -->Benchmark</span><span class="page__taxonomy-item">#<!-- -->Object Tracking</span><span class="page__taxonomy-item">#<!-- -->Computer Vision</span><span class="page__taxonomy-item">#<!-- -->Dataset Challenges</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-8-Marco-Voice_Technical_Report/">[논문리뷰] Marco-Voice Technical Report</a></h2><div class="archive__item-excerpt">Qingjuan Li이 [arXiv]에 게시한 &#x27;Marco-Voice Technical Report&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-08 13:32:22+0900">2025년 8월 8일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Speech Synthesis</span><span class="page__taxonomy-item">#<!-- -->Voice Cloning</span><span class="page__taxonomy-item">#<!-- -->Emotion Control</span><span class="page__taxonomy-item">#<!-- -->Text-to-Speech</span><span class="page__taxonomy-item">#<!-- -->Disentanglement</span><span class="page__taxonomy-item">#<!-- -->Contrastive Learning</span><span class="page__taxonomy-item">#<!-- -->Flow Matching</span><span class="page__taxonomy-item">#<!-- -->Emotional Speech Dataset</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-8-I_Think_Therefore_I_Am_Under-Qualified_A_Benchmark_for_Evaluating_Linguistic_Shibboleth_Detection_in_LLM_Hiring_Evaluations/">[논문리뷰] I Think, Therefore I Am Under-Qualified? A Benchmark for Evaluating Linguistic Shibboleth Detection in LLM Hiring Evaluations</a></h2><div class="archive__item-excerpt">Chirag Shah이 [arXiv]에 게시한 &#x27;I Think, Therefore I Am Under-Qualified? A Benchmark for Evaluating Linguistic Shibboleth Detection in LLM Hiring Evaluations&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-08 13:32:22+0900">2025년 8월 8일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLM Bias</span><span class="page__taxonomy-item">#<!-- -->Hiring Evaluation</span><span class="page__taxonomy-item">#<!-- -->Linguistic Shibboleth</span><span class="page__taxonomy-item">#<!-- -->Hedging Language</span><span class="page__taxonomy-item">#<!-- -->Fairness</span><span class="page__taxonomy-item">#<!-- -->Benchmarking</span><span class="page__taxonomy-item">#<!-- -->Sociolinguistics</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-8-InfiAlign_A_Scalable_and_Sample-Efficient_Framework_for_Aligning_LLMs_to_Enhance_Reasoning_Capabilities/">[논문리뷰] InfiAlign: A Scalable and Sample-Efficient Framework for Aligning LLMs to Enhance Reasoning Capabilities</a></h2><div class="archive__item-excerpt">Zhijie Sang이 [arXiv]에 게시한 &#x27;InfiAlign: A Scalable and Sample-Efficient Framework for Aligning LLMs to Enhance Reasoning Capabilities&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-08 13:32:22+0900">2025년 8월 8일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLM Alignment</span><span class="page__taxonomy-item">#<!-- -->Reasoning</span><span class="page__taxonomy-item">#<!-- -->Data Curation</span><span class="page__taxonomy-item">#<!-- -->Supervised Fine-tuning (SFT)</span><span class="page__taxonomy-item">#<!-- -->Direct Preference Optimization (DPO)</span><span class="page__taxonomy-item">#<!-- -->Sample Efficiency</span><span class="page__taxonomy-item">#<!-- -->Scalability</span><span class="page__taxonomy-item">#<!-- -->Multi-dimensional Filtering</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-8-I2CR_Intra-_and_Inter-modal_Collaborative_Reflections_for_Multimodal_Entity_Linking/">[논문리뷰] I2CR: Intra- and Inter-modal Collaborative Reflections for Multimodal Entity Linking</a></h2><div class="archive__item-excerpt">Chao Wang이 [arXiv]에 게시한 &#x27;I2CR: Intra- and Inter-modal Collaborative Reflections for Multimodal Entity Linking&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-08 13:32:22+0900">2025년 8월 8일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Multimodal Entity Linking</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Collaborative Reflection</span><span class="page__taxonomy-item">#<!-- -->Iterative Reasoning</span><span class="page__taxonomy-item">#<!-- -->Visual Information</span><span class="page__taxonomy-item">#<!-- -->Text-centric</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-8-Hop_Skip_and_Overthink_Diagnosing_Why_Reasoning_Models_Fumble_during_Multi-Hop_Analysis/">[논문리뷰] Hop, Skip, and Overthink: Diagnosing Why Reasoning Models Fumble during Multi-Hop Analysis</a></h2><div class="archive__item-excerpt">Reshmi Ghosh이 [arXiv]에 게시한 &#x27;Hop, Skip, and Overthink: Diagnosing Why Reasoning Models Fumble during Multi-Hop Analysis&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-08 13:32:22+0900">2025년 8월 8일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Multi-hop Question Answering</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Reasoning Errors</span><span class="page__taxonomy-item">#<!-- -->Error Taxonomy</span><span class="page__taxonomy-item">#<!-- -->Human Evaluation</span><span class="page__taxonomy-item">#<!-- -->Automated Evaluation</span><span class="page__taxonomy-item">#<!-- -->Overthinking</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-8-Hi3DEval_Advancing_3D_Generation_Evaluation_with_Hierarchical_Validity/">[논문리뷰] Hi3DEval: Advancing 3D Generation Evaluation with Hierarchical Validity</a></h2><div class="archive__item-excerpt">Zhibing Li이 [arXiv]에 게시한 &#x27;Hi3DEval: Advancing 3D Generation Evaluation with Hierarchical Validity&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-08 13:32:22+0900">2025년 8월 8일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->3D Generation Evaluation</span><span class="page__taxonomy-item">#<!-- -->Hierarchical Evaluation</span><span class="page__taxonomy-item">#<!-- -->Material Properties</span><span class="page__taxonomy-item">#<!-- -->Multi-Agent Annotation</span><span class="page__taxonomy-item">#<!-- -->Hybrid Scoring System</span><span class="page__taxonomy-item">#<!-- -->Video-based Evaluation</span><span class="page__taxonomy-item">#<!-- -->Part-level Analysis</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-8-Genie_Envisioner_A_Unified_World_Foundation_Platform_for_Robotic_Manipulation/">[논문리뷰] Genie Envisioner: A Unified World Foundation Platform for Robotic Manipulation</a></h2><div class="archive__item-excerpt">Shengcong Chen이 [arXiv]에 게시한 &#x27;Genie Envisioner: A Unified World Foundation Platform for Robotic Manipulation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-08 13:32:22+0900">2025년 8월 8일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Robotic Manipulation</span><span class="page__taxonomy-item">#<!-- -->World Model</span><span class="page__taxonomy-item">#<!-- -->Video Generation</span><span class="page__taxonomy-item">#<!-- -->Diffusion Model</span><span class="page__taxonomy-item">#<!-- -->Embodied AI</span><span class="page__taxonomy-item">#<!-- -->Foundation Model</span><span class="page__taxonomy-item">#<!-- -->Robotics Simulation</span><span class="page__taxonomy-item">#<!-- -->Policy Learning</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-8-Evaluating_Synthesizing_and_Enhancing_for_Customer_Support_Conversation/">[논문리뷰] Evaluating, Synthesizing, and Enhancing for Customer Support Conversation</a></h2><div class="archive__item-excerpt">Feng Chen이 [arXiv]에 게시한 &#x27;Evaluating, Synthesizing, and Enhancing for Customer Support Conversation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-08 13:32:22+0900">2025년 8월 8일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Customer Support</span><span class="page__taxonomy-item">#<!-- -->Dialogue Generation</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Role-Playing</span><span class="page__taxonomy-item">#<!-- -->COPC Framework</span><span class="page__taxonomy-item">#<!-- -->Synthetic Data</span><span class="page__taxonomy-item">#<!-- -->Strategy Prediction</span><span class="page__taxonomy-item">#<!-- -->Empathetic AI</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-8-Dont_Overthink_It_A_Survey_of_Efficient_R1-style_Large_Reasoning_Models/">[논문리뷰] Don&#x27;t Overthink It: A Survey of Efficient R1-style Large Reasoning Models</a></h2><div class="archive__item-excerpt">Fangzhou Yao이 [arXiv]에 게시한 &#x27;Don&#x27;t Overthink It: A Survey of Efficient R1-style Large Reasoning Models&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-08 13:32:22+0900">2025년 8월 8일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Large Reasoning Models</span><span class="page__taxonomy-item">#<!-- -->Efficient Reasoning</span><span class="page__taxonomy-item">#<!-- -->Chain-of-Thought</span><span class="page__taxonomy-item">#<!-- -->Model Optimization</span><span class="page__taxonomy-item">#<!-- -->Model Collaboration</span><span class="page__taxonomy-item">#<!-- -->Overthinking Problem</span><span class="page__taxonomy-item">#<!-- -->LLM Efficiency</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-8-DeepPHY_Benchmarking_Agentic_VLMs_on_Physical_Reasoning/">[논문리뷰] DeepPHY: Benchmarking Agentic VLMs on Physical Reasoning</a></h2><div class="archive__item-excerpt">Ziming Wang이 [arXiv]에 게시한 &#x27;DeepPHY: Benchmarking Agentic VLMs on Physical Reasoning&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-08 13:32:22+0900">2025년 8월 8일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Vision Language Models (VLMs)</span><span class="page__taxonomy-item">#<!-- -->Agentic AI</span><span class="page__taxonomy-item">#<!-- -->Physical Reasoning</span><span class="page__taxonomy-item">#<!-- -->Benchmark</span><span class="page__taxonomy-item">#<!-- -->Simulation Environments</span><span class="page__taxonomy-item">#<!-- -->Action Planning</span><span class="page__taxonomy-item">#<!-- -->Interactive AI</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-8-CoAct-1_Computer-using_Agents_with_Coding_as_Actions/">[논문리뷰] CoAct-1: Computer-using Agents with Coding as Actions</a></h2><div class="archive__item-excerpt">Taiwei Shi이 [arXiv]에 게시한 &#x27;CoAct-1: Computer-using Agents with Coding as Actions&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-08 13:32:22+0900">2025년 8월 8일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->AI Agent</span><span class="page__taxonomy-item">#<!-- -->Multi-agent System</span><span class="page__taxonomy-item">#<!-- -->GUI Automation</span><span class="page__taxonomy-item">#<!-- -->Programmatic Control</span><span class="page__taxonomy-item">#<!-- -->Code Generation</span><span class="page__taxonomy-item">#<!-- -->OSWorld Benchmark</span><span class="page__taxonomy-item">#<!-- -->Hybrid AI</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-8-Can_Large_Multimodal_Models_Actively_Recognize_Faulty_Inputs_A_Systematic_Evaluation_Framework_of_Their_Input_Scrutiny_Ability/">[논문리뷰] Can Large Multimodal Models Actively Recognize Faulty Inputs? A Systematic Evaluation Framework of Their Input Scrutiny Ability</a></h2><div class="archive__item-excerpt">Yuan Wu이 [arXiv]에 게시한 &#x27;Can Large Multimodal Models Actively Recognize Faulty Inputs? A Systematic Evaluation Framework of Their Input Scrutiny Ability&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-08 13:32:22+0900">2025년 8월 8일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Large Multimodal Models</span><span class="page__taxonomy-item">#<!-- -->Input Scrutiny</span><span class="page__taxonomy-item">#<!-- -->Error Detection</span><span class="page__taxonomy-item">#<!-- -->Faulty Inputs</span><span class="page__taxonomy-item">#<!-- -->Evaluation Framework</span><span class="page__taxonomy-item">#<!-- -->Modality Preference</span><span class="page__taxonomy-item">#<!-- -->Cross-Modal Inconsistency</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-8-Are_We_on_the_Right_Way_for_Assessing_Document_Retrieval-Augmented_Generation/">[논문리뷰] Are We on the Right Way for Assessing Document Retrieval-Augmented Generation?</a></h2><div class="archive__item-excerpt">Junjie Yang이 [arXiv]에 게시한 &#x27;Are We on the Right Way for Assessing Document Retrieval-Augmented Generation?&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-08 13:32:22+0900">2025년 8월 8일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Retrieval-Augmented Generation</span><span class="page__taxonomy-item">#<!-- -->Multimodal LLMs</span><span class="page__taxonomy-item">#<!-- -->Benchmark Evaluation</span><span class="page__taxonomy-item">#<!-- -->Document Understanding</span><span class="page__taxonomy-item">#<!-- -->Multi-hop Reasoning</span><span class="page__taxonomy-item">#<!-- -->Information Retrieval</span><span class="page__taxonomy-item">#<!-- -->Evaluation Dataset</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-8-Are_Todays_LLMs_Ready_to_Explain_Well-Being_Concepts/">[논문리뷰] Are Today&#x27;s LLMs Ready to Explain Well-Being Concepts?</a></h2><div class="archive__item-excerpt">Huan Liu이 [arXiv]에 게시한 &#x27;Are Today&#x27;s LLMs Ready to Explain Well-Being Concepts?&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-08 13:32:22+0900">2025년 8월 8일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Well-being Concepts</span><span class="page__taxonomy-item">#<!-- -->LLM Evaluation</span><span class="page__taxonomy-item">#<!-- -->Principle-Guided Evaluation</span><span class="page__taxonomy-item">#<!-- -->LLM-as-a-Judge</span><span class="page__taxonomy-item">#<!-- -->Supervised Fine-Tuning (SFT)</span><span class="page__taxonomy-item">#<!-- -->Direct Preference Optimization (DPO)</span><span class="page__taxonomy-item">#<!-- -->Explanation Generation</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-7-Web-CogReasoner_Towards_Knowledge-Induced_Cognitive_Reasoning_for_Web_Agents/">[논문리뷰] Web-CogReasoner: Towards Knowledge-Induced Cognitive Reasoning for Web Agents</a></h2><div class="archive__item-excerpt">Xinyu Yang이 [arXiv]에 게시한 &#x27;Web-CogReasoner: Towards Knowledge-Induced Cognitive Reasoning for Web Agents&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-07 13:38:21+0900">2025년 8월 7일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Web Agent</span><span class="page__taxonomy-item">#<!-- -->Cognitive Reasoning</span><span class="page__taxonomy-item">#<!-- -->Knowledge-Induced</span><span class="page__taxonomy-item">#<!-- -->Large Multimodal Models (LMMs)</span><span class="page__taxonomy-item">#<!-- -->Bloom&#x27;s Taxonomy</span><span class="page__taxonomy-item">#<!-- -->Chain-of-Thought (CoT)</span><span class="page__taxonomy-item">#<!-- -->Web-CogDataset</span><span class="page__taxonomy-item">#<!-- -->Web-CogBench</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-7-Training_Long-Context_Multi-Turn_Software_Engineering_Agents_with_Reinforcement_Learning/">[논문리뷰] Training Long-Context, Multi-Turn Software Engineering Agents with Reinforcement Learning</a></h2><div class="archive__item-excerpt">Maksim Nekrashevich이 [arXiv]에 게시한 &#x27;Training Long-Context, Multi-Turn Software Engineering Agents with Reinforcement Learning&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-07 13:38:21+0900">2025년 8월 7일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Software Engineering</span><span class="page__taxonomy-item">#<!-- -->Multi-Turn Interaction</span><span class="page__taxonomy-item">#<!-- -->Long Context</span><span class="page__taxonomy-item">#<!-- -->DAPO</span><span class="page__taxonomy-item">#<!-- -->Autonomous Agents</span><span class="page__taxonomy-item">#<!-- -->SWE-BENCH</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-7-The_Cow_of_Rembrandt_-_Analyzing_Artistic_Prompt_Interpretation_in_Text-to-Image_Models/">[논문리뷰] The Cow of Rembrandt - Analyzing Artistic Prompt Interpretation in Text-to-Image Models</a></h2><div class="archive__item-excerpt">Elisabetta Rocchetti이 [arXiv]에 게시한 &#x27;The Cow of Rembrandt - Analyzing Artistic Prompt Interpretation in Text-to-Image Models&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-07 13:38:21+0900">2025년 8월 7일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Text-to-Image Generation</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->Cross-Attention Analysis</span><span class="page__taxonomy-item">#<!-- -->Content-Style Disentanglement</span><span class="page__taxonomy-item">#<!-- -->Artistic Style Transfer</span><span class="page__taxonomy-item">#<!-- -->Explainable AI</span><span class="page__taxonomy-item">#<!-- -->SDXL</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-7-Sotopia-RL_Reward_Design_for_Social_Intelligence/">[논문리뷰] Sotopia-RL: Reward Design for Social Intelligence</a></h2><div class="archive__item-excerpt">Keyang Xuan이 [arXiv]에 게시한 &#x27;Sotopia-RL: Reward Design for Social Intelligence&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-07 13:38:21+0900">2025년 8월 7일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Social Intelligence</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Reward Design</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Utterance-level Rewards</span><span class="page__taxonomy-item">#<!-- -->Multi-dimensional Rewards</span><span class="page__taxonomy-item">#<!-- -->Partial Observability</span><span class="page__taxonomy-item">#<!-- -->SOTOPIA</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-7-SonicMaster_Towards_Controllable_All-in-One_Music_Restoration_and_Mastering/">[논문리뷰] SonicMaster: Towards Controllable All-in-One Music Restoration and Mastering</a></h2><div class="archive__item-excerpt">Ambuj Mehrish이 [arXiv]에 게시한 &#x27;SonicMaster: Towards Controllable All-in-One Music Restoration and Mastering&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-07 13:38:21+0900">2025년 8월 7일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Music Restoration</span><span class="page__taxonomy-item">#<!-- -->Audio Mastering</span><span class="page__taxonomy-item">#<!-- -->Generative Models</span><span class="page__taxonomy-item">#<!-- -->Flow Matching</span><span class="page__taxonomy-item">#<!-- -->Text-to-Audio</span><span class="page__taxonomy-item">#<!-- -->Audio Quality Enhancement</span><span class="page__taxonomy-item">#<!-- -->Multi-task Learning</span><span class="page__taxonomy-item">#<!-- -->Dataset Creation</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-7-Sel3DCraft_Interactive_Visual_Prompts_for_User-Friendly_Text-to-3D_Generation/">[논문리뷰] Sel3DCraft: Interactive Visual Prompts for User-Friendly Text-to-3D Generation</a></h2><div class="archive__item-excerpt">Hao Huang이 [arXiv]에 게시한 &#x27;Sel3DCraft: Interactive Visual Prompts for User-Friendly Text-to-3D Generation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-07 13:38:21+0900">2025년 8월 7일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Text-to-3D Generation</span><span class="page__taxonomy-item">#<!-- -->Prompt Engineering</span><span class="page__taxonomy-item">#<!-- -->Visual Analytics</span><span class="page__taxonomy-item">#<!-- -->Human-Computer Interaction</span><span class="page__taxonomy-item">#<!-- -->Multi-modal Large Language Models</span><span class="page__taxonomy-item">#<!-- -->3D Model Evaluation</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-7-SEAgent_Self-Evolving_Computer_Use_Agent_with_Autonomous_Learning_from_Experience/">[논문리뷰] SEAgent: Self-Evolving Computer Use Agent with Autonomous Learning from Experience</a></h2><div class="archive__item-excerpt">Xiaoyi Dong이 [arXiv]에 게시한 &#x27;SEAgent: Self-Evolving Computer Use Agent with Autonomous Learning from Experience&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-07 13:38:21+0900">2025년 8월 7일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Computer Use Agent</span><span class="page__taxonomy-item">#<!-- -->Self-Evolving</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Curriculum Learning</span><span class="page__taxonomy-item">#<!-- -->Vision-Language Models</span><span class="page__taxonomy-item">#<!-- -->Experiential Learning</span><span class="page__taxonomy-item">#<!-- -->Specialist-to-Generalist</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-7-Sculptor_Empowering_LLMs_with_Cognitive_Agency_via_Active_Context_Management/">[논문리뷰] Sculptor: Empowering LLMs with Cognitive Agency via Active Context Management</a></h2><div class="archive__item-excerpt">Yunxin Liu이 [arXiv]에 게시한 &#x27;Sculptor: Empowering LLMs with Cognitive Agency via Active Context Management&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-07 13:38:21+0900">2025년 8월 7일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Active Context Management</span><span class="page__taxonomy-item">#<!-- -->Proactive Interference</span><span class="page__taxonomy-item">#<!-- -->Tool Augmentation</span><span class="page__taxonomy-item">#<!-- -->Working Memory</span><span class="page__taxonomy-item">#<!-- -->Context Curation</span><span class="page__taxonomy-item">#<!-- -->Long Context</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-7-RL-PLUS_Countering_Capability_Boundary_Collapse_of_LLMs_in_Reinforcement_Learning_with_Hybrid-policy_Optimization/">[논문리뷰] RL-PLUS: Countering Capability Boundary Collapse of LLMs in Reinforcement Learning with Hybrid-policy Optimization</a></h2><div class="archive__item-excerpt">Kechi Zhang이 [arXiv]에 게시한 &#x27;RL-PLUS: Countering Capability Boundary Collapse of LLMs in Reinforcement Learning with Hybrid-policy Optimization&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-07 13:38:21+0900">2025년 8월 7일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Capability Collapse</span><span class="page__taxonomy-item">#<!-- -->Hybrid Policy Optimization</span><span class="page__taxonomy-item">#<!-- -->Multiple Importance Sampling</span><span class="page__taxonomy-item">#<!-- -->Exploration</span><span class="page__taxonomy-item">#<!-- -->Math Reasoning</span><span class="page__taxonomy-item">#<!-- -->Out-of-Distribution</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-7-Reasoning_Language_Models_for_Root_Cause_Analysis_in_5G_Wireless_Networks/">[논문리뷰] Reasoning Language Models for Root Cause Analysis in 5G Wireless Networks</a></h2><div class="archive__item-excerpt">Haozhe Zhang이 [arXiv]에 게시한 &#x27;Reasoning Language Models for Root Cause Analysis in 5G Wireless Networks&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-07 13:38:21+0900">2025년 8월 7일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Root Cause Analysis</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->5G Wireless Networks</span><span class="page__taxonomy-item">#<!-- -->Supervised Fine-Tuning</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Chain-of-Thought</span><span class="page__taxonomy-item">#<!-- -->TeleLogs Dataset</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-7-Position_The_Current_AI_Conference_Model_is_Unsustainable_Diagnosing_the_Crisis_of_Centralized_AI_Conference/">[논문리뷰] Position: The Current AI Conference Model is Unsustainable! Diagnosing the Crisis of Centralized AI Conference</a></h2><div class="archive__item-excerpt">Jiaying Wu이 [arXiv]에 게시한 &#x27;Position: The Current AI Conference Model is Unsustainable! Diagnosing the Crisis of Centralized AI Conference&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-07 13:38:21+0900">2025년 8월 7일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->AI Conferences</span><span class="page__taxonomy-item">#<!-- -->Sustainability</span><span class="page__taxonomy-item">#<!-- -->Peer Review</span><span class="page__taxonomy-item">#<!-- -->Community Building</span><span class="page__taxonomy-item">#<!-- -->Environmental Impact</span><span class="page__taxonomy-item">#<!-- -->Mental Health</span><span class="page__taxonomy-item">#<!-- -->Centralized Model</span><span class="page__taxonomy-item">#<!-- -->Decentralized Model</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-7-OpenMed_NER_Open-Source_Domain-Adapted_State-of-the-Art_Transformers_for_Biomedical_NER_Across_12_Public_Datasets/">[논문리뷰] OpenMed NER: Open-Source, Domain-Adapted State-of-the-Art Transformers for Biomedical NER Across 12 Public Datasets</a></h2><div class="archive__item-excerpt">MaziyarPanahi이 [arXiv]에 게시한 &#x27;OpenMed NER: Open-Source, Domain-Adapted State-of-the-Art Transformers for Biomedical NER Across 12 Public Datasets&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-07 13:38:21+0900">2025년 8월 7일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Biomedical NER</span><span class="page__taxonomy-item">#<!-- -->Transformer</span><span class="page__taxonomy-item">#<!-- -->Domain Adaptation</span><span class="page__taxonomy-item">#<!-- -->LoRA</span><span class="page__taxonomy-item">#<!-- -->Open-Source</span><span class="page__taxonomy-item">#<!-- -->Named Entity Recognition</span><span class="page__taxonomy-item">#<!-- -->Healthcare AI</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-7-MiDashengLM_Efficient_Audio_Understanding_with_General_Audio_Captions/">[논문리뷰] MiDashengLM: Efficient Audio Understanding with General Audio Captions</a></h2><div class="archive__item-excerpt">Yadong Niu이 [arXiv]에 게시한 &#x27;MiDashengLM: Efficient Audio Understanding with General Audio Captions&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-07 13:38:21+0900">2025년 8월 7일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Audio-Language Model</span><span class="page__taxonomy-item">#<!-- -->General Audio Captions</span><span class="page__taxonomy-item">#<!-- -->Audio Understanding</span><span class="page__taxonomy-item">#<!-- -->Speech Recognition</span><span class="page__taxonomy-item">#<!-- -->Efficient Inference</span><span class="page__taxonomy-item">#<!-- -->Public Datasets</span><span class="page__taxonomy-item">#<!-- -->Multimodality</span><span class="page__taxonomy-item">#<!-- -->Data Curation</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-7-Light-IF_Endowing_LLMs_with_Generalizable_Reasoning_via_Preview_and_Self-Checking_for_Complex_Instruction_Following/">[논문리뷰] Light-IF: Endowing LLMs with Generalizable Reasoning via Preview and Self-Checking for Complex Instruction Following</a></h2><div class="archive__item-excerpt">Liang Xu이 [arXiv]에 게시한 &#x27;Light-IF: Endowing LLMs with Generalizable Reasoning via Preview and Self-Checking for Complex Instruction Following&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-07 13:38:21+0900">2025년 8월 7일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLMs</span><span class="page__taxonomy-item">#<!-- -->Instruction Following</span><span class="page__taxonomy-item">#<!-- -->Reasoning</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Supervised Fine-tuning</span><span class="page__taxonomy-item">#<!-- -->Entropy Regularization</span><span class="page__taxonomy-item">#<!-- -->Self-Checking</span><span class="page__taxonomy-item">#<!-- -->Previewing</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-7-LeanK_Learnable_K_Cache_Channel_Pruning_for_Efficient_Decoding/">[논문리뷰] LeanK: Learnable K Cache Channel Pruning for Efficient Decoding</a></h2><div class="archive__item-excerpt">Yuqing Yang이 [arXiv]에 게시한 &#x27;LeanK: Learnable K Cache Channel Pruning for Efficient Decoding&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-07 13:38:21+0900">2025년 8월 7일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLM</span><span class="page__taxonomy-item">#<!-- -->KV Cache Optimization</span><span class="page__taxonomy-item">#<!-- -->Model Pruning</span><span class="page__taxonomy-item">#<!-- -->Efficient Decoding</span><span class="page__taxonomy-item">#<!-- -->Memory Optimization</span><span class="page__taxonomy-item">#<!-- -->Static Sparsity</span><span class="page__taxonomy-item">#<!-- -->Transformer</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-7-LaTCoder_Converting_Webpage_Design_to_Code_with_Layout-as-Thought/">[논문리뷰] LaTCoder: Converting Webpage Design to Code with Layout-as-Thought</a></h2><div class="archive__item-excerpt">Tianpeng Lv이 [arXiv]에 게시한 &#x27;LaTCoder: Converting Webpage Design to Code with Layout-as-Thought&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-07 13:38:21+0900">2025년 8월 7일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Design-to-Code</span><span class="page__taxonomy-item">#<!-- -->Webpage Generation</span><span class="page__taxonomy-item">#<!-- -->Multimodal Large Language Models (MLLMs)</span><span class="page__taxonomy-item">#<!-- -->Layout Preservation</span><span class="page__taxonomy-item">#<!-- -->Chain-of-Thought (CoT)</span><span class="page__taxonomy-item">#<!-- -->UI Automation</span><span class="page__taxonomy-item">#<!-- -->Code Generation</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-7-Is_Chain-of-Thought_Reasoning_of_LLMs_a_Mirage_A_Data_Distribution_Lens/">[논문리뷰] Is Chain-of-Thought Reasoning of LLMs a Mirage? A Data Distribution Lens</a></h2><div class="archive__item-excerpt">Zhen Tan이 [arXiv]에 게시한 &#x27;Is Chain-of-Thought Reasoning of LLMs a Mirage? A Data Distribution Lens&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-07 13:38:21+0900">2025년 8월 7일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Chain-of-Thought</span><span class="page__taxonomy-item">#<!-- -->LLMs</span><span class="page__taxonomy-item">#<!-- -->OOD Generalization</span><span class="page__taxonomy-item">#<!-- -->Data Distribution Shift</span><span class="page__taxonomy-item">#<!-- -->Reasoning</span><span class="page__taxonomy-item">#<!-- -->Pattern Matching</span><span class="page__taxonomy-item">#<!-- -->DataAlchemy</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-7-IFDECORATOR_Wrapping_Instruction_Following_Reinforcement_Learning_with_Verifiable_Rewards/">[논문리뷰] IFDECORATOR: Wrapping Instruction Following Reinforcement Learning with Verifiable Rewards</a></h2><div class="archive__item-excerpt">Ling-I Wu이 [arXiv]에 게시한 &#x27;IFDECORATOR: Wrapping Instruction Following Reinforcement Learning with Verifiable Rewards&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-07 13:38:21+0900">2025년 8월 7일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Instruction Following</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Reward Hacking</span><span class="page__taxonomy-item">#<!-- -->LLMs</span><span class="page__taxonomy-item">#<!-- -->Curriculum Learning</span><span class="page__taxonomy-item">#<!-- -->Data Flywheel</span><span class="page__taxonomy-item">#<!-- -->Verifiable Rewards</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-7-IAUNet_Instance-Aware_U-Net/">[논문리뷰] IAUNet: Instance-Aware U-Net</a></h2><div class="archive__item-excerpt">Dmytro Fishman이 [arXiv]에 게시한 &#x27;IAUNet: Instance-Aware U-Net&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-07 13:38:21+0900">2025년 8월 7일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Instance Segmentation</span><span class="page__taxonomy-item">#<!-- -->U-Net</span><span class="page__taxonomy-item">#<!-- -->Query-based Model</span><span class="page__taxonomy-item">#<!-- -->Transformer Decoder</span><span class="page__taxonomy-item">#<!-- -->Biomedical Imaging</span><span class="page__taxonomy-item">#<!-- -->Cell Segmentation</span><span class="page__taxonomy-item">#<!-- -->Deep Learning</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-7-HPSv3_Towards_Wide-Spectrum_Human_Preference_Score/">[논문리뷰] HPSv3: Towards Wide-Spectrum Human Preference Score</a></h2><div class="archive__item-excerpt">Hongsheng Li이 [arXiv]에 게시한 &#x27;HPSv3: Towards Wide-Spectrum Human Preference Score&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-07 13:38:21+0900">2025년 8월 7일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Human Preference Score</span><span class="page__taxonomy-item">#<!-- -->Text-to-Image Generation</span><span class="page__taxonomy-item">#<!-- -->Image Evaluation</span><span class="page__taxonomy-item">#<!-- -->Vision-Language Models (VLMs)</span><span class="page__taxonomy-item">#<!-- -->Uncertainty-Aware Ranking Loss</span><span class="page__taxonomy-item">#<!-- -->Dataset</span><span class="page__taxonomy-item">#<!-- -->Iterative Refinement</span><span class="page__taxonomy-item">#<!-- -->Chain-of-Thought</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-7-Gaussian_Variation_Field_Diffusion_for_High-fidelity_Video-to-4D_Synthesis/">[논문리뷰] Gaussian Variation Field Diffusion for High-fidelity Video-to-4D Synthesis</a></h2><div class="archive__item-excerpt">Feng Zhao이 [arXiv]에 게시한 &#x27;Gaussian Variation Field Diffusion for High-fidelity Video-to-4D Synthesis&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-07 13:38:21+0900">2025년 8월 7일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->4D Generation</span><span class="page__taxonomy-item">#<!-- -->Video-to-3D Synthesis</span><span class="page__taxonomy-item">#<!-- -->Gaussian Splatting</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->Latent Space Modeling</span><span class="page__taxonomy-item">#<!-- -->Variational Autoencoder</span><span class="page__taxonomy-item">#<!-- -->Temporal Coherence</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-7-EVOC2RUST_A_Skeleton-guided_Framework_for_Project-Level_C-to-Rust_Translation/">[논문리뷰] EVOC2RUST: A Skeleton-guided Framework for Project-Level C-to-Rust Translation</a></h2><div class="archive__item-excerpt">Dong Chen이 [arXiv]에 게시한 &#x27;EVOC2RUST: A Skeleton-guided Framework for Project-Level C-to-Rust Translation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-07 13:38:21+0900">2025년 8월 7일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->C-to-Rust Conversion</span><span class="page__taxonomy-item">#<!-- -->Project-Level Translation</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Code Synthesis</span><span class="page__taxonomy-item">#<!-- -->Memory Safety</span><span class="page__taxonomy-item">#<!-- -->Software Migration</span><span class="page__taxonomy-item">#<!-- -->Hybrid Translation</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-7-Enhancing_Vision-Language_Model_Training_with_Reinforcement_Learning_in_Synthetic_Worlds_for_Real-World_Success/">[논문리뷰] Enhancing Vision-Language Model Training with Reinforcement Learning in Synthetic Worlds for Real-World Success</a></h2><div class="archive__item-excerpt">Ruslan Rakhimov이 [arXiv]에 게시한 &#x27;Enhancing Vision-Language Model Training with Reinforcement Learning in Synthetic Worlds for Real-World Success&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-07 13:38:21+0900">2025년 8월 7일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Vision-Language Models</span><span class="page__taxonomy-item">#<!-- -->Synthetic Worlds</span><span class="page__taxonomy-item">#<!-- -->Transfer Learning</span><span class="page__taxonomy-item">#<!-- -->PPO</span><span class="page__taxonomy-item">#<!-- -->Actor-Critic</span><span class="page__taxonomy-item">#<!-- -->Embodied AI</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-7-Efficient_Agents_Building_Effective_Agents_While_Reducing_Cost/">[논문리뷰] Efficient Agents: Building Effective Agents While Reducing Cost</a></h2><div class="archive__item-excerpt">Yue Hou이 [arXiv]에 게시한 &#x27;Efficient Agents: Building Effective Agents While Reducing Cost&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-07 13:38:21+0900">2025년 8월 7일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLM Agents</span><span class="page__taxonomy-item">#<!-- -->Cost Efficiency</span><span class="page__taxonomy-item">#<!-- -->Performance-Cost Trade-off</span><span class="page__taxonomy-item">#<!-- -->Agent Frameworks</span><span class="page__taxonomy-item">#<!-- -->GAIA Benchmark</span><span class="page__taxonomy-item">#<!-- -->Optimization</span><span class="page__taxonomy-item">#<!-- -->Resource Management</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-7-DreamVVT_Mastering_Realistic_Video_Virtual_Try-On_in_the_Wild_via_a_Stage-Wise_Diffusion_Transformer_Framework/">[논문리뷰] DreamVVT: Mastering Realistic Video Virtual Try-On in the Wild via a Stage-Wise Diffusion Transformer Framework</a></h2><div class="archive__item-excerpt">Chao Liang이 [arXiv]에 게시한 &#x27;DreamVVT: Mastering Realistic Video Virtual Try-On in the Wild via a Stage-Wise Diffusion Transformer Framework&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-07 13:38:21+0900">2025년 8월 7일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Video Virtual Try-On</span><span class="page__taxonomy-item">#<!-- -->Diffusion Transformers</span><span class="page__taxonomy-item">#<!-- -->Stage-Wise Framework</span><span class="page__taxonomy-item">#<!-- -->Vision-Language Models</span><span class="page__taxonomy-item">#<!-- -->LoRA</span><span class="page__taxonomy-item">#<!-- -->Temporal Consistency</span><span class="page__taxonomy-item">#<!-- -->Garment Preservation</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-7-CoTox_Chain-of-Thought-Based_Molecular_Toxicity_Reasoning_and_Prediction/">[논문리뷰] CoTox: Chain-of-Thought-Based Molecular Toxicity Reasoning and Prediction</a></h2><div class="archive__item-excerpt">Donghyeon Lee이 [arXiv]에 게시한 &#x27;CoTox: Chain-of-Thought-Based Molecular Toxicity Reasoning and Prediction&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-07 13:38:21+0900">2025년 8월 7일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Toxicity Prediction</span><span class="page__taxonomy-item">#<!-- -->Large Language Model</span><span class="page__taxonomy-item">#<!-- -->Chain-of-Thought</span><span class="page__taxonomy-item">#<!-- -->Drug Development</span><span class="page__taxonomy-item">#<!-- -->Cheminformatics</span><span class="page__taxonomy-item">#<!-- -->Interpretable AI</span><span class="page__taxonomy-item">#<!-- -->IUPAC Nomenclature</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-7-C3D-AD_Toward_Continual_3D_Anomaly_Detection_via_Kernel_Attention_with_Learnable_Advisor/">[논문리뷰] C3D-AD: Toward Continual 3D Anomaly Detection via Kernel Attention with Learnable Advisor</a></h2><div class="archive__item-excerpt">Jinbao Wang이 [arXiv]에 게시한 &#x27;C3D-AD: Toward Continual 3D Anomaly Detection via Kernel Attention with Learnable Advisor&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-07 13:38:21+0900">2025년 8월 7일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->3D Anomaly Detection</span><span class="page__taxonomy-item">#<!-- -->Continual Learning</span><span class="page__taxonomy-item">#<!-- -->Kernel Attention</span><span class="page__taxonomy-item">#<!-- -->Learnable Advisor</span><span class="page__taxonomy-item">#<!-- -->Parameter Perturbation</span><span class="page__taxonomy-item">#<!-- -->Point Cloud</span><span class="page__taxonomy-item">#<!-- -->Industrial AI</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-7-A_Coarse-to-Fine_Approach_to_Multi-Modality_3D_Occupancy_Grounding/">[논문리뷰] A Coarse-to-Fine Approach to Multi-Modality 3D Occupancy Grounding</a></h2><div class="archive__item-excerpt">Jianke Zhu이 [arXiv]에 게시한 &#x27;A Coarse-to-Fine Approach to Multi-Modality 3D Occupancy Grounding&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-07 13:38:21+0900">2025년 8월 7일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->3D Occupancy Grounding</span><span class="page__taxonomy-item">#<!-- -->Multi-modal Learning</span><span class="page__taxonomy-item">#<!-- -->Natural Language Understanding</span><span class="page__taxonomy-item">#<!-- -->Autonomous Driving</span><span class="page__taxonomy-item">#<!-- -->Voxel-based Prediction</span><span class="page__taxonomy-item">#<!-- -->Benchmark Dataset</span><span class="page__taxonomy-item">#<!-- -->Coarse-to-Fine</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-7-Agent_Lightning_Train_ANY_AI_Agents_with_Reinforcement_Learning/">[논문리뷰] Agent Lightning: Train ANY AI Agents with Reinforcement Learning</a></h2><div class="archive__item-excerpt">Zilong Wang이 [arXiv]에 게시한 &#x27;Agent Lightning: Train ANY AI Agents with Reinforcement Learning&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-07 13:38:21+0900">2025년 8월 7일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->AI Agents</span><span class="page__taxonomy-item">#<!-- -->Framework</span><span class="page__taxonomy-item">#<!-- -->Markov Decision Process</span><span class="page__taxonomy-item">#<!-- -->Hierarchical RL</span><span class="page__taxonomy-item">#<!-- -->Training-Agent Disaggregation</span><span class="page__taxonomy-item">#<!-- -->Observability</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-6-TRACEALIGN_--_Tracing_the_Drift_Attributing_Alignment_Failures_to_Training-Time_Belief_Sources_in_LLMs/">[논문리뷰] TRACEALIGN -- Tracing the Drift: Attributing Alignment Failures to Training-Time Belief Sources in LLMs</a></h2><div class="archive__item-excerpt">Aman Chadha이 [arXiv]에 게시한 &#x27;TRACEALIGN -- Tracing the Drift: Attributing Alignment Failures to Training-Time Belief Sources in LLMs&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-06 13:46:36+0900">2025년 8월 6일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLM Alignment</span><span class="page__taxonomy-item">#<!-- -->Alignment Drift</span><span class="page__taxonomy-item">#<!-- -->Training Data Provenance</span><span class="page__taxonomy-item">#<!-- -->Belief Conflict Index (BCI)</span><span class="page__taxonomy-item">#<!-- -->Suffix Array</span><span class="page__taxonomy-item">#<!-- -->Safety Interventions</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning from Human Feedback</span><span class="page__taxonomy-item">#<!-- -->Explainable AI</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-6-Tool-integrated_Reinforcement_Learning_for_Repo_Deep_Search/">[논문리뷰] Tool-integrated Reinforcement Learning for Repo Deep Search</a></h2><div class="archive__item-excerpt">Yanzhen Zou이 [arXiv]에 게시한 &#x27;Tool-integrated Reinforcement Learning for Repo Deep Search&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-06 13:46:36+0900">2025년 8월 6일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Issue Localization</span><span class="page__taxonomy-item">#<!-- -->Large Language Models (LLMs)</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning (RL)</span><span class="page__taxonomy-item">#<!-- -->Supervised Fine-tuning (SFT)</span><span class="page__taxonomy-item">#<!-- -->Tool-integrated Agents</span><span class="page__taxonomy-item">#<!-- -->Software Engineering</span><span class="page__taxonomy-item">#<!-- -->Code Search</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-6-Skywork_UniPic_Unified_Autoregressive_Modeling_for_Visual_Understanding_and_Generation/">[논문리뷰] Skywork UniPic: Unified Autoregressive Modeling for Visual Understanding and Generation</a></h2><div class="archive__item-excerpt">Tianyidan Xie이 [arXiv]에 게시한 &#x27;Skywork UniPic: Unified Autoregressive Modeling for Visual Understanding and Generation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-06 13:46:36+0900">2025년 8월 6일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Autoregressive Models</span><span class="page__taxonomy-item">#<!-- -->Multimodal AI</span><span class="page__taxonomy-item">#<!-- -->Image Generation</span><span class="page__taxonomy-item">#<!-- -->Image Editing</span><span class="page__taxonomy-item">#<!-- -->Visual Understanding</span><span class="page__taxonomy-item">#<!-- -->Unified Architecture</span><span class="page__taxonomy-item">#<!-- -->Parameter Efficiency</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-6-Seed_Diffusion_A_Large-Scale_Diffusion_Language_Model_with_High-Speed_Inference/">[논문리뷰] Seed Diffusion: A Large-Scale Diffusion Language Model with High-Speed Inference</a></h2><div class="archive__item-excerpt">Fan Xia이 [arXiv]에 게시한 &#x27;Seed Diffusion: A Large-Scale Diffusion Language Model with High-Speed Inference&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-06 13:46:36+0900">2025년 8월 6일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->Language Models</span><span class="page__taxonomy-item">#<!-- -->Code Generation</span><span class="page__taxonomy-item">#<!-- -->Non-Autoregressive Inference</span><span class="page__taxonomy-item">#<!-- -->High-Speed Inference</span><span class="page__taxonomy-item">#<!-- -->Discrete Diffusion</span><span class="page__taxonomy-item">#<!-- -->LLM Inference</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-6-Multi-human_Interactive_Talking_Dataset/">[논문리뷰] Multi-human Interactive Talking Dataset</a></h2><div class="archive__item-excerpt">Mike Zheng Shou이 [arXiv]에 게시한 &#x27;Multi-human Interactive Talking Dataset&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-06 13:46:36+0900">2025년 8월 6일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Multi-human Video Generation</span><span class="page__taxonomy-item">#<!-- -->Interactive Talking</span><span class="page__taxonomy-item">#<!-- -->Dataset</span><span class="page__taxonomy-item">#<!-- -->Audio-driven Animation</span><span class="page__taxonomy-item">#<!-- -->Pose Control</span><span class="page__taxonomy-item">#<!-- -->Speech Interaction</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-6-LongVie_Multimodal-Guided_Controllable_Ultra-Long_Video_Generation/">[논문리뷰] LongVie: Multimodal-Guided Controllable Ultra-Long Video Generation</a></h2><div class="archive__item-excerpt">Chenyang Si이 [arXiv]에 게시한 &#x27;LongVie: Multimodal-Guided Controllable Ultra-Long Video Generation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-06 13:46:36+0900">2025년 8월 6일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Ultra-long Video Generation</span><span class="page__taxonomy-item">#<!-- -->Multimodal Guidance</span><span class="page__taxonomy-item">#<!-- -->Controllable Video Generation</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->Temporal Consistency</span><span class="page__taxonomy-item">#<!-- -->Visual Quality</span><span class="page__taxonomy-item">#<!-- -->Autoregressive Generation</span><span class="page__taxonomy-item">#<!-- -->Degradation-aware Training</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-6-LiveMCPBench_Can_Agents_Navigate_an_Ocean_of_MCP_Tools/">[논문리뷰] LiveMCPBench: Can Agents Navigate an Ocean of MCP Tools?</a></h2><div class="archive__item-excerpt">Yaojie Lu이 [arXiv]에 게시한 &#x27;LiveMCPBench: Can Agents Navigate an Ocean of MCP Tools?&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-06 13:46:36+0900">2025년 8월 6일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLM Agent</span><span class="page__taxonomy-item">#<!-- -->Tool-use</span><span class="page__taxonomy-item">#<!-- -->MCP</span><span class="page__taxonomy-item">#<!-- -->Benchmark</span><span class="page__taxonomy-item">#<!-- -->Large-scale</span><span class="page__taxonomy-item">#<!-- -->Real-world tasks</span><span class="page__taxonomy-item">#<!-- -->Automated Evaluation</span><span class="page__taxonomy-item">#<!-- -->Meta-tool-learning</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-6-LAMIC_Layout-Aware_Multi-Image_Composition_via_Scalability_of_Multimodal_Diffusion_Transformer/">[논문리뷰] LAMIC: Layout-Aware Multi-Image Composition via Scalability of Multimodal Diffusion Transformer</a></h2><div class="archive__item-excerpt">Shunyu Yao이 [arXiv]에 게시한 &#x27;LAMIC: Layout-Aware Multi-Image Composition via Scalability of Multimodal Diffusion Transformer&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-06 13:46:36+0900">2025년 8월 6일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Multi-Image Composition</span><span class="page__taxonomy-item">#<!-- -->Layout Control</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->Transformer</span><span class="page__taxonomy-item">#<!-- -->Attention Mechanisms</span><span class="page__taxonomy-item">#<!-- -->Training-Free</span><span class="page__taxonomy-item">#<!-- -->Zero-Shot Generalization</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-6-Goedel-Prover-V2_Scaling_Formal_Theorem_Proving_with_Scaffolded_Data_Synthesis_and_Self-Correction/">[논문리뷰] Goedel-Prover-V2: Scaling Formal Theorem Proving with Scaffolded Data Synthesis and Self-Correction</a></h2><div class="archive__item-excerpt">Jui-Hui Chung이 [arXiv]에 게시한 &#x27;Goedel-Prover-V2: Scaling Formal Theorem Proving with Scaffolded Data Synthesis and Self-Correction&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-06 13:46:36+0900">2025년 8월 6일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Automated Theorem Proving</span><span class="page__taxonomy-item">#<!-- -->Formal Verification</span><span class="page__taxonomy-item">#<!-- -->Language Models</span><span class="page__taxonomy-item">#<!-- -->Self-Correction</span><span class="page__taxonomy-item">#<!-- -->Data Synthesis</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Model Averaging</span><span class="page__taxonomy-item">#<!-- -->Lean</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-6-CRINN_Contrastive_Reinforcement_Learning_for_Approximate_Nearest_Neighbor_Search/">[논문리뷰] CRINN: Contrastive Reinforcement Learning for Approximate Nearest Neighbor Search</a></h2><div class="archive__item-excerpt">Jiwei Li이 [arXiv]에 게시한 &#x27;CRINN: Contrastive Reinforcement Learning for Approximate Nearest Neighbor Search&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-06 13:46:36+0900">2025년 8월 6일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Approximate Nearest Neighbor Search</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Code Optimization</span><span class="page__taxonomy-item">#<!-- -->HNSW</span><span class="page__taxonomy-item">#<!-- -->Retrieval-Augmented Generation</span><span class="page__taxonomy-item">#<!-- -->Contrastive Learning</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-6-CompassVerifier_A_Unified_and_Robust_Verifier_for_LLMs_Evaluation_and_Outcome_Reward/">[논문리뷰] CompassVerifier: A Unified and Robust Verifier for LLMs Evaluation and Outcome Reward</a></h2><div class="archive__item-excerpt">Songyang Gao이 [arXiv]에 게시한 &#x27;CompassVerifier: A Unified and Robust Verifier for LLMs Evaluation and Outcome Reward&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-06 13:46:36+0900">2025년 8월 6일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLM Evaluation</span><span class="page__taxonomy-item">#<!-- -->Answer Verification</span><span class="page__taxonomy-item">#<!-- -->Reward Model</span><span class="page__taxonomy-item">#<!-- -->Benchmarking</span><span class="page__taxonomy-item">#<!-- -->Data Augmentation</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Formula Verification</span><span class="page__taxonomy-item">#<!-- -->Hallucination Detection</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-6-ChartCap_Mitigating_Hallucination_of_Dense_Chart_Captioning/">[논문리뷰] ChartCap: Mitigating Hallucination of Dense Chart Captioning</a></h2><div class="archive__item-excerpt">Gunhee Kim이 [arXiv]에 게시한 &#x27;ChartCap: Mitigating Hallucination of Dense Chart Captioning&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-06 13:46:36+0900">2025년 8월 6일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Chart Captioning</span><span class="page__taxonomy-item">#<!-- -->Hallucination Mitigation</span><span class="page__taxonomy-item">#<!-- -->Dataset Generation</span><span class="page__taxonomy-item">#<!-- -->Visual Language Models</span><span class="page__taxonomy-item">#<!-- -->Cycle Consistency</span><span class="page__taxonomy-item">#<!-- -->Reference-Free Metric</span><span class="page__taxonomy-item">#<!-- -->Data Visualization</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-6-AlignGuard-LoRA_Alignment-Preserving_Fine-Tuning_via_Fisher-Guided_Decomposition_and_Riemannian-Geodesic_Collision_Regularization/">[논문리뷰] AlignGuard-LoRA: Alignment-Preserving Fine-Tuning via Fisher-Guided Decomposition and Riemannian-Geodesic Collision Regularization</a></h2><div class="archive__item-excerpt">Aman Chadha이 [arXiv]에 게시한 &#x27;AlignGuard-LoRA: Alignment-Preserving Fine-Tuning via Fisher-Guided Decomposition and Riemannian-Geodesic Collision Regularization&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-06 13:46:36+0900">2025년 8월 6일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Alignment Preservation</span><span class="page__taxonomy-item">#<!-- -->Fine-Tuning</span><span class="page__taxonomy-item">#<!-- -->LoRA</span><span class="page__taxonomy-item">#<!-- -->Fisher Information Matrix</span><span class="page__taxonomy-item">#<!-- -->Catastrophic Forgetting</span><span class="page__taxonomy-item">#<!-- -->LLM Safety</span><span class="page__taxonomy-item">#<!-- -->Riemannian Geometry</span><span class="page__taxonomy-item">#<!-- -->Parameter-Efficient Learning</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-5-VeOmni__Scaling_Any_Modality_Model_Training_with_Model-Centric __Distributed_Recipe_Zoo/">[논문리뷰] VeOmni: Scaling Any Modality Model Training with Model-Centric Distributed Recipe Zoo</a></h2><div class="archive__item-excerpt">Bin Jia이 [arXiv]에 게시한 &#x27;VeOmni: Scaling Any Modality Model Training with Model-Centric Distributed Recipe Zoo&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-05 11:40:52+0900">2025년 8월 5일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Omni-modal LLMs</span><span class="page__taxonomy-item">#<!-- -->Distributed Training</span><span class="page__taxonomy-item">#<!-- -->Model-centric</span><span class="page__taxonomy-item">#<!-- -->Parallelism</span><span class="page__taxonomy-item">#<!-- -->FSDP</span><span class="page__taxonomy-item">#<!-- -->Sequence Parallelism</span><span class="page__taxonomy-item">#<!-- -->Expert Parallelism</span><span class="page__taxonomy-item">#<!-- -->Mixture-of-Experts</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-5-SitEmb-v1.5__Improved_Context-Aware_Dense_Retrieval_for_Semantic __Association_and_Long_Story_Comprehension">[논문리뷰] SitEmb-v1.5: Improved Context-Aware Dense Retrieval for Semantic Association and Long Story Comprehension</a></h2><div class="archive__item-excerpt">Liyan Xu이 [arXiv]에 게시한 &#x27;SitEmb-v1.5: Improved Context-Aware Dense Retrieval for Semantic Association and Long Story Comprehension&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-05 11:40:52+0900">2025년 8월 5일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Dense Retrieval</span><span class="page__taxonomy-item">#<!-- -->Context-Aware Embedding</span><span class="page__taxonomy-item">#<!-- -->RAG</span><span class="page__taxonomy-item">#<!-- -->Long Document Comprehension</span><span class="page__taxonomy-item">#<!-- -->Residual Learning</span><span class="page__taxonomy-item">#<!-- -->Semantic Association</span><span class="page__taxonomy-item">#<!-- -->Text Embedding</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-5-RoboMemory__A_Brain-inspired_Multi-memory_Agentic_Framework_for_Lifelong __Learning_in_Physical_Embodied_Systems/">[논문리뷰] RoboMemory: A Brain-inspired Multi-memory Agentic Framework for Lifelong Learning in Physical Embodied Systems</a></h2><div class="archive__item-excerpt">Junkun Hong이 [arXiv]에 게시한 &#x27;RoboMemory: A Brain-inspired Multi-memory Agentic Framework for Lifelong Learning in Physical Embodied Systems&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-05 11:40:52+0900">2025년 8월 5일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Brain-inspired AI</span><span class="page__taxonomy-item">#<!-- -->Lifelong Learning</span><span class="page__taxonomy-item">#<!-- -->Embodied AI</span><span class="page__taxonomy-item">#<!-- -->Multi-memory Systems</span><span class="page__taxonomy-item">#<!-- -->Knowledge Graph</span><span class="page__taxonomy-item">#<!-- -->Robotics</span><span class="page__taxonomy-item">#<!-- -->Closed-Loop Planning</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-5-Qwen-Image_Technical_Report/">[논문리뷰] Qwen-Image Technical Report</a></h2><div class="archive__item-excerpt">Kaiyuan Gao이 [arXiv]에 게시한 &#x27;Qwen-Image Technical Report&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-05 11:40:52+0900">2025년 8월 5일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Image Generation</span><span class="page__taxonomy-item">#<!-- -->Text-to-Image</span><span class="page__taxonomy-item">#<!-- -->Image Editing</span><span class="page__taxonomy-item">#<!-- -->Text Rendering</span><span class="page__taxonomy-item">#<!-- -->Multimodal Diffusion Transformer</span><span class="page__taxonomy-item">#<!-- -->Curriculum Learning</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Foundation Model</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-5-Personalized_Safety_Alignment_for_Text-to-Image_Diffusion_Models/">[논문리뷰] Personalized Safety Alignment for Text-to-Image Diffusion Models</a></h2><div class="archive__item-excerpt">Kaidong Yu이 [arXiv]에 게시한 &#x27;Personalized Safety Alignment for Text-to-Image Diffusion Models&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-05 11:40:52+0900">2025년 8월 5일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Personalized Safety Alignment</span><span class="page__taxonomy-item">#<!-- -->Text-to-Image Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->DPO</span><span class="page__taxonomy-item">#<!-- -->User Preferences</span><span class="page__taxonomy-item">#<!-- -->Content Moderation</span><span class="page__taxonomy-item">#<!-- -->Generative AI</span><span class="page__taxonomy-item">#<!-- -->Cross-Attention</span><span class="page__taxonomy-item">#<!-- -->Safety Alignment</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-5-Llama-3.1-FoundationAI-SecurityLLM-8B-Instruct_Technical_Report">[논문리뷰] Llama-3.1-FoundationAI-SecurityLLM-8B-Instruct Technical Report</a></h2><div class="archive__item-excerpt">Anu Vellore이 [arXiv]에 게시한 &#x27;Llama-3.1-FoundationAI-SecurityLLM-8B-Instruct Technical Report&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-05 11:40:52+0900">2025년 8월 5일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Large Language Model</span><span class="page__taxonomy-item">#<!-- -->Cybersecurity</span><span class="page__taxonomy-item">#<!-- -->Instruction Tuning</span><span class="page__taxonomy-item">#<!-- -->Direct Preference Optimization</span><span class="page__taxonomy-item">#<!-- -->Cyber Threat Intelligence</span><span class="page__taxonomy-item">#<!-- -->Foundation Model</span><span class="page__taxonomy-item">#<!-- -->Chatbot</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-5-InstructVLA__Vision-Language-Action_Instruction_Tuning_from __Understanding_to_Manipulation/">[논문리뷰] InstructVLA: Vision-Language-Action Instruction Tuning from Understanding to Manipulation</a></h2><div class="archive__item-excerpt">Yang Tian이 [arXiv]에 게시한 &#x27;InstructVLA: Vision-Language-Action Instruction Tuning from Understanding to Manipulation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-05 11:40:52+0900">2025년 8월 5일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Vision-Language-Action (VLA)</span><span class="page__taxonomy-item">#<!-- -->Instruction Tuning</span><span class="page__taxonomy-item">#<!-- -->Multimodal Reasoning</span><span class="page__taxonomy-item">#<!-- -->Robotic Manipulation</span><span class="page__taxonomy-item">#<!-- -->Catastrophic Forgetting</span><span class="page__taxonomy-item">#<!-- -->Mixture-of-Experts (MoE)</span><span class="page__taxonomy-item">#<!-- -->Flow Matching</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-5-Exploitation_Is_All_You_Need..._for_Exploration">[논문리뷰] Exploitation Is All You Need... for Exploration</a></h2><div class="archive__item-excerpt">Jesse Roberts이 [arXiv]에 게시한 &#x27;Exploitation Is All You Need... for Exploration&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-05 11:40:52+0900">2025년 8월 5일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Exploration-Exploitation</span><span class="page__taxonomy-item">#<!-- -->Meta-RL</span><span class="page__taxonomy-item">#<!-- -->Transformer Architecture</span><span class="page__taxonomy-item">#<!-- -->Emergent Behavior</span><span class="page__taxonomy-item">#<!-- -->Multi-Armed Bandits</span><span class="page__taxonomy-item">#<!-- -->Gridworlds</span><span class="page__taxonomy-item">#<!-- -->Pseudo-Thompson Sampling</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-5-Cyber-Zero__Training_Cybersecurity_Agents_without_Runtime/">[논문리뷰] Cyber-Zero: Training Cybersecurity Agents without Runtime</a></h2><div class="archive__item-excerpt">Zijian Wang이 [arXiv]에 게시한 &#x27;Cyber-Zero: Training Cybersecurity Agents without Runtime&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-05 11:40:52+0900">2025년 8월 5일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Cybersecurity Agents</span><span class="page__taxonomy-item">#<!-- -->LLM Training</span><span class="page__taxonomy-item">#<!-- -->Trajectory Synthesis</span><span class="page__taxonomy-item">#<!-- -->Runtime-Free Training</span><span class="page__taxonomy-item">#<!-- -->CTF Challenges</span><span class="page__taxonomy-item">#<!-- -->LLM Simulation</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-5-CellForge__Agentic_Design_of_Virtual_Cell_Models/">[논문리뷰] CellForge: Agentic Design of Virtual Cell Models</a></h2><div class="archive__item-excerpt">Daniel Shao이 [arXiv]에 게시한 &#x27;CellForge: Agentic Design of Virtual Cell Models&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-05 11:40:52+0900">2025년 8월 5일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->AI Scientist</span><span class="page__taxonomy-item">#<!-- -->Multi-Agent System</span><span class="page__taxonomy-item">#<!-- -->Virtual Cell Modeling</span><span class="page__taxonomy-item">#<!-- -->Single-Cell Perturbation Prediction</span><span class="page__taxonomy-item">#<!-- -->Deep Learning</span><span class="page__taxonomy-item">#<!-- -->Automated Model Design</span><span class="page__taxonomy-item">#<!-- -->Code Generation</span><span class="page__taxonomy-item">#<!-- -->Retrieval-Augmented Generation</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-5-Beyond_the_Trade-off__Self-Supervised_Reinforcement_Learning_for __Reasoning_Models&#x27;_Instruction_Following/">[논문리뷰] Beyond the Trade-off: Self-Supervised Reinforcement Learning for Reasoning Models&#x27; Instruction Following</a></h2><div class="archive__item-excerpt">Jiaqing Liang이 [arXiv]에 게시한 &#x27;Beyond the Trade-off: Self-Supervised Reinforcement Learning for Reasoning Models&#x27; Instruction Following&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-05 11:40:52+0900">2025년 8월 5일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Self-Supervised RL</span><span class="page__taxonomy-item">#<!-- -->Instruction Following</span><span class="page__taxonomy-item">#<!-- -->Reasoning Models</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Reward Modeling</span><span class="page__taxonomy-item">#<!-- -->Curriculum Learning</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-5-A_Glimpse_to_Compress__Dynamic_Visual_Token_Pruning_for_Large __Vision-Language_Models/">[논문리뷰] A Glimpse to Compress: Dynamic Visual Token Pruning for Large Vision-Language Models</a></h2><div class="archive__item-excerpt">Zuxuan Wu이 [arXiv]에 게시한 &#x27;A Glimpse to Compress: Dynamic Visual Token Pruning for Large Vision-Language Models&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-05 11:40:52+0900">2025년 8월 5일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Large Vision-Language Models (LVLMs)</span><span class="page__taxonomy-item">#<!-- -->Visual Token Pruning</span><span class="page__taxonomy-item">#<!-- -->Dynamic Compression</span><span class="page__taxonomy-item">#<!-- -->GlimpsePrune</span><span class="page__taxonomy-item">#<!-- -->Computational Efficiency</span><span class="page__taxonomy-item">#<!-- -->VQA</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-5-AgentTTS__Large_Language_Model_Agent_for_Test-time_Compute-optimal __Scaling_Strategy_in_Complex_Tasks/">[논문리뷰] AgentTTS: Large Language Model Agent for Test-time Compute-optimal Scaling Strategy in Complex Tasks</a></h2><div class="archive__item-excerpt">Zhiwei Zhang이 [arXiv]에 게시한 &#x27;AgentTTS: Large Language Model Agent for Test-time Compute-optimal Scaling Strategy in Complex Tasks&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-05 11:40:52+0900">2025년 8월 5일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->LLM Agents</span><span class="page__taxonomy-item">#<!-- -->Test-time Scaling</span><span class="page__taxonomy-item">#<!-- -->Compute Optimization</span><span class="page__taxonomy-item">#<!-- -->Multi-stage Tasks</span><span class="page__taxonomy-item">#<!-- -->Resource Allocation</span><span class="page__taxonomy-item">#<!-- -->Search Efficiency</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-4-SWE-Exp__Experience-Driven_Software_Issue_Resolution/">[논문리뷰] SWE-Exp: Experience-Driven Software Issue Resolution</a></h2><div class="archive__item-excerpt">Heng Lian이 [arXiv]에 게시한 &#x27;SWE-Exp: Experience-Driven Software Issue Resolution&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-04 12:17:01+0900">2025년 8월 4일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Software Issue Resolution</span><span class="page__taxonomy-item">#<!-- -->LLM Agents</span><span class="page__taxonomy-item">#<!-- -->Experience-Driven Learning</span><span class="page__taxonomy-item">#<!-- -->Automated Program Repair</span><span class="page__taxonomy-item">#<!-- -->Multi-Agent Systems</span><span class="page__taxonomy-item">#<!-- -->Knowledge Management</span><span class="page__taxonomy-item">#<!-- -->Continuous Learning</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-4-SWE-Debate__Competitive_Multi-Agent_Debate_for_Software_Issue_Resolution/">[논문리뷰] SWE-Debate: Competitive Multi-Agent Debate for Software Issue Resolution</a></h2><div class="archive__item-excerpt">Heng Lian이 [arXiv]에 게시한 &#x27;SWE-Debate: Competitive Multi-Agent Debate for Software Issue Resolution&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-04 12:17:01+0900">2025년 8월 4일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Multi-Agent System</span><span class="page__taxonomy-item">#<!-- -->Software Engineering</span><span class="page__taxonomy-item">#<!-- -->Fault Localization</span><span class="page__taxonomy-item">#<!-- -->Issue Resolution</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Competitive Debate</span><span class="page__taxonomy-item">#<!-- -->Graph Traversal</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-4-SpA2V__Harnessing_Spatial_Auditory_Cues_for_Audio-driven_Spatially-aware __Video_Generation/">[논문리뷰] SpA2V: Harnessing Spatial Auditory Cues for Audio-driven Spatially-aware Video Generation</a></h2><div class="archive__item-excerpt">Long Chen이 [arXiv]에 게시한 &#x27;SpA2V: Harnessing Spatial Auditory Cues for Audio-driven Spatially-aware Video Generation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-04 12:17:01+0900">2025년 8월 4일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Audio-driven Video Generation</span><span class="page__taxonomy-item">#<!-- -->Spatial Auditory Cues</span><span class="page__taxonomy-item">#<!-- -->Video Scene Layout</span><span class="page__taxonomy-item">#<!-- -->MLLM</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->Training-free</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-4-PixNerd__Pixel_Neural_Field_Diffusion/">[논문리뷰] PixNerd: Pixel Neural Field Diffusion</a></h2><div class="archive__item-excerpt">Limin Wang이 [arXiv]에 게시한 &#x27;PixNerd: Pixel Neural Field Diffusion&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-04 12:17:01+0900">2025년 8월 4일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->Neural Fields</span><span class="page__taxonomy-item">#<!-- -->Pixel Space</span><span class="page__taxonomy-item">#<!-- -->Generative Models</span><span class="page__taxonomy-item">#<!-- -->Image Synthesis</span><span class="page__taxonomy-item">#<!-- -->Transformer Architecture</span><span class="page__taxonomy-item">#<!-- -->End-to-End Learning</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-4-Multimodal_Referring_Segmentation__A_Survey/">[논문리뷰] Multimodal Referring Segmentation: A Survey</a></h2><div class="archive__item-excerpt">Zuxuan Wu이 [arXiv]에 게시한 &#x27;Multimodal Referring Segmentation: A Survey&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-04 12:17:01+0900">2025년 8월 4일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Multimodal Learning</span><span class="page__taxonomy-item">#<!-- -->Referring Segmentation</span><span class="page__taxonomy-item">#<!-- -->Vision-Language Models</span><span class="page__taxonomy-item">#<!-- -->Image Segmentation</span><span class="page__taxonomy-item">#<!-- -->Video Segmentation</span><span class="page__taxonomy-item">#<!-- -->3D Vision</span><span class="page__taxonomy-item">#<!-- -->Survey</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-4-Learning_an_Efficient_Multi-Turn_Dialogue_Evaluator_from_Multiple_Judges/">[논문리뷰] Learning an Efficient Multi-Turn Dialogue Evaluator from Multiple Judges</a></h2><div class="archive__item-excerpt">Chengfei Lv이 [arXiv]에 게시한 &#x27;Learning an Efficient Multi-Turn Dialogue Evaluator from Multiple Judges&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-04 12:17:01+0900">2025년 8월 4일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Multi-Turn Dialogue Evaluation</span><span class="page__taxonomy-item">#<!-- -->LLM-as-a-Judge</span><span class="page__taxonomy-item">#<!-- -->Multi-Judge Aggregation</span><span class="page__taxonomy-item">#<!-- -->Preference Learning</span><span class="page__taxonomy-item">#<!-- -->Dialogue Quality Assessment</span><span class="page__taxonomy-item">#<!-- -->Maximum Likelihood Estimation</span><span class="page__taxonomy-item">#<!-- -->Computational Efficiency</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-4-Investigating_Hallucination_in_Conversations_for_Low_Resource_Languages/">[논문리뷰] Investigating Hallucination in Conversations for Low Resource Languages</a></h2><div class="archive__item-excerpt">Fatemeh Jamshidi이 [arXiv]에 게시한 &#x27;Investigating Hallucination in Conversations for Low Resource Languages&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-04 12:17:01+0900">2025년 8월 4일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->LLM Hallucination</span><span class="page__taxonomy-item">#<!-- -->Low-resource Languages</span><span class="page__taxonomy-item">#<!-- -->Conversational AI</span><span class="page__taxonomy-item">#<!-- -->ROUGE Score</span><span class="page__taxonomy-item">#<!-- -->Cross-lingual Evaluation</span><span class="page__taxonomy-item">#<!-- -->Factual Consistency</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-4-IGL-Nav__Incremental_3D_Gaussian_Localization_for_Image-goal_Navigation/">[논문리뷰] IGL-Nav: Incremental 3D Gaussian Localization for Image-goal Navigation</a></h2><div class="archive__item-excerpt">Jianjiang Feng이 [arXiv]에 게시한 &#x27;IGL-Nav: Incremental 3D Gaussian Localization for Image-goal Navigation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-04 12:17:01+0900">2025년 8월 4일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Image-goal Navigation</span><span class="page__taxonomy-item">#<!-- -->3D Gaussian Splatting (3DGS)</span><span class="page__taxonomy-item">#<!-- -->Incremental Scene Representation</span><span class="page__taxonomy-item">#<!-- -->Coarse-to-fine Localization</span><span class="page__taxonomy-item">#<!-- -->Embodied AI</span><span class="page__taxonomy-item">#<!-- -->Robotics</span><span class="page__taxonomy-item">#<!-- -->Differentiable Rendering</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-4-Beyond_Fixed__Variable-Length_Denoising_for_Diffusion_Large_Language __Models/">[논문리뷰] Beyond Fixed: Variable-Length Denoising for Diffusion Large Language Models</a></h2><div class="archive__item-excerpt">Jiaqi Wang이 [arXiv]에 게시한 &#x27;Beyond Fixed: Variable-Length Denoising for Diffusion Large Language Models&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-04 12:17:01+0900">2025년 8월 4일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Diffusion Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Variable-Length Generation</span><span class="page__taxonomy-item">#<!-- -->Dynamic Length Adaptation</span><span class="page__taxonomy-item">#<!-- -->Denoising Strategy</span><span class="page__taxonomy-item">#<!-- -->Inference Optimization</span><span class="page__taxonomy-item">#<!-- -->Computational Efficiency</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-4-3D-R1__Enhancing_Reasoning_in_3D_VLMs_for_Unified_Scene_Understanding/">[논문리뷰] 3D-R1: Enhancing Reasoning in 3D VLMs for Unified Scene Understanding</a></h2><div class="archive__item-excerpt">Hao Tang이 [arXiv]에 게시한 &#x27;3D-R1: Enhancing Reasoning in 3D VLMs for Unified Scene Understanding&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-04 12:17:01+0900">2025년 8월 4일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->3D Vision-Language Models</span><span class="page__taxonomy-item">#<!-- -->Reasoning</span><span class="page__taxonomy-item">#<!-- -->Scene Understanding</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Chain-of-Thought</span><span class="page__taxonomy-item">#<!-- -->Dynamic View Selection</span><span class="page__taxonomy-item">#<!-- -->Multi-task Learning</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-3-villa-X__Enhancing_Latent_Action_Modeling_in_Vision-Language-Action__Models/">[논문리뷰] villa-X: Enhancing Latent Action Modeling in Vision-Language-Action Models</a></h2><div class="archive__item-excerpt">Kaixin Wang이 [arXiv]에 게시한 &#x27;villa-X: Enhancing Latent Action Modeling in Vision-Language-Action Models&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-03 07:35:17+0900">2025년 8월 3일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Vision-Language-Action Models</span><span class="page__taxonomy-item">#<!-- -->Latent Actions</span><span class="page__taxonomy-item">#<!-- -->Robot Manipulation</span><span class="page__taxonomy-item">#<!-- -->Pre-training</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span><span class="page__taxonomy-item">#<!-- -->Proprioceptive Feedback</span><span class="page__taxonomy-item">#<!-- -->Foundation Models</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-3-TARS__MinMax_Token-Adaptive_Preference_Strategy_for_Hallucination__Reduction_in_MLLMs/">[논문리뷰] TARS: MinMax Token-Adaptive Preference Strategy for Hallucination Reduction in MLLMs</a></h2><div class="archive__item-excerpt">Jiasheng Tang이 [arXiv]에 게시한 &#x27;TARS: MinMax Token-Adaptive Preference Strategy for Hallucination Reduction in MLLMs&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-03 07:35:17+0900">2025년 8월 3일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->MLLMs</span><span class="page__taxonomy-item">#<!-- -->Hallucination Reduction</span><span class="page__taxonomy-item">#<!-- -->Preference Optimization</span><span class="page__taxonomy-item">#<!-- -->Min-Max Optimization</span><span class="page__taxonomy-item">#<!-- -->Token-Adaptive Strategy</span><span class="page__taxonomy-item">#<!-- -->Spectral Regularization</span><span class="page__taxonomy-item">#<!-- -->Visual Grounding</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-3-Seed-Prover__Deep_and_Broad_Reasoning_for_Automated_Theorem_Proving/">[논문리뷰] Seed-Prover: Deep and Broad Reasoning for Automated Theorem Proving</a></h2><div class="archive__item-excerpt">Zhicheng Jiang이 [arXiv]에 게시한 &#x27;Seed-Prover: Deep and Broad Reasoning for Automated Theorem Proving&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-03 07:35:17+0900">2025년 8월 3일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Automated Theorem Proving</span><span class="page__taxonomy-item">#<!-- -->Large Language Models</span><span class="page__taxonomy-item">#<!-- -->Formal Verification</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Lean</span><span class="page__taxonomy-item">#<!-- -->Geometry Reasoning</span><span class="page__taxonomy-item">#<!-- -->Chain-of-Thought</span><span class="page__taxonomy-item">#<!-- -->Lemma-Style Proving</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-3-Scalable_Multi-Task_Reinforcement_Learning_for_Generalizable_Spatial__Intelligence_in_Visuomotor_Agents/">[논문리뷰] Scalable Multi-Task Reinforcement Learning for Generalizable Spatial Intelligence in Visuomotor Agents</a></h2><div class="archive__item-excerpt">Anji Liu이 [arXiv]에 게시한 &#x27;Scalable Multi-Task Reinforcement Learning for Generalizable Spatial Intelligence in Visuomotor Agents&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-03 07:35:17+0900">2025년 8월 3일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Reinforcement Learning</span><span class="page__taxonomy-item">#<!-- -->Multi-Task Learning</span><span class="page__taxonomy-item">#<!-- -->Visuomotor Agents</span><span class="page__taxonomy-item">#<!-- -->Spatial Reasoning</span><span class="page__taxonomy-item">#<!-- -->Generalization</span><span class="page__taxonomy-item">#<!-- -->Minecraft</span><span class="page__taxonomy-item">#<!-- -->Cross-View Goal Specification</span><span class="page__taxonomy-item">#<!-- -->Automated Task Synthesis</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-3-RecGPT_Technical_Report/">[논문리뷰] RecGPT Technical Report</a></h2><div class="archive__item-excerpt">Jian Wu이 [arXiv]에 게시한 &#x27;RecGPT Technical Report&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-03 07:35:17+0900">2025년 8월 3일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Recommender Systems</span><span class="page__taxonomy-item">#<!-- -->Large Language Models (LLMs)</span><span class="page__taxonomy-item">#<!-- -->User Intent Modeling</span><span class="page__taxonomy-item">#<!-- -->Multi-Stage Training</span><span class="page__taxonomy-item">#<!-- -->Human-in-the-Loop</span><span class="page__taxonomy-item">#<!-- -->E-commerce</span><span class="page__taxonomy-item">#<!-- -->Filter Bubble Mitigation</span><span class="page__taxonomy-item">#<!-- -->Matthew Effect</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-3-Phi-Ground_Tech_Report__Advancing_Perception_in_GUI_Grounding/">[논문리뷰] Phi-Ground Tech Report: Advancing Perception in GUI Grounding</a></h2><div class="archive__item-excerpt">Kai Qiu이 [arXiv]에 게시한 &#x27;Phi-Ground Tech Report: Advancing Perception in GUI Grounding&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-03 07:35:17+0900">2025년 8월 3일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->GUI grounding</span><span class="page__taxonomy-item">#<!-- -->AI agent</span><span class="page__taxonomy-item">#<!-- -->Large Multi-modal Model</span><span class="page__taxonomy-item">#<!-- -->Perception</span><span class="page__taxonomy-item">#<!-- -->Data Augmentation</span><span class="page__taxonomy-item">#<!-- -->Direct Preference Optimization</span><span class="page__taxonomy-item">#<!-- -->Computational Efficiency</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-3-Persona_Vectors__Monitoring_and_Controlling_Character_Traits_in_Language__Models/">[논문리뷰] Persona Vectors: Monitoring and Controlling Character Traits in Language Models</a></h2><div class="archive__item-excerpt">Jack Lindsey이 [arXiv]에 게시한 &#x27;Persona Vectors: Monitoring and Controlling Character Traits in Language Models&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-03 07:35:17+0900">2025년 8월 3일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Large Language Models (LLMs)</span><span class="page__taxonomy-item">#<!-- -->Persona Control</span><span class="page__taxonomy-item">#<!-- -->Activation Steering</span><span class="page__taxonomy-item">#<!-- -->Finetuning</span><span class="page__taxonomy-item">#<!-- -->Behavioral Shift Detection</span><span class="page__taxonomy-item">#<!-- -->Interpretability</span><span class="page__taxonomy-item">#<!-- -->Data Filtering</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-3-On_the_Expressiveness_of_Softmax_Attention__A_Recurrent_Neural_Network__Perspective/">[논문리뷰] On the Expressiveness of Softmax Attention: A Recurrent Neural Network Perspective</a></h2><div class="archive__item-excerpt">Eric C. Larson이 [arXiv]에 게시한 &#x27;On the Expressiveness of Softmax Attention: A Recurrent Neural Network Perspective&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-03 07:35:17+0900">2025년 8월 3일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Softmax Attention</span><span class="page__taxonomy-item">#<!-- -->Linear Attention</span><span class="page__taxonomy-item">#<!-- -->Recurrent Neural Networks (RNNs)</span><span class="page__taxonomy-item">#<!-- -->Taylor Series Expansion</span><span class="page__taxonomy-item">#<!-- -->Attention Mechanisms</span><span class="page__taxonomy-item">#<!-- -->Expressiveness</span><span class="page__taxonomy-item">#<!-- -->Transformer Architectures</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-3-NeRF_Is_a_Valuable_Assistant_for_3D_Gaussian_Splatting/">[논문리뷰] NeRF Is a Valuable Assistant for 3D Gaussian Splatting</a></h2><div class="archive__item-excerpt">ZeSheng Wang이 [arXiv]에 게시한 &#x27;NeRF Is a Valuable Assistant for 3D Gaussian Splatting&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-03 07:35:17+0900">2025년 8월 3일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->NeRF</span><span class="page__taxonomy-item">#<!-- -->3D Gaussian Splatting</span><span class="page__taxonomy-item">#<!-- -->Hybrid Model</span><span class="page__taxonomy-item">#<!-- -->Joint Optimization</span><span class="page__taxonomy-item">#<!-- -->Scene Representation</span><span class="page__taxonomy-item">#<!-- -->Neural Rendering</span><span class="page__taxonomy-item">#<!-- -->Residual Learning</span><span class="page__taxonomy-item">#<!-- -->Sparse View</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-3-iLRM__An_Iterative_Large_3D_Reconstruction_Model/">[논문리뷰] iLRM: An Iterative Large 3D Reconstruction Model</a></h2><div class="archive__item-excerpt">Abdelrahman Mohamed이 [arXiv]에 게시한 &#x27;iLRM: An Iterative Large 3D Reconstruction Model&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-03 07:35:17+0900">2025년 8월 3일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->3D Reconstruction</span><span class="page__taxonomy-item">#<!-- -->Gaussian Splatting</span><span class="page__taxonomy-item">#<!-- -->Iterative Refinement</span><span class="page__taxonomy-item">#<!-- -->Transformer Architecture</span><span class="page__taxonomy-item">#<!-- -->Multi-view Learning</span><span class="page__taxonomy-item">#<!-- -->Scalability</span><span class="page__taxonomy-item">#<!-- -->Feed-forward Models</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-3-Flow_Equivariant_Recurrent_Neural_Networks/">[논문리뷰] Flow Equivariant Recurrent Neural Networks</a></h2><div class="archive__item-excerpt">T. Anderson Keller이 [arXiv]에 게시한 &#x27;Flow Equivariant Recurrent Neural Networks&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-03 07:35:17+0900">2025년 8월 3일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Flow Equivariance</span><span class="page__taxonomy-item">#<!-- -->Recurrent Neural Networks</span><span class="page__taxonomy-item">#<!-- -->Sequence Models</span><span class="page__taxonomy-item">#<!-- -->Group Equivariance</span><span class="page__taxonomy-item">#<!-- -->Lie Subgroups</span><span class="page__taxonomy-item">#<!-- -->Generalization</span><span class="page__taxonomy-item">#<!-- -->Time-Parameterized Symmetries</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-3-Enhanced_Arabic_Text_Retrieval_with_Attentive_Relevance_Scoring/">[논문리뷰] Enhanced Arabic Text Retrieval with Attentive Relevance Scoring</a></h2><div class="archive__item-excerpt">Abdenour Hadid이 [arXiv]에 게시한 &#x27;Enhanced Arabic Text Retrieval with Attentive Relevance Scoring&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-03 07:35:17+0900">2025년 8월 3일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Arabic NLP</span><span class="page__taxonomy-item">#<!-- -->Dense Passage Retrieval</span><span class="page__taxonomy-item">#<!-- -->Attentive Relevance Scoring</span><span class="page__taxonomy-item">#<!-- -->Information Retrieval</span><span class="page__taxonomy-item">#<!-- -->Question Answering</span><span class="page__taxonomy-item">#<!-- -->Transformer Models</span><span class="page__taxonomy-item">#<!-- -->Semantic Matching</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-3-Efficient_Machine_Unlearning_via_Influence_Approximation/">[논문리뷰] Efficient Machine Unlearning via Influence Approximation</a></h2><div class="archive__item-excerpt">Enhong Chen이 [arXiv]에 게시한 &#x27;Efficient Machine Unlearning via Influence Approximation&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-03 07:35:17+0900">2025년 8월 3일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Machine Unlearning</span><span class="page__taxonomy-item">#<!-- -->Influence Function</span><span class="page__taxonomy-item">#<!-- -->Incremental Learning</span><span class="page__taxonomy-item">#<!-- -->Privacy Protection</span><span class="page__taxonomy-item">#<!-- -->Gradient Optimization</span><span class="page__taxonomy-item">#<!-- -->Model Editing</span><span class="page__taxonomy-item">#<!-- -->Computational Efficiency</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-3-C3__A_Bilingual_Benchmark_for_Spoken_Dialogue_Models_Exploring__Challenges_in_Complex_Conversations/">[논문리뷰] C3: A Bilingual Benchmark for Spoken Dialogue Models Exploring Challenges in Complex Conversations</a></h2><div class="archive__item-excerpt">Yiwen Guo이 [arXiv]에 게시한 &#x27;C3: A Bilingual Benchmark for Spoken Dialogue Models Exploring Challenges in Complex Conversations&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-03 07:35:17+0900">2025년 8월 3일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Spoken Dialogue Models</span><span class="page__taxonomy-item">#<!-- -->Bilingual Benchmark</span><span class="page__taxonomy-item">#<!-- -->Complex Conversations</span><span class="page__taxonomy-item">#<!-- -->Ambiguity Resolution</span><span class="page__taxonomy-item">#<!-- -->Context Understanding</span><span class="page__taxonomy-item">#<!-- -->LLM Evaluation</span><span class="page__taxonomy-item">#<!-- -->Human-Computer Interaction</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-3-Beyond_Linear_Bottlenecks__Spline-Based_Knowledge_Distillation_for__Culturally_Diverse_Art_Style_Classification/">[논문리뷰] Beyond Linear Bottlenecks: Spline-Based Knowledge Distillation for Culturally Diverse Art Style Classification</a></h2><div class="archive__item-excerpt">Abdelmalik Taleb-Ahmed이 [arXiv]에 게시한 &#x27;Beyond Linear Bottlenecks: Spline-Based Knowledge Distillation for Culturally Diverse Art Style Classification&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-03 07:35:17+0900">2025년 8월 3일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Kolmogorov-Arnold Networks</span><span class="page__taxonomy-item">#<!-- -->Knowledge Distillation</span><span class="page__taxonomy-item">#<!-- -->Art Style Classification</span><span class="page__taxonomy-item">#<!-- -->Self-Supervised Learning</span><span class="page__taxonomy-item">#<!-- -->Spline-Based Activation</span><span class="page__taxonomy-item">#<!-- -->Dual-Teacher</span><span class="page__taxonomy-item">#<!-- -->Gram Matrix</span></div></div></article><article class="archive__item"><h2 class="archive__item-title"><a href="/secrett2633.github.io/ai/review/2025-8-3-AgroBench__Vision-Language_Model_Benchmark_in_Agriculture/">[논문리뷰] AgroBench: Vision-Language Model Benchmark in Agriculture</a></h2><div class="archive__item-excerpt">Yoshitaka Ushiku이 [arXiv]에 게시한 &#x27;AgroBench: Vision-Language Model Benchmark in Agriculture&#x27; 논문에 대한 자세한 리뷰입니다.</div><div class="archive__item-meta"><time dateTime="2025-08-03 07:35:17+0900">2025년 8월 3일</time><div class="page__taxonomy mt-2"><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Vision-Language Models</span><span class="page__taxonomy-item">#<!-- -->Agriculture</span><span class="page__taxonomy-item">#<!-- -->Benchmarking</span><span class="page__taxonomy-item">#<!-- -->Disease Identification</span><span class="page__taxonomy-item">#<!-- -->Pest Management</span><span class="page__taxonomy-item">#<!-- -->Crop Management</span><span class="page__taxonomy-item">#<!-- -->Agronomy</span></div></div></article></div></main><aside class="lg:w-80"><div class="sidebar sticky"><nav class="space-y-4"><div><h4 class="font-medium text-gray-900 mb-2">Backend</h4><ul class="space-y-1 ml-4"><li><a href="/backend/django/" class="text-sm text-gray-600 hover:text-primary-600 block py-1">Django</a></li><li><a href="/backend/logging/" class="text-sm text-gray-600 hover:text-primary-600 block py-1">Logging</a></li></ul></div><div><h4 class="font-medium text-gray-900 mb-2">Python</h4><ul class="space-y-1 ml-4"><li><a href="/python/pep/" class="text-sm text-gray-600 hover:text-primary-600 block py-1">PEP</a></li></ul></div><div><h4 class="font-medium text-gray-900 mb-2">AI/ML</h4><ul class="space-y-1 ml-4"><li><a href="/ai/llm/" class="text-sm text-gray-600 hover:text-primary-600 block py-1">LLM</a></li><li><a href="/ai/review/" class="text-sm text-gray-600 hover:text-primary-600 block py-1">Review</a></li></ul></div><div><h4 class="font-medium text-gray-900 mb-2">DevOps</h4><ul class="space-y-1 ml-4"><li><a href="/devops/nginx/" class="text-sm text-gray-600 hover:text-primary-600 block py-1">Nginx</a></li><li><a href="/devops/docker/" class="text-sm text-gray-600 hover:text-primary-600 block py-1">Docker</a></li><li><a href="/devops/safeline/" class="text-sm text-gray-600 hover:text-primary-600 block py-1">SafeLine</a></li><li><a href="/devops/jenkins/" class="text-sm text-gray-600 hover:text-primary-600 block py-1">Jenkins</a></li><li><a href="/devops/github-actions/" class="text-sm text-gray-600 hover:text-primary-600 block py-1">GitHub Actions</a></li><li><a href="/devops/aws/" class="text-sm text-gray-600 hover:text-primary-600 block py-1">AWS</a></li></ul></div><div><h4 class="font-medium text-gray-900 mb-2">etc</h4><ul class="space-y-1 ml-4"><li><a href="/etc/me/" class="text-sm text-gray-600 hover:text-primary-600 block py-1">Me</a></li><li><a href="/etc/chrome-extension/" class="text-sm text-gray-600 hover:text-primary-600 block py-1">Chrome Extension</a></li></ul></div></nav></div></aside></div></div><div id="footer" class="page__footer"><footer class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8"><div class="text-center text-gray-500 text-sm"><p>© 2025 secrett2633. All rights reserved.</p></div></footer></div><!--/$--></main><div id="footer" class="page__footer"><footer class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8"><div class="text-center text-gray-500 text-sm"><p>© 2025 secrett2633. All rights reserved.</p></div></footer></div></div><script src="/secrett2633.github.io/_next/static/chunks/webpack-69f14ab6f9497210.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0]);self.__next_f.push([2,null])</script><script>self.__next_f.push([1,"1:HL[\"/secrett2633.github.io/_next/static/css/b9d6ec750ad82add.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"2:I[5751,[],\"\"]\n4:I[4281,[\"231\",\"static/chunks/231-c4b666723e6aae68.js\",\"257\",\"static/chunks/app/categories/%5Bcategory%5D/page-0d5ca9ae8400631f.js\"],\"default\"]\n5:I[231,[\"231\",\"static/chunks/231-c4b666723e6aae68.js\",\"257\",\"static/chunks/app/categories/%5Bcategory%5D/page-0d5ca9ae8400631f.js\"],\"\"]\n6:I[8573,[\"231\",\"static/chunks/231-c4b666723e6aae68.js\",\"257\",\"static/chunks/app/categories/%5Bcategory%5D/page-0d5ca9ae8400631f.js\"],\"default\"]\n7:I[9275,[],\"\"]\n9:I[1343,[],\"\"]\nb:I[6130,[],\"\"]\n8:[\"category\",\"review\",\"d\"]\nc:[]\n"])</script><script>self.__next_f.push([1,"0:[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/secrett2633.github.io/_next/static/css/b9d6ec750ad82add.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]],[\"$\",\"$L2\",null,{\"buildId\":\"QEl6I8KSnTmzUXH3R0Jbm\",\"assetPrefix\":\"/secrett2633.github.io\",\"initialCanonicalUrl\":\"/categories/review/\",\"initialTree\":[\"\",{\"children\":[\"categories\",{\"children\":[[\"category\",\"review\",\"d\"],{\"children\":[\"__PAGE__?{\\\"category\\\":\\\"review\\\"}\",{}]}]}]},\"$undefined\",\"$undefined\",true],\"initialSeedData\":[\"\",{\"children\":[\"categories\",{\"children\":[[\"category\",\"review\",\"d\"],{\"children\":[\"__PAGE__\",{},[[\"$L3\",[[\"$\",\"$L4\",null,{}],[\"$\",\"div\",null,{\"className\":\"initial-content\",\"children\":[\"$\",\"div\",null,{\"className\":\"flex flex-col lg:flex-row gap-8\",\"children\":[[\"$\",\"main\",null,{\"className\":\"flex-1\",\"children\":[[\"$\",\"h1\",null,{\"className\":\"page__title\",\"children\":[\"Review\",\" 카테고리\"]}],[\"$\",\"div\",null,{\"className\":\"entries-list\",\"children\":[[\"$\",\"article\",\"2025-10-2-Why_Cant_Transformers_Learn_Multiplication_Reverse-Engineering_Reveals_Long-Range_Dependency_Pitfalls\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-10-2-Why_Cant_Transformers_Learn_Multiplication_Reverse-Engineering_Reveals_Long-Range_Dependency_Pitfalls/\",\"children\":\"[논문리뷰] Why Can't Transformers Learn Multiplication? Reverse-Engineering Reveals Long-Range Dependency Pitfalls\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Stuart Shieber이 [arXiv]에 게시한 'Why Can't Transformers Learn Multiplication? Reverse-Engineering Reveals Long-Range Dependency Pitfalls' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-02 13:30:22+0900\",\"children\":\"2025년 10월 2일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Transformers\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Transformers\"]}],[\"$\",\"span\",\"Multiplication\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multiplication\"]}],[\"$\",\"span\",\"Long-Range Dependencies\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Long-Range Dependencies\"]}],[\"$\",\"span\",\"Implicit Chain-of-Thought\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Implicit Chain-of-Thought\"]}],[\"$\",\"span\",\"Attention Mechanisms\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Attention Mechanisms\"]}],[\"$\",\"span\",\"Inductive Bias\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Inductive Bias\"]}],[\"$\",\"span\",\"Reverse Engineering\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reverse Engineering\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-10-2-VLM-FO1_Bridging_the_Gap_Between_High-Level_Reasoning_and_Fine-Grained_Perception_in_VLMs\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-10-2-VLM-FO1_Bridging_the_Gap_Between_High-Level_Reasoning_and_Fine-Grained_Perception_in_VLMs/\",\"children\":\"[논문리뷰] VLM-FO1: Bridging the Gap Between High-Level Reasoning and Fine-Grained Perception in VLMs\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"이 [arXiv]에 게시한 'VLM-FO1: Bridging the Gap Between High-Level Reasoning and Fine-Grained Perception in VLMs' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-02 13:30:22+0900\",\"children\":\"2025년 10월 2일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Vision-Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision-Language Models\"]}],[\"$\",\"span\",\"Object Grounding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Object Grounding\"]}],[\"$\",\"span\",\"Fine-grained Perception\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Fine-grained Perception\"]}],[\"$\",\"span\",\"Hybrid Region Encoder\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Hybrid Region Encoder\"]}],[\"$\",\"span\",\"Plug-and-play\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Plug-and-play\"]}],[\"$\",\"span\",\"Two-stage Training\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Two-stage Training\"]}],[\"$\",\"span\",\"Visual Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Visual Reasoning\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-10-2-VLA-RFT_Vision-Language-Action_Reinforcement_Fine-tuning_with_Verified_Rewards_in_World_Simulators\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-10-2-VLA-RFT_Vision-Language-Action_Reinforcement_Fine-tuning_with_Verified_Rewards_in_World_Simulators/\",\"children\":\"[논문리뷰] VLA-RFT: Vision-Language-Action Reinforcement Fine-tuning with Verified Rewards in World Simulators\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Zirui Ge이 [arXiv]에 게시한 'VLA-RFT: Vision-Language-Action Reinforcement Fine-tuning with Verified Rewards in World Simulators' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-02 13:30:22+0900\",\"children\":\"2025년 10월 2일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Vision-Language-Action Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision-Language-Action Models\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"World Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"World Models\"]}],[\"$\",\"span\",\"Fine-tuning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Fine-tuning\"]}],[\"$\",\"span\",\"Embodied AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Embodied AI\"]}],[\"$\",\"span\",\"Robotics\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Robotics\"]}],[\"$\",\"span\",\"Reward Design\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reward Design\"]}],[\"$\",\"span\",\"Distribution Shift\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Distribution Shift\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-10-2-Training_Vision-Language_Process_Reward_Models_for_Test-Time_Scaling_in_Multimodal_Reasoning_Key_Insights_and_Lessons_Learned\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-10-2-Training_Vision-Language_Process_Reward_Models_for_Test-Time_Scaling_in_Multimodal_Reasoning_Key_Insights_and_Lessons_Learned/\",\"children\":\"[논문리뷰] Training Vision-Language Process Reward Models for Test-Time Scaling in Multimodal Reasoning: Key Insights and Lessons Learned\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"이 [arXiv]에 게시한 'Training Vision-Language Process Reward Models for Test-Time Scaling in Multimodal Reasoning: Key Insights and Lessons Learned' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-02 13:30:22+0900\",\"children\":\"2025년 10월 2일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Vision-Language Models (VLMs)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision-Language Models (VLMs)\"]}],[\"$\",\"span\",\"Process Reward Models (PRMs)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Process Reward Models (PRMs)\"]}],[\"$\",\"span\",\"Multimodal Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Reasoning\"]}],[\"$\",\"span\",\"Test-Time Scaling (TTS)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Test-Time Scaling (TTS)\"]}],[\"$\",\"span\",\"Process Supervision\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Process Supervision\"]}],[\"$\",\"span\",\"Dataset Construction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dataset Construction\"]}],[\"$\",\"span\",\"Perception Errors\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Perception Errors\"]}],[\"$\",\"span\",\"MCTS\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"MCTS\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-10-2-ReSWD_ReSTIRd_not_shaken._Combining_Reservoir_Sampling_and_Sliced_Wasserstein_Distance_for_Variance_Reduction\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-10-2-ReSWD_ReSTIRd_not_shaken._Combining_Reservoir_Sampling_and_Sliced_Wasserstein_Distance_for_Variance_Reduction/\",\"children\":\"[논문리뷰] ReSWD: ReSTIR'd, not shaken. Combining Reservoir Sampling and Sliced Wasserstein Distance for Variance Reduction\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"이 [arXiv]에 게시한 'ReSWD: ReSTIR'd, not shaken. Combining Reservoir Sampling and Sliced Wasserstein Distance for Variance Reduction' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-02 13:30:22+0900\",\"children\":\"2025년 10월 2일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Sliced Wasserstein Distance\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Sliced Wasserstein Distance\"]}],[\"$\",\"span\",\"Reservoir Sampling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reservoir Sampling\"]}],[\"$\",\"span\",\"Variance Reduction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Variance Reduction\"]}],[\"$\",\"span\",\"Distribution Matching\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Distribution Matching\"]}],[\"$\",\"span\",\"Diffusion Guidance\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Guidance\"]}],[\"$\",\"span\",\"Color Correction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Color Correction\"]}],[\"$\",\"span\",\"Monte Carlo Estimation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Monte Carlo Estimation\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-10-2-PIPer_On-Device_Environment_Setup_via_Online_Reinforcement_Learning\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-10-2-PIPer_On-Device_Environment_Setup_via_Online_Reinforcement_Learning/\",\"children\":\"[논문리뷰] PIPer: On-Device Environment Setup via Online Reinforcement Learning\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"이 [arXiv]에 게시한 'PIPer: On-Device Environment Setup via Online Reinforcement Learning' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-02 13:30:22+0900\",\"children\":\"2025년 10월 2일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Environment Setup\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Environment Setup\"]}],[\"$\",\"span\",\"LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLMs\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Supervised Fine-tuning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Supervised Fine-tuning\"]}],[\"$\",\"span\",\"On-device AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"On-device AI\"]}],[\"$\",\"span\",\"Software Engineering\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Software Engineering\"]}],[\"$\",\"span\",\"Verifiable Rewards\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Verifiable Rewards\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-10-2-On_Predictability_of_Reinforcement_Learning_Dynamics_for_Large_Language_Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-10-2-On_Predictability_of_Reinforcement_Learning_Dynamics_for_Large_Language_Models/\",\"children\":\"[논문리뷰] On Predictability of Reinforcement Learning Dynamics for Large Language Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yuqing Huang이 [arXiv]에 게시한 'On Predictability of Reinforcement Learning Dynamics for Large Language Models' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-02 13:30:22+0900\",\"children\":\"2025년 10월 2일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Parameter Dynamics\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Parameter Dynamics\"]}],[\"$\",\"span\",\"Rank-1 Dominance\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Rank-1 Dominance\"]}],[\"$\",\"span\",\"Linear Dynamics\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Linear Dynamics\"]}],[\"$\",\"span\",\"SVD\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"SVD\"]}],[\"$\",\"span\",\"Model Acceleration\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Model Acceleration\"]}],[\"$\",\"span\",\"Predictability\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Predictability\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-10-2-Making_not_Taking_the_Best_of_N\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-10-2-Making_not_Taking_the_Best_of_N/\",\"children\":\"[논문리뷰] Making, not Taking, the Best of N\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"이 [arXiv]에 게시한 'Making, not Taking, the Best of N' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-02 13:30:22+0900\",\"children\":\"2025년 10월 2일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLM Aggregation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Aggregation\"]}],[\"$\",\"span\",\"Generative Fusion\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generative Fusion\"]}],[\"$\",\"span\",\"Best-of-N\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Best-of-N\"]}],[\"$\",\"span\",\"Synthetic Data Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Synthetic Data Generation\"]}],[\"$\",\"span\",\"Test-Time Scaling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Test-Time Scaling\"]}],[\"$\",\"span\",\"Multilingual Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multilingual Models\"]}],[\"$\",\"span\",\"Ensemble Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Ensemble Learning\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-10-2-Knapsack_RL_Unlocking_Exploration_of_LLMs_via_Optimizing_Budget_Allocation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-10-2-Knapsack_RL_Unlocking_Exploration_of_LLMs_via_Optimizing_Budget_Allocation/\",\"children\":\"[논문리뷰] Knapsack RL: Unlocking Exploration of LLMs via Optimizing Budget Allocation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"이 [arXiv]에 게시한 'Knapsack RL: Unlocking Exploration of LLMs via Optimizing Budget Allocation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-02 13:30:22+0900\",\"children\":\"2025년 10월 2일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Large Language Models (LLMs)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models (LLMs)\"]}],[\"$\",\"span\",\"Reinforcement Learning (RL)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning (RL)\"]}],[\"$\",\"span\",\"Exploration Budget Allocation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Exploration Budget Allocation\"]}],[\"$\",\"span\",\"Knapsack Problem\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Knapsack Problem\"]}],[\"$\",\"span\",\"Group Relative Policy Optimization (GRPO)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Group Relative Policy Optimization (GRPO)\"]}],[\"$\",\"span\",\"Mathematical Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Mathematical Reasoning\"]}],[\"$\",\"span\",\"Resource Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Resource Optimization\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-10-2-JoyAgent-JDGenie_Technical_Report_on_the_GAIA\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-10-2-JoyAgent-JDGenie_Technical_Report_on_the_GAIA/\",\"children\":\"[논문리뷰] JoyAgent-JDGenie: Technical Report on the GAIA\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"이 [arXiv]에 게시한 'JoyAgent-JDGenie: Technical Report on the GAIA' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-02 13:30:22+0900\",\"children\":\"2025년 10월 2일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Generalist Agent\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generalist Agent\"]}],[\"$\",\"span\",\"Multi-Agent System\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-Agent System\"]}],[\"$\",\"span\",\"Plan-Execute\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Plan-Execute\"]}],[\"$\",\"span\",\"ReAct\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"ReAct\"]}],[\"$\",\"span\",\"Hierarchical Memory\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Hierarchical Memory\"]}],[\"$\",\"span\",\"Tool Integration\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Tool Integration\"]}],[\"$\",\"span\",\"GAIA Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"GAIA Benchmark\"]}],[\"$\",\"span\",\"LLM Agent\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Agent\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-10-2-Infusing_Theory_of_Mind_into_Socially_Intelligent_LLM_Agents\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-10-2-Infusing_Theory_of_Mind_into_Socially_Intelligent_LLM_Agents/\",\"children\":\"[논문리뷰] Infusing Theory of Mind into Socially Intelligent LLM Agents\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"이 [arXiv]에 게시한 'Infusing Theory of Mind into Socially Intelligent LLM Agents' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-02 13:30:22+0900\",\"children\":\"2025년 10월 2일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Theory of Mind\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Theory of Mind\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Social Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Social Agents\"]}],[\"$\",\"span\",\"Dialogue Systems\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dialogue Systems\"]}],[\"$\",\"span\",\"Mental State Modeling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Mental State Modeling\"]}],[\"$\",\"span\",\"Look-ahead Planning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Look-ahead Planning\"]}],[\"$\",\"span\",\"Supervised Fine-tuning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Supervised Fine-tuning\"]}],[\"$\",\"span\",\"Sotopia Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Sotopia Benchmark\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-10-2-In-Place_Feedback_A_New_Paradigm_for_Guiding_LLMs_in_Multi-Turn_Reasoning\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-10-2-In-Place_Feedback_A_New_Paradigm_for_Guiding_LLMs_in_Multi-Turn_Reasoning/\",\"children\":\"[논문리뷰] In-Place Feedback: A New Paradigm for Guiding LLMs in Multi-Turn Reasoning\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Chaehyeon Chung이 [arXiv]에 게시한 'In-Place Feedback: A New Paradigm for Guiding LLMs in Multi-Turn Reasoning' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-02 13:30:22+0900\",\"children\":\"2025년 10월 2일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLM Feedback\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Feedback\"]}],[\"$\",\"span\",\"Multi-turn Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-turn Reasoning\"]}],[\"$\",\"span\",\"In-place Editing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"In-place Editing\"]}],[\"$\",\"span\",\"Token Efficiency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Token Efficiency\"]}],[\"$\",\"span\",\"Error Correction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Error Correction\"]}],[\"$\",\"span\",\"Human-AI Interaction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Human-AI Interaction\"]}],[\"$\",\"span\",\"Reasoning Tasks\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reasoning Tasks\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-10-2-Hyperdimensional_Probe_Decoding_LLM_Representations_via_Vector_Symbolic_Architectures\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-10-2-Hyperdimensional_Probe_Decoding_LLM_Representations_via_Vector_Symbolic_Architectures/\",\"children\":\"[논문리뷰] Hyperdimensional Probe: Decoding LLM Representations via Vector Symbolic Architectures\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Andrea Passerini이 [arXiv]에 게시한 'Hyperdimensional Probe: Decoding LLM Representations via Vector Symbolic Architectures' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-02 13:30:22+0900\",\"children\":\"2025년 10월 2일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLM Interpretability\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Interpretability\"]}],[\"$\",\"span\",\"Vector Symbolic Architectures\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vector Symbolic Architectures\"]}],[\"$\",\"span\",\"Neural Probing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Neural Probing\"]}],[\"$\",\"span\",\"Information Decoding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Information Decoding\"]}],[\"$\",\"span\",\"Hyperdimensional Computing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Hyperdimensional Computing\"]}],[\"$\",\"span\",\"Latent Representations\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Latent Representations\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-10-2-GUI-KV_Efficient_GUI_Agents_via_KV_Cache_with_Spatio-Temporal_Awareness\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-10-2-GUI-KV_Efficient_GUI_Agents_via_KV_Cache_with_Spatio-Temporal_Awareness/\",\"children\":\"[논문리뷰] GUI-KV: Efficient GUI Agents via KV Cache with Spatio-Temporal Awareness\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Chien-Sheng Wu이 [arXiv]에 게시한 'GUI-KV: Efficient GUI Agents via KV Cache with Spatio-Temporal Awareness' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-02 13:30:22+0900\",\"children\":\"2025년 10월 2일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"GUI Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"GUI Agents\"]}],[\"$\",\"span\",\"KV Cache Compression\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"KV Cache Compression\"]}],[\"$\",\"span\",\"Spatio-Temporal Awareness\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Spatio-Temporal Awareness\"]}],[\"$\",\"span\",\"Vision-Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision-Language Models\"]}],[\"$\",\"span\",\"Efficiency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Efficiency\"]}],[\"$\",\"span\",\"Attention Sparsity\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Attention Sparsity\"]}],[\"$\",\"span\",\"QR Decomposition\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"QR Decomposition\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-10-2-GEM_A_Gym_for_Agentic_LLMs\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-10-2-GEM_A_Gym_for_Agentic_LLMs/\",\"children\":\"[논문리뷰] GEM: A Gym for Agentic LLMs\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"이 [arXiv]에 게시한 'GEM: A Gym for Agentic LLMs' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-02 13:30:22+0900\",\"children\":\"2025년 10월 2일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Agentic LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Agentic LLMs\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Environment Simulator\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Environment Simulator\"]}],[\"$\",\"span\",\"Multi-turn Interactions\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-turn Interactions\"]}],[\"$\",\"span\",\"Return Batch Normalization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Return Batch Normalization\"]}],[\"$\",\"span\",\"Tool Integration\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Tool Integration\"]}],[\"$\",\"span\",\"Benchmarking\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmarking\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-10-2-Flash-Searcher_Fast_and_Effective_Web_Agents_via_DAG-Based_Parallel_Execution\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-10-2-Flash-Searcher_Fast_and_Effective_Web_Agents_via_DAG-Based_Parallel_Execution/\",\"children\":\"[논문리뷰] Flash-Searcher: Fast and Effective Web Agents via DAG-Based Parallel Execution\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"이 [arXiv]에 게시한 'Flash-Searcher: Fast and Effective Web Agents via DAG-Based Parallel Execution' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-02 13:30:22+0900\",\"children\":\"2025년 10월 2일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLM Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Agents\"]}],[\"$\",\"span\",\"Parallel Execution\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Parallel Execution\"]}],[\"$\",\"span\",\"DAG-based Planning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"DAG-based Planning\"]}],[\"$\",\"span\",\"Tool Orchestration\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Tool Orchestration\"]}],[\"$\",\"span\",\"Web Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Web Agents\"]}],[\"$\",\"span\",\"Reasoning Framework\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reasoning Framework\"]}],[\"$\",\"span\",\"Efficiency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Efficiency\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-10-2-Eliciting_Secret_Knowledge_from_Language_Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-10-2-Eliciting_Secret_Knowledge_from_Language_Models/\",\"children\":\"[논문리뷰] Eliciting Secret Knowledge from Language Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Neel Nanda이 [arXiv]에 게시한 'Eliciting Secret Knowledge from Language Models' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-02 13:30:22+0900\",\"children\":\"2025년 10월 2일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Language Models\"]}],[\"$\",\"span\",\"Secret Elicitation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Secret Elicitation\"]}],[\"$\",\"span\",\"Mechanistic Interpretability\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Mechanistic Interpretability\"]}],[\"$\",\"span\",\"Black-box Methods\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Black-box Methods\"]}],[\"$\",\"span\",\"White-box Methods\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"White-box Methods\"]}],[\"$\",\"span\",\"AI Auditing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"AI Auditing\"]}],[\"$\",\"span\",\"Model Organisms\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Model Organisms\"]}],[\"$\",\"span\",\"Prefill Attacks\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Prefill Attacks\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-10-2-DeepSearch_Overcome_the_Bottleneck_of_Reinforcement_Learning_with_Verifiable_Rewards_via_Monte_Carlo_Tree_Search\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-10-2-DeepSearch_Overcome_the_Bottleneck_of_Reinforcement_Learning_with_Verifiable_Rewards_via_Monte_Carlo_Tree_Search/\",\"children\":\"[논문리뷰] DeepSearch: Overcome the Bottleneck of Reinforcement Learning with Verifiable Rewards via Monte Carlo Tree Search\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"이 [arXiv]에 게시한 'DeepSearch: Overcome the Bottleneck of Reinforcement Learning with Verifiable Rewards via Monte Carlo Tree Search' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-02 13:30:22+0900\",\"children\":\"2025년 10월 2일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Reinforcement Learning with Verifiable Rewards (RLVR)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning with Verifiable Rewards (RLVR)\"]}],[\"$\",\"span\",\"Monte Carlo Tree Search (MCTS)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Monte Carlo Tree Search (MCTS)\"]}],[\"$\",\"span\",\"Mathematical Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Mathematical Reasoning\"]}],[\"$\",\"span\",\"Large Language Models (LLMs)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models (LLMs)\"]}],[\"$\",\"span\",\"Systematic Exploration\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Systematic Exploration\"]}],[\"$\",\"span\",\"Adaptive Training\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Adaptive Training\"]}],[\"$\",\"span\",\"Tree-GRPO\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Tree-GRPO\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-10-2-CurES_From_Gradient_Analysis_to_Efficient_Curriculum_Learning_for_Reasoning_LLMs\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-10-2-CurES_From_Gradient_Analysis_to_Efficient_Curriculum_Learning_for_Reasoning_LLMs/\",\"children\":\"[논문리뷰] CurES: From Gradient Analysis to Efficient Curriculum Learning for Reasoning LLMs\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Hengyi Cai이 [arXiv]에 게시한 'CurES: From Gradient Analysis to Efficient Curriculum Learning for Reasoning LLMs' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-02 13:30:22+0900\",\"children\":\"2025년 10월 2일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Curriculum Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Curriculum Learning\"]}],[\"$\",\"span\",\"LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLMs\"]}],[\"$\",\"span\",\"Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reasoning\"]}],[\"$\",\"span\",\"Gradient Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Gradient Optimization\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Bayesian Inference\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Bayesian Inference\"]}],[\"$\",\"span\",\"Sample Efficiency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Sample Efficiency\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-10-2-Code2Video_A_Code-centric_Paradigm_for_Educational_Video_Generation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-10-2-Code2Video_A_Code-centric_Paradigm_for_Educational_Video_Generation/\",\"children\":\"[논문리뷰] Code2Video: A Code-centric Paradigm for Educational Video Generation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"이 [arXiv]에 게시한 'Code2Video: A Code-centric Paradigm for Educational Video Generation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-02 13:30:22+0900\",\"children\":\"2025년 10월 2일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Educational Video Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Educational Video Generation\"]}],[\"$\",\"span\",\"Code-centric AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Code-centric AI\"]}],[\"$\",\"span\",\"Multi-agent Framework\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-agent Framework\"]}],[\"$\",\"span\",\"Manim\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Manim\"]}],[\"$\",\"span\",\"Vision-Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision-Language Models\"]}],[\"$\",\"span\",\"Knowledge Transfer\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Knowledge Transfer\"]}],[\"$\",\"span\",\"Code Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Code Generation\"]}],[\"$\",\"span\",\"MMMC Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"MMMC Benchmark\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-10-2-BroRL_Scaling_Reinforcement_Learning_via_Broadened_Exploration\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-10-2-BroRL_Scaling_Reinforcement_Learning_via_Broadened_Exploration/\",\"children\":\"[논문리뷰] BroRL: Scaling Reinforcement Learning via Broadened Exploration\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"이 [arXiv]에 게시한 'BroRL: Scaling Reinforcement Learning via Broadened Exploration' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-02 13:30:22+0900\",\"children\":\"2025년 10월 2일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLMs\"]}],[\"$\",\"span\",\"Scaling Laws\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Scaling Laws\"]}],[\"$\",\"span\",\"Exploration\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Exploration\"]}],[\"$\",\"span\",\"Rollout Size\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Rollout Size\"]}],[\"$\",\"span\",\"Verifiable Rewards\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Verifiable Rewards\"]}],[\"$\",\"span\",\"PPO\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"PPO\"]}],[\"$\",\"span\",\"Mass Balance Equation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Mass Balance Equation\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-10-2-Boolean_Satisfiability_via_Imitation_Learning\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-10-2-Boolean_Satisfiability_via_Imitation_Learning/\",\"children\":\"[논문리뷰] Boolean Satisfiability via Imitation Learning\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Xiangyu Xu이 [arXiv]에 게시한 'Boolean Satisfiability via Imitation Learning' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-02 13:30:22+0900\",\"children\":\"2025년 10월 2일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Boolean Satisfiability\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Boolean Satisfiability\"]}],[\"$\",\"span\",\"Imitation Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Imitation Learning\"]}],[\"$\",\"span\",\"CDCL Solvers\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"CDCL Solvers\"]}],[\"$\",\"span\",\"Branching Policy\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Branching Policy\"]}],[\"$\",\"span\",\"KeyTrace\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"KeyTrace\"]}],[\"$\",\"span\",\"Transformer Architecture\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Transformer Architecture\"]}],[\"$\",\"span\",\"Perceiver AR\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Perceiver AR\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-10-2-BindWeave_Subject-Consistent_Video_Generation_via_Cross-Modal_Integration\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-10-2-BindWeave_Subject-Consistent_Video_Generation_via_Cross-Modal_Integration/\",\"children\":\"[논문리뷰] BindWeave: Subject-Consistent Video Generation via Cross-Modal Integration\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Xiangyang Xia이 [arXiv]에 게시한 'BindWeave: Subject-Consistent Video Generation via Cross-Modal Integration' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-02 13:30:22+0900\",\"children\":\"2025년 10월 2일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Video Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video Generation\"]}],[\"$\",\"span\",\"Subject Consistency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Subject Consistency\"]}],[\"$\",\"span\",\"Cross-Modal Integration\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Cross-Modal Integration\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}],[\"$\",\"span\",\"Multimodal LLM\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal LLM\"]}],[\"$\",\"span\",\"Diffusion Transformer\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Transformer\"]}],[\"$\",\"span\",\"Text-to-Video\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Text-to-Video\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-10-2-BiasFreeBench_a_Benchmark_for_Mitigating_Bias_in_Large_Language_Model_Responses\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-10-2-BiasFreeBench_a_Benchmark_for_Mitigating_Bias_in_Large_Language_Model_Responses/\",\"children\":\"[논문리뷰] BiasFreeBench: a Benchmark for Mitigating Bias in Large Language Model Responses\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Julian McAuley이 [arXiv]에 게시한 'BiasFreeBench: a Benchmark for Mitigating Bias in Large Language Model Responses' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-02 13:30:22+0900\",\"children\":\"2025년 10월 2일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLM Bias Mitigation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Bias Mitigation\"]}],[\"$\",\"span\",\"Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmark\"]}],[\"$\",\"span\",\"Evaluation Metrics\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Evaluation Metrics\"]}],[\"$\",\"span\",\"Prompt Engineering\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Prompt Engineering\"]}],[\"$\",\"span\",\"Fine-tuning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Fine-tuning\"]}],[\"$\",\"span\",\"Bias-Free Score\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Bias-Free Score\"]}],[\"$\",\"span\",\"Fairness\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Fairness\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-10-2-Beyond_Log_Likelihood_Probability-Based_Objectives_for_Supervised_Fine-Tuning_across_the_Model_Capability_Continuum\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-10-2-Beyond_Log_Likelihood_Probability-Based_Objectives_for_Supervised_Fine-Tuning_across_the_Model_Capability_Continuum/\",\"children\":\"[논문리뷰] Beyond Log Likelihood: Probability-Based Objectives for Supervised Fine-Tuning across the Model Capability Continuum\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Hanghang Tong이 [arXiv]에 게시한 'Beyond Log Likelihood: Probability-Based Objectives for Supervised Fine-Tuning across the Model Capability Continuum' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-02 13:30:22+0900\",\"children\":\"2025년 10월 2일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Supervised Fine-tuning (SFT)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Supervised Fine-tuning (SFT)\"]}],[\"$\",\"span\",\"Large Language Models (LLMs)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models (LLMs)\"]}],[\"$\",\"span\",\"Training Objectives\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Training Objectives\"]}],[\"$\",\"span\",\"Negative Log Likelihood (NLL)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Negative Log Likelihood (NLL)\"]}],[\"$\",\"span\",\"Model Capability Continuum\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Model Capability Continuum\"]}],[\"$\",\"span\",\"Generalization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generalization\"]}],[\"$\",\"span\",\"Probability-based Loss Functions\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Probability-based Loss Functions\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-10-2-An_Empirical_Study_of_Testing_Practices_in_Open_Source_AI_Agent_Frameworks_and_Agentic_Applications\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-10-2-An_Empirical_Study_of_Testing_Practices_in_Open_Source_AI_Agent_Frameworks_and_Agentic_Applications/\",\"children\":\"[논문리뷰] An Empirical Study of Testing Practices in Open Source AI Agent Frameworks and Agentic Applications\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Bram Adams이 [arXiv]에 게시한 'An Empirical Study of Testing Practices in Open Source AI Agent Frameworks and Agentic Applications' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-02 13:30:22+0900\",\"children\":\"2025년 10월 2일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"AI Agent\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"AI Agent\"]}],[\"$\",\"span\",\"LLM Agent\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Agent\"]}],[\"$\",\"span\",\"Testing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Testing\"]}],[\"$\",\"span\",\"Empirical Study\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Empirical Study\"]}],[\"$\",\"span\",\"Software Quality\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Software Quality\"]}],[\"$\",\"span\",\"Agent Frameworks\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Agent Frameworks\"]}],[\"$\",\"span\",\"Agentic Applications\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Agentic Applications\"]}],[\"$\",\"span\",\"Non-Determinism\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Non-Determinism\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-10-2-ACON_Optimizing_Context_Compression_for_Long-horizon_LLM_Agents\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-10-2-ACON_Optimizing_Context_Compression_for_Long-horizon_LLM_Agents/\",\"children\":\"[논문리뷰] ACON: Optimizing Context Compression for Long-horizon LLM Agents\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"이 [arXiv]에 게시한 'ACON: Optimizing Context Compression for Long-horizon LLM Agents' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-02 13:30:22+0900\",\"children\":\"2025년 10월 2일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLM Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Agents\"]}],[\"$\",\"span\",\"Context Compression\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Context Compression\"]}],[\"$\",\"span\",\"Long-horizon Tasks\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Long-horizon Tasks\"]}],[\"$\",\"span\",\"Prompt Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Prompt Optimization\"]}],[\"$\",\"span\",\"Knowledge Distillation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Knowledge Distillation\"]}],[\"$\",\"span\",\"Memory Efficiency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Memory Efficiency\"]}],[\"$\",\"span\",\"Task Performance\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Task Performance\"]}],[\"$\",\"span\",\"Failure Analysis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Failure Analysis\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-10-1-Winning_the_Pruning_Gamble_A_Unified_Approach_to_Joint_Sample_and_Token_Pruning_for_Efficient_Supervised_Fine-Tuning\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-10-1-Winning_the_Pruning_Gamble_A_Unified_Approach_to_Joint_Sample_and_Token_Pruning_for_Efficient_Supervised_Fine-Tuning/\",\"children\":\"[논문리뷰] Winning the Pruning Gamble: A Unified Approach to Joint Sample and Token Pruning for Efficient Supervised Fine-Tuning\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yue Min이 [arXiv]에 게시한 'Winning the Pruning Gamble: A Unified Approach to Joint Sample and Token Pruning for Efficient Supervised Fine-Tuning' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-01 14:04:08+0900\",\"children\":\"2025년 10월 1일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLM SFT\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM SFT\"]}],[\"$\",\"span\",\"Data Pruning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Pruning\"]}],[\"$\",\"span\",\"Sample Pruning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Sample Pruning\"]}],[\"$\",\"span\",\"Token Pruning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Token Pruning\"]}],[\"$\",\"span\",\"Error-Uncertainty Plane\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Error-Uncertainty Plane\"]}],[\"$\",\"span\",\"Q-Tuning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Q-Tuning\"]}],[\"$\",\"span\",\"Data Efficiency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Efficiency\"]}],[\"$\",\"span\",\"Dynamic Pruning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dynamic Pruning\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-10-1-Who_invented_deep_residual_learning\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-10-1-Who_invented_deep_residual_learning/\",\"children\":\"[논문리뷰] Who invented deep residual learning?\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Juergen Schmidhuber이 [arXiv]에 게시한 'Who invented deep residual learning?' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-01 14:04:08+0900\",\"children\":\"2025년 10월 1일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Deep Learning History\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Deep Learning History\"]}],[\"$\",\"span\",\"Residual Connections\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Residual Connections\"]}],[\"$\",\"span\",\"Recurrent Neural Networks (RNN)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Recurrent Neural Networks (RNN)\"]}],[\"$\",\"span\",\"Long Short-Term Memory (LSTM)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Long Short-Term Memory (LSTM)\"]}],[\"$\",\"span\",\"Feedforward Neural Networks (FNN)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Feedforward Neural Networks (FNN)\"]}],[\"$\",\"span\",\"Highway Networks\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Highway Networks\"]}],[\"$\",\"span\",\"ResNet\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"ResNet\"]}],[\"$\",\"span\",\"Vanishing Gradient\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vanishing Gradient\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-10-1-Whos_Your_Judge_On_the_Detectability_of_LLM-Generated_Judgments\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-10-1-Whos_Your_Judge_On_the_Detectability_of_LLM-Generated_Judgments/\",\"children\":\"[논문리뷰] Who's Your Judge? On the Detectability of LLM-Generated Judgments\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"이 [arXiv]에 게시한 'Who's Your Judge? On the Detectability of LLM-Generated Judgments' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-01 14:04:08+0900\",\"children\":\"2025년 10월 1일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLM-as-a-judge\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM-as-a-judge\"]}],[\"$\",\"span\",\"Judgment Detection\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Judgment Detection\"]}],[\"$\",\"span\",\"Bias Quantification\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Bias Quantification\"]}],[\"$\",\"span\",\"Feature Engineering\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Feature Engineering\"]}],[\"$\",\"span\",\"Interpretability\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Interpretability\"]}],[\"$\",\"span\",\"Peer Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Peer Review\"]}],[\"$\",\"span\",\"AI Ethics\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"AI Ethics\"]}],[\"$\",\"span\",\"Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Evaluation\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-10-1-Voice_Evaluation_of_Reasoning_Ability_Diagnosing_the_Modality-Induced_Performance_Gap\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-10-1-Voice_Evaluation_of_Reasoning_Ability_Diagnosing_the_Modality-Induced_Performance_Gap/\",\"children\":\"[논문리뷰] Voice Evaluation of Reasoning Ability: Diagnosing the Modality-Induced Performance Gap\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Hengfan Zhang이 [arXiv]에 게시한 'Voice Evaluation of Reasoning Ability: Diagnosing the Modality-Induced Performance Gap' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-01 14:04:08+0900\",\"children\":\"2025년 10월 1일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Voice AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Voice AI\"]}],[\"$\",\"span\",\"LLM\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM\"]}],[\"$\",\"span\",\"Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reasoning\"]}],[\"$\",\"span\",\"Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmark\"]}],[\"$\",\"span\",\"Modality Gap\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Modality Gap\"]}],[\"$\",\"span\",\"Latency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Latency\"]}],[\"$\",\"span\",\"Speech Recognition\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Speech Recognition\"]}],[\"$\",\"span\",\"Generative AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generative AI\"]}],[\"$\",\"span\",\"Real-time Systems\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Real-time Systems\"]}],[\"$\",\"span\",\"Conversational AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Conversational AI\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-10-1-VitaBench_Benchmarking_LLM_Agents_with_Versatile_Interactive_Tasks_in_Real-world_Applications\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-10-1-VitaBench_Benchmarking_LLM_Agents_with_Versatile_Interactive_Tasks_in_Real-world_Applications/\",\"children\":\"[논문리뷰] VitaBench: Benchmarking LLM Agents with Versatile Interactive Tasks in Real-world Applications\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"이 [arXiv]에 게시한 'VitaBench: Benchmarking LLM Agents with Versatile Interactive Tasks in Real-world Applications' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-01 14:04:08+0900\",\"children\":\"2025년 10월 1일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLM Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Agents\"]}],[\"$\",\"span\",\"Benchmarking\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmarking\"]}],[\"$\",\"span\",\"Interactive Tasks\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Interactive Tasks\"]}],[\"$\",\"span\",\"Real-world Applications\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Real-world Applications\"]}],[\"$\",\"span\",\"Tool Use\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Tool Use\"]}],[\"$\",\"span\",\"Multi-turn Conversation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-turn Conversation\"]}],[\"$\",\"span\",\"Task Complexity\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Task Complexity\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-10-1-VisualOverload_Probing_Visual_Understanding_of_VLMs_in_Really_Dense_Scenes\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-10-1-VisualOverload_Probing_Visual_Understanding_of_VLMs_in_Really_Dense_Scenes/\",\"children\":\"[논문리뷰] VisualOverload: Probing Visual Understanding of VLMs in Really Dense Scenes\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Muhammad Huzaifa이 [arXiv]에 게시한 'VisualOverload: Probing Visual Understanding of VLMs in Really Dense Scenes' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-01 14:04:08+0900\",\"children\":\"2025년 10월 1일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Visual Question Answering\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Visual Question Answering\"]}],[\"$\",\"span\",\"Multimodal Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Models\"]}],[\"$\",\"span\",\"Dense Scenes\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dense Scenes\"]}],[\"$\",\"span\",\"Fine-Grained Perception\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Fine-Grained Perception\"]}],[\"$\",\"span\",\"Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmark\"]}],[\"$\",\"span\",\"Error Analysis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Error Analysis\"]}],[\"$\",\"span\",\"Counting\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Counting\"]}],[\"$\",\"span\",\"OCR\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"OCR\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-10-1-Vision-Zero_Scalable_VLM_Self-Improvement_via_Strategic_Gamified_Self-Play\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-10-1-Vision-Zero_Scalable_VLM_Self-Improvement_via_Strategic_Gamified_Self-Play/\",\"children\":\"[논문리뷰] Vision-Zero: Scalable VLM Self-Improvement via Strategic Gamified Self-Play\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Jing Shi이 [arXiv]에 게시한 'Vision-Zero: Scalable VLM Self-Improvement via Strategic Gamified Self-Play' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-01 14:04:08+0900\",\"children\":\"2025년 10월 1일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Vision-Language Models (VLMs)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision-Language Models (VLMs)\"]}],[\"$\",\"span\",\"Self-Play\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Self-Play\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Gamification\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Gamification\"]}],[\"$\",\"span\",\"Data Efficiency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Efficiency\"]}],[\"$\",\"span\",\"Strategic Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Strategic Reasoning\"]}],[\"$\",\"span\",\"Multimodal AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal AI\"]}],[\"$\",\"span\",\"Self-Improvement\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Self-Improvement\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-10-1-TTT3R_3D_Reconstruction_as_Test-Time_Training\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-10-1-TTT3R_3D_Reconstruction_as_Test-Time_Training/\",\"children\":\"[논문리뷰] TTT3R: 3D Reconstruction as Test-Time Training\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Anpei Chen이 [arXiv]에 게시한 'TTT3R: 3D Reconstruction as Test-Time Training' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-01 14:04:08+0900\",\"children\":\"2025년 10월 1일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"3D Reconstruction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D Reconstruction\"]}],[\"$\",\"span\",\"Test-Time Training (TTT)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Test-Time Training (TTT)\"]}],[\"$\",\"span\",\"Recurrent Neural Networks (RNN)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Recurrent Neural Networks (RNN)\"]}],[\"$\",\"span\",\"Online Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Online Learning\"]}],[\"$\",\"span\",\"Length Generalization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Length Generalization\"]}],[\"$\",\"span\",\"Associative Memory\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Associative Memory\"]}],[\"$\",\"span\",\"State Update Rule\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"State Update Rule\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-10-1-TruthRL_Incentivizing_Truthful_LLMs_via_Reinforcement_Learning\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-10-1-TruthRL_Incentivizing_Truthful_LLMs_via_Reinforcement_Learning/\",\"children\":\"[논문리뷰] TruthRL: Incentivizing Truthful LLMs via Reinforcement Learning\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"이 [arXiv]에 게시한 'TruthRL: Incentivizing Truthful LLMs via Reinforcement Learning' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-01 14:04:08+0900\",\"children\":\"2025년 10월 1일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLM Hallucination\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Hallucination\"]}],[\"$\",\"span\",\"Truthfulness\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Truthfulness\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Ternary Reward\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Ternary Reward\"]}],[\"$\",\"span\",\"Abstention\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Abstention\"]}],[\"$\",\"span\",\"Knowledge Boundary\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Knowledge Boundary\"]}],[\"$\",\"span\",\"GRPO\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"GRPO\"]}],[\"$\",\"span\",\"RLHF\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"RLHF\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-10-1-Thinking_Sparks_Emergent_Attention_Heads_in_Reasoning_Models_During_Post_Training\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-10-1-Thinking_Sparks_Emergent_Attention_Heads_in_Reasoning_Models_During_Post_Training/\",\"children\":\"[논문리뷰] Thinking Sparks!: Emergent Attention Heads in Reasoning Models During Post Training\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"이 [arXiv]에 게시한 'Thinking Sparks!: Emergent Attention Heads in Reasoning Models During Post Training' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-01 14:04:08+0900\",\"children\":\"2025년 10월 1일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Mechanistic Interpretability\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Mechanistic Interpretability\"]}],[\"$\",\"span\",\"Attention Heads\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Attention Heads\"]}],[\"$\",\"span\",\"Post-Training\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Post-Training\"]}],[\"$\",\"span\",\"Supervised Fine-Tuning (SFT)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Supervised Fine-Tuning (SFT)\"]}],[\"$\",\"span\",\"Reinforcement Learning (RL)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning (RL)\"]}],[\"$\",\"span\",\"Circuit Analysis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Circuit Analysis\"]}],[\"$\",\"span\",\"Reasoning Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reasoning Models\"]}],[\"$\",\"span\",\"Transformer Architecture\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Transformer Architecture\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-10-1-The_Dragon_Hatchling_The_Missing_Link_between_the_Transformer_and_Models_of_the_Brain\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-10-1-The_Dragon_Hatchling_The_Missing_Link_between_the_Transformer_and_Models_of_the_Brain/\",\"children\":\"[논문리뷰] The Dragon Hatchling: The Missing Link between the Transformer and Models of the Brain\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"이 [arXiv]에 게시한 'The Dragon Hatchling: The Missing Link between the Transformer and Models of the Brain' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-01 14:04:08+0900\",\"children\":\"2025년 10월 1일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Brain-Inspired AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Brain-Inspired AI\"]}],[\"$\",\"span\",\"Graph Neural Networks\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Graph Neural Networks\"]}],[\"$\",\"span\",\"Hebbian Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Hebbian Learning\"]}],[\"$\",\"span\",\"Scale-Free Networks\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Scale-Free Networks\"]}],[\"$\",\"span\",\"Model Interpretability\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Model Interpretability\"]}],[\"$\",\"span\",\"Transformer Architecture\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Transformer Architecture\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-10-1-Test-Time_Policy_Adaptation_for_Enhanced_Multi-Turn_Interactions_with_LLMs\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-10-1-Test-Time_Policy_Adaptation_for_Enhanced_Multi-Turn_Interactions_with_LLMs/\",\"children\":\"[논문리뷰] Test-Time Policy Adaptation for Enhanced Multi-Turn Interactions with LLMs\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yao Shu이 [arXiv]에 게시한 'Test-Time Policy Adaptation for Enhanced Multi-Turn Interactions with LLMs' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-01 14:04:08+0900\",\"children\":\"2025년 10월 1일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Multi-turn Interaction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-turn Interaction\"]}],[\"$\",\"span\",\"Test-Time Adaptation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Test-Time Adaptation\"]}],[\"$\",\"span\",\"Reinforcement Learning from Human Feedback\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning from Human Feedback\"]}],[\"$\",\"span\",\"Policy Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Policy Optimization\"]}],[\"$\",\"span\",\"Online Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Online Learning\"]}],[\"$\",\"span\",\"Self-Correction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Self-Correction\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-10-1-TAU_A_Benchmark_for_Cultural_Sound_Understanding_Beyond_Semantics\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-10-1-TAU_A_Benchmark_for_Cultural_Sound_Understanding_Beyond_Semantics/\",\"children\":\"[논문리뷰] TAU: A Benchmark for Cultural Sound Understanding Beyond Semantics\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Szu-Chi Chen이 [arXiv]에 게시한 'TAU: A Benchmark for Cultural Sound Understanding Beyond Semantics' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-01 14:04:08+0900\",\"children\":\"2025년 10월 1일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Audio Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Audio Language Models\"]}],[\"$\",\"span\",\"Cultural Sound Understanding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Cultural Sound Understanding\"]}],[\"$\",\"span\",\"Localized Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Localized Benchmark\"]}],[\"$\",\"span\",\"Non-semantic Audio\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Non-semantic Audio\"]}],[\"$\",\"span\",\"Human-in-the-loop\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Human-in-the-loop\"]}],[\"$\",\"span\",\"Multimodal AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal AI\"]}],[\"$\",\"span\",\"Taipei Soundscape\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Taipei Soundscape\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-10-1-Stable_Cinemetrics_Structured_Taxonomy_and_Evaluation_for_Professional_Video_Generation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-10-1-Stable_Cinemetrics_Structured_Taxonomy_and_Evaluation_for_Professional_Video_Generation/\",\"children\":\"[논문리뷰] Stable Cinemetrics : Structured Taxonomy and Evaluation for Professional Video Generation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"이 [arXiv]에 게시한 'Stable Cinemetrics : Structured Taxonomy and Evaluation for Professional Video Generation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-01 14:04:08+0900\",\"children\":\"2025년 10월 1일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Video Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video Generation\"]}],[\"$\",\"span\",\"Evaluation Framework\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Evaluation Framework\"]}],[\"$\",\"span\",\"Cinematic Control\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Cinematic Control\"]}],[\"$\",\"span\",\"Taxonomy\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Taxonomy\"]}],[\"$\",\"span\",\"Human Annotation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Human Annotation\"]}],[\"$\",\"span\",\"Vision-Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision-Language Models\"]}],[\"$\",\"span\",\"Text-to-Video\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Text-to-Video\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-10-1-Specialization_after_Generalization_Towards_Understanding_Test-Time_Training_in_Foundation_Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-10-1-Specialization_after_Generalization_Towards_Understanding_Test-Time_Training_in_Foundation_Models/\",\"children\":\"[논문리뷰] Specialization after Generalization: Towards Understanding Test-Time Training in Foundation Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"이 [arXiv]에 게시한 'Specialization after Generalization: Towards Understanding Test-Time Training in Foundation Models' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-01 14:04:08+0900\",\"children\":\"2025년 10월 1일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Test-Time Training (TTT)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Test-Time Training (TTT)\"]}],[\"$\",\"span\",\"Foundation Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Foundation Models\"]}],[\"$\",\"span\",\"Underparameterization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Underparameterization\"]}],[\"$\",\"span\",\"Sparse Autoencoders (SAE)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Sparse Autoencoders (SAE)\"]}],[\"$\",\"span\",\"Linear Representation Hypothesis (LRH)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Linear Representation Hypothesis (LRH)\"]}],[\"$\",\"span\",\"Specialization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Specialization\"]}],[\"$\",\"span\",\"Scaling Laws\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Scaling Laws\"]}],[\"$\",\"span\",\"In-Distribution Data\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"In-Distribution Data\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-10-1-Regression_Language_Models_for_Code\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-10-1-Regression_Language_Models_for_Code/\",\"children\":\"[논문리뷰] Regression Language Models for Code\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"이 [arXiv]에 게시한 'Regression Language Models for Code' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-01 14:04:08+0900\",\"children\":\"2025년 10월 1일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Regression Language Model\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Regression Language Model\"]}],[\"$\",\"span\",\"Code Performance Prediction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Code Performance Prediction\"]}],[\"$\",\"span\",\"Static Analysis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Static Analysis\"]}],[\"$\",\"span\",\"Neural Architecture Search\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Neural Architecture Search\"]}],[\"$\",\"span\",\"Text-to-Text Regression\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Text-to-Text Regression\"]}],[\"$\",\"span\",\"Multi-task Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-task Learning\"]}],[\"$\",\"span\",\"T5Gemma\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"T5Gemma\"]}],[\"$\",\"span\",\"ONNX\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"ONNX\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-10-1-ProfVLM_A_Lightweight_Video-Language_Model_for_Multi-View_Proficiency_Estimation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-10-1-ProfVLM_A_Lightweight_Video-Language_Model_for_Multi-View_Proficiency_Estimation/\",\"children\":\"[논문리뷰] ProfVLM: A Lightweight Video-Language Model for Multi-View Proficiency Estimation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Antonio Liotta이 [arXiv]에 게시한 'ProfVLM: A Lightweight Video-Language Model for Multi-View Proficiency Estimation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-01 14:04:08+0900\",\"children\":\"2025년 10월 1일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Video-Language Model\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video-Language Model\"]}],[\"$\",\"span\",\"Proficiency Estimation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Proficiency Estimation\"]}],[\"$\",\"span\",\"Multi-View Video\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-View Video\"]}],[\"$\",\"span\",\"Action Quality Assessment\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Action Quality Assessment\"]}],[\"$\",\"span\",\"Lightweight Model\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Lightweight Model\"]}],[\"$\",\"span\",\"Generative Feedback\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generative Feedback\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-10-1-Probing_the_Critical_Point_CritPt_of_AI_Reasoning_a_Frontier_Physics_Research_Benchmark\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-10-1-Probing_the_Critical_Point_CritPt_of_AI_Reasoning_a_Frontier_Physics_Research_Benchmark/\",\"children\":\"[논문리뷰] Probing the Critical Point (CritPt) of AI Reasoning: a Frontier Physics Research Benchmark\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Penghao Zhu이 [arXiv]에 게시한 'Probing the Critical Point (CritPt) of AI Reasoning: a Frontier Physics Research Benchmark' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-01 14:04:08+0900\",\"children\":\"2025년 10월 1일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"AI Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"AI Reasoning\"]}],[\"$\",\"span\",\"Physics Research\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Physics Research\"]}],[\"$\",\"span\",\"LLM Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Evaluation\"]}],[\"$\",\"span\",\"Scientific Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Scientific Benchmark\"]}],[\"$\",\"span\",\"Frontier Physics\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Frontier Physics\"]}],[\"$\",\"span\",\"Problem Solving\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Problem Solving\"]}],[\"$\",\"span\",\"Model Reliability\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Model Reliability\"]}],[\"$\",\"span\",\"Auto-grading\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Auto-grading\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-10-1-OffTopicEval_When_Large_Language_Models_Enter_the_Wrong_Chat_Almost_Always\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-10-1-OffTopicEval_When_Large_Language_Models_Enter_the_Wrong_Chat_Almost_Always/\",\"children\":\"[논문리뷰] OffTopicEval: When Large Language Models Enter the Wrong Chat, Almost Always!\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"이 [arXiv]에 게시한 'OffTopicEval: When Large Language Models Enter the Wrong Chat, Almost Always!' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-01 14:04:08+0900\",\"children\":\"2025년 10월 1일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Large Language Models (LLMs)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models (LLMs)\"]}],[\"$\",\"span\",\"Operational Safety\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Operational Safety\"]}],[\"$\",\"span\",\"Out-of-Domain (OOD)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Out-of-Domain (OOD)\"]}],[\"$\",\"span\",\"Prompt Steering\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Prompt Steering\"]}],[\"$\",\"span\",\"Jailbreak Attacks\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Jailbreak Attacks\"]}],[\"$\",\"span\",\"Evaluation Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Evaluation Benchmark\"]}],[\"$\",\"span\",\"Refusal Rate\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Refusal Rate\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-10-1-OceanGym_A_Benchmark_Environment_for_Underwater_Embodied_Agents\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-10-1-OceanGym_A_Benchmark_Environment_for_Underwater_Embodied_Agents/\",\"children\":\"[논문리뷰] OceanGym: A Benchmark Environment for Underwater Embodied Agents\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"이 [arXiv]에 게시한 'OceanGym: A Benchmark Environment for Underwater Embodied Agents' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-01 14:04:08+0900\",\"children\":\"2025년 10월 1일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Underwater Robotics\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Underwater Robotics\"]}],[\"$\",\"span\",\"Embodied AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Embodied AI\"]}],[\"$\",\"span\",\"Benchmark Environment\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmark Environment\"]}],[\"$\",\"span\",\"Multi-modal Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-modal Large Language Models\"]}],[\"$\",\"span\",\"Autonomous Underwater Vehicles\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Autonomous Underwater Vehicles\"]}],[\"$\",\"span\",\"Perception\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Perception\"]}],[\"$\",\"span\",\"Decision-Making\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Decision-Making\"]}],[\"$\",\"span\",\"Simulation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Simulation\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-10-1-MotionRAG_Motion_Retrieval-Augmented_Image-to-Video_Generation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-10-1-MotionRAG_Motion_Retrieval-Augmented_Image-to-Video_Generation/\",\"children\":\"[논문리뷰] MotionRAG: Motion Retrieval-Augmented Image-to-Video Generation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Limin Wang이 [arXiv]에 게시한 'MotionRAG: Motion Retrieval-Augmented Image-to-Video Generation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-01 14:04:08+0900\",\"children\":\"2025년 10월 1일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Image-to-Video Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image-to-Video Generation\"]}],[\"$\",\"span\",\"Motion Transfer\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Motion Transfer\"]}],[\"$\",\"span\",\"Retrieval-Augmented Generation (RAG)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Retrieval-Augmented Generation (RAG)\"]}],[\"$\",\"span\",\"In-Context Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"In-Context Learning\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}],[\"$\",\"span\",\"Video Diffusion\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video Diffusion\"]}],[\"$\",\"span\",\"Motion Realism\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Motion Realism\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-10-1-More_Thought_Less_Accuracy_On_the_Dual_Nature_of_Reasoning_in_Vision-Language_Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-10-1-More_Thought_Less_Accuracy_On_the_Dual_Nature_of_Reasoning_in_Vision-Language_Models/\",\"children\":\"[논문리뷰] More Thought, Less Accuracy? On the Dual Nature of Reasoning in Vision-Language Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Fabian Waschkowski이 [arXiv]에 게시한 'More Thought, Less Accuracy? On the Dual Nature of Reasoning in Vision-Language Models' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-01 14:04:08+0900\",\"children\":\"2025년 10월 1일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Vision-Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision-Language Models\"]}],[\"$\",\"span\",\"Multimodal Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Reasoning\"]}],[\"$\",\"span\",\"Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reasoning\"]}],[\"$\",\"span\",\"Visual Forgetting\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Visual Forgetting\"]}],[\"$\",\"span\",\"Perceptual Grounding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Perceptual Grounding\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Policy Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Policy Optimization\"]}],[\"$\",\"span\",\"Visual Anchors\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Visual Anchors\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-10-1-Mem-α_Learning_Memory_Construction_via_Reinforcement_Learning\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-10-1-Mem-α_Learning_Memory_Construction_via_Reinforcement_Learning/\",\"children\":\"[논문리뷰] Mem-α: Learning Memory Construction via Reinforcement Learning\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yuzhen Mao이 [arXiv]에 게시한 'Mem-α: Learning Memory Construction via Reinforcement Learning' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-01 14:04:08+0900\",\"children\":\"2025년 10월 1일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLM Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Agents\"]}],[\"$\",\"span\",\"External Memory\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"External Memory\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Memory Management\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Memory Management\"]}],[\"$\",\"span\",\"Long-Context Understanding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Long-Context Understanding\"]}],[\"$\",\"span\",\"Tool Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Tool Learning\"]}],[\"$\",\"span\",\"RAG\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"RAG\"]}],[\"$\",\"span\",\"Memory Architecture\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Memory Architecture\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-10-1-MCPMark_A_Benchmark_for_Stress-Testing_Realistic_and_Comprehensive_MCP_Use\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-10-1-MCPMark_A_Benchmark_for_Stress-Testing_Realistic_and_Comprehensive_MCP_Use/\",\"children\":\"[논문리뷰] MCPMark: A Benchmark for Stress-Testing Realistic and Comprehensive MCP Use\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"이 [arXiv]에 게시한 'MCPMark: A Benchmark for Stress-Testing Realistic and Comprehensive MCP Use' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-01 14:04:08+0900\",\"children\":\"2025년 10월 1일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLM Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Agents\"]}],[\"$\",\"span\",\"Model Context Protocol\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Model Context Protocol\"]}],[\"$\",\"span\",\"Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmark\"]}],[\"$\",\"span\",\"Tool Use\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Tool Use\"]}],[\"$\",\"span\",\"CRUD Operations\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"CRUD Operations\"]}],[\"$\",\"span\",\"Workflow Automation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Workflow Automation\"]}],[\"$\",\"span\",\"Stress Testing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Stress Testing\"]}],[\"$\",\"span\",\"Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Evaluation\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-10-1-MANI-Pure_Magnitude-Adaptive_Noise_Injection_for_Adversarial_Purification\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-10-1-MANI-Pure_Magnitude-Adaptive_Noise_Injection_for_Adversarial_Purification/\",\"children\":\"[논문리뷰] MANI-Pure: Magnitude-Adaptive Noise Injection for Adversarial Purification\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Zhiming Luo이 [arXiv]에 게시한 'MANI-Pure: Magnitude-Adaptive Noise Injection for Adversarial Purification' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-01 14:04:08+0900\",\"children\":\"2025년 10월 1일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Adversarial Purification\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Adversarial Purification\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}],[\"$\",\"span\",\"Frequency Domain\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Frequency Domain\"]}],[\"$\",\"span\",\"Adaptive Noise Injection\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Adaptive Noise Injection\"]}],[\"$\",\"span\",\"Robustness\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Robustness\"]}],[\"$\",\"span\",\"Image Security\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image Security\"]}],[\"$\",\"span\",\"Magnitude Spectrum\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Magnitude Spectrum\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-10-1-Learning_to_See_Before_Seeing_Demystifying_LLM_Visual_Priors_from_Language_Pre-training\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-10-1-Learning_to_See_Before_Seeing_Demystifying_LLM_Visual_Priors_from_Language_Pre-training/\",\"children\":\"[논문리뷰] Learning to See Before Seeing: Demystifying LLM Visual Priors from Language Pre-training\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Koustuv Sinha이 [arXiv]에 게시한 'Learning to See Before Seeing: Demystifying LLM Visual Priors from Language Pre-training' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-01 14:04:08+0900\",\"children\":\"2025년 10월 1일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLM Visual Priors\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Visual Priors\"]}],[\"$\",\"span\",\"Language Pre-training\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Language Pre-training\"]}],[\"$\",\"span\",\"Multimodal LLM\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal LLM\"]}],[\"$\",\"span\",\"Data Mixture Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Mixture Optimization\"]}],[\"$\",\"span\",\"Reasoning Prior\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reasoning Prior\"]}],[\"$\",\"span\",\"Perception Prior\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Perception Prior\"]}],[\"$\",\"span\",\"VQA\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"VQA\"]}],[\"$\",\"span\",\"MLE-Bench\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"MLE-Bench\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-10-1-Learning_Human-Perceived_Fakeness_in_AI-Generated_Videos_via_Multimodal_LLMs\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-10-1-Learning_Human-Perceived_Fakeness_in_AI-Generated_Videos_via_Multimodal_LLMs/\",\"children\":\"[논문리뷰] Learning Human-Perceived Fakeness in AI-Generated Videos via Multimodal LLMs\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"이 [arXiv]에 게시한 'Learning Human-Perceived Fakeness in AI-Generated Videos via Multimodal LLMs' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-01 14:04:08+0900\",\"children\":\"2025년 10월 1일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"AI-Generated Videos\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"AI-Generated Videos\"]}],[\"$\",\"span\",\"Deepfake Detection\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Deepfake Detection\"]}],[\"$\",\"span\",\"Multimodal LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal LLMs\"]}],[\"$\",\"span\",\"Human Perception\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Human Perception\"]}],[\"$\",\"span\",\"Video Generation Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video Generation Evaluation\"]}],[\"$\",\"span\",\"Spatiotemporal Annotation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Spatiotemporal Annotation\"]}],[\"$\",\"span\",\"Reward Modeling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reward Modeling\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-10-1-LayerD_Decomposing_Raster_Graphic_Designs_into_Layers\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-10-1-LayerD_Decomposing_Raster_Graphic_Designs_into_Layers/\",\"children\":\"[논문리뷰] LayerD: Decomposing Raster Graphic Designs into Layers\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Kota Yamaguchi이 [arXiv]에 게시한 'LayerD: Decomposing Raster Graphic Designs into Layers' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-01 14:04:08+0900\",\"children\":\"2025년 10월 1일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Graphic Design\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Graphic Design\"]}],[\"$\",\"span\",\"Image Decomposition\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image Decomposition\"]}],[\"$\",\"span\",\"Layer Extraction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Layer Extraction\"]}],[\"$\",\"span\",\"Image Matting\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image Matting\"]}],[\"$\",\"span\",\"Background Completion\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Background Completion\"]}],[\"$\",\"span\",\"Deep Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Deep Learning\"]}],[\"$\",\"span\",\"Creative AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Creative AI\"]}],[\"$\",\"span\",\"Dynamic Time Warping\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dynamic Time Warping\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-10-1-Knowledge_Homophily_in_Large_Language_Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-10-1-Knowledge_Homophily_in_Large_Language_Models/\",\"children\":\"[논문리뷰] Knowledge Homophily in Large Language Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Nedim Lipka이 [arXiv]에 게시한 'Knowledge Homophily in Large Language Models' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-01 14:04:08+0900\",\"children\":\"2025년 10월 1일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLM\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM\"]}],[\"$\",\"span\",\"Knowledge Homophily\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Knowledge Homophily\"]}],[\"$\",\"span\",\"Graph Neural Networks\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Graph Neural Networks\"]}],[\"$\",\"span\",\"Knowledge Graph\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Knowledge Graph\"]}],[\"$\",\"span\",\"Knowledge Injection\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Knowledge Injection\"]}],[\"$\",\"span\",\"Question Answering\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Question Answering\"]}],[\"$\",\"span\",\"Fine-tuning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Fine-tuning\"]}],[\"$\",\"span\",\"Knowledge Retrieval\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Knowledge Retrieval\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-10-1-jina-reranker-v3_Last_but_Not_Late_Interaction_for_Document_Reranking\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-10-1-jina-reranker-v3_Last_but_Not_Late_Interaction_for_Document_Reranking/\",\"children\":\"[논문리뷰] jina-reranker-v3: Last but Not Late Interaction for Document Reranking\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"이 [arXiv]에 게시한 'jina-reranker-v3: Last but Not Late Interaction for Document Reranking' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-01 14:04:08+0900\",\"children\":\"2025년 10월 1일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Document Reranking\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Document Reranking\"]}],[\"$\",\"span\",\"Last but Not Late Interaction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Last but Not Late Interaction\"]}],[\"$\",\"span\",\"Multilingual\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multilingual\"]}],[\"$\",\"span\",\"Transformer Architecture\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Transformer Architecture\"]}],[\"$\",\"span\",\"Cross-Encoder\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Cross-Encoder\"]}],[\"$\",\"span\",\"InfoNCE Loss\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"InfoNCE Loss\"]}],[\"$\",\"span\",\"Contextual Embedding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Contextual Embedding\"]}],[\"$\",\"span\",\"Qwen3\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Qwen3\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-10-1-InfoAgent_Advancing_Autonomous_Information-Seeking_Agents\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-10-1-InfoAgent_Advancing_Autonomous_Information-Seeking_Agents/\",\"children\":\"[논문리뷰] InfoAgent: Advancing Autonomous Information-Seeking Agents\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"이 [arXiv]에 게시한 'InfoAgent: Advancing Autonomous Information-Seeking Agents' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-01 14:04:08+0900\",\"children\":\"2025년 10월 1일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLM Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Agents\"]}],[\"$\",\"span\",\"Information Seeking\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Information Seeking\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Data Synthesis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Synthesis\"]}],[\"$\",\"span\",\"Web Search Tools\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Web Search Tools\"]}],[\"$\",\"span\",\"Tool Use\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Tool Use\"]}],[\"$\",\"span\",\"Deep Research Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Deep Research Agents\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-10-1-IMG_Calibrating_Diffusion_Models_via_Implicit_Multimodal_Guidance\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-10-1-IMG_Calibrating_Diffusion_Models_via_Implicit_Multimodal_Guidance/\",\"children\":\"[논문리뷰] IMG: Calibrating Diffusion Models via Implicit Multimodal Guidance\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"이 [arXiv]에 게시한 'IMG: Calibrating Diffusion Models via Implicit Multimodal Guidance' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-01 14:04:08+0900\",\"children\":\"2025년 10월 1일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}],[\"$\",\"span\",\"Multimodal Alignment\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Alignment\"]}],[\"$\",\"span\",\"MLLM\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"MLLM\"]}],[\"$\",\"span\",\"Image Re-generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image Re-generation\"]}],[\"$\",\"span\",\"Preference Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Preference Learning\"]}],[\"$\",\"span\",\"Implicit Guidance\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Implicit Guidance\"]}],[\"$\",\"span\",\"Text-to-Image\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Text-to-Image\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-10-1-Humanline_Online_Alignment_as_Perceptual_Loss\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-10-1-Humanline_Online_Alignment_as_Perceptual_Loss/\",\"children\":\"[논문리뷰] Humanline: Online Alignment as Perceptual Loss\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"이 [arXiv]에 게시한 'Humanline: Online Alignment as Perceptual Loss' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-01 14:04:08+0900\",\"children\":\"2025년 10월 1일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLM Alignment\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Alignment\"]}],[\"$\",\"span\",\"Online RLHF\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Online RLHF\"]}],[\"$\",\"span\",\"Offline RLHF\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Offline RLHF\"]}],[\"$\",\"span\",\"Prospect Theory\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Prospect Theory\"]}],[\"$\",\"span\",\"Perceptual Loss\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Perceptual Loss\"]}],[\"$\",\"span\",\"Human-Centric AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Human-Centric AI\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-10-1-Ferret-UI_Lite_Lessons_from_Building_Small_On-Device_GUI_Agents\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-10-1-Ferret-UI_Lite_Lessons_from_Building_Small_On-Device_GUI_Agents/\",\"children\":\"[논문리뷰] Ferret-UI Lite: Lessons from Building Small On-Device GUI Agents\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"이 [arXiv]에 게시한 'Ferret-UI Lite: Lessons from Building Small On-Device GUI Agents' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-01 14:04:08+0900\",\"children\":\"2025년 10월 1일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"GUI Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"GUI Agents\"]}],[\"$\",\"span\",\"On-Device AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"On-Device AI\"]}],[\"$\",\"span\",\"Multimodal LLM\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal LLM\"]}],[\"$\",\"span\",\"GUI Grounding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"GUI Grounding\"]}],[\"$\",\"span\",\"GUI Navigation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"GUI Navigation\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Supervised Fine-tuning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Supervised Fine-tuning\"]}],[\"$\",\"span\",\"Synthetic Data\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Synthetic Data\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-10-1-Estimating_Time_Series_Foundation_Model_Transferability_via_In-Context_Learning\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-10-1-Estimating_Time_Series_Foundation_Model_Transferability_via_In-Context_Learning/\",\"children\":\"[논문리뷰] Estimating Time Series Foundation Model Transferability via In-Context Learning\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Jun Qi이 [arXiv]에 게시한 'Estimating Time Series Foundation Model Transferability via In-Context Learning' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-01 14:04:08+0900\",\"children\":\"2025년 10월 1일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Time Series Foundation Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Time Series Foundation Models\"]}],[\"$\",\"span\",\"Transferability Estimation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Transferability Estimation\"]}],[\"$\",\"span\",\"In-Context Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"In-Context Learning\"]}],[\"$\",\"span\",\"Tabular Foundation Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Tabular Foundation Models\"]}],[\"$\",\"span\",\"Model Selection\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Model Selection\"]}],[\"$\",\"span\",\"Entropy Profile\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Entropy Profile\"]}],[\"$\",\"span\",\"Meta-learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Meta-learning\"]}],[\"$\",\"span\",\"Forecasting\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Forecasting\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-10-1-EntroPE_Entropy-Guided_Dynamic_Patch_Encoder_for_Time_Series_Forecasting\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-10-1-EntroPE_Entropy-Guided_Dynamic_Patch_Encoder_for_Time_Series_Forecasting/\",\"children\":\"[논문리뷰] EntroPE: Entropy-Guided Dynamic Patch Encoder for Time Series Forecasting\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"이 [arXiv]에 게시한 'EntroPE: Entropy-Guided Dynamic Patch Encoder for Time Series Forecasting' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-01 14:04:08+0900\",\"children\":\"2025년 10월 1일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Time Series Forecasting\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Time Series Forecasting\"]}],[\"$\",\"span\",\"Transformer\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Transformer\"]}],[\"$\",\"span\",\"Dynamic Patching\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dynamic Patching\"]}],[\"$\",\"span\",\"Entropy\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Entropy\"]}],[\"$\",\"span\",\"Predictive Uncertainty\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Predictive Uncertainty\"]}],[\"$\",\"span\",\"Adaptive Encoding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Adaptive Encoding\"]}],[\"$\",\"span\",\"Attention Mechanisms\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Attention Mechanisms\"]}],[\"$\",\"span\",\"Causal Transformer\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Causal Transformer\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-10-1-Efficient_Audio-Visual_Speech_Separation_with_Discrete_Lip_Semantics_and_Multi-Scale_Global-Local_Attention\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-10-1-Efficient_Audio-Visual_Speech_Separation_with_Discrete_Lip_Semantics_and_Multi-Scale_Global-Local_Attention/\",\"children\":\"[논문리뷰] Efficient Audio-Visual Speech Separation with Discrete Lip Semantics and Multi-Scale Global-Local Attention\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"이 [arXiv]에 게시한 'Efficient Audio-Visual Speech Separation with Discrete Lip Semantics and Multi-Scale Global-Local Attention' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-01 14:04:08+0900\",\"children\":\"2025년 10월 1일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Audio-Visual Speech Separation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Audio-Visual Speech Separation\"]}],[\"$\",\"span\",\"Deep Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Deep Learning\"]}],[\"$\",\"span\",\"Efficiency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Efficiency\"]}],[\"$\",\"span\",\"Discrete Lip Semantics\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Discrete Lip Semantics\"]}],[\"$\",\"span\",\"Global-Local Attention\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Global-Local Attention\"]}],[\"$\",\"span\",\"Lightweight Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Lightweight Models\"]}],[\"$\",\"span\",\"VQ-VAE\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"VQ-VAE\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-10-1-dParallel_Learnable_Parallel_Decoding_for_dLLMs\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-10-1-dParallel_Learnable_Parallel_Decoding_for_dLLMs/\",\"children\":\"[논문리뷰] dParallel: Learnable Parallel Decoding for dLLMs\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"이 [arXiv]에 게시한 'dParallel: Learnable Parallel Decoding for dLLMs' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-01 14:04:08+0900\",\"children\":\"2025년 10월 1일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Diffusion Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Language Models\"]}],[\"$\",\"span\",\"Parallel Decoding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Parallel Decoding\"]}],[\"$\",\"span\",\"Inference Acceleration\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Inference Acceleration\"]}],[\"$\",\"span\",\"Certainty Distillation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Certainty Distillation\"]}],[\"$\",\"span\",\"Self-Distillation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Self-Distillation\"]}],[\"$\",\"span\",\"Masked Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Masked Language Models\"]}],[\"$\",\"span\",\"LLaDA\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLaDA\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-10-1-DeepScientist_Advancing_Frontier-Pushing_Scientific_Findings_Progressively\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-10-1-DeepScientist_Advancing_Frontier-Pushing_Scientific_Findings_Progressively/\",\"children\":\"[논문리뷰] DeepScientist: Advancing Frontier-Pushing Scientific Findings Progressively\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"이 [arXiv]에 게시한 'DeepScientist: Advancing Frontier-Pushing Scientific Findings Progressively' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-01 14:04:08+0900\",\"children\":\"2025년 10월 1일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"AI Scientist\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"AI Scientist\"]}],[\"$\",\"span\",\"Autonomous Scientific Discovery\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Autonomous Scientific Discovery\"]}],[\"$\",\"span\",\"Bayesian Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Bayesian Optimization\"]}],[\"$\",\"span\",\"LLM-based Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM-based Agents\"]}],[\"$\",\"span\",\"SOTA-Surpassing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"SOTA-Surpassing\"]}],[\"$\",\"span\",\"Findings Memory\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Findings Memory\"]}],[\"$\",\"span\",\"Exploration-Exploitation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Exploration-Exploitation\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-10-1-DC-VideoGen_Efficient_Video_Generation_with_Deep_Compression_Video_Autoencoder\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-10-1-DC-VideoGen_Efficient_Video_Generation_with_Deep_Compression_Video_Autoencoder/\",\"children\":\"[논문리뷰] DC-VideoGen: Efficient Video Generation with Deep Compression Video Autoencoder\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"이 [arXiv]에 게시한 'DC-VideoGen: Efficient Video Generation with Deep Compression Video Autoencoder' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-01 14:04:08+0900\",\"children\":\"2025년 10월 1일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Video Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video Generation\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}],[\"$\",\"span\",\"Video Autoencoder\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video Autoencoder\"]}],[\"$\",\"span\",\"Deep Compression\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Deep Compression\"]}],[\"$\",\"span\",\"Model Acceleration\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Model Acceleration\"]}],[\"$\",\"span\",\"Fine-tuning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Fine-tuning\"]}],[\"$\",\"span\",\"Latent Space\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Latent Space\"]}],[\"$\",\"span\",\"Temporal Modeling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Temporal Modeling\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-10-1-DA2_Depth_Anything_in_Any_Direction\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-10-1-DA2_Depth_Anything_in_Any_Direction/\",\"children\":\"[논문리뷰] DA^2: Depth Anything in Any Direction\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"이 [arXiv]에 게시한 'DA^2: Depth Anything in Any Direction' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-01 14:04:08+0900\",\"children\":\"2025년 10월 1일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Panoramic Depth Estimation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Panoramic Depth Estimation\"]}],[\"$\",\"span\",\"Zero-shot Generalization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Zero-shot Generalization\"]}],[\"$\",\"span\",\"Data Curation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Curation\"]}],[\"$\",\"span\",\"SphereViT\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"SphereViT\"]}],[\"$\",\"span\",\"Spherical Geometry\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Spherical Geometry\"]}],[\"$\",\"span\",\"360-degree Imaging\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"360-degree Imaging\"]}],[\"$\",\"span\",\"Vision Transformer\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision Transformer\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-10-1-d2Cache_Accelerating_Diffusion-Based_LLMs_via_Dual_Adaptive_Caching\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-10-1-d2Cache_Accelerating_Diffusion-Based_LLMs_via_Dual_Adaptive_Caching/\",\"children\":\"[논문리뷰] d^2Cache: Accelerating Diffusion-Based LLMs via Dual Adaptive Caching\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Jiarui Wang이 [arXiv]에 게시한 'd^2Cache: Accelerating Diffusion-Based LLMs via Dual Adaptive Caching' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-01 14:04:08+0900\",\"children\":\"2025년 10월 1일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}],[\"$\",\"span\",\"Large Language Models (LLMs)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models (LLMs)\"]}],[\"$\",\"span\",\"Inference Acceleration\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Inference Acceleration\"]}],[\"$\",\"span\",\"KV Cache\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"KV Cache\"]}],[\"$\",\"span\",\"Bidirectional Attention\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Bidirectional Attention\"]}],[\"$\",\"span\",\"Adaptive Caching\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Adaptive Caching\"]}],[\"$\",\"span\",\"Token Selection\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Token Selection\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-10-1-Context_Is_What_You_Need_The_Maximum_Effective_Context_Window_for_Real_World_Limits_of_LLMs\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-10-1-Context_Is_What_You_Need_The_Maximum_Effective_Context_Window_for_Real_World_Limits_of_LLMs/\",\"children\":\"[논문리뷰] Context Is What You Need: The Maximum Effective Context Window for Real World Limits of LLMs\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"normanpaulsen이 [arXiv]에 게시한 'Context Is What You Need: The Maximum Effective Context Window for Real World Limits of LLMs' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-01 14:04:08+0900\",\"children\":\"2025년 10월 1일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Context Window\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Context Window\"]}],[\"$\",\"span\",\"Effective Context Window\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Effective Context Window\"]}],[\"$\",\"span\",\"Model Performance\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Model Performance\"]}],[\"$\",\"span\",\"Hallucination Rates\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Hallucination Rates\"]}],[\"$\",\"span\",\"RAG Systems\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"RAG Systems\"]}],[\"$\",\"span\",\"Token Limits\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Token Limits\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-10-1-BuildBench_Benchmarking_LLM_Agents_on_Compiling_Real-World_Open-Source_Software\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-10-1-BuildBench_Benchmarking_LLM_Agents_on_Compiling_Real-World_Open-Source_Software/\",\"children\":\"[논문리뷰] BuildBench: Benchmarking LLM Agents on Compiling Real-World Open-Source Software\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"이 [arXiv]에 게시한 'BuildBench: Benchmarking LLM Agents on Compiling Real-World Open-Source Software' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-01 14:04:08+0900\",\"children\":\"2025년 10월 1일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLM Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Agents\"]}],[\"$\",\"span\",\"Open-Source Software\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Open-Source Software\"]}],[\"$\",\"span\",\"Compilation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Compilation\"]}],[\"$\",\"span\",\"Benchmarking\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmarking\"]}],[\"$\",\"span\",\"Software Engineering\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Software Engineering\"]}],[\"$\",\"span\",\"Error Resolution\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Error Resolution\"]}],[\"$\",\"span\",\"Retrieval-Augmented Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Retrieval-Augmented Generation\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-10-1-Benefits_and_Pitfalls_of_Reinforcement_Learning_for_Language_Model_Planning_A_Theoretical_Perspective\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-10-1-Benefits_and_Pitfalls_of_Reinforcement_Learning_for_Language_Model_Planning_A_Theoretical_Perspective/\",\"children\":\"[논문리뷰] Benefits and Pitfalls of Reinforcement Learning for Language Model Planning: A Theoretical Perspective\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"이 [arXiv]에 게시한 'Benefits and Pitfalls of Reinforcement Learning for Language Model Planning: A Theoretical Perspective' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-01 14:04:08+0900\",\"children\":\"2025년 10월 1일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Planning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Planning\"]}],[\"$\",\"span\",\"Policy Gradient\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Policy Gradient\"]}],[\"$\",\"span\",\"Q-learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Q-learning\"]}],[\"$\",\"span\",\"Supervised Fine-Tuning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Supervised Fine-Tuning\"]}],[\"$\",\"span\",\"Diversity Collapse\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diversity Collapse\"]}],[\"$\",\"span\",\"Reward Hacking\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reward Hacking\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-10-1-A_Cartography_of_Open_Collaboration_in_Open_Source_AI_Mapping_Practices_Motivations_and_Governance_in_14_Open_Large_Language_Model_Projects\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-10-1-A_Cartography_of_Open_Collaboration_in_Open_Source_AI_Mapping_Practices_Motivations_and_Governance_in_14_Open_Large_Language_Model_Projects/\",\"children\":\"[논문리뷰] A Cartography of Open Collaboration in Open Source AI: Mapping Practices, Motivations, and Governance in 14 Open Large Language Model Projects\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Jennifer Ding이 [arXiv]에 게시한 'A Cartography of Open Collaboration in Open Source AI: Mapping Practices, Motivations, and Governance in 14 Open Large Language Model Projects' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-01 14:04:08+0900\",\"children\":\"2025년 10월 1일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Open Source AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Open Source AI\"]}],[\"$\",\"span\",\"LLM Development\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Development\"]}],[\"$\",\"span\",\"Open Collaboration\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Open Collaboration\"]}],[\"$\",\"span\",\"Governance Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Governance Models\"]}],[\"$\",\"span\",\"Developer Motivations\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Developer Motivations\"]}],[\"$\",\"span\",\"Community Engagement\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Community Engagement\"]}],[\"$\",\"span\",\"AI Ecosystem\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"AI Ecosystem\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-10-1-Attention_as_a_Compass_Efficient_Exploration_for_Process-Supervised_RL_in_Reasoning_Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-10-1-Attention_as_a_Compass_Efficient_Exploration_for_Process-Supervised_RL_in_Reasoning_Models/\",\"children\":\"[논문리뷰] Attention as a Compass: Efficient Exploration for Process-Supervised RL in Reasoning Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"이 [arXiv]에 게시한 'Attention as a Compass: Efficient Exploration for Process-Supervised RL in Reasoning Models' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-10-01 14:04:08+0900\",\"children\":\"2025년 10월 1일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Process-Supervised RL\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Process-Supervised RL\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Reasoning Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reasoning Models\"]}],[\"$\",\"span\",\"Attention Mechanism\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Attention Mechanism\"]}],[\"$\",\"span\",\"Efficient Exploration\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Efficient Exploration\"]}],[\"$\",\"span\",\"Adaptive Sampling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Adaptive Sampling\"]}],[\"$\",\"span\",\"Off-Policy Training\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Off-Policy Training\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-30-Visual_Jigsaw_Post-Training_Improves_MLLMs\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-30-Visual_Jigsaw_Post-Training_Improves_MLLMs/\",\"children\":\"[논문리뷰] Visual Jigsaw Post-Training Improves MLLMs\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Lewei Lu이 [arXiv]에 게시한 'Visual Jigsaw Post-Training Improves MLLMs' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-30 13:52:24+0900\",\"children\":\"2025년 9월 30일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"MLLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"MLLMs\"]}],[\"$\",\"span\",\"Post-training\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Post-training\"]}],[\"$\",\"span\",\"Self-supervised Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Self-supervised Learning\"]}],[\"$\",\"span\",\"Visual Understanding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Visual Understanding\"]}],[\"$\",\"span\",\"Jigsaw Puzzles\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Jigsaw Puzzles\"]}],[\"$\",\"span\",\"RLVR\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"RLVR\"]}],[\"$\",\"span\",\"Multimodal Perception\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Perception\"]}],[\"$\",\"span\",\"Spatial Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Spatial Reasoning\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-30-StableToken_A_Noise-Robust_Semantic_Speech_Tokenizer_for_Resilient_SpeechLLMs\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-30-StableToken_A_Noise-Robust_Semantic_Speech_Tokenizer_for_Resilient_SpeechLLMs/\",\"children\":\"[논문리뷰] StableToken: A Noise-Robust Semantic Speech Tokenizer for Resilient SpeechLLMs\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Wei Jia이 [arXiv]에 게시한 'StableToken: A Noise-Robust Semantic Speech Tokenizer for Resilient SpeechLLMs' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-30 13:52:24+0900\",\"children\":\"2025년 9월 30일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Speech Tokenizer\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Speech Tokenizer\"]}],[\"$\",\"span\",\"Noise Robustness\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Noise Robustness\"]}],[\"$\",\"span\",\"Semantic Tokens\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Semantic Tokens\"]}],[\"$\",\"span\",\"SpeechLLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"SpeechLLMs\"]}],[\"$\",\"span\",\"Voting-LFQ\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Voting-LFQ\"]}],[\"$\",\"span\",\"Consensus Training\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Consensus Training\"]}],[\"$\",\"span\",\"Automatic Speech Recognition\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Automatic Speech Recognition\"]}],[\"$\",\"span\",\"Speech Synthesis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Speech Synthesis\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-30-SLA_Beyond_Sparsity_in_Diffusion_Transformers_via_Fine-Tunable_Sparse-Linear_Attention\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-30-SLA_Beyond_Sparsity_in_Diffusion_Transformers_via_Fine-Tunable_Sparse-Linear_Attention/\",\"children\":\"[논문리뷰] SLA: Beyond Sparsity in Diffusion Transformers via Fine-Tunable Sparse-Linear Attention\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"이 [arXiv]에 게시한 'SLA: Beyond Sparsity in Diffusion Transformers via Fine-Tunable Sparse-Linear Attention' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-30 13:52:24+0900\",\"children\":\"2025년 9월 30일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Diffusion Transformers\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Transformers\"]}],[\"$\",\"span\",\"Sparse Attention\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Sparse Attention\"]}],[\"$\",\"span\",\"Linear Attention\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Linear Attention\"]}],[\"$\",\"span\",\"Model Acceleration\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Model Acceleration\"]}],[\"$\",\"span\",\"Video Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video Generation\"]}],[\"$\",\"span\",\"Attention Mechanisms\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Attention Mechanisms\"]}],[\"$\",\"span\",\"Fine-tuning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Fine-tuning\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-30-SANA-Video_Efficient_Video_Generation_with_Block_Linear_Diffusion_Transformer\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-30-SANA-Video_Efficient_Video_Generation_with_Block_Linear_Diffusion_Transformer/\",\"children\":\"[논문리뷰] SANA-Video: Efficient Video Generation with Block Linear Diffusion Transformer\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"이 [arXiv]에 게시한 'SANA-Video: Efficient Video Generation with Block Linear Diffusion Transformer' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-30 13:52:24+0900\",\"children\":\"2025년 9월 30일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Video Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video Generation\"]}],[\"$\",\"span\",\"Diffusion Model\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Model\"]}],[\"$\",\"span\",\"Linear Attention\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Linear Attention\"]}],[\"$\",\"span\",\"Transformer\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Transformer\"]}],[\"$\",\"span\",\"Long Video\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Long Video\"]}],[\"$\",\"span\",\"Efficient Inference\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Efficient Inference\"]}],[\"$\",\"span\",\"Constant Memory\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Constant Memory\"]}],[\"$\",\"span\",\"Low-Cost Training\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Low-Cost Training\"]}],[\"$\",\"span\",\"RTX Deployment\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"RTX Deployment\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-30-RealUnify_Do_Unified_Models_Truly_Benefit_from_Unification_A_Comprehensive_Benchmark\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-30-RealUnify_Do_Unified_Models_Truly_Benefit_from_Unification_A_Comprehensive_Benchmark/\",\"children\":\"[논문리뷰] RealUnify: Do Unified Models Truly Benefit from Unification? A Comprehensive Benchmark\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yuran Wang이 [arXiv]에 게시한 'RealUnify: Do Unified Models Truly Benefit from Unification? A Comprehensive Benchmark' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-30 13:52:24+0900\",\"children\":\"2025년 9월 30일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Unified Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Unified Models\"]}],[\"$\",\"span\",\"Multimodal AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal AI\"]}],[\"$\",\"span\",\"Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmark\"]}],[\"$\",\"span\",\"Capability Synergy\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Capability Synergy\"]}],[\"$\",\"span\",\"Visual Understanding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Visual Understanding\"]}],[\"$\",\"span\",\"Image Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image Generation\"]}],[\"$\",\"span\",\"Dual-Evaluation Protocol\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dual-Evaluation Protocol\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-30-Random_Policy_Valuation_is_Enough_for_LLM_Reasoning_with_Verifiable_Rewards\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-30-Random_Policy_Valuation_is_Enough_for_LLM_Reasoning_with_Verifiable_Rewards/\",\"children\":\"[논문리뷰] Random Policy Valuation is Enough for LLM Reasoning with Verifiable Rewards\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Binxing Jiao이 [arXiv]에 게시한 'Random Policy Valuation is Enough for LLM Reasoning with Verifiable Rewards' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-30 13:52:24+0900\",\"children\":\"2025년 9월 30일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"LLM Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Reasoning\"]}],[\"$\",\"span\",\"Policy Valuation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Policy Valuation\"]}],[\"$\",\"span\",\"Markov Decision Process\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Markov Decision Process\"]}],[\"$\",\"span\",\"Diversity\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diversity\"]}],[\"$\",\"span\",\"Math Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Math Reasoning\"]}],[\"$\",\"span\",\"Verifiable Rewards\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Verifiable Rewards\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-30-OpenGPT-4o-Image_A_Comprehensive_Dataset_for_Advanced_Image_Generation_and_Editing\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-30-OpenGPT-4o-Image_A_Comprehensive_Dataset_for_Advanced_Image_Generation_and_Editing/\",\"children\":\"[논문리뷰] OpenGPT-4o-Image: A Comprehensive Dataset for Advanced Image Generation and Editing\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Huanyu Zhang이 [arXiv]에 게시한 'OpenGPT-4o-Image: A Comprehensive Dataset for Advanced Image Generation and Editing' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-30 13:52:24+0900\",\"children\":\"2025년 9월 30일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Image Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image Generation\"]}],[\"$\",\"span\",\"Image Editing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image Editing\"]}],[\"$\",\"span\",\"Multimodal AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal AI\"]}],[\"$\",\"span\",\"Dataset\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dataset\"]}],[\"$\",\"span\",\"Instruction Following\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Instruction Following\"]}],[\"$\",\"span\",\"Taxonomy\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Taxonomy\"]}],[\"$\",\"span\",\"GPT-40\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"GPT-40\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-30-Multiplayer_Nash_Preference_Optimization\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-30-Multiplayer_Nash_Preference_Optimization/\",\"children\":\"[논문리뷰] Multiplayer Nash Preference Optimization\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"이 [arXiv]에 게시한 'Multiplayer Nash Preference Optimization' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-30 13:52:24+0900\",\"children\":\"2025년 9월 30일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"RLHF\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"RLHF\"]}],[\"$\",\"span\",\"LLM Alignment\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Alignment\"]}],[\"$\",\"span\",\"Nash Equilibrium\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Nash Equilibrium\"]}],[\"$\",\"span\",\"Multiplayer Games\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multiplayer Games\"]}],[\"$\",\"span\",\"Preference Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Preference Optimization\"]}],[\"$\",\"span\",\"Non-transitive Preferences\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Non-transitive Preferences\"]}],[\"$\",\"span\",\"Game Theory\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Game Theory\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-30-EditScore_Unlocking_Online_RL_for_Image_Editing_via_High-Fidelity_Reward_Modeling\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-30-EditScore_Unlocking_Online_RL_for_Image_Editing_via_High-Fidelity_Reward_Modeling/\",\"children\":\"[논문리뷰] EditScore: Unlocking Online RL for Image Editing via High-Fidelity Reward Modeling\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"이 [arXiv]에 게시한 'EditScore: Unlocking Online RL for Image Editing via High-Fidelity Reward Modeling' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-30 13:52:24+0900\",\"children\":\"2025년 9월 30일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Image Editing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image Editing\"]}],[\"$\",\"span\",\"Reward Modeling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reward Modeling\"]}],[\"$\",\"span\",\"Instruction-Guided Editing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Instruction-Guided Editing\"]}],[\"$\",\"span\",\"Online RL\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Online RL\"]}],[\"$\",\"span\",\"Visual Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Visual Language Models\"]}],[\"$\",\"span\",\"Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmark\"]}],[\"$\",\"span\",\"Self-Ensembling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Self-Ensembling\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-30-EasySteer_A_Unified_Framework_for_High-Performance_and_Extensible_LLM_Steering\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-30-EasySteer_A_Unified_Framework_for_High-Performance_and_Extensible_LLM_Steering/\",\"children\":\"[논문리뷰] EasySteer: A Unified Framework for High-Performance and Extensible LLM Steering\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"이 [arXiv]에 게시한 'EasySteer: A Unified Framework for High-Performance and Extensible LLM Steering' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-30 13:52:24+0900\",\"children\":\"2025년 9월 30일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLM Steering Framework\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Steering Framework\"]}],[\"$\",\"span\",\"vLLM Integration\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"vLLM Integration\"]}],[\"$\",\"span\",\"Hidden State Manipulation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Hidden State Manipulation\"]}],[\"$\",\"span\",\"Inference Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Inference Optimization\"]}],[\"$\",\"span\",\"Extensibility\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Extensibility\"]}],[\"$\",\"span\",\"Modular Architecture\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Modular Architecture\"]}],[\"$\",\"span\",\"Reasoning Mitigation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reasoning Mitigation\"]}],[\"$\",\"span\",\"Hallucination Reduction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Hallucination Reduction\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-29-X-Streamer_Unified_Human_World_Modeling_with_Audiovisual_Interaction\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-29-X-Streamer_Unified_Human_World_Modeling_with_Audiovisual_Interaction/\",\"children\":\"[논문리뷰] X-Streamer: Unified Human World Modeling with Audiovisual Interaction\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Guoxian Song이 [arXiv]에 게시한 'X-Streamer: Unified Human World Modeling with Audiovisual Interaction' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-29 13:47:46+0900\",\"children\":\"2025년 9월 29일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Digital Human\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Digital Human\"]}],[\"$\",\"span\",\"Multimodal AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal AI\"]}],[\"$\",\"span\",\"Real-time Streaming\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Real-time Streaming\"]}],[\"$\",\"span\",\"Video Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video Generation\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}],[\"$\",\"span\",\"Transformer Architecture\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Transformer Architecture\"]}],[\"$\",\"span\",\"Audiovisual Synchronization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Audiovisual Synchronization\"]}],[\"$\",\"span\",\"World Modeling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"World Modeling\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-29-X-CoT_Explainable_Text-to-Video_Retrieval_via_LLM-based_Chain-of-Thought_Reasoning\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-29-X-CoT_Explainable_Text-to-Video_Retrieval_via_LLM-based_Chain-of-Thought_Reasoning/\",\"children\":\"[논문리뷰] X-CoT: Explainable Text-to-Video Retrieval via LLM-based Chain-of-Thought Reasoning\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Raghuveer Rao이 [arXiv]에 게시한 'X-CoT: Explainable Text-to-Video Retrieval via LLM-based Chain-of-Thought Reasoning' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-29 13:47:46+0900\",\"children\":\"2025년 9월 29일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Text-to-Video Retrieval\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Text-to-Video Retrieval\"]}],[\"$\",\"span\",\"LLM\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM\"]}],[\"$\",\"span\",\"Chain-of-Thought\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Chain-of-Thought\"]}],[\"$\",\"span\",\"Explainable AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Explainable AI\"]}],[\"$\",\"span\",\"Multimodal Retrieval\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Retrieval\"]}],[\"$\",\"span\",\"Bradley-Terry Model\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Bradley-Terry Model\"]}],[\"$\",\"span\",\"Video Annotation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video Annotation\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-29-WoW_Towards_a_World_omniscient_World_model_Through_Embodied_Interaction\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-29-WoW_Towards_a_World_omniscient_World_model_Through_Embodied_Interaction/\",\"children\":\"[논문리뷰] WoW: Towards a World omniscient World model Through Embodied Interaction\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Weishi Mi이 [arXiv]에 게시한 'WoW: Towards a World omniscient World model Through Embodied Interaction' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-29 13:47:46+0900\",\"children\":\"2025년 9월 29일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"World Model\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"World Model\"]}],[\"$\",\"span\",\"Embodied AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Embodied AI\"]}],[\"$\",\"span\",\"Robotics\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Robotics\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}],[\"$\",\"span\",\"Physical Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Physical Reasoning\"]}],[\"$\",\"span\",\"Vision Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision Language Models\"]}],[\"$\",\"span\",\"Interaction Data\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Interaction Data\"]}],[\"$\",\"span\",\"Self-Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Self-Optimization\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-29-Where_MLLMs_Attend_and_What_They_Rely_On_Explaining_Autoregressive_Token_Generation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-29-Where_MLLMs_Attend_and_What_They_Rely_On_Explaining_Autoregressive_Token_Generation/\",\"children\":\"[논문리뷰] Where MLLMs Attend and What They Rely On: Explaining Autoregressive Token Generation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Shiming Liu이 [arXiv]에 게시한 'Where MLLMs Attend and What They Rely On: Explaining Autoregressive Token Generation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-29 13:47:46+0900\",\"children\":\"2025년 9월 29일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"MLLM\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"MLLM\"]}],[\"$\",\"span\",\"Interpretability\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Interpretability\"]}],[\"$\",\"span\",\"Attribution\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Attribution\"]}],[\"$\",\"span\",\"Token Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Token Generation\"]}],[\"$\",\"span\",\"Black-box Explanation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Black-box Explanation\"]}],[\"$\",\"span\",\"Hallucination Diagnosis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Hallucination Diagnosis\"]}],[\"$\",\"span\",\"Multimodality\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodality\"]}],[\"$\",\"span\",\"VQA\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"VQA\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-29-WebGen-Agent_Enhancing_Interactive_Website_Generation_with_Multi-Level_Feedback_and_Step-Level_Reinforcement_Learning\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-29-WebGen-Agent_Enhancing_Interactive_Website_Generation_with_Multi-Level_Feedback_and_Step-Level_Reinforcement_Learning/\",\"children\":\"[논문리뷰] WebGen-Agent: Enhancing Interactive Website Generation with Multi-Level Feedback and Step-Level Reinforcement Learning\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Zhuofan Zong이 [arXiv]에 게시한 'WebGen-Agent: Enhancing Interactive Website Generation with Multi-Level Feedback and Step-Level Reinforcement Learning' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-29 13:47:46+0900\",\"children\":\"2025년 9월 29일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Website Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Website Generation\"]}],[\"$\",\"span\",\"Code Agent\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Code Agent\"]}],[\"$\",\"span\",\"LLM\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM\"]}],[\"$\",\"span\",\"VLM\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"VLM\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Multi-Level Feedback\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-Level Feedback\"]}],[\"$\",\"span\",\"GUI Agent\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"GUI Agent\"]}],[\"$\",\"span\",\"Step-GRPO\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Step-GRPO\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-29-VoiceAssistant-Eval_Benchmarking_AI_Assistants_across_Listening_Speaking_and_Viewing\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-29-VoiceAssistant-Eval_Benchmarking_AI_Assistants_across_Listening_Speaking_and_Viewing/\",\"children\":\"[논문리뷰] VoiceAssistant-Eval: Benchmarking AI Assistants across Listening, Speaking, and Viewing\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"이 [arXiv]에 게시한 'VoiceAssistant-Eval: Benchmarking AI Assistants across Listening, Speaking, and Viewing' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-29 13:47:46+0900\",\"children\":\"2025년 9월 29일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"AI Assistants\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"AI Assistants\"]}],[\"$\",\"span\",\"Multimodal Benchmarking\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Benchmarking\"]}],[\"$\",\"span\",\"Audio Understanding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Audio Understanding\"]}],[\"$\",\"span\",\"Speech Synthesis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Speech Synthesis\"]}],[\"$\",\"span\",\"Vision-Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision-Language Models\"]}],[\"$\",\"span\",\"Role-play\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Role-play\"]}],[\"$\",\"span\",\"Safety\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Safety\"]}],[\"$\",\"span\",\"Robustness\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Robustness\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-29-Variational_Reasoning_for_Language_Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-29-Variational_Reasoning_for_Language_Models/\",\"children\":\"[논문리뷰] Variational Reasoning for Language Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"이 [arXiv]에 게시한 'Variational Reasoning for Language Models' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-29 13:47:46+0900\",\"children\":\"2025년 9월 29일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Variational Inference\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Variational Inference\"]}],[\"$\",\"span\",\"Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Language Models\"]}],[\"$\",\"span\",\"Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reasoning\"]}],[\"$\",\"span\",\"ELBO\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"ELBO\"]}],[\"$\",\"span\",\"IWAE\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"IWAE\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Latent Variables\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Latent Variables\"]}],[\"$\",\"span\",\"Forward-KL\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Forward-KL\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-29-UniVid_Unifying_Vision_Tasks_with_Pre-trained_Video_Generation_Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-29-UniVid_Unifying_Vision_Tasks_with_Pre-trained_Video_Generation_Models/\",\"children\":\"[논문리뷰] UniVid: Unifying Vision Tasks with Pre-trained Video Generation Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yuchao Gu이 [arXiv]에 게시한 'UniVid: Unifying Vision Tasks with Pre-trained Video Generation Models' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-29 13:47:46+0900\",\"children\":\"2025년 9월 29일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Unified Vision Modeling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Unified Vision Modeling\"]}],[\"$\",\"span\",\"Video Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video Generation\"]}],[\"$\",\"span\",\"Diffusion Transformer\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Transformer\"]}],[\"$\",\"span\",\"Supervised Fine-tuning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Supervised Fine-tuning\"]}],[\"$\",\"span\",\"Cross-modal\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Cross-modal\"]}],[\"$\",\"span\",\"Cross-source Tasks\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Cross-source Tasks\"]}],[\"$\",\"span\",\"Visual Sentences\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Visual Sentences\"]}],[\"$\",\"span\",\"LoRA\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LoRA\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-29-UltraHorizon_Benchmarking_Agent_Capabilities_in_Ultra_Long-Horizon_Scenarios\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-29-UltraHorizon_Benchmarking_Agent_Capabilities_in_Ultra_Long-Horizon_Scenarios/\",\"children\":\"[논문리뷰] UltraHorizon: Benchmarking Agent Capabilities in Ultra Long-Horizon Scenarios\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Zeyu Qin이 [arXiv]에 게시한 'UltraHorizon: Benchmarking Agent Capabilities in Ultra Long-Horizon Scenarios' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-29 13:47:46+0900\",\"children\":\"2025년 9월 29일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLM Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Agents\"]}],[\"$\",\"span\",\"Long-Horizon Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Long-Horizon Reasoning\"]}],[\"$\",\"span\",\"Benchmarking\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmarking\"]}],[\"$\",\"span\",\"Partially Observable\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Partially Observable\"]}],[\"$\",\"span\",\"Tool Use\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Tool Use\"]}],[\"$\",\"span\",\"Memory Management\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Memory Management\"]}],[\"$\",\"span\",\"Exploration\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Exploration\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-29-TUN3D_Towards_Real-World_Scene_Understanding_from_Unposed_Images\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-29-TUN3D_Towards_Real-World_Scene_Understanding_from_Unposed_Images/\",\"children\":\"[논문리뷰] TUN3D: Towards Real-World Scene Understanding from Unposed Images\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Anna Vorontsova이 [arXiv]에 게시한 'TUN3D: Towards Real-World Scene Understanding from Unposed Images' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-29 13:47:46+0900\",\"children\":\"2025년 9월 29일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"3D Scene Understanding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D Scene Understanding\"]}],[\"$\",\"span\",\"Layout Estimation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Layout Estimation\"]}],[\"$\",\"span\",\"3D Object Detection\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D Object Detection\"]}],[\"$\",\"span\",\"Unposed Images\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Unposed Images\"]}],[\"$\",\"span\",\"Sparse Convolutional Networks\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Sparse Convolutional Networks\"]}],[\"$\",\"span\",\"Multi-view Stereo\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-view Stereo\"]}],[\"$\",\"span\",\"Real-time AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Real-time AI\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-29-Think-on-Graph_3.0_Efficient_and_Adaptive_LLM_Reasoning_on_Heterogeneous_Graphs_via_Multi-Agent_Dual-Evolving_Context_Retrieval\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-29-Think-on-Graph_3.0_Efficient_and_Adaptive_LLM_Reasoning_on_Heterogeneous_Graphs_via_Multi-Agent_Dual-Evolving_Context_Retrieval/\",\"children\":\"[논문리뷰] Think-on-Graph 3.0: Efficient and Adaptive LLM Reasoning on Heterogeneous Graphs via Multi-Agent Dual-Evolving Context Retrieval\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"이 [arXiv]에 게시한 'Think-on-Graph 3.0: Efficient and Adaptive LLM Reasoning on Heterogeneous Graphs via Multi-Agent Dual-Evolving Context Retrieval' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-29 13:47:46+0900\",\"children\":\"2025년 9월 29일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"RAG\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"RAG\"]}],[\"$\",\"span\",\"LLM Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Reasoning\"]}],[\"$\",\"span\",\"Knowledge Graphs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Knowledge Graphs\"]}],[\"$\",\"span\",\"Multi-Agent Systems\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-Agent Systems\"]}],[\"$\",\"span\",\"Context Retrieval\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Context Retrieval\"]}],[\"$\",\"span\",\"Heterogeneous Graphs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Heterogeneous Graphs\"]}],[\"$\",\"span\",\"Adaptive Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Adaptive Learning\"]}],[\"$\",\"span\",\"Dual-Evolution\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dual-Evolution\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-29-StateX_Enhancing_RNN_Recall_via_Post-training_State_Expansion\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-29-StateX_Enhancing_RNN_Recall_via_Post-training_State_Expansion/\",\"children\":\"[논문리뷰] StateX: Enhancing RNN Recall via Post-training State Expansion\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Zhiyuan Liu이 [arXiv]에 게시한 'StateX: Enhancing RNN Recall via Post-training State Expansion' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-29 13:47:46+0900\",\"children\":\"2025년 9월 29일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"RNN\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"RNN\"]}],[\"$\",\"span\",\"State Expansion\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"State Expansion\"]}],[\"$\",\"span\",\"Post-training\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Post-training\"]}],[\"$\",\"span\",\"Long-context Recall\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Long-context Recall\"]}],[\"$\",\"span\",\"Linear Attention\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Linear Attention\"]}],[\"$\",\"span\",\"State Space Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"State Space Models\"]}],[\"$\",\"span\",\"GLA\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"GLA\"]}],[\"$\",\"span\",\"Mamba2\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Mamba2\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-29-SPARK_Synergistic_Policy_And_Reward_Co-Evolving_Framework\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-29-SPARK_Synergistic_Policy_And_Reward_Co-Evolving_Framework/\",\"children\":\"[논문리뷰] SPARK: Synergistic Policy And Reward Co-Evolving Framework\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"이 [arXiv]에 게시한 'SPARK: Synergistic Policy And Reward Co-Evolving Framework' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-29 13:47:46+0900\",\"children\":\"2025년 9월 29일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLMs\"]}],[\"$\",\"span\",\"LVLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LVLMs\"]}],[\"$\",\"span\",\"Reward Modeling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reward Modeling\"]}],[\"$\",\"span\",\"Policy Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Policy Optimization\"]}],[\"$\",\"span\",\"Self-Reflection\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Self-Reflection\"]}],[\"$\",\"span\",\"Verifiable Rewards\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Verifiable Rewards\"]}],[\"$\",\"span\",\"Co-evolution\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Co-evolution\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-29-See_Point_Fly_A_Learning-Free_VLM_Framework_for_Universal_Unmanned_Aerial_Navigation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-29-See_Point_Fly_A_Learning-Free_VLM_Framework_for_Universal_Unmanned_Aerial_Navigation/\",\"children\":\"[논문리뷰] See, Point, Fly: A Learning-Free VLM Framework for Universal Unmanned Aerial Navigation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Chih-Hai Su이 [arXiv]에 게시한 'See, Point, Fly: A Learning-Free VLM Framework for Universal Unmanned Aerial Navigation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-29 13:47:46+0900\",\"children\":\"2025년 9월 29일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Vision-Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision-Language Models\"]}],[\"$\",\"span\",\"UAV Navigation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"UAV Navigation\"]}],[\"$\",\"span\",\"Zero-shot\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Zero-shot\"]}],[\"$\",\"span\",\"Spatial Grounding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Spatial Grounding\"]}],[\"$\",\"span\",\"Waypoint Prompting\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Waypoint Prompting\"]}],[\"$\",\"span\",\"Autonomous Navigation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Autonomous Navigation\"]}],[\"$\",\"span\",\"Adaptive Control\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Adaptive Control\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-29-ReviewScore_Misinformed_Peer_Review_Detection_with_Large_Language_Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-29-ReviewScore_Misinformed_Peer_Review_Detection_with_Large_Language_Models/\",\"children\":\"[논문리뷰] ReviewScore: Misinformed Peer Review Detection with Large Language Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"이 [arXiv]에 게시한 'ReviewScore: Misinformed Peer Review Detection with Large Language Models' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-29 13:47:46+0900\",\"children\":\"2025년 9월 29일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Peer Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Peer Review\"]}],[\"$\",\"span\",\"Review Quality\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review Quality\"]}],[\"$\",\"span\",\"Large Language Models (LLMs)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models (LLMs)\"]}],[\"$\",\"span\",\"Misinformed Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Misinformed Review\"]}],[\"$\",\"span\",\"Argument Reconstruction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Argument Reconstruction\"]}],[\"$\",\"span\",\"Factuality Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Factuality Evaluation\"]}],[\"$\",\"span\",\"Natural Language Processing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Natural Language Processing\"]}],[\"$\",\"span\",\"Automated Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Automated Evaluation\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-29-RefAM_Attention_Magnets_for_Zero-Shot_Referral_Segmentation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-29-RefAM_Attention_Magnets_for_Zero-Shot_Referral_Segmentation/\",\"children\":\"[논문리뷰] RefAM: Attention Magnets for Zero-Shot Referral Segmentation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Federico Tombari이 [arXiv]에 게시한 'RefAM: Attention Magnets for Zero-Shot Referral Segmentation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-29 13:47:46+0900\",\"children\":\"2025년 9월 29일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Zero-Shot Segmentation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Zero-Shot Segmentation\"]}],[\"$\",\"span\",\"Referring Segmentation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Referring Segmentation\"]}],[\"$\",\"span\",\"Diffusion Transformers (DiTs)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Transformers (DiTs)\"]}],[\"$\",\"span\",\"Attention Mechanisms\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Attention Mechanisms\"]}],[\"$\",\"span\",\"Attention Sinks\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Attention Sinks\"]}],[\"$\",\"span\",\"Stop Words\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Stop Words\"]}],[\"$\",\"span\",\"Vision-Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision-Language Models\"]}],[\"$\",\"span\",\"Training-Free Methods\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Training-Free Methods\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-29-Real-Time_Object_Detection_Meets_DINOv3\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-29-Real-Time_Object_Detection_Meets_DINOv3/\",\"children\":\"[논문리뷰] Real-Time Object Detection Meets DINOv3\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Xi Shen이 [arXiv]에 게시한 'Real-Time Object Detection Meets DINOv3' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-29 13:47:46+0900\",\"children\":\"2025년 9월 29일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Real-time Object Detection\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Real-time Object Detection\"]}],[\"$\",\"span\",\"DINOv3\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"DINOv3\"]}],[\"$\",\"span\",\"DEIMv2\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"DEIMv2\"]}],[\"$\",\"span\",\"Vision Transformer\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision Transformer\"]}],[\"$\",\"span\",\"Multi-scale Features\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-scale Features\"]}],[\"$\",\"span\",\"Spatial Tuning Adapter\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Spatial Tuning Adapter\"]}],[\"$\",\"span\",\"Lightweight Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Lightweight Models\"]}],[\"$\",\"span\",\"Object Detection Framework\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Object Detection Framework\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-29-Quantile_Advantage_Estimation_for_Entropy-Safe_Reasoning\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-29-Quantile_Advantage_Estimation_for_Entropy-Safe_Reasoning/\",\"children\":\"[논문리뷰] Quantile Advantage Estimation for Entropy-Safe Reasoning\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"An Zhang이 [arXiv]에 게시한 'Quantile Advantage Estimation for Entropy-Safe Reasoning' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-29 13:47:46+0900\",\"children\":\"2025년 9월 29일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"LLM Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Reasoning\"]}],[\"$\",\"span\",\"Entropy Control\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Entropy Control\"]}],[\"$\",\"span\",\"Advantage Estimation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Advantage Estimation\"]}],[\"$\",\"span\",\"Quantile Baseline\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Quantile Baseline\"]}],[\"$\",\"span\",\"Exploration-Exploitation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Exploration-Exploitation\"]}],[\"$\",\"span\",\"RLVR\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"RLVR\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-29-PromptCoT_2.0_Scaling_Prompt_Synthesis_for_Large_Language_Model_Reasoning\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-29-PromptCoT_2.0_Scaling_Prompt_Synthesis_for_Large_Language_Model_Reasoning/\",\"children\":\"[논문리뷰] PromptCoT 2.0: Scaling Prompt Synthesis for Large Language Model Reasoning\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Lingpeng Kong이 [arXiv]에 게시한 'PromptCoT 2.0: Scaling Prompt Synthesis for Large Language Model Reasoning' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-29 13:47:46+0900\",\"children\":\"2025년 9월 29일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Prompt Synthesis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Prompt Synthesis\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reasoning\"]}],[\"$\",\"span\",\"Expectation-Maximization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Expectation-Maximization\"]}],[\"$\",\"span\",\"Self-Play\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Self-Play\"]}],[\"$\",\"span\",\"Supervised Fine-Tuning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Supervised Fine-Tuning\"]}],[\"$\",\"span\",\"Task Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Task Generation\"]}],[\"$\",\"span\",\"Rationale Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Rationale Generation\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-29-No_Prompt_Left_Behind_Exploiting_Zero-Variance_Prompts_in_LLM_Reinforcement_Learning_via_Entropy-Guided_Advantage_Shaping\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-29-No_Prompt_Left_Behind_Exploiting_Zero-Variance_Prompts_in_LLM_Reinforcement_Learning_via_Entropy-Guided_Advantage_Shaping/\",\"children\":\"[논문리뷰] No Prompt Left Behind: Exploiting Zero-Variance Prompts in LLM Reinforcement Learning via Entropy-Guided Advantage Shaping\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"이 [arXiv]에 게시한 'No Prompt Left Behind: Exploiting Zero-Variance Prompts in LLM Reinforcement Learning via Entropy-Guided Advantage Shaping' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-29 13:47:46+0900\",\"children\":\"2025년 9월 29일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLM Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Reinforcement Learning\"]}],[\"$\",\"span\",\"Zero-Variance Prompts\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Zero-Variance Prompts\"]}],[\"$\",\"span\",\"Advantage Shaping\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Advantage Shaping\"]}],[\"$\",\"span\",\"Entropy-Guided\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Entropy-Guided\"]}],[\"$\",\"span\",\"Math Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Math Reasoning\"]}],[\"$\",\"span\",\"RLVR\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"RLVR\"]}],[\"$\",\"span\",\"Group Relative Policy Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Group Relative Policy Optimization\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-29-MinerU2.5_A_Decoupled_Vision-Language_Model_for_Efficient_High-Resolution_Document_Parsing\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-29-MinerU2.5_A_Decoupled_Vision-Language_Model_for_Efficient_High-Resolution_Document_Parsing/\",\"children\":\"[논문리뷰] MinerU2.5: A Decoupled Vision-Language Model for Efficient High-Resolution Document Parsing\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"SunYuefeng이 [arXiv]에 게시한 'MinerU2.5: A Decoupled Vision-Language Model for Efficient High-Resolution Document Parsing' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-29 13:47:46+0900\",\"children\":\"2025년 9월 29일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Document Parsing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Document Parsing\"]}],[\"$\",\"span\",\"Vision-Language Model\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision-Language Model\"]}],[\"$\",\"span\",\"High-Resolution\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"High-Resolution\"]}],[\"$\",\"span\",\"Two-Stage Inference\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Two-Stage Inference\"]}],[\"$\",\"span\",\"Layout Analysis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Layout Analysis\"]}],[\"$\",\"span\",\"Content Recognition\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Content Recognition\"]}],[\"$\",\"span\",\"Data Engine\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Engine\"]}],[\"$\",\"span\",\"Computational Efficiency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Computational Efficiency\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-29-Mind-the-Glitch_Visual_Correspondence_for_Detecting_Inconsistencies_in_Subject-Driven_Generation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-29-Mind-the-Glitch_Visual_Correspondence_for_Detecting_Inconsistencies_in_Subject-Driven_Generation/\",\"children\":\"[논문리뷰] Mind-the-Glitch: Visual Correspondence for Detecting Inconsistencies in Subject-Driven Generation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Peter Wonka이 [arXiv]에 게시한 'Mind-the-Glitch: Visual Correspondence for Detecting Inconsistencies in Subject-Driven Generation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-29 13:47:46+0900\",\"children\":\"2025년 9월 29일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Subject-Driven Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Subject-Driven Generation\"]}],[\"$\",\"span\",\"Visual Inconsistency Detection\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Visual Inconsistency Detection\"]}],[\"$\",\"span\",\"Feature Disentanglement\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Feature Disentanglement\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}],[\"$\",\"span\",\"Semantic Correspondence\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Semantic Correspondence\"]}],[\"$\",\"span\",\"Evaluation Metric\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Evaluation Metric\"]}],[\"$\",\"span\",\"Spatial Localization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Spatial Localization\"]}],[\"$\",\"span\",\"Contrastive Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Contrastive Learning\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-29-MesaTask_Towards_Task-Driven_Tabletop_Scene_Generation_via_3D_Spatial_Reasoning\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-29-MesaTask_Towards_Task-Driven_Tabletop_Scene_Generation_via_3D_Spatial_Reasoning/\",\"children\":\"[논문리뷰] MesaTask: Towards Task-Driven Tabletop Scene Generation via 3D Spatial Reasoning\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Weipeng Zhong이 [arXiv]에 게시한 'MesaTask: Towards Task-Driven Tabletop Scene Generation via 3D Spatial Reasoning' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-29 13:47:46+0900\",\"children\":\"2025년 9월 29일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"3D Scene Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D Scene Generation\"]}],[\"$\",\"span\",\"Robotic Manipulation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Robotic Manipulation\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Spatial Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Spatial Reasoning\"]}],[\"$\",\"span\",\"Dataset\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dataset\"]}],[\"$\",\"span\",\"Direct Preference Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Direct Preference Optimization\"]}],[\"$\",\"span\",\"Tabletop Scene\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Tabletop Scene\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-29-LucidFlux_Caption-Free_Universal_Image_Restoration_via_a_Large-Scale_Diffusion_Transformer\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-29-LucidFlux_Caption-Free_Universal_Image_Restoration_via_a_Large-Scale_Diffusion_Transformer/\",\"children\":\"[논문리뷰] LucidFlux: Caption-Free Universal Image Restoration via a Large-Scale Diffusion Transformer\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"이 [arXiv]에 게시한 'LucidFlux: Caption-Free Universal Image Restoration via a Large-Scale Diffusion Transformer' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-29 13:47:46+0900\",\"children\":\"2025년 9월 29일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Universal Image Restoration\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Universal Image Restoration\"]}],[\"$\",\"span\",\"Diffusion Transformer\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Transformer\"]}],[\"$\",\"span\",\"Caption-Free\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Caption-Free\"]}],[\"$\",\"span\",\"Semantic Alignment\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Semantic Alignment\"]}],[\"$\",\"span\",\"Image Quality Assessment\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image Quality Assessment\"]}],[\"$\",\"span\",\"Data Curation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Curation\"]}],[\"$\",\"span\",\"Real-World Degradations\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Real-World Degradations\"]}],[\"$\",\"span\",\"Deep Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Deep Learning\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-29-LongLive_Real-time_Interactive_Long_Video_Generation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-29-LongLive_Real-time_Interactive_Long_Video_Generation/\",\"children\":\"[논문리뷰] LongLive: Real-time Interactive Long Video Generation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"이 [arXiv]에 게시한 'LongLive: Real-time Interactive Long Video Generation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-29 13:47:46+0900\",\"children\":\"2025년 9월 29일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Long Video Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Long Video Generation\"]}],[\"$\",\"span\",\"Real-time\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Real-time\"]}],[\"$\",\"span\",\"Interactive AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Interactive AI\"]}],[\"$\",\"span\",\"Autoregressive Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Autoregressive Models\"]}],[\"$\",\"span\",\"KV Cache\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"KV Cache\"]}],[\"$\",\"span\",\"Streaming Tuning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Streaming Tuning\"]}],[\"$\",\"span\",\"Attention Sink\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Attention Sink\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-29-Learn_the_Ropes_Then_Trust_the_Wins_Self-imitation_with_Progressive_Exploration_for_Agentic_Reinforcement_Learning\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-29-Learn_the_Ropes_Then_Trust_the_Wins_Self-imitation_with_Progressive_Exploration_for_Agentic_Reinforcement_Learning/\",\"children\":\"[논문리뷰] Learn the Ropes, Then Trust the Wins: Self-imitation with Progressive Exploration for Agentic Reinforcement Learning\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Gang Li이 [arXiv]에 게시한 'Learn the Ropes, Then Trust the Wins: Self-imitation with Progressive Exploration for Agentic Reinforcement Learning' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-29 13:47:46+0900\",\"children\":\"2025년 9월 29일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"LLM Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Agents\"]}],[\"$\",\"span\",\"Exploration-Exploitation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Exploration-Exploitation\"]}],[\"$\",\"span\",\"Self-Imitation Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Self-Imitation Learning\"]}],[\"$\",\"span\",\"Intrinsic Rewards\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Intrinsic Rewards\"]}],[\"$\",\"span\",\"Curriculum Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Curriculum Learning\"]}],[\"$\",\"span\",\"Policy Entropy\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Policy Entropy\"]}],[\"$\",\"span\",\"Tool Use\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Tool Use\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-29-Language_Models_Can_Learn_from_Verbal_Feedback_Without_Scalar_Rewards\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-29-Language_Models_Can_Learn_from_Verbal_Feedback_Without_Scalar_Rewards/\",\"children\":\"[논문리뷰] Language Models Can Learn from Verbal Feedback Without Scalar Rewards\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"이 [arXiv]에 게시한 'Language Models Can Learn from Verbal Feedback Without Scalar Rewards' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-29 13:47:46+0900\",\"children\":\"2025년 9월 29일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Verbal Feedback\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Verbal Feedback\"]}],[\"$\",\"span\",\"Conditional Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Conditional Generation\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Feedback-Conditional Policy\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Feedback-Conditional Policy\"]}],[\"$\",\"span\",\"Offline-Online Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Offline-Online Learning\"]}],[\"$\",\"span\",\"Reward Hypothesis Bypass\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reward Hypothesis Bypass\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-29-Instruction-Following_Evaluation_in_Function_Calling_for_Large_Language_Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-29-Instruction-Following_Evaluation_in_Function_Calling_for_Large_Language_Models/\",\"children\":\"[논문리뷰] Instruction-Following Evaluation in Function Calling for Large Language Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"NikolaiSkripko이 [arXiv]에 게시한 'Instruction-Following Evaluation in Function Calling for Large Language Models' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-29 13:47:46+0900\",\"children\":\"2025년 9월 29일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Function Calling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Function Calling\"]}],[\"$\",\"span\",\"LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLMs\"]}],[\"$\",\"span\",\"Instruction Following\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Instruction Following\"]}],[\"$\",\"span\",\"Benchmarking\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmarking\"]}],[\"$\",\"span\",\"JSON Schema\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"JSON Schema\"]}],[\"$\",\"span\",\"AI Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"AI Agents\"]}],[\"$\",\"span\",\"Evaluation Metrics\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Evaluation Metrics\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-29-HiGS_History-Guided_Sampling_for_Plug-and-Play_Enhancement_of_Diffusion_Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-29-HiGS_History-Guided_Sampling_for_Plug-and-Play_Enhancement_of_Diffusion_Models/\",\"children\":\"[논문리뷰] HiGS: History-Guided Sampling for Plug-and-Play Enhancement of Diffusion Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Romann M. Weber이 [arXiv]에 게시한 'HiGS: History-Guided Sampling for Plug-and-Play Enhancement of Diffusion Models' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-29 13:47:46+0900\",\"children\":\"2025년 9월 29일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}],[\"$\",\"span\",\"Sampling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Sampling\"]}],[\"$\",\"span\",\"Generative AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generative AI\"]}],[\"$\",\"span\",\"Image Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image Generation\"]}],[\"$\",\"span\",\"Plug-and-Play\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Plug-and-Play\"]}],[\"$\",\"span\",\"Training-Free\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Training-Free\"]}],[\"$\",\"span\",\"Guidance\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Guidance\"]}],[\"$\",\"span\",\"Momentum-Based Methods\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Momentum-Based Methods\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-29-FlashEdit_Decoupling_Speed_Structure_and_Semantics_for_Precise_Image_Editing\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-29-FlashEdit_Decoupling_Speed_Structure_and_Semantics_for_Precise_Image_Editing/\",\"children\":\"[논문리뷰] FlashEdit: Decoupling Speed, Structure, and Semantics for Precise Image Editing\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Linghe Kong이 [arXiv]에 게시한 'FlashEdit: Decoupling Speed, Structure, and Semantics for Precise Image Editing' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-29 13:47:46+0900\",\"children\":\"2025년 9월 29일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Text-Guided Image Editing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Text-Guided Image Editing\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}],[\"$\",\"span\",\"Real-Time Editing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Real-Time Editing\"]}],[\"$\",\"span\",\"One-Step Inversion\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"One-Step Inversion\"]}],[\"$\",\"span\",\"Attention Control\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Attention Control\"]}],[\"$\",\"span\",\"Background Preservation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Background Preservation\"]}],[\"$\",\"span\",\"Semantic Disentanglement\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Semantic Disentanglement\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-29-Fine-tuning_Done_Right_in_Model_Editing\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-29-Fine-tuning_Done_Right_in_Model_Editing/\",\"children\":\"[논문리뷰] Fine-tuning Done Right in Model Editing\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Du Su이 [arXiv]에 게시한 'Fine-tuning Done Right in Model Editing' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-29 13:47:46+0900\",\"children\":\"2025년 9월 29일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Model Editing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Model Editing\"]}],[\"$\",\"span\",\"Fine-tuning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Fine-tuning\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Catastrophic Forgetting\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Catastrophic Forgetting\"]}],[\"$\",\"span\",\"Breadth-First Pipeline\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Breadth-First Pipeline\"]}],[\"$\",\"span\",\"Depth-First Pipeline\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Depth-First Pipeline\"]}],[\"$\",\"span\",\"Localized Tuning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Localized Tuning\"]}],[\"$\",\"span\",\"Lifelong Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Lifelong Learning\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-29-Finding_3D_Positions_of_Distant_Objects_from_Noisy_Camera_Movement_and_Semantic_Segmentation_Sequences\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-29-Finding_3D_Positions_of_Distant_Objects_from_Noisy_Camera_Movement_and_Semantic_Segmentation_Sequences/\",\"children\":\"[논문리뷰] Finding 3D Positions of Distant Objects from Noisy Camera Movement and Semantic Segmentation Sequences\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Eija Honkavaara이 [arXiv]에 게시한 'Finding 3D Positions of Distant Objects from Noisy Camera Movement and Semantic Segmentation Sequences' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-29 13:47:46+0900\",\"children\":\"2025년 9월 29일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"3D Object Localization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D Object Localization\"]}],[\"$\",\"span\",\"Particle Filter\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Particle Filter\"]}],[\"$\",\"span\",\"Multi-target Tracking\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-target Tracking\"]}],[\"$\",\"span\",\"Drone Surveillance\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Drone Surveillance\"]}],[\"$\",\"span\",\"Wildfire Monitoring\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Wildfire Monitoring\"]}],[\"$\",\"span\",\"Semantic Segmentation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Semantic Segmentation\"]}],[\"$\",\"span\",\"Camera Pose Estimation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Camera Pose Estimation\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-29-ERGO_Efficient_High-Resolution_Visual_Understanding_for_Vision-Language_Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-29-ERGO_Efficient_High-Resolution_Visual_Understanding_for_Vision-Language_Models/\",\"children\":\"[논문리뷰] ERGO: Efficient High-Resolution Visual Understanding for Vision-Language Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Ki-Ung Song이 [arXiv]에 게시한 'ERGO: Efficient High-Resolution Visual Understanding for Vision-Language Models' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-29 13:47:46+0900\",\"children\":\"2025년 9월 29일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"High-Resolution Vision\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"High-Resolution Vision\"]}],[\"$\",\"span\",\"Vision-Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision-Language Models\"]}],[\"$\",\"span\",\"Efficient Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Efficient Reasoning\"]}],[\"$\",\"span\",\"Coarse-to-Fine\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Coarse-to-Fine\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Visual Understanding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Visual Understanding\"]}],[\"$\",\"span\",\"Attention Mechanism\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Attention Mechanism\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-29-EPO_Entropy-regularized_Policy_Optimization_for_LLM_Agents_Reinforcement_Learning\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-29-EPO_Entropy-regularized_Policy_Optimization_for_LLM_Agents_Reinforcement_Learning/\",\"children\":\"[논문리뷰] EPO: Entropy-regularized Policy Optimization for LLM Agents Reinforcement Learning\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Li Yu-Jhe이 [arXiv]에 게시한 'EPO: Entropy-regularized Policy Optimization for LLM Agents Reinforcement Learning' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-29 13:47:46+0900\",\"children\":\"2025년 9월 29일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLM Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Agents\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Entropy Regularization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Entropy Regularization\"]}],[\"$\",\"span\",\"Policy Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Policy Optimization\"]}],[\"$\",\"span\",\"Sparse Rewards\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Sparse Rewards\"]}],[\"$\",\"span\",\"Multi-turn Environments\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-turn Environments\"]}],[\"$\",\"span\",\"Exploration-Exploitation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Exploration-Exploitation\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-29-D-Artemis_A_Deliberative_Cognitive_Framework_for_Mobile_GUI_Multi-Agents\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-29-D-Artemis_A_Deliberative_Cognitive_Framework_for_Mobile_GUI_Multi-Agents/\",\"children\":\"[논문리뷰] D-Artemis: A Deliberative Cognitive Framework for Mobile GUI Multi-Agents\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Jinyuan Li이 [arXiv]에 게시한 'D-Artemis: A Deliberative Cognitive Framework for Mobile GUI Multi-Agents' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-29 13:47:46+0900\",\"children\":\"2025년 9월 29일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Mobile GUI Automation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Mobile GUI Automation\"]}],[\"$\",\"span\",\"Multi-Agent System\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-Agent System\"]}],[\"$\",\"span\",\"Cognitive Architecture\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Cognitive Architecture\"]}],[\"$\",\"span\",\"Pre-execution Alignment\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Pre-execution Alignment\"]}],[\"$\",\"span\",\"Post-execution Reflection\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Post-execution Reflection\"]}],[\"$\",\"span\",\"Retrieval-Augmented Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Retrieval-Augmented Generation\"]}],[\"$\",\"span\",\"Multimodal LLM\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal LLM\"]}],[\"$\",\"span\",\"Deliberative AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Deliberative AI\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-29-CHURRO_Making_History_Readable_with_an_Open-Weight_Large_Vision-Language_Model_for_High-Accuracy_Low-Cost_Historical_Text_Recognition\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-29-CHURRO_Making_History_Readable_with_an_Open-Weight_Large_Vision-Language_Model_for_High-Accuracy_Low-Cost_Historical_Text_Recognition/\",\"children\":\"[논문리뷰] CHURRO: Making History Readable with an Open-Weight Large Vision-Language Model for High-Accuracy, Low-Cost Historical Text Recognition\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"이 [arXiv]에 게시한 'CHURRO: Making History Readable with an Open-Weight Large Vision-Language Model for High-Accuracy, Low-Cost Historical Text Recognition' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-29 13:47:46+0900\",\"children\":\"2025년 9월 29일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Historical Text Recognition\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Historical Text Recognition\"]}],[\"$\",\"span\",\"Vision-Language Model\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision-Language Model\"]}],[\"$\",\"span\",\"Open-Weight Model\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Open-Weight Model\"]}],[\"$\",\"span\",\"OCR\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"OCR\"]}],[\"$\",\"span\",\"Cultural Heritage\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Cultural Heritage\"]}],[\"$\",\"span\",\"Low-Cost AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Low-Cost AI\"]}],[\"$\",\"span\",\"Dataset Curation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dataset Curation\"]}],[\"$\",\"span\",\"Fine-tuning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Fine-tuning\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-29-Chasing_the_Tail_Effective_Rubric-based_Reward_Modeling_for_Large_Language_Model_Post-Training\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-29-Chasing_the_Tail_Effective_Rubric-based_Reward_Modeling_for_Large_Language_Model_Post-Training/\",\"children\":\"[논문리뷰] Chasing the Tail: Effective Rubric-based Reward Modeling for Large Language Model Post-Training\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"이 [arXiv]에 게시한 'Chasing the Tail: Effective Rubric-based Reward Modeling for Large Language Model Post-Training' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-29 13:47:46+0900\",\"children\":\"2025년 9월 29일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLM\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM\"]}],[\"$\",\"span\",\"Reinforcement Fine-tuning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Fine-tuning\"]}],[\"$\",\"span\",\"Reward Modeling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reward Modeling\"]}],[\"$\",\"span\",\"Reward Over-optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reward Over-optimization\"]}],[\"$\",\"span\",\"Rubric-based Rewards\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Rubric-based Rewards\"]}],[\"$\",\"span\",\"High-reward Tail\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"High-reward Tail\"]}],[\"$\",\"span\",\"Off-policy Data\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Off-policy Data\"]}],[\"$\",\"span\",\"LLM Alignment\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Alignment\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-29-CapRL_Stimulating_Dense_Image_Caption_Capabilities_via_Reinforcement_Learning\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-29-CapRL_Stimulating_Dense_Image_Caption_Capabilities_via_Reinforcement_Learning/\",\"children\":\"[논문리뷰] CapRL: Stimulating Dense Image Caption Capabilities via Reinforcement Learning\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"이 [arXiv]에 게시한 'CapRL: Stimulating Dense Image Caption Capabilities via Reinforcement Learning' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-29 13:47:46+0900\",\"children\":\"2025년 9월 29일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Image Captioning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image Captioning\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Verifiable Rewards\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Verifiable Rewards\"]}],[\"$\",\"span\",\"LVLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LVLMs\"]}],[\"$\",\"span\",\"VQA\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"VQA\"]}],[\"$\",\"span\",\"Data Curation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Curation\"]}],[\"$\",\"span\",\"Caption Quality\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Caption Quality\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-26-When_Judgment_Becomes_Noise_How_Design_Failures_in_LLM_Judge_Benchmarks_Silently_Undermine_Validity\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-26-When_Judgment_Becomes_Noise_How_Design_Failures_in_LLM_Judge_Benchmarks_Silently_Undermine_Validity/\",\"children\":\"[논문리뷰] When Judgment Becomes Noise: How Design Failures in LLM Judge Benchmarks Silently Undermine Validity\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"John P Dickerson이 [arXiv]에 게시한 'When Judgment Becomes Noise: How Design Failures in LLM Judge Benchmarks Silently Undermine Validity' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-26 13:35:32+0900\",\"children\":\"2025년 9월 26일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLM Judge\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Judge\"]}],[\"$\",\"span\",\"Benchmark Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmark Evaluation\"]}],[\"$\",\"span\",\"Validity\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Validity\"]}],[\"$\",\"span\",\"Reliability\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reliability\"]}],[\"$\",\"span\",\"Psychometrics\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Psychometrics\"]}],[\"$\",\"span\",\"Factor Analysis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Factor Analysis\"]}],[\"$\",\"span\",\"Schema Adherence\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Schema Adherence\"]}],[\"$\",\"span\",\"ELO Ranking\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"ELO Ranking\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-26-VCRL_Variance-based_Curriculum_Reinforcement_Learning_for_Large_Language_Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-26-VCRL_Variance-based_Curriculum_Reinforcement_Learning_for_Large_Language_Models/\",\"children\":\"[논문리뷰] VCRL: Variance-based Curriculum Reinforcement Learning for Large Language Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yuewei Zhang이 [arXiv]에 게시한 'VCRL: Variance-based Curriculum Reinforcement Learning for Large Language Models' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-26 13:35:32+0900\",\"children\":\"2025년 9월 26일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Curriculum Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Curriculum Learning\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Mathematical Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Mathematical Reasoning\"]}],[\"$\",\"span\",\"Variance-based Sampling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Variance-based Sampling\"]}],[\"$\",\"span\",\"Replay Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Replay Learning\"]}],[\"$\",\"span\",\"Policy Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Policy Optimization\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-26-V-GameGym_Visual_Game_Generation_for_Code_Large_Language_Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-26-V-GameGym_Visual_Game_Generation_for_Code_Large_Language_Models/\",\"children\":\"[논문리뷰] V-GameGym: Visual Game Generation for Code Large Language Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Shawn Guo이 [arXiv]에 게시한 'V-GameGym: Visual Game Generation for Code Large Language Models' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-26 13:35:32+0900\",\"children\":\"2025년 9월 26일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Code Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Code Large Language Models\"]}],[\"$\",\"span\",\"Visual Game Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Visual Game Generation\"]}],[\"$\",\"span\",\"Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmark\"]}],[\"$\",\"span\",\"Pygame\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Pygame\"]}],[\"$\",\"span\",\"Multimodal Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Evaluation\"]}],[\"$\",\"span\",\"Software Engineering\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Software Engineering\"]}],[\"$\",\"span\",\"AI-assisted Game Development\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"AI-assisted Game Development\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-26-Understanding_the_Thinking_Process_of_Reasoning_Models_A_Perspective_from_Schoenfelds_Episode_Theory\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-26-Understanding_the_Thinking_Process_of_Reasoning_Models_A_Perspective_from_Schoenfelds_Episode_Theory/\",\"children\":\"[논문리뷰] Understanding the Thinking Process of Reasoning Models: A Perspective from Schoenfeld's Episode Theory\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yanbin Fu이 [arXiv]에 게시한 'Understanding the Thinking Process of Reasoning Models: A Perspective from Schoenfeld's Episode Theory' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-26 13:35:32+0900\",\"children\":\"2025년 9월 26일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Large Reasoning Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Reasoning Models\"]}],[\"$\",\"span\",\"Cognitive Science\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Cognitive Science\"]}],[\"$\",\"span\",\"Schoenfeld's Episode Theory\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Schoenfeld's Episode Theory\"]}],[\"$\",\"span\",\"Math Problem Solving\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Math Problem Solving\"]}],[\"$\",\"span\",\"Chain-of-Thought\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Chain-of-Thought\"]}],[\"$\",\"span\",\"Behavioral Analysis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Behavioral Analysis\"]}],[\"$\",\"span\",\"Dataset Annotation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dataset Annotation\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-26-TrustJudge_Inconsistencies_of_LLM-as-a-Judge_and_How_to_Alleviate_Them\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-26-TrustJudge_Inconsistencies_of_LLM-as-a-Judge_and_How_to_Alleviate_Them/\",\"children\":\"[논문리뷰] TrustJudge: Inconsistencies of LLM-as-a-Judge and How to Alleviate Them\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Zhuohao Yu이 [arXiv]에 게시한 'TrustJudge: Inconsistencies of LLM-as-a-Judge and How to Alleviate Them' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-26 13:35:32+0900\",\"children\":\"2025년 9월 26일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLM-as-a-Judge\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM-as-a-Judge\"]}],[\"$\",\"span\",\"Evaluation Frameworks\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Evaluation Frameworks\"]}],[\"$\",\"span\",\"Inconsistency Reduction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Inconsistency Reduction\"]}],[\"$\",\"span\",\"Probabilistic Scoring\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Probabilistic Scoring\"]}],[\"$\",\"span\",\"Transitivity\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Transitivity\"]}],[\"$\",\"span\",\"Information Loss\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Information Loss\"]}],[\"$\",\"span\",\"Perplexity\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Perplexity\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-26-Tree_Search_for_LLM_Agent_Reinforcement_Learning\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-26-Tree_Search_for_LLM_Agent_Reinforcement_Learning/\",\"children\":\"[논문리뷰] Tree Search for LLM Agent Reinforcement Learning\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Xiangxiang Chu이 [arXiv]에 게시한 'Tree Search for LLM Agent Reinforcement Learning' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-26 13:35:32+0900\",\"children\":\"2025년 9월 26일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLM Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Agents\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Tree Search\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Tree Search\"]}],[\"$\",\"span\",\"Policy Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Policy Optimization\"]}],[\"$\",\"span\",\"Preference Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Preference Learning\"]}],[\"$\",\"span\",\"Sparse Rewards\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Sparse Rewards\"]}],[\"$\",\"span\",\"Multi-turn Tasks\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-turn Tasks\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-26-Thinking_While_Listening_Simple_Test_Time_Scaling_For_Audio_Classification\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-26-Thinking_While_Listening_Simple_Test_Time_Scaling_For_Audio_Classification/\",\"children\":\"[논문리뷰] Thinking While Listening: Simple Test Time Scaling For Audio Classification\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Mert Pilanci이 [arXiv]에 게시한 'Thinking While Listening: Simple Test Time Scaling For Audio Classification' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-26 13:35:32+0900\",\"children\":\"2025년 9월 26일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Audio Classification\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Audio Classification\"]}],[\"$\",\"span\",\"Test-Time Scaling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Test-Time Scaling\"]}],[\"$\",\"span\",\"Reasoning Traces\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reasoning Traces\"]}],[\"$\",\"span\",\"Large Language Models (LLMs)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models (LLMs)\"]}],[\"$\",\"span\",\"Transformer Architectures\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Transformer Architectures\"]}],[\"$\",\"span\",\"Zero-shot Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Zero-shot Reasoning\"]}],[\"$\",\"span\",\"Computational Efficiency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Computational Efficiency\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-26-Thinking_Augmented_Pre-training\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-26-Thinking_Augmented_Pre-training/\",\"children\":\"[논문리뷰] Thinking Augmented Pre-training\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Furu Wei이 [arXiv]에 게시한 'Thinking Augmented Pre-training' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-26 13:35:32+0900\",\"children\":\"2025년 9월 26일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Large Language Models (LLMs)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models (LLMs)\"]}],[\"$\",\"span\",\"Pre-training\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Pre-training\"]}],[\"$\",\"span\",\"Data Augmentation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Augmentation\"]}],[\"$\",\"span\",\"Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reasoning\"]}],[\"$\",\"span\",\"Data Efficiency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Efficiency\"]}],[\"$\",\"span\",\"Thinking Trajectories\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Thinking Trajectories\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-26-The_Unanticipated_Asymmetry_Between_Perceptual_Optimization_and_Assessment\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-26-The_Unanticipated_Asymmetry_Between_Perceptual_Optimization_and_Assessment/\",\"children\":\"[논문리뷰] The Unanticipated Asymmetry Between Perceptual Optimization and Assessment\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Du Chen이 [arXiv]에 게시한 'The Unanticipated Asymmetry Between Perceptual Optimization and Assessment' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-26 13:35:32+0900\",\"children\":\"2025년 9월 26일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Perceptual Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Perceptual Optimization\"]}],[\"$\",\"span\",\"Image Quality Assessment (IQA)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image Quality Assessment (IQA)\"]}],[\"$\",\"span\",\"Adversarial Training\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Adversarial Training\"]}],[\"$\",\"span\",\"Discriminators\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Discriminators\"]}],[\"$\",\"span\",\"Super-Resolution\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Super-Resolution\"]}],[\"$\",\"span\",\"Fidelity Metrics\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Fidelity Metrics\"]}],[\"$\",\"span\",\"Deep Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Deep Learning\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-26-StyleBench_Evaluating_thinking_styles_in_Large_Language_Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-26-StyleBench_Evaluating_thinking_styles_in_Large_Language_Models/\",\"children\":\"[논문리뷰] StyleBench: Evaluating thinking styles in Large Language Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Javad Lavaei이 [arXiv]에 게시한 'StyleBench: Evaluating thinking styles in Large Language Models' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-26 13:35:32+0900\",\"children\":\"2025년 9월 26일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Reasoning Strategies\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reasoning Strategies\"]}],[\"$\",\"span\",\"Prompt Engineering\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Prompt Engineering\"]}],[\"$\",\"span\",\"LLM Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Evaluation\"]}],[\"$\",\"span\",\"Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmark\"]}],[\"$\",\"span\",\"Thinking Styles\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Thinking Styles\"]}],[\"$\",\"span\",\"Scaling Laws\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Scaling Laws\"]}],[\"$\",\"span\",\"Meta-Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Meta-Reasoning\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-26-Seedream_4.0_Toward_Next-generation_Multimodal_Image_Generation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-26-Seedream_4.0_Toward_Next-generation_Multimodal_Image_Generation/\",\"children\":\"[논문리뷰] Seedream 4.0: Toward Next-generation Multimodal Image Generation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yunpeng Chen이 [arXiv]에 게시한 'Seedream 4.0: Toward Next-generation Multimodal Image Generation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-26 13:35:32+0900\",\"children\":\"2025년 9월 26일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Multimodal Image Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Image Generation\"]}],[\"$\",\"span\",\"Diffusion Transformer\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Transformer\"]}],[\"$\",\"span\",\"VAE\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"VAE\"]}],[\"$\",\"span\",\"Image Editing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image Editing\"]}],[\"$\",\"span\",\"Text-to-Image\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Text-to-Image\"]}],[\"$\",\"span\",\"Model Acceleration\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Model Acceleration\"]}],[\"$\",\"span\",\"Human Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Human Evaluation\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-26-SD3.5-Flash_Distribution-Guided_Distillation_of_Generative_Flows\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-26-SD3.5-Flash_Distribution-Guided_Distillation_of_Generative_Flows/\",\"children\":\"[논문리뷰] SD3.5-Flash: Distribution-Guided Distillation of Generative Flows\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yi-Zhe Song이 [arXiv]에 게시한 'SD3.5-Flash: Distribution-Guided Distillation of Generative Flows' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-26 13:35:32+0900\",\"children\":\"2025년 9월 26일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Generative AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generative AI\"]}],[\"$\",\"span\",\"Image Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image Generation\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}],[\"$\",\"span\",\"Rectified Flow\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Rectified Flow\"]}],[\"$\",\"span\",\"Model Distillation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Model Distillation\"]}],[\"$\",\"span\",\"Few-Step Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Few-Step Generation\"]}],[\"$\",\"span\",\"Computational Efficiency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Computational Efficiency\"]}],[\"$\",\"span\",\"Prompt Alignment\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Prompt Alignment\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-26-SciReasoner_Laying_the_Scientific_Reasoning_Ground_Across_Disciplines\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-26-SciReasoner_Laying_the_Scientific_Reasoning_Ground_Across_Disciplines/\",\"children\":\"[논문리뷰] SciReasoner: Laying the Scientific Reasoning Ground Across Disciplines\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Jiabei Xiao이 [arXiv]에 게시한 'SciReasoner: Laying the Scientific Reasoning Ground Across Disciplines' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-26 13:35:32+0900\",\"children\":\"2025년 9월 26일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Scientific Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Scientific Reasoning\"]}],[\"$\",\"span\",\"Foundation Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Foundation Models\"]}],[\"$\",\"span\",\"Multi-modal Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-modal Learning\"]}],[\"$\",\"span\",\"Cross-domain Generalization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Cross-domain Generalization\"]}],[\"$\",\"span\",\"Chain-of-Thought\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Chain-of-Thought\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Scientific Discovery\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Scientific Discovery\"]}],[\"$\",\"span\",\"Molecular Design\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Molecular Design\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-26-SceneWeaver_All-in-One_3D_Scene_Synthesis_with_an_Extensible_and_Self-Reflective_Agent\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-26-SceneWeaver_All-in-One_3D_Scene_Synthesis_with_an_Extensible_and_Self-Reflective_Agent/\",\"children\":\"[논문리뷰] SceneWeaver: All-in-One 3D Scene Synthesis with an Extensible and Self-Reflective Agent\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Siyuan Huang이 [arXiv]에 게시한 'SceneWeaver: All-in-One 3D Scene Synthesis with an Extensible and Self-Reflective Agent' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-26 13:35:32+0900\",\"children\":\"2025년 9월 26일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"3D Scene Synthesis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D Scene Synthesis\"]}],[\"$\",\"span\",\"Agentic Framework\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Agentic Framework\"]}],[\"$\",\"span\",\"LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLMs\"]}],[\"$\",\"span\",\"Self-Reflection\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Self-Reflection\"]}],[\"$\",\"span\",\"Tool-Use\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Tool-Use\"]}],[\"$\",\"span\",\"Physical Plausibility\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Physical Plausibility\"]}],[\"$\",\"span\",\"Iterative Refinement\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Iterative Refinement\"]}],[\"$\",\"span\",\"Embodied AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Embodied AI\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-26-ScaleDiff_Scaling_Difficult_Problems_for_Advanced_Mathematical_Reasoning\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-26-ScaleDiff_Scaling_Difficult_Problems_for_Advanced_Mathematical_Reasoning/\",\"children\":\"[논문리뷰] ScaleDiff: Scaling Difficult Problems for Advanced Mathematical Reasoning\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yu Li이 [arXiv]에 게시한 'ScaleDiff: Scaling Difficult Problems for Advanced Mathematical Reasoning' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-26 13:35:32+0900\",\"children\":\"2025년 9월 26일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Mathematical Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Mathematical Reasoning\"]}],[\"$\",\"span\",\"Large Reasoning Models (LRMs)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Reasoning Models (LRMs)\"]}],[\"$\",\"span\",\"Difficulty Scaling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Difficulty Scaling\"]}],[\"$\",\"span\",\"Data Augmentation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Augmentation\"]}],[\"$\",\"span\",\"Supervised Fine-Tuning (SFT)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Supervised Fine-Tuning (SFT)\"]}],[\"$\",\"span\",\"Problem Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Problem Generation\"]}],[\"$\",\"span\",\"Solution Distillation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Solution Distillation\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-26-Residual_Off-Policy_RL_for_Finetuning_Behavior_Cloning_Policies\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-26-Residual_Off-Policy_RL_for_Finetuning_Behavior_Cloning_Policies/\",\"children\":\"[논문리뷰] Residual Off-Policy RL for Finetuning Behavior Cloning Policies\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Pieter Abbeel이 [arXiv]에 게시한 'Residual Off-Policy RL for Finetuning Behavior Cloning Policies' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-26 13:35:32+0900\",\"children\":\"2025년 9월 26일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Reinforcement Learning (RL)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning (RL)\"]}],[\"$\",\"span\",\"Behavior Cloning (BC)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Behavior Cloning (BC)\"]}],[\"$\",\"span\",\"Residual Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Residual Learning\"]}],[\"$\",\"span\",\"Off-Policy RL\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Off-Policy RL\"]}],[\"$\",\"span\",\"Robot Manipulation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Robot Manipulation\"]}],[\"$\",\"span\",\"Real-World Robotics\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Real-World Robotics\"]}],[\"$\",\"span\",\"High-DoF Systems\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"High-DoF Systems\"]}],[\"$\",\"span\",\"Sample Efficiency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Sample Efficiency\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-26-Recon-Act_A_Self-Evolving_Multi-Agent_Browser-Use_System_via_Web_Reconnaissance_Tool_Generation_and_Task_Execution\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-26-Recon-Act_A_Self-Evolving_Multi-Agent_Browser-Use_System_via_Web_Reconnaissance_Tool_Generation_and_Task_Execution/\",\"children\":\"[논문리뷰] Recon-Act: A Self-Evolving Multi-Agent Browser-Use System via Web Reconnaissance, Tool Generation, and Task Execution\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Jinjie Gu이 [arXiv]에 게시한 'Recon-Act: A Self-Evolving Multi-Agent Browser-Use System via Web Reconnaissance, Tool Generation, and Task Execution' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-26 13:35:32+0900\",\"children\":\"2025년 9월 26일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Multi-Agent System\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-Agent System\"]}],[\"$\",\"span\",\"Browser Automation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Browser Automation\"]}],[\"$\",\"span\",\"Web Reconnaissance\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Web Reconnaissance\"]}],[\"$\",\"span\",\"Tool Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Tool Generation\"]}],[\"$\",\"span\",\"Task Execution\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Task Execution\"]}],[\"$\",\"span\",\"Self-Evolving AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Self-Evolving AI\"]}],[\"$\",\"span\",\"LLM/VLM\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM/VLM\"]}],[\"$\",\"span\",\"VisualWebArena\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"VisualWebArena\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-26-Quantized_Visual_Geometry_Grounded_Transformer\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-26-Quantized_Visual_Geometry_Grounded_Transformer/\",\"children\":\"[논문리뷰] Quantized Visual Geometry Grounded Transformer\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yuqi Li이 [arXiv]에 게시한 'Quantized Visual Geometry Grounded Transformer' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-26 13:35:32+0900\",\"children\":\"2025년 9월 26일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Quantization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Quantization\"]}],[\"$\",\"span\",\"Post-Training Quantization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Post-Training Quantization\"]}],[\"$\",\"span\",\"3D Reconstruction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D Reconstruction\"]}],[\"$\",\"span\",\"Visual Transformer\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Visual Transformer\"]}],[\"$\",\"span\",\"Model Compression\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Model Compression\"]}],[\"$\",\"span\",\"Efficient Inference\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Efficient Inference\"]}],[\"$\",\"span\",\"Hadamard Rotation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Hadamard Rotation\"]}],[\"$\",\"span\",\"Calibration Sampling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Calibration Sampling\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-26-MOSS-ChatV_Reinforcement_Learning_with_Process_Reasoning_Reward_for_Video_Temporal_Reasoning\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-26-MOSS-ChatV_Reinforcement_Learning_with_Process_Reasoning_Reward_for_Video_Temporal_Reasoning/\",\"children\":\"[논문리뷰] MOSS-ChatV: Reinforcement Learning with Process Reasoning Reward for Video Temporal Reasoning\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Junyan Zhang이 [arXiv]에 게시한 'MOSS-ChatV: Reinforcement Learning with Process Reasoning Reward for Video Temporal Reasoning' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-26 13:35:32+0900\",\"children\":\"2025년 9월 26일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Video Temporal Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video Temporal Reasoning\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Process Supervision\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Process Supervision\"]}],[\"$\",\"span\",\"Dynamic Time Warping\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dynamic Time Warping\"]}],[\"$\",\"span\",\"Multimodal Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Large Language Models\"]}],[\"$\",\"span\",\"Video State Prediction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video State Prediction\"]}],[\"$\",\"span\",\"Reward Hacking\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reward Hacking\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-26-MMR1_Enhancing_Multimodal_Reasoning_with_Variance-Aware_Sampling_and_Open_Resources\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-26-MMR1_Enhancing_Multimodal_Reasoning_with_Variance-Aware_Sampling_and_Open_Resources/\",\"children\":\"[논문리뷰] MMR1: Enhancing Multimodal Reasoning with Variance-Aware Sampling and Open Resources\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Jing Wang이 [arXiv]에 게시한 'MMR1: Enhancing Multimodal Reasoning with Variance-Aware Sampling and Open Resources' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-26 13:35:32+0900\",\"children\":\"2025년 9월 26일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Multimodal Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Reasoning\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Variance-Aware Sampling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Variance-Aware Sampling\"]}],[\"$\",\"span\",\"Gradient Vanishing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Gradient Vanishing\"]}],[\"$\",\"span\",\"Data Curation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Curation\"]}],[\"$\",\"span\",\"Chain-of-Thought\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Chain-of-Thought\"]}],[\"$\",\"span\",\"GRPO\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"GRPO\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-26-MI-Fuse_Label_Fusion_for_Unsupervised_Domain_Adaptation_with_Closed-Source_Large-Audio_Language_Model\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-26-MI-Fuse_Label_Fusion_for_Unsupervised_Domain_Adaptation_with_Closed-Source_Large-Audio_Language_Model/\",\"children\":\"[논문리뷰] MI-Fuse: Label Fusion for Unsupervised Domain Adaptation with Closed-Source Large-Audio Language Model\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Hung-yi Lee이 [arXiv]에 게시한 'MI-Fuse: Label Fusion for Unsupervised Domain Adaptation with Closed-Source Large-Audio Language Model' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-26 13:35:32+0900\",\"children\":\"2025년 9월 26일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Speech Emotion Recognition\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Speech Emotion Recognition\"]}],[\"$\",\"span\",\"Source-Free Unsupervised Domain Adaptation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Source-Free Unsupervised Domain Adaptation\"]}],[\"$\",\"span\",\"Large Audio-Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Audio-Language Models\"]}],[\"$\",\"span\",\"Label Fusion\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Label Fusion\"]}],[\"$\",\"span\",\"Mutual Information\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Mutual Information\"]}],[\"$\",\"span\",\"API-Only Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"API-Only Models\"]}],[\"$\",\"span\",\"Domain Mismatch\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Domain Mismatch\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-26-Interactive_Recommendation_Agent_with_Active_User_Commands\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-26-Interactive_Recommendation_Agent_with_Active_User_Commands/\",\"children\":\"[논문리뷰] Interactive Recommendation Agent with Active User Commands\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Xueyang Feng이 [arXiv]에 게시한 'Interactive Recommendation Agent with Active User Commands' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-26 13:35:32+0900\",\"children\":\"2025년 9월 26일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Interactive Recommendation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Interactive Recommendation\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Multi-Agent System\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-Agent System\"]}],[\"$\",\"span\",\"Natural Language Processing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Natural Language Processing\"]}],[\"$\",\"span\",\"Knowledge Distillation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Knowledge Distillation\"]}],[\"$\",\"span\",\"User Control\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"User Control\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-26-Hunyuan3D-Omni_A_Unified_Framework_for_Controllable_Generation_of_3D_Assets\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-26-Hunyuan3D-Omni_A_Unified_Framework_for_Controllable_Generation_of_3D_Assets/\",\"children\":\"[논문리뷰] Hunyuan3D-Omni: A Unified Framework for Controllable Generation of 3D Assets\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Bowen Zhang이 [arXiv]에 게시한 'Hunyuan3D-Omni: A Unified Framework for Controllable Generation of 3D Assets' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-26 13:35:32+0900\",\"children\":\"2025년 9월 26일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"3D Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D Generation\"]}],[\"$\",\"span\",\"Controllable Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Controllable Generation\"]}],[\"$\",\"span\",\"Multi-modal Conditioning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-modal Conditioning\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}],[\"$\",\"span\",\"Point Clouds\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Point Clouds\"]}],[\"$\",\"span\",\"Voxels\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Voxels\"]}],[\"$\",\"span\",\"Bounding Boxes\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Bounding Boxes\"]}],[\"$\",\"span\",\"Skeletons\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Skeletons\"]}],[\"$\",\"span\",\"Hunyuan3D\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Hunyuan3D\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-26-Does_FLUX_Already_Know_How_to_Perform_Physically_Plausible_Image_Composition\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-26-Does_FLUX_Already_Know_How_to_Perform_Physically_Plausible_Image_Composition/\",\"children\":\"[논문리뷰] Does FLUX Already Know How to Perform Physically Plausible Image Composition?\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Chen Zhao이 [arXiv]에 게시한 'Does FLUX Already Know How to Perform Physically Plausible Image Composition?' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-26 13:35:32+0900\",\"children\":\"2025년 9월 26일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Image Composition\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image Composition\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}],[\"$\",\"span\",\"Training-Free\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Training-Free\"]}],[\"$\",\"span\",\"Physically Plausible\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Physically Plausible\"]}],[\"$\",\"span\",\"FLUX\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"FLUX\"]}],[\"$\",\"span\",\"Adapter\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Adapter\"]}],[\"$\",\"span\",\"Guidance\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Guidance\"]}],[\"$\",\"span\",\"Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmark\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-26-Discrete_Diffusion_for_Reflective_Vision-Language-Action_Models_in_Autonomous_Driving\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-26-Discrete_Diffusion_for_Reflective_Vision-Language-Action_Models_in_Autonomous_Driving/\",\"children\":\"[논문리뷰] Discrete Diffusion for Reflective Vision-Language-Action Models in Autonomous Driving\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Hang Zhao이 [arXiv]에 게시한 'Discrete Diffusion for Reflective Vision-Language-Action Models in Autonomous Driving' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-26 13:35:32+0900\",\"children\":\"2025년 9월 26일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Autonomous Driving\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Autonomous Driving\"]}],[\"$\",\"span\",\"Vision-Language-Action Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision-Language-Action Models\"]}],[\"$\",\"span\",\"Discrete Diffusion\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Discrete Diffusion\"]}],[\"$\",\"span\",\"Reflection Mechanism\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reflection Mechanism\"]}],[\"$\",\"span\",\"Trajectory Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Trajectory Generation\"]}],[\"$\",\"span\",\"Safety Constraints\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Safety Constraints\"]}],[\"$\",\"span\",\"Imitation Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Imitation Learning\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-26-CHARM_Control-point-based_3D_Anime_Hairstyle_Auto-Regressive_Modeling\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-26-CHARM_Control-point-based_3D_Anime_Hairstyle_Auto-Regressive_Modeling/\",\"children\":\"[논문리뷰] CHARM: Control-point-based 3D Anime Hairstyle Auto-Regressive Modeling\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yushi Bai이 [arXiv]에 게시한 'CHARM: Control-point-based 3D Anime Hairstyle Auto-Regressive Modeling' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-26 13:35:32+0900\",\"children\":\"2025년 9월 26일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"3D Anime Hairstyle\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D Anime Hairstyle\"]}],[\"$\",\"span\",\"Autoregressive Modeling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Autoregressive Modeling\"]}],[\"$\",\"span\",\"Control Points\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Control Points\"]}],[\"$\",\"span\",\"Parametric Representation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Parametric Representation\"]}],[\"$\",\"span\",\"Transformer\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Transformer\"]}],[\"$\",\"span\",\"Generative AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generative AI\"]}],[\"$\",\"span\",\"Dataset (AnimeHair)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dataset (AnimeHair)\"]}],[\"$\",\"span\",\"Computer Graphics\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Computer Graphics\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-26-CE-GPPO_Controlling_Entropy_via_Gradient-Preserving_Clipping_Policy_Optimization_in_Reinforcement_Learning\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-26-CE-GPPO_Controlling_Entropy_via_Gradient-Preserving_Clipping_Policy_Optimization_in_Reinforcement_Learning/\",\"children\":\"[논문리뷰] CE-GPPO: Controlling Entropy via Gradient-Preserving Clipping Policy Optimization in Reinforcement Learning\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Wenping Hu이 [arXiv]에 게시한 'CE-GPPO: Controlling Entropy via Gradient-Preserving Clipping Policy Optimization in Reinforcement Learning' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-26 13:35:32+0900\",\"children\":\"2025년 9월 26일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Policy Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Policy Optimization\"]}],[\"$\",\"span\",\"PPO\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"PPO\"]}],[\"$\",\"span\",\"Entropy Control\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Entropy Control\"]}],[\"$\",\"span\",\"Gradient Clipping\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Gradient Clipping\"]}],[\"$\",\"span\",\"Exploration-Exploitation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Exploration-Exploitation\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-26-Blueprints_of_Trust_AI_System_Cards_for_End_to_End_Transparency_and_Governance\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-26-Blueprints_of_Trust_AI_System_Cards_for_End_to_End_Transparency_and_Governance/\",\"children\":\"[논문리뷰] Blueprints of Trust: AI System Cards for End to End Transparency and Governance\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Roman Zhukov이 [arXiv]에 게시한 'Blueprints of Trust: AI System Cards for End to End Transparency and Governance' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-26 13:35:32+0900\",\"children\":\"2025년 9월 26일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"AI Governance\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"AI Governance\"]}],[\"$\",\"span\",\"Transparency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Transparency\"]}],[\"$\",\"span\",\"AI System Card\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"AI System Card\"]}],[\"$\",\"span\",\"Hazard-Aware System Card\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Hazard-Aware System Card\"]}],[\"$\",\"span\",\"Data Provenance\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Provenance\"]}],[\"$\",\"span\",\"AI Safety\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"AI Safety\"]}],[\"$\",\"span\",\"AI Risk Management\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"AI Risk Management\"]}],[\"$\",\"span\",\"ISO/IEC 42001\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"ISO/IEC 42001\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-26-BESPOKE_Benchmark_for_Search-Augmented_Large_Language_Model_Personalization_via_Diagnostic_Feedback\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-26-BESPOKE_Benchmark_for_Search-Augmented_Large_Language_Model_Personalization_via_Diagnostic_Feedback/\",\"children\":\"[논문리뷰] BESPOKE: Benchmark for Search-Augmented Large Language Model Personalization via Diagnostic Feedback\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Dongha Lee이 [arXiv]에 게시한 'BESPOKE: Benchmark for Search-Augmented Large Language Model Personalization via Diagnostic Feedback' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-26 13:35:32+0900\",\"children\":\"2025년 9월 26일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Search-Augmented LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Search-Augmented LLMs\"]}],[\"$\",\"span\",\"Personalization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Personalization\"]}],[\"$\",\"span\",\"Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmark\"]}],[\"$\",\"span\",\"Diagnostic Feedback\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diagnostic Feedback\"]}],[\"$\",\"span\",\"User History\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"User History\"]}],[\"$\",\"span\",\"Evaluation Framework\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Evaluation Framework\"]}],[\"$\",\"span\",\"RAG\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"RAG\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-26-Behind_RoPE_How_Does_Causal_Mask_Encode_Positional_Information\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-26-Behind_RoPE_How_Does_Causal_Mask_Encode_Positional_Information/\",\"children\":\"[논문리뷰] Behind RoPE: How Does Causal Mask Encode Positional Information?\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yeyun Gong이 [arXiv]에 게시한 'Behind RoPE: How Does Causal Mask Encode Positional Information?' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-26 13:35:32+0900\",\"children\":\"2025년 9월 26일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Transformer Decoder\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Transformer Decoder\"]}],[\"$\",\"span\",\"Causal Mask\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Causal Mask\"]}],[\"$\",\"span\",\"Positional Encoding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Positional Encoding\"]}],[\"$\",\"span\",\"RoPE\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"RoPE\"]}],[\"$\",\"span\",\"Attention Mechanism\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Attention Mechanism\"]}],[\"$\",\"span\",\"Length Generalization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Length Generalization\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-26-AutoIntent_AutoML_for_Text_Classification\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-26-AutoIntent_AutoML_for_Text_Classification/\",\"children\":\"[논문리뷰] AutoIntent: AutoML for Text Classification\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Denis Kuznetsov이 [arXiv]에 게시한 'AutoIntent: AutoML for Text Classification' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-26 13:35:32+0900\",\"children\":\"2025년 9월 26일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"AutoML\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"AutoML\"]}],[\"$\",\"span\",\"Text Classification\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Text Classification\"]}],[\"$\",\"span\",\"Intent Classification\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Intent Classification\"]}],[\"$\",\"span\",\"Transformer Embeddings\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Transformer Embeddings\"]}],[\"$\",\"span\",\"Out-of-Scope Detection\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Out-of-Scope Detection\"]}],[\"$\",\"span\",\"Multi-label Classification\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-label Classification\"]}],[\"$\",\"span\",\"Few-shot Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Few-shot Learning\"]}],[\"$\",\"span\",\"Sklearn-like Interface\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Sklearn-like Interface\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-25-Video_models_are_zero-shot_learners_and_reasoners\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-25-Video_models_are_zero-shot_learners_and_reasoners/\",\"children\":\"[논문리뷰] Video models are zero-shot learners and reasoners\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"rgeirhos이 [arXiv]에 게시한 'Video models are zero-shot learners and reasoners' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-25 13:08:16+0900\",\"children\":\"2025년 9월 25일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Video Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video Models\"]}],[\"$\",\"span\",\"Zero-shot Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Zero-shot Learning\"]}],[\"$\",\"span\",\"Visual Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Visual Reasoning\"]}],[\"$\",\"span\",\"Foundation Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Foundation Models\"]}],[\"$\",\"span\",\"Generative AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generative AI\"]}],[\"$\",\"span\",\"Perception\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Perception\"]}],[\"$\",\"span\",\"Manipulation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Manipulation\"]}],[\"$\",\"span\",\"Modeling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Modeling\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-25-SIM-CoT_Supervised_Implicit_Chain-of-Thought\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-25-SIM-CoT_Supervised_Implicit_Chain-of-Thought/\",\"children\":\"[논문리뷰] SIM-CoT: Supervised Implicit Chain-of-Thought\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yuhang Cao이 [arXiv]에 게시한 'SIM-CoT: Supervised Implicit Chain-of-Thought' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-25 13:08:16+0900\",\"children\":\"2025년 9월 25일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Implicit Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Implicit Reasoning\"]}],[\"$\",\"span\",\"Chain-of-Thought\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Chain-of-Thought\"]}],[\"$\",\"span\",\"LLM\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM\"]}],[\"$\",\"span\",\"Latent Space\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Latent Space\"]}],[\"$\",\"span\",\"Supervised Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Supervised Learning\"]}],[\"$\",\"span\",\"Model Stability\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Model Stability\"]}],[\"$\",\"span\",\"Interpretability\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Interpretability\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-25-PhysCtrl_Generative_Physics_for_Controllable_and_Physics-Grounded_Video_Generation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-25-PhysCtrl_Generative_Physics_for_Controllable_and_Physics-Grounded_Video_Generation/\",\"children\":\"[논문리뷰] PhysCtrl: Generative Physics for Controllable and Physics-Grounded Video Generation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yiming Huang이 [arXiv]에 게시한 'PhysCtrl: Generative Physics for Controllable and Physics-Grounded Video Generation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-25 13:08:16+0900\",\"children\":\"2025년 9월 25일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Video Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video Generation\"]}],[\"$\",\"span\",\"Physics-Grounded\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Physics-Grounded\"]}],[\"$\",\"span\",\"Controllable Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Controllable Generation\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}],[\"$\",\"span\",\"Point Cloud Trajectories\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Point Cloud Trajectories\"]}],[\"$\",\"span\",\"Material Simulation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Material Simulation\"]}],[\"$\",\"span\",\"Generative Physics\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generative Physics\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-25-On_the_Use_of_Agentic_Coding_An_Empirical_Study_of_Pull_Requests_on_GitHub\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-25-On_the_Use_of_Agentic_Coding_An_Empirical_Study_of_Pull_Requests_on_GitHub/\",\"children\":\"[논문리뷰] On the Use of Agentic Coding: An Empirical Study of Pull Requests on GitHub\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Hajimu Iida이 [arXiv]에 게시한 'On the Use of Agentic Coding: An Empirical Study of Pull Requests on GitHub' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-25 13:08:16+0900\",\"children\":\"2025년 9월 25일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Agentic Coding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Agentic Coding\"]}],[\"$\",\"span\",\"AI Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"AI Agents\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"GitHub Pull Requests\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"GitHub Pull Requests\"]}],[\"$\",\"span\",\"Software Engineering\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Software Engineering\"]}],[\"$\",\"span\",\"Empirical Study\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Empirical Study\"]}],[\"$\",\"span\",\"Code Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Code Generation\"]}],[\"$\",\"span\",\"Software Development\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Software Development\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-25-Logics-Parsing_Technical_Report\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-25-Logics-Parsing_Technical_Report/\",\"children\":\"[논문리뷰] Logics-Parsing Technical Report\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Fan Yang이 [arXiv]에 게시한 'Logics-Parsing Technical Report' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-25 13:08:16+0900\",\"children\":\"2025년 9월 25일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Document Parsing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Document Parsing\"]}],[\"$\",\"span\",\"Large Vision-Language Models (LVLM)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Vision-Language Models (LVLM)\"]}],[\"$\",\"span\",\"Reinforcement Learning (RL)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning (RL)\"]}],[\"$\",\"span\",\"Layout Analysis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Layout Analysis\"]}],[\"$\",\"span\",\"Reading Order\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reading Order\"]}],[\"$\",\"span\",\"Supervised Fine-Tuning (SFT)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Supervised Fine-Tuning (SFT)\"]}],[\"$\",\"span\",\"HTML Annotation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"HTML Annotation\"]}],[\"$\",\"span\",\"Benchmarking\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmarking\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-25-LLMs4All_A_Review_on_Large_Language_Models_for_Research_and_Applications_in_Academic_Disciplines\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-25-LLMs4All_A_Review_on_Large_Language_Models_for_Research_and_Applications_in_Academic_Disciplines/\",\"children\":\"[논문리뷰] LLMs4All: A Review on Large Language Models for Research and Applications in Academic Disciplines\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yanfang이 [arXiv]에 게시한 'LLMs4All: A Review on Large Language Models for Research and Applications in Academic Disciplines' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-25 13:08:16+0900\",\"children\":\"2025년 9월 25일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Generative AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generative AI\"]}],[\"$\",\"span\",\"Academic Disciplines\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Academic Disciplines\"]}],[\"$\",\"span\",\"LLM Applications\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Applications\"]}],[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Cross-disciplinary Research\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Cross-disciplinary Research\"]}],[\"$\",\"span\",\"Benchmarks\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmarks\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-25-Lavida-O_Elastic_Large_Masked_Diffusion_Models_for_Unified_Multimodal_Understanding_and_Generation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-25-Lavida-O_Elastic_Large_Masked_Diffusion_Models_for_Unified_Multimodal_Understanding_and_Generation/\",\"children\":\"[논문리뷰] Lavida-O: Elastic Large Masked Diffusion Models for Unified Multimodal Understanding and Generation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Zhe Lin이 [arXiv]에 게시한 'Lavida-O: Elastic Large Masked Diffusion Models for Unified Multimodal Understanding and Generation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-25 13:08:16+0900\",\"children\":\"2025년 9월 25일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Multimodal AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal AI\"]}],[\"$\",\"span\",\"Masked Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Masked Diffusion Models\"]}],[\"$\",\"span\",\"Image Understanding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image Understanding\"]}],[\"$\",\"span\",\"Image Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image Generation\"]}],[\"$\",\"span\",\"Image Editing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image Editing\"]}],[\"$\",\"span\",\"Object Grounding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Object Grounding\"]}],[\"$\",\"span\",\"ElasticMoT\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"ElasticMoT\"]}],[\"$\",\"span\",\"Self-reflection\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Self-reflection\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-25-EmbeddingGemma_Powerful_and_Lightweight_Text_Representations\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-25-EmbeddingGemma_Powerful_and_Lightweight_Text_Representations/\",\"children\":\"[논문리뷰] EmbeddingGemma: Powerful and Lightweight Text Representations\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Marksherwood이 [arXiv]에 게시한 'EmbeddingGemma: Powerful and Lightweight Text Representations' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-25 13:08:16+0900\",\"children\":\"2025년 9월 25일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Text Embeddings\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Text Embeddings\"]}],[\"$\",\"span\",\"Lightweight Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Lightweight Models\"]}],[\"$\",\"span\",\"Encoder-Decoder\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Encoder-Decoder\"]}],[\"$\",\"span\",\"Knowledge Distillation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Knowledge Distillation\"]}],[\"$\",\"span\",\"Model Souping\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Model Souping\"]}],[\"$\",\"span\",\"Quantization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Quantization\"]}],[\"$\",\"span\",\"Multilingual\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multilingual\"]}],[\"$\",\"span\",\"Gemma\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Gemma\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-25-EditVerse_Unifying_Image_and_Video_Editing_and_Generation_with_In-Context_Learning\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-25-EditVerse_Unifying_Image_and_Video_Editing_and_Generation_with_In-Context_Learning/\",\"children\":\"[논문리뷰] EditVerse: Unifying Image and Video Editing and Generation with In-Context Learning\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Tianyu Wang이 [arXiv]에 게시한 'EditVerse: Unifying Image and Video Editing and Generation with In-Context Learning' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-25 13:08:16+0900\",\"children\":\"2025년 9월 25일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Unified Multimodal Model\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Unified Multimodal Model\"]}],[\"$\",\"span\",\"In-Context Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"In-Context Learning\"]}],[\"$\",\"span\",\"Image and Video Editing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image and Video Editing\"]}],[\"$\",\"span\",\"Video Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video Generation\"]}],[\"$\",\"span\",\"Full Self-Attention\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Full Self-Attention\"]}],[\"$\",\"span\",\"Rotary Positional Embedding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Rotary Positional Embedding\"]}],[\"$\",\"span\",\"Cross-Modal Knowledge Transfer\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Cross-Modal Knowledge Transfer\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-25-Advancing_Speech_Understanding_in_Speech-Aware_Language_Models_with_GRPO\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-25-Advancing_Speech_Understanding_in_Speech-Aware_Language_Models_with_GRPO/\",\"children\":\"[논문리뷰] Advancing Speech Understanding in Speech-Aware Language Models with GRPO\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Avihu이 [arXiv]에 게시한 'Advancing Speech Understanding in Speech-Aware Language Models with GRPO' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-25 13:08:16+0900\",\"children\":\"2025년 9월 25일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Speech-Aware Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Speech-Aware Language Models\"]}],[\"$\",\"span\",\"SALLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"SALLMs\"]}],[\"$\",\"span\",\"GRPO\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"GRPO\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Speech Understanding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Speech Understanding\"]}],[\"$\",\"span\",\"Spoken Question Answering\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Spoken Question Answering\"]}],[\"$\",\"span\",\"Automatic Speech Translation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Automatic Speech Translation\"]}],[\"$\",\"span\",\"BLEU Metric\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"BLEU Metric\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-24-Zero-Shot_Multi-Spectral_Learning_Reimagining_a_Generalist_Multimodal_Gemini_2.5_Model_for_Remote_Sensing_Applications\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-24-Zero-Shot_Multi-Spectral_Learning_Reimagining_a_Generalist_Multimodal_Gemini_2.5_Model_for_Remote_Sensing_Applications/\",\"children\":\"[논문리뷰] Zero-Shot Multi-Spectral Learning: Reimagining a Generalist Multimodal Gemini 2.5 Model for Remote Sensing Applications\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Genady Beryozkin이 [arXiv]에 게시한 'Zero-Shot Multi-Spectral Learning: Reimagining a Generalist Multimodal Gemini 2.5 Model for Remote Sensing Applications' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-24 13:14:19+0900\",\"children\":\"2025년 9월 24일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Remote Sensing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Remote Sensing\"]}],[\"$\",\"span\",\"Zero-Shot Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Zero-Shot Learning\"]}],[\"$\",\"span\",\"Multimodal Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Models\"]}],[\"$\",\"span\",\"Multi-spectral Imagery\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-spectral Imagery\"]}],[\"$\",\"span\",\"Gemini 2.5\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Gemini 2.5\"]}],[\"$\",\"span\",\"Prompt Engineering\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Prompt Engineering\"]}],[\"$\",\"span\",\"Land Cover Classification\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Land Cover Classification\"]}],[\"$\",\"span\",\"Pseudo-Image\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Pseudo-Image\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-24-What_Characterizes_Effective_Reasoning_Revisiting_Length_Review_and_Structure_of_CoT\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-24-What_Characterizes_Effective_Reasoning_Revisiting_Length_Review_and_Structure_of_CoT/\",\"children\":\"[논문리뷰] What Characterizes Effective Reasoning? Revisiting Length, Review, and Structure of CoT\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Anthony Hartshorn이 [arXiv]에 게시한 'What Characterizes Effective Reasoning? Revisiting Length, Review, and Structure of CoT' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-24 13:14:19+0900\",\"children\":\"2025년 9월 24일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Chain-of-Thought\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Chain-of-Thought\"]}],[\"$\",\"span\",\"Reasoning Effectiveness\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reasoning Effectiveness\"]}],[\"$\",\"span\",\"Large Reasoning Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Reasoning Models\"]}],[\"$\",\"span\",\"Failed-Step Fraction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Failed-Step Fraction\"]}],[\"$\",\"span\",\"Test-time Scaling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Test-time Scaling\"]}],[\"$\",\"span\",\"Reasoning Graph\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reasoning Graph\"]}],[\"$\",\"span\",\"Model Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Model Evaluation\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-24-VolSplat_Rethinking_Feed-Forward_3D_Gaussian_Splatting_with_Voxel-Aligned_Prediction\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-24-VolSplat_Rethinking_Feed-Forward_3D_Gaussian_Splatting_with_Voxel-Aligned_Prediction/\",\"children\":\"[논문리뷰] VolSplat: Rethinking Feed-Forward 3D Gaussian Splatting with Voxel-Aligned Prediction\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Haoxiao Wang이 [arXiv]에 게시한 'VolSplat: Rethinking Feed-Forward 3D Gaussian Splatting with Voxel-Aligned Prediction' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-24 13:14:19+0900\",\"children\":\"2025년 9월 24일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"3D Gaussian Splatting\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D Gaussian Splatting\"]}],[\"$\",\"span\",\"Novel View Synthesis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Novel View Synthesis\"]}],[\"$\",\"span\",\"Voxel-Aligned Prediction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Voxel-Aligned Prediction\"]}],[\"$\",\"span\",\"Feed-Forward Reconstruction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Feed-Forward Reconstruction\"]}],[\"$\",\"span\",\"Multi-View Consistency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-View Consistency\"]}],[\"$\",\"span\",\"Scene Representation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Scene Representation\"]}],[\"$\",\"span\",\"Computer Vision\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Computer Vision\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-24-VIR-Bench_Evaluating_Geospatial_and_Temporal_Understanding_of_MLLMs_via_Travel_Video_Itinerary_Reconstruction\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-24-VIR-Bench_Evaluating_Geospatial_and_Temporal_Understanding_of_MLLMs_via_Travel_Video_Itinerary_Reconstruction/\",\"children\":\"[논문리뷰] VIR-Bench: Evaluating Geospatial and Temporal Understanding of MLLMs via Travel Video Itinerary Reconstruction\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"So Fukuda이 [arXiv]에 게시한 'VIR-Bench: Evaluating Geospatial and Temporal Understanding of MLLMs via Travel Video Itinerary Reconstruction' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-24 13:14:19+0900\",\"children\":\"2025년 9월 24일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Multimodal LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal LLMs\"]}],[\"$\",\"span\",\"Video Understanding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video Understanding\"]}],[\"$\",\"span\",\"Geospatial Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Geospatial Reasoning\"]}],[\"$\",\"span\",\"Temporal Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Temporal Reasoning\"]}],[\"$\",\"span\",\"Travel Itinerary Reconstruction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Travel Itinerary Reconstruction\"]}],[\"$\",\"span\",\"Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmark\"]}],[\"$\",\"span\",\"Agent System\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Agent System\"]}],[\"$\",\"span\",\"VLOG\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"VLOG\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-24-Reinforcement_Learning_on_Pre-Training_Data\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-24-Reinforcement_Learning_on_Pre-Training_Data/\",\"children\":\"[논문리뷰] Reinforcement Learning on Pre-Training Data\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Evander Yang이 [arXiv]에 게시한 'Reinforcement Learning on Pre-Training Data' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-24 13:14:19+0900\",\"children\":\"2025년 9월 24일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Pre-training\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Pre-training\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Self-supervised Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Self-supervised Learning\"]}],[\"$\",\"span\",\"Scaling Laws\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Scaling Laws\"]}],[\"$\",\"span\",\"Next-segment Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Next-segment Reasoning\"]}],[\"$\",\"span\",\"Reward Modeling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reward Modeling\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-24-OpenGVL_-_Benchmarking_Visual_Temporal_Progress_for_Data_Curation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-24-OpenGVL_-_Benchmarking_Visual_Temporal_Progress_for_Data_Curation/\",\"children\":\"[논문리뷰] OpenGVL - Benchmarking Visual Temporal Progress for Data Curation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Viktor Petrenko이 [arXiv]에 게시한 'OpenGVL - Benchmarking Visual Temporal Progress for Data Curation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-24 13:14:19+0900\",\"children\":\"2025년 9월 24일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Robotics Data Curation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Robotics Data Curation\"]}],[\"$\",\"span\",\"Visual Temporal Progress\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Visual Temporal Progress\"]}],[\"$\",\"span\",\"Generative Value Learning (GVL)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generative Value Learning (GVL)\"]}],[\"$\",\"span\",\"Vision-Language Models (VLMs)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision-Language Models (VLMs)\"]}],[\"$\",\"span\",\"Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmark\"]}],[\"$\",\"span\",\"Task Progress Prediction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Task Progress Prediction\"]}],[\"$\",\"span\",\"Value-Order Correlation (VOC)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Value-Order Correlation (VOC)\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-24-MiniCPM-V_4.5_Cooking_Efficient_MLLMs_via_Architecture_Data_and_Training_Recipe\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-24-MiniCPM-V_4.5_Cooking_Efficient_MLLMs_via_Architecture_Data_and_Training_Recipe/\",\"children\":\"[논문리뷰] MiniCPM-V 4.5: Cooking Efficient MLLMs via Architecture, Data, and Training Recipe\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Wenshuo Ma이 [arXiv]에 게시한 'MiniCPM-V 4.5: Cooking Efficient MLLMs via Architecture, Data, and Training Recipe' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-24 13:14:19+0900\",\"children\":\"2025년 9월 24일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"MLLM Efficiency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"MLLM Efficiency\"]}],[\"$\",\"span\",\"Multimodal Transformer\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Transformer\"]}],[\"$\",\"span\",\"3D-Resampler\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D-Resampler\"]}],[\"$\",\"span\",\"Document AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Document AI\"]}],[\"$\",\"span\",\"Hybrid Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Hybrid Reinforcement Learning\"]}],[\"$\",\"span\",\"Video Understanding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video Understanding\"]}],[\"$\",\"span\",\"Efficient Inference\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Efficient Inference\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-24-MAPO_Mixed_Advantage_Policy_Optimization\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-24-MAPO_Mixed_Advantage_Policy_Optimization/\",\"children\":\"[논문리뷰] MAPO: Mixed Advantage Policy Optimization\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Xuankun Rong이 [arXiv]에 게시한 'MAPO: Mixed Advantage Policy Optimization' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-24 13:14:19+0900\",\"children\":\"2025년 9월 24일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Foundation Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Foundation Models\"]}],[\"$\",\"span\",\"Policy Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Policy Optimization\"]}],[\"$\",\"span\",\"Advantage Function\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Advantage Function\"]}],[\"$\",\"span\",\"Trajectory Certainty\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Trajectory Certainty\"]}],[\"$\",\"span\",\"Multimodal Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Reasoning\"]}],[\"$\",\"span\",\"GRPO\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"GRPO\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-24-Lyra_Generative_3D_Scene_Reconstruction_via_Video_Diffusion_Model_Self-Distillation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-24-Lyra_Generative_3D_Scene_Reconstruction_via_Video_Diffusion_Model_Self-Distillation/\",\"children\":\"[논문리뷰] Lyra: Generative 3D Scene Reconstruction via Video Diffusion Model Self-Distillation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yifeng Jiang이 [arXiv]에 게시한 'Lyra: Generative 3D Scene Reconstruction via Video Diffusion Model Self-Distillation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-24 13:14:19+0900\",\"children\":\"2025년 9월 24일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Generative AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generative AI\"]}],[\"$\",\"span\",\"3D Scene Reconstruction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D Scene Reconstruction\"]}],[\"$\",\"span\",\"Video Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video Diffusion Models\"]}],[\"$\",\"span\",\"Self-Distillation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Self-Distillation\"]}],[\"$\",\"span\",\"3D Gaussian Splatting\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D Gaussian Splatting\"]}],[\"$\",\"span\",\"Dynamic 4D Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dynamic 4D Generation\"]}],[\"$\",\"span\",\"Monocular Input\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Monocular Input\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-24-Large_Language_Models_Discriminate_Against_Speakers_of_German_Dialects\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-24-Large_Language_Models_Discriminate_Against_Speakers_of_German_Dialects/\",\"children\":\"[논문리뷰] Large Language Models Discriminate Against Speakers of German Dialects\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Katharina von der Wense이 [arXiv]에 게시한 'Large Language Models Discriminate Against Speakers of German Dialects' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-24 13:14:19+0900\",\"children\":\"2025년 9월 24일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Bias\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Bias\"]}],[\"$\",\"span\",\"German Dialects\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"German Dialects\"]}],[\"$\",\"span\",\"Sociolinguistics\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Sociolinguistics\"]}],[\"$\",\"span\",\"Stereotypes\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Stereotypes\"]}],[\"$\",\"span\",\"Implicit Association Test\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Implicit Association Test\"]}],[\"$\",\"span\",\"Decision Making\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Decision Making\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-24-HyRF_Hybrid_Radiance_Fields_for_Memory-efficient_and_High-quality_Novel_View_Synthesis\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-24-HyRF_Hybrid_Radiance_Fields_for_Memory-efficient_and_High-quality_Novel_View_Synthesis/\",\"children\":\"[논문리뷰] HyRF: Hybrid Radiance Fields for Memory-efficient and High-quality Novel View Synthesis\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Dan Xu이 [arXiv]에 게시한 'HyRF: Hybrid Radiance Fields for Memory-efficient and High-quality Novel View Synthesis' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-24 13:14:19+0900\",\"children\":\"2025년 9월 24일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Novel View Synthesis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Novel View Synthesis\"]}],[\"$\",\"span\",\"3D Gaussian Splatting (3DGS)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D Gaussian Splatting (3DGS)\"]}],[\"$\",\"span\",\"Neural Radiance Fields (NeRF)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Neural Radiance Fields (NeRF)\"]}],[\"$\",\"span\",\"Memory Efficiency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Memory Efficiency\"]}],[\"$\",\"span\",\"High-Quality Rendering\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"High-Quality Rendering\"]}],[\"$\",\"span\",\"Hybrid Representation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Hybrid Representation\"]}],[\"$\",\"span\",\"Real-time Rendering\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Real-time Rendering\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-24-Hyper-Bagel_A_Unified_Acceleration_Framework_for_Multimodal_Understanding_and_Generation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-24-Hyper-Bagel_A_Unified_Acceleration_Framework_for_Multimodal_Understanding_and_Generation/\",\"children\":\"[논문리뷰] Hyper-Bagel: A Unified Acceleration Framework for Multimodal Understanding and Generation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Jianbin Zheng이 [arXiv]에 게시한 'Hyper-Bagel: A Unified Acceleration Framework for Multimodal Understanding and Generation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-24 13:14:19+0900\",\"children\":\"2025년 9월 24일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Multimodal AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal AI\"]}],[\"$\",\"span\",\"Acceleration Framework\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Acceleration Framework\"]}],[\"$\",\"span\",\"Speculative Decoding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Speculative Decoding\"]}],[\"$\",\"span\",\"Diffusion Distillation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Distillation\"]}],[\"$\",\"span\",\"Unified Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Unified Models\"]}],[\"$\",\"span\",\"Text-to-Image Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Text-to-Image Generation\"]}],[\"$\",\"span\",\"Image Editing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image Editing\"]}],[\"$\",\"span\",\"Computational Efficiency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Computational Efficiency\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-24-GeoSVR_Taming_Sparse_Voxels_for_Geometrically_Accurate_Surface_Reconstruction\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-24-GeoSVR_Taming_Sparse_Voxels_for_Geometrically_Accurate_Surface_Reconstruction/\",\"children\":\"[논문리뷰] GeoSVR: Taming Sparse Voxels for Geometrically Accurate Surface Reconstruction\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Jin Zheng이 [arXiv]에 게시한 'GeoSVR: Taming Sparse Voxels for Geometrically Accurate Surface Reconstruction' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-24 13:14:19+0900\",\"children\":\"2025년 9월 24일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Surface Reconstruction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Surface Reconstruction\"]}],[\"$\",\"span\",\"Sparse Voxels\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Sparse Voxels\"]}],[\"$\",\"span\",\"Geometric Accuracy\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Geometric Accuracy\"]}],[\"$\",\"span\",\"Neural Radiance Fields\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Neural Radiance Fields\"]}],[\"$\",\"span\",\"3D Gaussian Splatting\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D Gaussian Splatting\"]}],[\"$\",\"span\",\"Monocular Depth\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Monocular Depth\"]}],[\"$\",\"span\",\"Voxel Uncertainty\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Voxel Uncertainty\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-24-Do_You_Need_Proprioceptive_States_in_Visuomotor_Policies\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-24-Do_You_Need_Proprioceptive_States_in_Visuomotor_Policies/\",\"children\":\"[논문리뷰] Do You Need Proprioceptive States in Visuomotor Policies?\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yushen Liang이 [arXiv]에 게시한 'Do You Need Proprioceptive States in Visuomotor Policies?' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-24 13:14:19+0900\",\"children\":\"2025년 9월 24일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Visuomotor Policies\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Visuomotor Policies\"]}],[\"$\",\"span\",\"Spatial Generalization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Spatial Generalization\"]}],[\"$\",\"span\",\"Imitation Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Imitation Learning\"]}],[\"$\",\"span\",\"Proprioception\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Proprioception\"]}],[\"$\",\"span\",\"State-free Policies\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"State-free Policies\"]}],[\"$\",\"span\",\"Robot Manipulation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Robot Manipulation\"]}],[\"$\",\"span\",\"End-Effector Control\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"End-Effector Control\"]}],[\"$\",\"span\",\"Data Efficiency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Efficiency\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-24-CAR-Flow_Condition-Aware_Reparameterization_Aligns_Source_and_Target_for_Better_Flow_Matching\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-24-CAR-Flow_Condition-Aware_Reparameterization_Aligns_Source_and_Target_for_Better_Flow_Matching/\",\"children\":\"[논문리뷰] CAR-Flow: Condition-Aware Reparameterization Aligns Source and Target for Better Flow Matching\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Rui Qian이 [arXiv]에 게시한 'CAR-Flow: Condition-Aware Reparameterization Aligns Source and Target for Better Flow Matching' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-24 13:14:19+0900\",\"children\":\"2025년 9월 24일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Flow Matching\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Flow Matching\"]}],[\"$\",\"span\",\"Conditional Generative Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Conditional Generative Models\"]}],[\"$\",\"span\",\"Reparameterization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reparameterization\"]}],[\"$\",\"span\",\"Mode Collapse\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Mode Collapse\"]}],[\"$\",\"span\",\"Image Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image Generation\"]}],[\"$\",\"span\",\"Latent Space Alignment\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Latent Space Alignment\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-24-Baseer_A_Vision-Language_Model_for_Arabic_Document-to-Markdown_OCR\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-24-Baseer_A_Vision-Language_Model_for_Arabic_Document-to-Markdown_OCR/\",\"children\":\"[논문리뷰] Baseer: A Vision-Language Model for Arabic Document-to-Markdown OCR\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Zeina Aldallal이 [arXiv]에 게시한 'Baseer: A Vision-Language Model for Arabic Document-to-Markdown OCR' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-24 13:14:19+0900\",\"children\":\"2025년 9월 24일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Arabic OCR\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Arabic OCR\"]}],[\"$\",\"span\",\"Vision-Language Model\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision-Language Model\"]}],[\"$\",\"span\",\"Fine-tuning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Fine-tuning\"]}],[\"$\",\"span\",\"Document Understanding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Document Understanding\"]}],[\"$\",\"span\",\"Markdown Conversion\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Markdown Conversion\"]}],[\"$\",\"span\",\"Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmark\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-23-When_Big_Models_Train_Small_Ones_Label-Free_Model_Parity_Alignment_for_Efficient_Visual_Question_Answering_using_Small_VLMs\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-23-When_Big_Models_Train_Small_Ones_Label-Free_Model_Parity_Alignment_for_Efficient_Visual_Question_Answering_using_Small_VLMs/\",\"children\":\"[논문리뷰] When Big Models Train Small Ones: Label-Free Model Parity Alignment for Efficient Visual Question Answering using Small VLMs\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Anand Mishra이 [arXiv]에 게시한 'When Big Models Train Small Ones: Label-Free Model Parity Alignment for Efficient Visual Question Answering using Small VLMs' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-23 13:36:03+0900\",\"children\":\"2025년 9월 23일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"VQA\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"VQA\"]}],[\"$\",\"span\",\"Small VLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Small VLMs\"]}],[\"$\",\"span\",\"Large VLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large VLMs\"]}],[\"$\",\"span\",\"Knowledge Transfer\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Knowledge Transfer\"]}],[\"$\",\"span\",\"Pseudo-labeling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Pseudo-labeling\"]}],[\"$\",\"span\",\"Label-Free Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Label-Free Learning\"]}],[\"$\",\"span\",\"Model Parity Alignment\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Model Parity Alignment\"]}],[\"$\",\"span\",\"Computational Efficiency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Computational Efficiency\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-23-VideoFrom3D_3D_Scene_Video_Generation_via_Complementary_Image_and_Video_Diffusion_Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-23-VideoFrom3D_3D_Scene_Video_Generation_via_Complementary_Image_and_Video_Diffusion_Models/\",\"children\":\"[논문리뷰] VideoFrom3D: 3D Scene Video Generation via Complementary Image and Video Diffusion Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Sunghyun Cho이 [arXiv]에 게시한 'VideoFrom3D: 3D Scene Video Generation via Complementary Image and Video Diffusion Models' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-23 13:36:03+0900\",\"children\":\"2025년 9월 23일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"3D Scene Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D Scene Generation\"]}],[\"$\",\"span\",\"Video Diffusion\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video Diffusion\"]}],[\"$\",\"span\",\"Image Diffusion\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image Diffusion\"]}],[\"$\",\"span\",\"Generative Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generative Models\"]}],[\"$\",\"span\",\"Computer Graphics\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Computer Graphics\"]}],[\"$\",\"span\",\"Temporal Consistency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Temporal Consistency\"]}],[\"$\",\"span\",\"Sparse Anchor Views\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Sparse Anchor Views\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-23-VaseVQA_Multimodal_Agent_and_Benchmark_for_Ancient_Greek_Pottery\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-23-VaseVQA_Multimodal_Agent_and_Benchmark_for_Ancient_Greek_Pottery/\",\"children\":\"[논문리뷰] VaseVQA: Multimodal Agent and Benchmark for Ancient Greek Pottery\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Shiya Huang이 [arXiv]에 게시한 'VaseVQA: Multimodal Agent and Benchmark for Ancient Greek Pottery' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-23 13:36:03+0900\",\"children\":\"2025년 9월 23일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Multimodal Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Large Language Models\"]}],[\"$\",\"span\",\"Visual Question Answering\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Visual Question Answering\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Cultural Heritage\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Cultural Heritage\"]}],[\"$\",\"span\",\"Ancient Greek Pottery\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Ancient Greek Pottery\"]}],[\"$\",\"span\",\"Supervised Fine-Tuning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Supervised Fine-Tuning\"]}],[\"$\",\"span\",\"Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmark\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-23-Understanding_Embedding_Scaling_in_Collaborative_Filtering\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-23-Understanding_Embedding_Scaling_in_Collaborative_Filtering/\",\"children\":\"[논문리뷰] Understanding Embedding Scaling in Collaborative Filtering\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yonghui Yang이 [arXiv]에 게시한 'Understanding Embedding Scaling in Collaborative Filtering' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-23 13:36:03+0900\",\"children\":\"2025년 9월 23일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Collaborative Filtering\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Collaborative Filtering\"]}],[\"$\",\"span\",\"Embedding Scaling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Embedding Scaling\"]}],[\"$\",\"span\",\"Noise Robustness\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Noise Robustness\"]}],[\"$\",\"span\",\"Recommender Systems\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Recommender Systems\"]}],[\"$\",\"span\",\"Graph Neural Networks\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Graph Neural Networks\"]}],[\"$\",\"span\",\"Self-supervised Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Self-supervised Learning\"]}],[\"$\",\"span\",\"Performance Degradation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Performance Degradation\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-23-Turk-LettuceDetect_A_Hallucination_Detection_Models_for_Turkish_RAG_Applications\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-23-Turk-LettuceDetect_A_Hallucination_Detection_Models_for_Turkish_RAG_Applications/\",\"children\":\"[논문리뷰] Turk-LettuceDetect: A Hallucination Detection Models for Turkish RAG Applications\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Fatma Betül Terzioğlu이 [arXiv]에 게시한 'Turk-LettuceDetect: A Hallucination Detection Models for Turkish RAG Applications' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-23 13:36:03+0900\",\"children\":\"2025년 9월 23일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Hallucination Detection\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Hallucination Detection\"]}],[\"$\",\"span\",\"Retrieval Augmented Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Retrieval Augmented Generation\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Turkish NLP\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Turkish NLP\"]}],[\"$\",\"span\",\"Token Classification\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Token Classification\"]}],[\"$\",\"span\",\"ModernBERT\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"ModernBERT\"]}],[\"$\",\"span\",\"Low-Resource Languages\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Low-Resource Languages\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-23-TempSamp-R1_Effective_Temporal_Sampling_with_Reinforcement_Fine-Tuning_for_Video_LLMs\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-23-TempSamp-R1_Effective_Temporal_Sampling_with_Reinforcement_Fine-Tuning_for_Video_LLMs/\",\"children\":\"[논문리뷰] TempSamp-R1: Effective Temporal Sampling with Reinforcement Fine-Tuning for Video LLMs\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Shaohui Jiao이 [arXiv]에 게시한 'TempSamp-R1: Effective Temporal Sampling with Reinforcement Fine-Tuning for Video LLMs' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-23 13:36:03+0900\",\"children\":\"2025년 9월 23일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Video LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video LLMs\"]}],[\"$\",\"span\",\"Temporal Grounding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Temporal Grounding\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Off-policy Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Off-policy Learning\"]}],[\"$\",\"span\",\"Reward Shaping\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reward Shaping\"]}],[\"$\",\"span\",\"Chain-of-Thought\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Chain-of-Thought\"]}],[\"$\",\"span\",\"Multimodal LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal LLMs\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-23-Synthetic_bootstrapped_pretraining\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-23-Synthetic_bootstrapped_pretraining/\",\"children\":\"[논문리뷰] Synthetic bootstrapped pretraining\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Emmanuel Candès이 [arXiv]에 게시한 'Synthetic bootstrapped pretraining' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-23 13:36:03+0900\",\"children\":\"2025년 9월 23일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Language Model Pretraining\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Language Model Pretraining\"]}],[\"$\",\"span\",\"Synthetic Data\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Synthetic Data\"]}],[\"$\",\"span\",\"Inter-document Correlation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Inter-document Correlation\"]}],[\"$\",\"span\",\"Data Augmentation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Augmentation\"]}],[\"$\",\"span\",\"Transformer\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Transformer\"]}],[\"$\",\"span\",\"Bootstrapping\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Bootstrapping\"]}],[\"$\",\"span\",\"Concept Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Concept Learning\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-23-SWE-Bench_Pro_Can_AI_Agents_Solve_Long-Horizon_Software_Engineering_Tasks\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-23-SWE-Bench_Pro_Can_AI_Agents_Solve_Long-Horizon_Software_Engineering_Tasks/\",\"children\":\"[논문리뷰] SWE-Bench Pro: Can AI Agents Solve Long-Horizon Software Engineering Tasks?\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yannis Yiming He이 [arXiv]에 게시한 'SWE-Bench Pro: Can AI Agents Solve Long-Horizon Software Engineering Tasks?' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-23 13:36:03+0900\",\"children\":\"2025년 9월 23일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"AI Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"AI Agents\"]}],[\"$\",\"span\",\"Software Engineering\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Software Engineering\"]}],[\"$\",\"span\",\"LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLMs\"]}],[\"$\",\"span\",\"Code Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Code Generation\"]}],[\"$\",\"span\",\"Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmark\"]}],[\"$\",\"span\",\"Contamination Resistance\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Contamination Resistance\"]}],[\"$\",\"span\",\"Long-Horizon Tasks\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Long-Horizon Tasks\"]}],[\"$\",\"span\",\"Enterprise Software\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Enterprise Software\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-23-SCAN_Self-Denoising_Monte_Carlo_Annotation_for_Robust_Process_Reward_Learning\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-23-SCAN_Self-Denoising_Monte_Carlo_Annotation_for_Robust_Process_Reward_Learning/\",\"children\":\"[논문리뷰] SCAN: Self-Denoising Monte Carlo Annotation for Robust Process Reward Learning\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Zhaopeng Tu이 [arXiv]에 게시한 'SCAN: Self-Denoising Monte Carlo Annotation for Robust Process Reward Learning' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-23 13:36:03+0900\",\"children\":\"2025년 9월 23일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Process Reward Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Process Reward Models\"]}],[\"$\",\"span\",\"Monte Carlo Annotation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Monte Carlo Annotation\"]}],[\"$\",\"span\",\"Noise Denoising\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Noise Denoising\"]}],[\"$\",\"span\",\"Robust Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Robust Learning\"]}],[\"$\",\"span\",\"Self-Supervision\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Self-Supervision\"]}],[\"$\",\"span\",\"Mathematical Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Mathematical Reasoning\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-23-Reasoning_Core_A_Scalable_RL_Environment_for_LLM_Symbolic_Reasoning\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-23-Reasoning_Core_A_Scalable_RL_Environment_for_LLM_Symbolic_Reasoning/\",\"children\":\"[논문리뷰] Reasoning Core: A Scalable RL Environment for LLM Symbolic Reasoning\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Damien Sileo이 [arXiv]에 게시한 'Reasoning Core: A Scalable RL Environment for LLM Symbolic Reasoning' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-23 13:36:03+0900\",\"children\":\"2025년 9월 23일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLM Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Reasoning\"]}],[\"$\",\"span\",\"Symbolic AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Symbolic AI\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Procedural Content Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Procedural Content Generation\"]}],[\"$\",\"span\",\"Verifiable Rewards\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Verifiable Rewards\"]}],[\"$\",\"span\",\"Adaptive Curricula\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Adaptive Curricula\"]}],[\"$\",\"span\",\"First-Order Logic\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"First-Order Logic\"]}],[\"$\",\"span\",\"PDDL Planning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"PDDL Planning\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-23-QWHA_Quantization-Aware_Walsh-Hadamard_Adaptation_for_Parameter-Efficient_Fine-Tuning_on_Large_Language_Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-23-QWHA_Quantization-Aware_Walsh-Hadamard_Adaptation_for_Parameter-Efficient_Fine-Tuning_on_Large_Language_Models/\",\"children\":\"[논문리뷰] QWHA: Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-Tuning on Large Language Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Jae-Joon Kim이 [arXiv]에 게시한 'QWHA: Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-Tuning on Large Language Models' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-23 13:36:03+0900\",\"children\":\"2025년 9월 23일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLM Fine-tuning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Fine-tuning\"]}],[\"$\",\"span\",\"Quantization-Aware PEFT\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Quantization-Aware PEFT\"]}],[\"$\",\"span\",\"Walsh-Hadamard Transform\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Walsh-Hadamard Transform\"]}],[\"$\",\"span\",\"Sparse Adaptation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Sparse Adaptation\"]}],[\"$\",\"span\",\"Low-bit Quantization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Low-bit Quantization\"]}],[\"$\",\"span\",\"Parameter-Efficient Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Parameter-Efficient Learning\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-23-Qwen3-Omni_Technical_Report\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-23-Qwen3-Omni_Technical_Report/\",\"children\":\"[논문리뷰] Qwen3-Omni Technical Report\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Lhma-aslp이 [arXiv]에 게시한 'Qwen3-Omni Technical Report' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-23 13:36:03+0900\",\"children\":\"2025년 9월 23일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Multimodal Model\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Model\"]}],[\"$\",\"span\",\"Thinker-Talker Architecture\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Thinker-Talker Architecture\"]}],[\"$\",\"span\",\"Mixture-of-Experts\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Mixture-of-Experts\"]}],[\"$\",\"span\",\"Low-latency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Low-latency\"]}],[\"$\",\"span\",\"Audio Understanding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Audio Understanding\"]}],[\"$\",\"span\",\"Cross-modal Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Cross-modal Reasoning\"]}],[\"$\",\"span\",\"State-of-the-Art\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"State-of-the-Art\"]}],[\"$\",\"span\",\"Real-time Interaction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Real-time Interaction\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-23-OmniInsert_Mask-Free_Video_Insertion_of_Any_Reference_via_Diffusion_Transformer_Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-23-OmniInsert_Mask-Free_Video_Insertion_of_Any_Reference_via_Diffusion_Transformer_Models/\",\"children\":\"[논문리뷰] OmniInsert: Mask-Free Video Insertion of Any Reference via Diffusion Transformer Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Pengze Zhang이 [arXiv]에 게시한 'OmniInsert: Mask-Free Video Insertion of Any Reference via Diffusion Transformer Models' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-23 13:36:03+0900\",\"children\":\"2025년 9월 23일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Video Insertion\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video Insertion\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}],[\"$\",\"span\",\"Diffusion Transformers\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Transformers\"]}],[\"$\",\"span\",\"Mask-Free\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Mask-Free\"]}],[\"$\",\"span\",\"Data Augmentation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Augmentation\"]}],[\"$\",\"span\",\"Progressive Training\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Progressive Training\"]}],[\"$\",\"span\",\"Preference Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Preference Optimization\"]}],[\"$\",\"span\",\"Video Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video Generation\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-23-MetaEmbed_Scaling_Multimodal_Retrieval_at_Test-Time_with_Flexible_Late_Interaction\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-23-MetaEmbed_Scaling_Multimodal_Retrieval_at_Test-Time_with_Flexible_Late_Interaction/\",\"children\":\"[논문리뷰] MetaEmbed: Scaling Multimodal Retrieval at Test-Time with Flexible Late Interaction\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Xintao Chen이 [arXiv]에 게시한 'MetaEmbed: Scaling Multimodal Retrieval at Test-Time with Flexible Late Interaction' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-23 13:36:03+0900\",\"children\":\"2025년 9월 23일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Multimodal Retrieval\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Retrieval\"]}],[\"$\",\"span\",\"Late Interaction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Late Interaction\"]}],[\"$\",\"span\",\"Meta Tokens\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Meta Tokens\"]}],[\"$\",\"span\",\"Matryoshka Representation Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Matryoshka Representation Learning\"]}],[\"$\",\"span\",\"Test-Time Scaling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Test-Time Scaling\"]}],[\"$\",\"span\",\"Vision-Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision-Language Models\"]}],[\"$\",\"span\",\"Dense Retrieval\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dense Retrieval\"]}],[\"$\",\"span\",\"Efficiency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Efficiency\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-23-Mano_Report\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-23-Mano_Report/\",\"children\":\"[논문리뷰] Mano Report\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Minghui Wu이 [arXiv]에 게시한 'Mano Report' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-23 13:36:03+0900\",\"children\":\"2025년 9월 23일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"GUI Agent\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"GUI Agent\"]}],[\"$\",\"span\",\"Multi-modal Foundation Model\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-modal Foundation Model\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Supervised Fine-tuning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Supervised Fine-tuning\"]}],[\"$\",\"span\",\"Simulated Environment\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Simulated Environment\"]}],[\"$\",\"span\",\"Data Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Generation\"]}],[\"$\",\"span\",\"Error Recovery\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Error Recovery\"]}],[\"$\",\"span\",\"Web Automation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Web Automation\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-23-LIMI_Less_is_More_for_Agency\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-23-LIMI_Less_is_More_for_Agency/\",\"children\":\"[논문리뷰] LIMI: Less is More for Agency\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"happyZYM이 [arXiv]에 게시한 'LIMI: Less is More for Agency' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-23 13:36:03+0900\",\"children\":\"2025년 9월 23일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"AI Agency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"AI Agency\"]}],[\"$\",\"span\",\"Data Curation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Curation\"]}],[\"$\",\"span\",\"Less Is More\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Less Is More\"]}],[\"$\",\"span\",\"Agentic Intelligence\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Agentic Intelligence\"]}],[\"$\",\"span\",\"Foundation Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Foundation Models\"]}],[\"$\",\"span\",\"Evaluation Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Evaluation Benchmark\"]}],[\"$\",\"span\",\"Efficiency Principle\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Efficiency Principle\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-23-GeoPQA_Bridging_the_Visual_Perception_Gap_in_MLLMs_for_Geometric_Reasoning\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-23-GeoPQA_Bridging_the_Visual_Perception_Gap_in_MLLMs_for_Geometric_Reasoning/\",\"children\":\"[논문리뷰] GeoPQA: Bridging the Visual Perception Gap in MLLMs for Geometric Reasoning\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Hou Pong Chan이 [arXiv]에 게시한 'GeoPQA: Bridging the Visual Perception Gap in MLLMs for Geometric Reasoning' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-23 13:36:03+0900\",\"children\":\"2025년 9월 23일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Multimodal Large Language Models (MLLMs)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Large Language Models (MLLMs)\"]}],[\"$\",\"span\",\"Geometric Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Geometric Reasoning\"]}],[\"$\",\"span\",\"Visual Perception\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Visual Perception\"]}],[\"$\",\"span\",\"Reinforcement Learning (RL)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning (RL)\"]}],[\"$\",\"span\",\"Two-stage Training\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Two-stage Training\"]}],[\"$\",\"span\",\"GeoPQA Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"GeoPQA Benchmark\"]}],[\"$\",\"span\",\"Perceptual Bottleneck\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Perceptual Bottleneck\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-23-From_Uniform_to_Heterogeneous_Tailoring_Policy_Optimization_to_Every_Tokens_Nature\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-23-From_Uniform_to_Heterogeneous_Tailoring_Policy_Optimization_to_Every_Tokens_Nature/\",\"children\":\"[논문리뷰] From Uniform to Heterogeneous: Tailoring Policy Optimization to Every Token's Nature\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Bin Cui이 [arXiv]에 게시한 'From Uniform to Heterogeneous: Tailoring Policy Optimization to Every Token's Nature' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-23 13:36:03+0900\",\"children\":\"2025년 9월 23일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLMs\"]}],[\"$\",\"span\",\"Policy Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Policy Optimization\"]}],[\"$\",\"span\",\"Token Heterogeneity\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Token Heterogeneity\"]}],[\"$\",\"span\",\"Adaptive Sampling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Adaptive Sampling\"]}],[\"$\",\"span\",\"Advantage Redistribution\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Advantage Redistribution\"]}],[\"$\",\"span\",\"Asymmetric Clipping\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Asymmetric Clipping\"]}],[\"$\",\"span\",\"Entropy-based RL\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Entropy-based RL\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-23-From_Hugging_Face_to_GitHub_Tracing_License_Drift_in_the_Open-Source_AI_Ecosystem\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-23-From_Hugging_Face_to_GitHub_Tracing_License_Drift_in_the_Open-Source_AI_Ecosystem/\",\"children\":\"[논문리뷰] From Hugging Face to GitHub: Tracing License Drift in the Open-Source AI Ecosystem\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Ahmed E. Hassan이 [arXiv]에 게시한 'From Hugging Face to GitHub: Tracing License Drift in the Open-Source AI Ecosystem' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-23 13:36:03+0900\",\"children\":\"2025년 9월 23일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Open-Source AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Open-Source AI\"]}],[\"$\",\"span\",\"License Compliance\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"License Compliance\"]}],[\"$\",\"span\",\"License Drift\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"License Drift\"]}],[\"$\",\"span\",\"AI Supply Chain\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"AI Supply Chain\"]}],[\"$\",\"span\",\"Hugging Face\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Hugging Face\"]}],[\"$\",\"span\",\"GitHub\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"GitHub\"]}],[\"$\",\"span\",\"LicenseRec\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LicenseRec\"]}],[\"$\",\"span\",\"Legal Risk\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Legal Risk\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-23-FlagEval_Findings_Report_A_Preliminary_Evaluation_of_Large_Reasoning_Models_on_Automatically_Verifiable_Textual_and_Visual_Questions\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-23-FlagEval_Findings_Report_A_Preliminary_Evaluation_of_Large_Reasoning_Models_on_Automatically_Verifiable_Textual_and_Visual_Questions/\",\"children\":\"[논문리뷰] FlagEval Findings Report: A Preliminary Evaluation of Large Reasoning Models on Automatically Verifiable Textual and Visual Questions\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"tengdai722이 [arXiv]에 게시한 'FlagEval Findings Report: A Preliminary Evaluation of Large Reasoning Models on Automatically Verifiable Textual and Visual Questions' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-23 13:36:03+0900\",\"children\":\"2025년 9월 23일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Large Reasoning Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Reasoning Models\"]}],[\"$\",\"span\",\"LLM Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Evaluation\"]}],[\"$\",\"span\",\"Multimodal AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal AI\"]}],[\"$\",\"span\",\"Reasoning Behaviors\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reasoning Behaviors\"]}],[\"$\",\"span\",\"Hallucination\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Hallucination\"]}],[\"$\",\"span\",\"Contamination-Free\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Contamination-Free\"]}],[\"$\",\"span\",\"AI Safety\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"AI Safety\"]}],[\"$\",\"span\",\"Instruction Following\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Instruction Following\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-23-EpiCache_Episodic_KV_Cache_Management_for_Long_Conversational_Question_Answering\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-23-EpiCache_Episodic_KV_Cache_Management_for_Long_Conversational_Question_Answering/\",\"children\":\"[논문리뷰] EpiCache: Episodic KV Cache Management for Long Conversational Question Answering\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Minsik Cho이 [arXiv]에 게시한 'EpiCache: Episodic KV Cache Management for Long Conversational Question Answering' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-23 13:36:03+0900\",\"children\":\"2025년 9월 23일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"KV Cache Management\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"KV Cache Management\"]}],[\"$\",\"span\",\"Long Conversational QA\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Long Conversational QA\"]}],[\"$\",\"span\",\"LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLMs\"]}],[\"$\",\"span\",\"Memory Efficiency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Memory Efficiency\"]}],[\"$\",\"span\",\"Episodic Clustering\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Episodic Clustering\"]}],[\"$\",\"span\",\"Block Prefill Eviction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Block Prefill Eviction\"]}],[\"$\",\"span\",\"Sensitivity-aware Allocation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Sensitivity-aware Allocation\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-23-DIWALI_-_Diversity_and_Inclusivity_aWare_cuLture_specific_Items_for_India_Dataset_and_Assessment_of_LLMs_for_Cultural_Text_Adaptation_in_Indian_Context\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-23-DIWALI_-_Diversity_and_Inclusivity_aWare_cuLture_specific_Items_for_India_Dataset_and_Assessment_of_LLMs_for_Cultural_Text_Adaptation_in_Indian_Context/\",\"children\":\"[논문리뷰] DIWALI - Diversity and Inclusivity aWare cuLture specific Items for India: Dataset and Assessment of LLMs for Cultural Text Adaptation in Indian Context\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Maunendra Sankar Desarkar이 [arXiv]에 게시한 'DIWALI - Diversity and Inclusivity aWare cuLture specific Items for India: Dataset and Assessment of LLMs for Cultural Text Adaptation in Indian Context' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-23 13:36:03+0900\",\"children\":\"2025년 9월 23일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Cultural Adaptation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Cultural Adaptation\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Indian Culture\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Indian Culture\"]}],[\"$\",\"span\",\"Dataset Creation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dataset Creation\"]}],[\"$\",\"span\",\"CSI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"CSI\"]}],[\"$\",\"span\",\"Human Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Human Evaluation\"]}],[\"$\",\"span\",\"LLM Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Evaluation\"]}],[\"$\",\"span\",\"Cultural Bias\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Cultural Bias\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-23-DiffusionNFT_Online_Diffusion_Reinforcement_with_Forward_Process\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-23-DiffusionNFT_Online_Diffusion_Reinforcement_with_Forward_Process/\",\"children\":\"[논문리뷰] DiffusionNFT: Online Diffusion Reinforcement with Forward Process\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Qinsheng Zhang이 [arXiv]에 게시한 'DiffusionNFT: Online Diffusion Reinforcement with Forward Process' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-23 13:36:03+0900\",\"children\":\"2025년 9월 23일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Online RL\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Online RL\"]}],[\"$\",\"span\",\"Flow Matching\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Flow Matching\"]}],[\"$\",\"span\",\"Forward Process\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Forward Process\"]}],[\"$\",\"span\",\"CFG-free\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"CFG-free\"]}],[\"$\",\"span\",\"Image Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image Generation\"]}],[\"$\",\"span\",\"Negative-Aware FineTuning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Negative-Aware FineTuning\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-23-Cross-Attention_is_Half_Explanation_in_Speech-to-Text_Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-23-Cross-Attention_is_Half_Explanation_in_Speech-to-Text_Models/\",\"children\":\"[논문리뷰] Cross-Attention is Half Explanation in Speech-to-Text Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Luisa Bentivogli이 [arXiv]에 게시한 'Cross-Attention is Half Explanation in Speech-to-Text Models' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-23 13:36:03+0900\",\"children\":\"2025년 9월 23일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Cross-attention\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Cross-attention\"]}],[\"$\",\"span\",\"Speech-to-Text (S2T)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Speech-to-Text (S2T)\"]}],[\"$\",\"span\",\"Explainable AI (XAI)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Explainable AI (XAI)\"]}],[\"$\",\"span\",\"Saliency Maps\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Saliency Maps\"]}],[\"$\",\"span\",\"Feature Attribution\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Feature Attribution\"]}],[\"$\",\"span\",\"Transformer\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Transformer\"]}],[\"$\",\"span\",\"Context Mixing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Context Mixing\"]}],[\"$\",\"span\",\"Correlation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Correlation\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-23-ContextFlow_Training-Free_Video_Object_Editing_via_Adaptive_Context_Enrichment\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-23-ContextFlow_Training-Free_Video_Object_Editing_via_Adaptive_Context_Enrichment/\",\"children\":\"[논문리뷰] ContextFlow: Training-Free Video Object Editing via Adaptive Context Enrichment\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yue Ma이 [arXiv]에 게시한 'ContextFlow: Training-Free Video Object Editing via Adaptive Context Enrichment' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-23 13:36:03+0900\",\"children\":\"2025년 9월 23일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Video Object Editing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video Object Editing\"]}],[\"$\",\"span\",\"Training-Free\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Training-Free\"]}],[\"$\",\"span\",\"Diffusion Transformers\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Transformers\"]}],[\"$\",\"span\",\"Rectified Flow\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Rectified Flow\"]}],[\"$\",\"span\",\"Adaptive Context Enrichment\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Adaptive Context Enrichment\"]}],[\"$\",\"span\",\"Guidance Responsiveness\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Guidance Responsiveness\"]}],[\"$\",\"span\",\"Temporal Consistency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Temporal Consistency\"]}],[\"$\",\"span\",\"Image-to-Video\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image-to-Video\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-23-CodeFuse-CR-Bench_A_Comprehensiveness-aware_Benchmark_for_End-to-End_Code_Review_Evaluation_in_Python_Projects\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-23-CodeFuse-CR-Bench_A_Comprehensiveness-aware_Benchmark_for_End-to-End_Code_Review_Evaluation_in_Python_Projects/\",\"children\":\"[논문리뷰] CodeFuse-CR-Bench: A Comprehensiveness-aware Benchmark for End-to-End Code Review Evaluation in Python Projects\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Hang Yu이 [arXiv]에 게시한 'CodeFuse-CR-Bench: A Comprehensiveness-aware Benchmark for End-to-End Code Review Evaluation in Python Projects' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-23 13:36:03+0900\",\"children\":\"2025년 9월 23일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Code Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Code Review\"]}],[\"$\",\"span\",\"LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLMs\"]}],[\"$\",\"span\",\"Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmark\"]}],[\"$\",\"span\",\"Python Projects\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Python Projects\"]}],[\"$\",\"span\",\"End-to-End Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"End-to-End Evaluation\"]}],[\"$\",\"span\",\"Context-Awareness\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Context-Awareness\"]}],[\"$\",\"span\",\"Software Engineering\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Software Engineering\"]}],[\"$\",\"span\",\"LLM-as-a-Judge\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM-as-a-Judge\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-23-ByteWrist_A_Parallel_Robotic_Wrist_Enabling_Flexible_and_Anthropomorphic_Motion_for_Confined_Spaces\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-23-ByteWrist_A_Parallel_Robotic_Wrist_Enabling_Flexible_and_Anthropomorphic_Motion_for_Confined_Spaces/\",\"children\":\"[논문리뷰] ByteWrist: A Parallel Robotic Wrist Enabling Flexible and Anthropomorphic Motion for Confined Spaces\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Jiafeng Xu이 [arXiv]에 게시한 'ByteWrist: A Parallel Robotic Wrist Enabling Flexible and Anthropomorphic Motion for Confined Spaces' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-23 13:36:03+0900\",\"children\":\"2025년 9월 23일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Robotics\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Robotics\"]}],[\"$\",\"span\",\"Parallel Manipulator\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Parallel Manipulator\"]}],[\"$\",\"span\",\"Robotic Wrist\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Robotic Wrist\"]}],[\"$\",\"span\",\"Confined Space Manipulation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Confined Space Manipulation\"]}],[\"$\",\"span\",\"Kinematics\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Kinematics\"]}],[\"$\",\"span\",\"Anthropomorphic Robot\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Anthropomorphic Robot\"]}],[\"$\",\"span\",\"Robot Design\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Robot Design\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-23-AuditoryBench_Can_Language_Models_Understand_Auditory_Knowledge_without_Hearing\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-23-AuditoryBench_Can_Language_Models_Understand_Auditory_Knowledge_without_Hearing/\",\"children\":\"[논문리뷰] AuditoryBench++: Can Language Models Understand Auditory Knowledge without Hearing?\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Jaeho Lee이 [arXiv]에 게시한 'AuditoryBench++: Can Language Models Understand Auditory Knowledge without Hearing?' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-23 13:36:03+0900\",\"children\":\"2025년 9월 23일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Auditory Knowledge\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Auditory Knowledge\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Multimodal Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Reasoning\"]}],[\"$\",\"span\",\"Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmark\"]}],[\"$\",\"span\",\"Chain-of-Thought\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Chain-of-Thought\"]}],[\"$\",\"span\",\"Auditory Imagination\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Auditory Imagination\"]}],[\"$\",\"span\",\"Text-only Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Text-only Reasoning\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-23-ARE_Scaling_Up_Agent_Environments_and_Evaluations\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-23-ARE_Scaling_Up_Agent_Environments_and_Evaluations/\",\"children\":\"[논문리뷰] ARE: Scaling Up Agent Environments and Evaluations\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Matteo Bettini이 [arXiv]에 게시한 'ARE: Scaling Up Agent Environments and Evaluations' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-23 13:36:03+0900\",\"children\":\"2025년 9월 23일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Agent Environments\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Agent Environments\"]}],[\"$\",\"span\",\"Agent Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Agent Evaluation\"]}],[\"$\",\"span\",\"LLM Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Agents\"]}],[\"$\",\"span\",\"Asynchronous Systems\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Asynchronous Systems\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Tool Use\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Tool Use\"]}],[\"$\",\"span\",\"Multi-agent Collaboration\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-agent Collaboration\"]}],[\"$\",\"span\",\"Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmark\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-23-Analyzing_the_Effects_of_Supervised_Fine-Tuning_on_Model_Knowledge_from_Token_and_Parameter_Levels\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-23-Analyzing_the_Effects_of_Supervised_Fine-Tuning_on_Model_Knowledge_from_Token_and_Parameter_Levels/\",\"children\":\"[논문리뷰] Analyzing the Effects of Supervised Fine-Tuning on Model Knowledge from Token and Parameter Levels\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Qi Zhang이 [arXiv]에 게시한 'Analyzing the Effects of Supervised Fine-Tuning on Model Knowledge from Token and Parameter Levels' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-23 13:36:03+0900\",\"children\":\"2025년 9월 23일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Supervised Fine-Tuning (SFT)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Supervised Fine-Tuning (SFT)\"]}],[\"$\",\"span\",\"Large Language Models (LLMs)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models (LLMs)\"]}],[\"$\",\"span\",\"Model Knowledge\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Model Knowledge\"]}],[\"$\",\"span\",\"Closed-Book Question Answering (CBQA)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Closed-Book Question Answering (CBQA)\"]}],[\"$\",\"span\",\"Parameter Restoration\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Parameter Restoration\"]}],[\"$\",\"span\",\"Kullback-Leibler Divergence\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Kullback-Leibler Divergence\"]}],[\"$\",\"span\",\"Knowledge Forgetting\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Knowledge Forgetting\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-22-WhisTLE_Deeply_Supervised_Text-Only_Domain_Adaptation_for_Pretrained_Speech_Recognition_Transformers\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-22-WhisTLE_Deeply_Supervised_Text-Only_Domain_Adaptation_for_Pretrained_Speech_Recognition_Transformers/\",\"children\":\"[논문리뷰] WhisTLE: Deeply Supervised, Text-Only Domain Adaptation for Pretrained Speech Recognition Transformers\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Karun Kumar이 [arXiv]에 게시한 'WhisTLE: Deeply Supervised, Text-Only Domain Adaptation for Pretrained Speech Recognition Transformers' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-22 13:11:29+0900\",\"children\":\"2025년 9월 22일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"ASR\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"ASR\"]}],[\"$\",\"span\",\"Domain Adaptation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Domain Adaptation\"]}],[\"$\",\"span\",\"Text-Only Training\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Text-Only Training\"]}],[\"$\",\"span\",\"Transformer\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Transformer\"]}],[\"$\",\"span\",\"Variational Autoencoder\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Variational Autoencoder\"]}],[\"$\",\"span\",\"Deep Supervision\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Deep Supervision\"]}],[\"$\",\"span\",\"Whisper\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Whisper\"]}],[\"$\",\"span\",\"Encoder-Decoder Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Encoder-Decoder Models\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-22-Video2Roleplay_A_Multimodal_Dataset_and_Framework_for_Video-Guided_Role-playing_Agents\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-22-Video2Roleplay_A_Multimodal_Dataset_and_Framework_for_Video-Guided_Role-playing_Agents/\",\"children\":\"[논문리뷰] Video2Roleplay: A Multimodal Dataset and Framework for Video-Guided Role-playing Agents\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Chao Zhang이 [arXiv]에 게시한 'Video2Roleplay: A Multimodal Dataset and Framework for Video-Guided Role-playing Agents' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-22 13:11:29+0900\",\"children\":\"2025년 9월 22일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Role-playing Agents (RPAs)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Role-playing Agents (RPAs)\"]}],[\"$\",\"span\",\"Multimodal AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal AI\"]}],[\"$\",\"span\",\"Video Understanding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video Understanding\"]}],[\"$\",\"span\",\"Large Language Models (LLMs)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models (LLMs)\"]}],[\"$\",\"span\",\"Dataset Creation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dataset Creation\"]}],[\"$\",\"span\",\"Dynamic Role Profiles\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dynamic Role Profiles\"]}],[\"$\",\"span\",\"Adaptive Temporal Sampling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Adaptive Temporal Sampling\"]}],[\"$\",\"span\",\"Fine-tuning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Fine-tuning\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-22-SPATIALGEN_Layout-guided_3D_Indoor_Scene_Generation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-22-SPATIALGEN_Layout-guided_3D_Indoor_Scene_Generation/\",\"children\":\"[논문리뷰] SPATIALGEN: Layout-guided 3D Indoor Scene Generation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yongsen Mao이 [arXiv]에 게시한 'SPATIALGEN: Layout-guided 3D Indoor Scene Generation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-22 13:11:29+0900\",\"children\":\"2025년 9월 22일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"3D Scene Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D Scene Generation\"]}],[\"$\",\"span\",\"Layout Guidance\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Layout Guidance\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}],[\"$\",\"span\",\"Multi-view Synthesis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-view Synthesis\"]}],[\"$\",\"span\",\"Synthetic Dataset\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Synthetic Dataset\"]}],[\"$\",\"span\",\"Indoor Environments\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Indoor Environments\"]}],[\"$\",\"span\",\"Gaussian Splatting\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Gaussian Splatting\"]}],[\"$\",\"span\",\"Semantic Consistency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Semantic Consistency\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-22-RPG_A_Repository_Planning_Graph_for_Unified_and_Scalable_Codebase_Generation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-22-RPG_A_Repository_Planning_Graph_for_Unified_and_Scalable_Codebase_Generation/\",\"children\":\"[논문리뷰] RPG: A Repository Planning Graph for Unified and Scalable Codebase Generation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Steven Liu이 [arXiv]에 게시한 'RPG: A Repository Planning Graph for Unified and Scalable Codebase Generation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-22 13:11:29+0900\",\"children\":\"2025년 9월 22일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Code Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Code Generation\"]}],[\"$\",\"span\",\"LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLMs\"]}],[\"$\",\"span\",\"Repository Planning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Repository Planning\"]}],[\"$\",\"span\",\"Graph-based Representation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Graph-based Representation\"]}],[\"$\",\"span\",\"Software Engineering\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Software Engineering\"]}],[\"$\",\"span\",\"Agent Frameworks\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Agent Frameworks\"]}],[\"$\",\"span\",\"Scalable Codebase\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Scalable Codebase\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-22-RGB-Only_Supervised_Camera_Parameter_Optimization_in_Dynamic_Scenes\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-22-RGB-Only_Supervised_Camera_Parameter_Optimization_in_Dynamic_Scenes/\",\"children\":\"[논문리뷰] RGB-Only Supervised Camera Parameter Optimization in Dynamic Scenes\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Narendra Ahuja이 [arXiv]에 게시한 'RGB-Only Supervised Camera Parameter Optimization in Dynamic Scenes' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-22 13:11:29+0900\",\"children\":\"2025년 9월 22일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Camera Parameter Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Camera Parameter Optimization\"]}],[\"$\",\"span\",\"Dynamic Scenes\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dynamic Scenes\"]}],[\"$\",\"span\",\"RGB-Only Supervision\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"RGB-Only Supervision\"]}],[\"$\",\"span\",\"Structure from Motion\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Structure from Motion\"]}],[\"$\",\"span\",\"Outlier Robustness\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Outlier Robustness\"]}],[\"$\",\"span\",\"3D Gaussian Splatting\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D Gaussian Splatting\"]}],[\"$\",\"span\",\"Two-stage Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Two-stage Optimization\"]}],[\"$\",\"span\",\"Point Tracking\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Point Tracking\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-22-MANZANO_A_Simple_and_Scalable_Unified_Multimodal_Model_with_a_Hybrid_Vision_Tokenizer\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-22-MANZANO_A_Simple_and_Scalable_Unified_Multimodal_Model_with_a_Hybrid_Vision_Tokenizer/\",\"children\":\"[논문리뷰] MANZANO: A Simple and Scalable Unified Multimodal Model with a Hybrid Vision Tokenizer\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"jialingt이 [arXiv]에 게시한 'MANZANO: A Simple and Scalable Unified Multimodal Model with a Hybrid Vision Tokenizer' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-22 13:11:29+0900\",\"children\":\"2025년 9월 22일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Multimodal LLM\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal LLM\"]}],[\"$\",\"span\",\"Hybrid Tokenizer\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Hybrid Tokenizer\"]}],[\"$\",\"span\",\"Text-to-Image Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Text-to-Image Generation\"]}],[\"$\",\"span\",\"Visual Question Answering\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Visual Question Answering\"]}],[\"$\",\"span\",\"Autoregressive Model\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Autoregressive Model\"]}],[\"$\",\"span\",\"Diffusion Decoder\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Decoder\"]}],[\"$\",\"span\",\"Unified Architecture\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Unified Architecture\"]}],[\"$\",\"span\",\"Model Scaling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Model Scaling\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-22-Lynx_Towards_High-Fidelity_Personalized_Video_Generation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-22-Lynx_Towards_High-Fidelity_Personalized_Video_Generation/\",\"children\":\"[논문리뷰] Lynx: Towards High-Fidelity Personalized Video Generation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Linjie Luo이 [arXiv]에 게시한 'Lynx: Towards High-Fidelity Personalized Video Generation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-22 13:11:29+0900\",\"children\":\"2025년 9월 22일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Personalized Video Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Personalized Video Generation\"]}],[\"$\",\"span\",\"Diffusion Transformer\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Transformer\"]}],[\"$\",\"span\",\"Identity Preservation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Identity Preservation\"]}],[\"$\",\"span\",\"Video Synthesis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video Synthesis\"]}],[\"$\",\"span\",\"Adapter Networks\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Adapter Networks\"]}],[\"$\",\"span\",\"Facial Recognition\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Facial Recognition\"]}],[\"$\",\"span\",\"Cross-Attention\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Cross-Attention\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-22-Latent_Zoning_Network_A_Unified_Principle_for_Generative_Modeling_Representation_Learning_and_Classification\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-22-Latent_Zoning_Network_A_Unified_Principle_for_Generative_Modeling_Representation_Learning_and_Classification/\",\"children\":\"[논문리뷰] Latent Zoning Network: A Unified Principle for Generative Modeling, Representation Learning, and Classification\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Wenyu Wang이 [arXiv]에 게시한 'Latent Zoning Network: A Unified Principle for Generative Modeling, Representation Learning, and Classification' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-22 13:11:29+0900\",\"children\":\"2025년 9월 22일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Generative Modeling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generative Modeling\"]}],[\"$\",\"span\",\"Representation Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Representation Learning\"]}],[\"$\",\"span\",\"Classification\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Classification\"]}],[\"$\",\"span\",\"Unified Framework\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Unified Framework\"]}],[\"$\",\"span\",\"Latent Space\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Latent Space\"]}],[\"$\",\"span\",\"Flow Matching\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Flow Matching\"]}],[\"$\",\"span\",\"Deep Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Deep Learning\"]}],[\"$\",\"span\",\"Image Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image Generation\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-22-Do_You_Hear_What_I_Mean_Quantifying_the_Instruction-Perception_Gap_in_Instruction-Guided_Expressive_Text-To-Speech_Systems\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-22-Do_You_Hear_What_I_Mean_Quantifying_the_Instruction-Perception_Gap_in_Instruction-Guided_Expressive_Text-To-Speech_Systems/\",\"children\":\"[논문리뷰] Do You Hear What I Mean? Quantifying the Instruction-Perception Gap in Instruction-Guided Expressive Text-To-Speech Systems\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Hung-yi Lee이 [arXiv]에 게시한 'Do You Hear What I Mean? Quantifying the Instruction-Perception Gap in Instruction-Guided Expressive Text-To-Speech Systems' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-22 13:11:29+0900\",\"children\":\"2025년 9월 22일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Instruction-Guided TTS\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Instruction-Guided TTS\"]}],[\"$\",\"span\",\"Expressive Speech Synthesis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Expressive Speech Synthesis\"]}],[\"$\",\"span\",\"Human Perception\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Human Perception\"]}],[\"$\",\"span\",\"Subjective Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Subjective Evaluation\"]}],[\"$\",\"span\",\"Controllability\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Controllability\"]}],[\"$\",\"span\",\"Instruction Following\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Instruction Following\"]}],[\"$\",\"span\",\"Evaluation Metrics\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Evaluation Metrics\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-22-BTL-UI_Blink-Think-Link_Reasoning_Model_for_GUI_Agent\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-22-BTL-UI_Blink-Think-Link_Reasoning_Model_for_GUI_Agent/\",\"children\":\"[논문리뷰] BTL-UI: Blink-Think-Link Reasoning Model for GUI Agent\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Jiahui Yang이 [arXiv]에 게시한 'BTL-UI: Blink-Think-Link Reasoning Model for GUI Agent' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-22 13:11:29+0900\",\"children\":\"2025년 9월 22일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"GUI Agent\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"GUI Agent\"]}],[\"$\",\"span\",\"Human-GUI Interaction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Human-GUI Interaction\"]}],[\"$\",\"span\",\"Cognitive Modeling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Cognitive Modeling\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Multimodal Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Large Language Models\"]}],[\"$\",\"span\",\"Attention Mechanisms\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Attention Mechanisms\"]}],[\"$\",\"span\",\"Action Planning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Action Planning\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-22-BaseReward_A_Strong_Baseline_for_Multimodal_Reward_Model\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-22-BaseReward_A_Strong_Baseline_for_Multimodal_Reward_Model/\",\"children\":\"[논문리뷰] BaseReward: A Strong Baseline for Multimodal Reward Model\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"jianfeipan이 [arXiv]에 게시한 'BaseReward: A Strong Baseline for Multimodal Reward Model' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-22 13:11:29+0900\",\"children\":\"2025년 9월 22일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Multimodal Reward Model\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Reward Model\"]}],[\"$\",\"span\",\"MLLM Alignment\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"MLLM Alignment\"]}],[\"$\",\"span\",\"RLHF\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"RLHF\"]}],[\"$\",\"span\",\"Reward Head Architecture\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reward Head Architecture\"]}],[\"$\",\"span\",\"Data Curation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Curation\"]}],[\"$\",\"span\",\"Ensemble Methods\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Ensemble Methods\"]}],[\"$\",\"span\",\"BaseReward\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"BaseReward\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-22-A_Vision-Language-Action-Critic_Model_for_Robotic_Real-World_Reinforcement_Learning\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-22-A_Vision-Language-Action-Critic_Model_for_Robotic_Real-World_Reinforcement_Learning/\",\"children\":\"[논문리뷰] A Vision-Language-Action-Critic Model for Robotic Real-World Reinforcement Learning\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Jiangmiao이 [arXiv]에 게시한 'A Vision-Language-Action-Critic Model for Robotic Real-World Reinforcement Learning' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-22 13:11:29+0900\",\"children\":\"2025년 9월 22일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Robotics\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Robotics\"]}],[\"$\",\"span\",\"Reinforcement Learning (RL)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning (RL)\"]}],[\"$\",\"span\",\"Vision-Language-Action (VLA) Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision-Language-Action (VLA) Models\"]}],[\"$\",\"span\",\"Reward Modeling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reward Modeling\"]}],[\"$\",\"span\",\"Human-in-the-Loop\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Human-in-the-Loop\"]}],[\"$\",\"span\",\"Dense Rewards\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dense Rewards\"]}],[\"$\",\"span\",\"Generalization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generalization\"]}],[\"$\",\"span\",\"Autoregressive Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Autoregressive Models\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-22-Ask-to-Clarify_Resolving_Instruction_Ambiguity_through_Multi-turn_Dialogue\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-22-Ask-to-Clarify_Resolving_Instruction_Ambiguity_through_Multi-turn_Dialogue/\",\"children\":\"[논문리뷰] Ask-to-Clarify: Resolving Instruction Ambiguity through Multi-turn Dialogue\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Hui Zhang이 [arXiv]에 게시한 'Ask-to-Clarify: Resolving Instruction Ambiguity through Multi-turn Dialogue' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-22 13:11:29+0900\",\"children\":\"2025년 9월 22일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Embodied AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Embodied AI\"]}],[\"$\",\"span\",\"Human-Robot Interaction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Human-Robot Interaction\"]}],[\"$\",\"span\",\"Multi-turn Dialogue\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-turn Dialogue\"]}],[\"$\",\"span\",\"Instruction Following\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Instruction Following\"]}],[\"$\",\"span\",\"Vision-Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision-Language Models\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}],[\"$\",\"span\",\"Ambiguity Resolution\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Ambiguity Resolution\"]}],[\"$\",\"span\",\"Low-level Actions\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Low-level Actions\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-19-WorldForge_Unlocking_Emergent_3D4D_Generation_in_Video_Diffusion_Model_via_Training-Free_Guidance\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-19-WorldForge_Unlocking_Emergent_3D4D_Generation_in_Video_Diffusion_Model_via_Training-Free_Guidance/\",\"children\":\"[논문리뷰] WorldForge: Unlocking Emergent 3D/4D Generation in Video Diffusion Model via Training-Free Guidance\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Ruibo Li이 [arXiv]에 게시한 'WorldForge: Unlocking Emergent 3D/4D Generation in Video Diffusion Model via Training-Free Guidance' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-19 13:12:21+0900\",\"children\":\"2025년 9월 19일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Video Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video Diffusion Models\"]}],[\"$\",\"span\",\"3D/4D Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D/4D Generation\"]}],[\"$\",\"span\",\"Training-Free Guidance\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Training-Free Guidance\"]}],[\"$\",\"span\",\"Camera Trajectory Control\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Camera Trajectory Control\"]}],[\"$\",\"span\",\"Novel View Synthesis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Novel View Synthesis\"]}],[\"$\",\"span\",\"Geometric Consistency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Geometric Consistency\"]}],[\"$\",\"span\",\"Inference-Time Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Inference-Time Optimization\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-19-Unleashing_the_Potential_of_Multimodal_LLMs_for_Zero-Shot_Spatio-Temporal_Video_Grounding\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-19-Unleashing_the_Potential_of_Multimodal_LLMs_for_Zero-Shot_Spatio-Temporal_Video_Grounding/\",\"children\":\"[논문리뷰] Unleashing the Potential of Multimodal LLMs for Zero-Shot Spatio-Temporal Video Grounding\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Rynson W. H. Lau이 [arXiv]에 게시한 'Unleashing the Potential of Multimodal LLMs for Zero-Shot Spatio-Temporal Video Grounding' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-19 13:12:21+0900\",\"children\":\"2025년 9월 19일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Spatio-Temporal Video Grounding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Spatio-Temporal Video Grounding\"]}],[\"$\",\"span\",\"Multimodal Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Large Language Models\"]}],[\"$\",\"span\",\"Zero-Shot Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Zero-Shot Learning\"]}],[\"$\",\"span\",\"Visual Grounding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Visual Grounding\"]}],[\"$\",\"span\",\"Decomposed Spatio-Temporal Highlighting\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Decomposed Spatio-Temporal Highlighting\"]}],[\"$\",\"span\",\"Logit-Guided Re-attention\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Logit-Guided Re-attention\"]}],[\"$\",\"span\",\"Temporal-Augmented Assembling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Temporal-Augmented Assembling\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-19-Understand_Before_You_Generate_Self-Guided_Training_for_Autoregressive_Image_Generation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-19-Understand_Before_You_Generate_Self-Guided_Training_for_Autoregressive_Image_Generation/\",\"children\":\"[논문리뷰] Understand Before You Generate: Self-Guided Training for Autoregressive Image Generation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Xihui Liu이 [arXiv]에 게시한 'Understand Before You Generate: Self-Guided Training for Autoregressive Image Generation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-19 13:12:21+0900\",\"children\":\"2025년 9월 19일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Autoregressive Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Autoregressive Models\"]}],[\"$\",\"span\",\"Image Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image Generation\"]}],[\"$\",\"span\",\"Self-Supervised Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Self-Supervised Learning\"]}],[\"$\",\"span\",\"Visual Understanding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Visual Understanding\"]}],[\"$\",\"span\",\"Masked Image Modeling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Masked Image Modeling\"]}],[\"$\",\"span\",\"Contrastive Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Contrastive Learning\"]}],[\"$\",\"span\",\"Next-Token Prediction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Next-Token Prediction\"]}],[\"$\",\"span\",\"LlamaGen\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LlamaGen\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-19-ScaleCUA_Scaling_Open-Source_Computer_Use_Agents_with_Cross-Platform_Data\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-19-ScaleCUA_Scaling_Open-Source_Computer_Use_Agents_with_Cross-Platform_Data/\",\"children\":\"[논문리뷰] ScaleCUA: Scaling Open-Source Computer Use Agents with Cross-Platform Data\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Zehao Li이 [arXiv]에 게시한 'ScaleCUA: Scaling Open-Source Computer Use Agents with Cross-Platform Data' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-19 13:12:21+0900\",\"children\":\"2025년 9월 19일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Computer Use Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Computer Use Agents\"]}],[\"$\",\"span\",\"Vision-Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision-Language Models\"]}],[\"$\",\"span\",\"Cross-Platform Data\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Cross-Platform Data\"]}],[\"$\",\"span\",\"GUI Automation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"GUI Automation\"]}],[\"$\",\"span\",\"Data Scaling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Scaling\"]}],[\"$\",\"span\",\"Open-Source\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Open-Source\"]}],[\"$\",\"span\",\"Task Completion\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Task Completion\"]}],[\"$\",\"span\",\"GUI Grounding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"GUI Grounding\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-19-RynnVLA-001_Using_Human_Demonstrations_to_Improve_Robot_Manipulation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-19-RynnVLA-001_Using_Human_Demonstrations_to_Improve_Robot_Manipulation/\",\"children\":\"[논문리뷰] RynnVLA-001: Using Human Demonstrations to Improve Robot Manipulation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"SpaceProduct이 [arXiv]에 게시한 'RynnVLA-001: Using Human Demonstrations to Improve Robot Manipulation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-19 13:12:21+0900\",\"children\":\"2025년 9월 19일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Vision-Language-Action (VLA) Model\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision-Language-Action (VLA) Model\"]}],[\"$\",\"span\",\"Robot Manipulation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Robot Manipulation\"]}],[\"$\",\"span\",\"Human Demonstrations\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Human Demonstrations\"]}],[\"$\",\"span\",\"Video Generative Pretraining\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video Generative Pretraining\"]}],[\"$\",\"span\",\"Ego-Centric Video\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Ego-Centric Video\"]}],[\"$\",\"span\",\"Trajectory Prediction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Trajectory Prediction\"]}],[\"$\",\"span\",\"ActionVAE\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"ActionVAE\"]}],[\"$\",\"span\",\"Transformer\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Transformer\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-19-RecoWorld_Building_Simulated_Environments_for_Agentic_Recommender_Systems\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-19-RecoWorld_Building_Simulated_Environments_for_Agentic_Recommender_Systems/\",\"children\":\"[논문리뷰] RecoWorld: Building Simulated Environments for Agentic Recommender Systems\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Mingyuan Wu이 [arXiv]에 게시한 'RecoWorld: Building Simulated Environments for Agentic Recommender Systems' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-19 13:12:21+0900\",\"children\":\"2025년 9월 19일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Agentic Recommender Systems\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Agentic Recommender Systems\"]}],[\"$\",\"span\",\"Simulated Environments\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Simulated Environments\"]}],[\"$\",\"span\",\"LLM-driven Simulation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM-driven Simulation\"]}],[\"$\",\"span\",\"Multi-turn Interaction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-turn Interaction\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"User Retention\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"User Retention\"]}],[\"$\",\"span\",\"Instruction Following\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Instruction Following\"]}],[\"$\",\"span\",\"Multi-agent Systems\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-agent Systems\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-19-Reasoning_over_Boundaries_Enhancing_Specification_Alignment_via_Test-time_Delibration\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-19-Reasoning_over_Boundaries_Enhancing_Specification_Alignment_via_Test-time_Delibration/\",\"children\":\"[논문리뷰] Reasoning over Boundaries: Enhancing Specification Alignment via Test-time Delibration\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Zhilin Wang이 [arXiv]에 게시한 'Reasoning over Boundaries: Enhancing Specification Alignment via Test-time Delibration' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-19 13:12:21+0900\",\"children\":\"2025년 9월 19일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLMs\"]}],[\"$\",\"span\",\"Specification Alignment\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Specification Alignment\"]}],[\"$\",\"span\",\"Test-Time Deliberation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Test-Time Deliberation\"]}],[\"$\",\"span\",\"Safety-Behavior Trade-off\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Safety-Behavior Trade-off\"]}],[\"$\",\"span\",\"ALIGN3\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"ALIGN3\"]}],[\"$\",\"span\",\"SPECBENCH\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"SPECBENCH\"]}],[\"$\",\"span\",\"Prompt Engineering\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Prompt Engineering\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-19-MultiEdit_Advancing_Instruction-based_Image_Editing_on_Diverse_and_Challenging_Tasks\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-19-MultiEdit_Advancing_Instruction-based_Image_Editing_on_Diverse_and_Challenging_Tasks/\",\"children\":\"[논문리뷰] MultiEdit: Advancing Instruction-based Image Editing on Diverse and Challenging Tasks\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Xijun Gu이 [arXiv]에 게시한 'MultiEdit: Advancing Instruction-based Image Editing on Diverse and Challenging Tasks' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-19 13:12:21+0900\",\"children\":\"2025년 9월 19일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Instruction-based Image Editing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Instruction-based Image Editing\"]}],[\"$\",\"span\",\"Dataset\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dataset\"]}],[\"$\",\"span\",\"Multi-modal LLM\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-modal LLM\"]}],[\"$\",\"span\",\"Image Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image Generation\"]}],[\"$\",\"span\",\"Style Transfer\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Style Transfer\"]}],[\"$\",\"span\",\"Multi-task Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-task Learning\"]}],[\"$\",\"span\",\"Fine-tuning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Fine-tuning\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-19-Mind_the_Gap_A_Closer_Look_at_Tokenization_for_Multiple-Choice_Question_Answering_with_LLMs\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-19-Mind_the_Gap_A_Closer_Look_at_Tokenization_for_Multiple-Choice_Question_Answering_with_LLMs/\",\"children\":\"[논문리뷰] Mind the Gap: A Closer Look at Tokenization for Multiple-Choice Question Answering with LLMs\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Katharina von der Wense이 [arXiv]에 게시한 'Mind the Gap: A Closer Look at Tokenization for Multiple-Choice Question Answering with LLMs' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-19 13:12:21+0900\",\"children\":\"2025년 9월 19일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLM Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Evaluation\"]}],[\"$\",\"span\",\"Multiple-Choice QA\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multiple-Choice QA\"]}],[\"$\",\"span\",\"Tokenization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Tokenization\"]}],[\"$\",\"span\",\"Prompt Sensitivity\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Prompt Sensitivity\"]}],[\"$\",\"span\",\"Accuracy\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Accuracy\"]}],[\"$\",\"span\",\"Calibration\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Calibration\"]}],[\"$\",\"span\",\"Model Ranking\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Model Ranking\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-19-FSG-Net_Frequency-Spatial_Synergistic_Gated_Network_for_High-Resolution_Remote_Sensing_Change_Detection\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-19-FSG-Net_Frequency-Spatial_Synergistic_Gated_Network_for_High-Resolution_Remote_Sensing_Change_Detection/\",\"children\":\"[논문리뷰] FSG-Net: Frequency-Spatial Synergistic Gated Network for High-Resolution Remote Sensing Change Detection\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Zhewei Zhang이 [arXiv]에 게시한 'FSG-Net: Frequency-Spatial Synergistic Gated Network for High-Resolution Remote Sensing Change Detection' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-19 13:12:21+0900\",\"children\":\"2025년 9월 19일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Change Detection\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Change Detection\"]}],[\"$\",\"span\",\"Remote Sensing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Remote Sensing\"]}],[\"$\",\"span\",\"Frequency-Spatial Analysis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Frequency-Spatial Analysis\"]}],[\"$\",\"span\",\"Wavelet Transform\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Wavelet Transform\"]}],[\"$\",\"span\",\"Attention Mechanism\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Attention Mechanism\"]}],[\"$\",\"span\",\"Gated Fusion\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Gated Fusion\"]}],[\"$\",\"span\",\"Deep Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Deep Learning\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-19-FlowRL_Matching_Reward_Distributions_for_LLM_Reasoning\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-19-FlowRL_Matching_Reward_Distributions_for_LLM_Reasoning/\",\"children\":\"[논문리뷰] FlowRL: Matching Reward Distributions for LLM Reasoning\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Hengli Li이 [arXiv]에 게시한 'FlowRL: Matching Reward Distributions for LLM Reasoning' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-19 13:12:21+0900\",\"children\":\"2025년 9월 19일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Reward Distribution Matching\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reward Distribution Matching\"]}],[\"$\",\"span\",\"GFlowNets\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"GFlowNets\"]}],[\"$\",\"span\",\"Mode Collapse\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Mode Collapse\"]}],[\"$\",\"span\",\"Diverse Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diverse Reasoning\"]}],[\"$\",\"span\",\"Flow-Balanced Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Flow-Balanced Optimization\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-19-FinSearchComp_Towards_a_Realistic_Expert-Level_Evaluation_of_Financial_Search_and_Reasoning\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-19-FinSearchComp_Towards_a_Realistic_Expert-Level_Evaluation_of_Financial_Search_and_Reasoning/\",\"children\":\"[논문리뷰] FinSearchComp: Towards a Realistic, Expert-Level Evaluation of Financial Search and Reasoning\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Jiashuo Liu이 [arXiv]에 게시한 'FinSearchComp: Towards a Realistic, Expert-Level Evaluation of Financial Search and Reasoning' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-19 13:12:21+0900\",\"children\":\"2025년 9월 19일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Financial LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Financial LLMs\"]}],[\"$\",\"span\",\"Agent Benchmarking\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Agent Benchmarking\"]}],[\"$\",\"span\",\"Open-domain Search\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Open-domain Search\"]}],[\"$\",\"span\",\"Financial Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Financial Reasoning\"]}],[\"$\",\"span\",\"Time-Sensitive Data\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Time-Sensitive Data\"]}],[\"$\",\"span\",\"Multi-hop QA\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-hop QA\"]}],[\"$\",\"span\",\"Tool Use\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Tool Use\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-19-Evolving_Language_Models_without_Labels_Majority_Drives_Selection_Novelty_Promotes_Variation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-19-Evolving_Language_Models_without_Labels_Majority_Drives_Selection_Novelty_Promotes_Variation/\",\"children\":\"[논문리뷰] Evolving Language Models without Labels: Majority Drives Selection, Novelty Promotes Variation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Kishan Panaganti이 [arXiv]에 게시한 'Evolving Language Models without Labels: Majority Drives Selection, Novelty Promotes Variation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-19 13:12:21+0900\",\"children\":\"2025년 9월 19일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Label-free Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Label-free Reinforcement Learning\"]}],[\"$\",\"span\",\"LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLMs\"]}],[\"$\",\"span\",\"Self-improvement\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Self-improvement\"]}],[\"$\",\"span\",\"Entropy Collapse\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Entropy Collapse\"]}],[\"$\",\"span\",\"Novelty Reward\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Novelty Reward\"]}],[\"$\",\"span\",\"Test-Time RL\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Test-Time RL\"]}],[\"$\",\"span\",\"GRPO\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"GRPO\"]}],[\"$\",\"span\",\"Evolutionary Computing Principles\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Evolutionary Computing Principles\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-19-EchoVLM_Dynamic_Mixture-of-Experts_Vision-Language_Model_for_Universal_Ultrasound_Intelligence\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-19-EchoVLM_Dynamic_Mixture-of-Experts_Vision-Language_Model_for_Universal_Ultrasound_Intelligence/\",\"children\":\"[논문리뷰] EchoVLM: Dynamic Mixture-of-Experts Vision-Language Model for Universal Ultrasound Intelligence\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Qinghua Huang이 [arXiv]에 게시한 'EchoVLM: Dynamic Mixture-of-Experts Vision-Language Model for Universal Ultrasound Intelligence' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-19 13:12:21+0900\",\"children\":\"2025년 9월 19일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Vision-Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision-Language Models\"]}],[\"$\",\"span\",\"Ultrasound Imaging\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Ultrasound Imaging\"]}],[\"$\",\"span\",\"Medical Diagnosis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Medical Diagnosis\"]}],[\"$\",\"span\",\"Mixture-of-Experts (MoE)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Mixture-of-Experts (MoE)\"]}],[\"$\",\"span\",\"Instruction Tuning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Instruction Tuning\"]}],[\"$\",\"span\",\"Multimodal AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal AI\"]}],[\"$\",\"span\",\"Report Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Report Generation\"]}],[\"$\",\"span\",\"VQA\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"VQA\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-19-AToken_A_Unified_Tokenizer_for_Vision\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-19-AToken_A_Unified_Tokenizer_for_Vision/\",\"children\":\"[논문리뷰] AToken: A Unified Tokenizer for Vision\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Mingze Xu이 [arXiv]에 게시한 'AToken: A Unified Tokenizer for Vision' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-19 13:12:21+0900\",\"children\":\"2025년 9월 19일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Unified Visual Tokenizer\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Unified Visual Tokenizer\"]}],[\"$\",\"span\",\"Multimodal AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal AI\"]}],[\"$\",\"span\",\"Transformer Architecture\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Transformer Architecture\"]}],[\"$\",\"span\",\"4D Representation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"4D Representation\"]}],[\"$\",\"span\",\"Adversarial-free Training\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Adversarial-free Training\"]}],[\"$\",\"span\",\"Reconstruction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reconstruction\"]}],[\"$\",\"span\",\"Semantic Understanding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Semantic Understanding\"]}],[\"$\",\"span\",\"Generative Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generative Models\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-18-Wan-Animate_Unified_Character_Animation_and_Replacement_with_Holistic_Replication\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-18-Wan-Animate_Unified_Character_Animation_and_Replacement_with_Holistic_Replication/\",\"children\":\"[논문리뷰] Wan-Animate: Unified Character Animation and Replacement with Holistic Replication\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Mingyang Huang이 [arXiv]에 게시한 'Wan-Animate: Unified Character Animation and Replacement with Holistic Replication' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-18 13:07:00+0900\",\"children\":\"2025년 9월 18일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Character Animation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Character Animation\"]}],[\"$\",\"span\",\"Video Replacement\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video Replacement\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}],[\"$\",\"span\",\"Transformer\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Transformer\"]}],[\"$\",\"span\",\"DiT\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"DiT\"]}],[\"$\",\"span\",\"Relighting LoRA\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Relighting LoRA\"]}],[\"$\",\"span\",\"Holistic Replication\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Holistic Replication\"]}],[\"$\",\"span\",\"Open-Source\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Open-Source\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-18-THOR_Tool-Integrated_Hierarchical_Optimization_via_RL_for_Mathematical_Reasoning\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-18-THOR_Tool-Integrated_Hierarchical_Optimization_via_RL_for_Mathematical_Reasoning/\",\"children\":\"[논문리뷰] THOR: Tool-Integrated Hierarchical Optimization via RL for Mathematical Reasoning\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yicheng Pan이 [arXiv]에 게시한 'THOR: Tool-Integrated Hierarchical Optimization via RL for Mathematical Reasoning' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-18 13:07:00+0900\",\"children\":\"2025년 9월 18일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Mathematical Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Mathematical Reasoning\"]}],[\"$\",\"span\",\"Tool-Integrated Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Tool-Integrated Reasoning\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Hierarchical Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Hierarchical Optimization\"]}],[\"$\",\"span\",\"Self-Correction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Self-Correction\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Code Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Code Generation\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-18-SteeringControl_Holistic_Evaluation_of_Alignment_Steering_in_LLMs\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-18-SteeringControl_Holistic_Evaluation_of_Alignment_Steering_in_LLMs/\",\"children\":\"[논문리뷰] SteeringControl: Holistic Evaluation of Alignment Steering in LLMs\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Zhun Wang이 [arXiv]에 게시한 'SteeringControl: Holistic Evaluation of Alignment Steering in LLMs' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-18 13:07:00+0900\",\"children\":\"2025년 9월 18일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLM Alignment\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Alignment\"]}],[\"$\",\"span\",\"Representation Steering\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Representation Steering\"]}],[\"$\",\"span\",\"Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmark\"]}],[\"$\",\"span\",\"Behavioral Entanglement\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Behavioral Entanglement\"]}],[\"$\",\"span\",\"Bias Mitigation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Bias Mitigation\"]}],[\"$\",\"span\",\"Harmful Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Harmful Generation\"]}],[\"$\",\"span\",\"Hallucination Control\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Hallucination Control\"]}],[\"$\",\"span\",\"Modular Framework\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Modular Framework\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-18-Scrub_It_Out_Erasing_Sensitive_Memorization_in_Code_Language_Models_via_Machine_Unlearning\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-18-Scrub_It_Out_Erasing_Sensitive_Memorization_in_Code_Language_Models_via_Machine_Unlearning/\",\"children\":\"[논문리뷰] Scrub It Out! Erasing Sensitive Memorization in Code Language Models via Machine Unlearning\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Zhou Yang이 [arXiv]에 게시한 'Scrub It Out! Erasing Sensitive Memorization in Code Language Models via Machine Unlearning' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-18 13:07:00+0900\",\"children\":\"2025년 9월 18일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Code Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Code Language Models\"]}],[\"$\",\"span\",\"Machine Unlearning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Machine Unlearning\"]}],[\"$\",\"span\",\"Sensitive Memorization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Sensitive Memorization\"]}],[\"$\",\"span\",\"Privacy\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Privacy\"]}],[\"$\",\"span\",\"Gradient Ascent\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Gradient Ascent\"]}],[\"$\",\"span\",\"Model Utility\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Model Utility\"]}],[\"$\",\"span\",\"Code Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Code Generation\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-18-SAIL-VL2_Technical_Report\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-18-SAIL-VL2_Technical_Report/\",\"children\":\"[논문리뷰] SAIL-VL2 Technical Report\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Zijian Kang이 [arXiv]에 게시한 'SAIL-VL2 Technical Report' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-18 13:07:00+0900\",\"children\":\"2025년 9월 18일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Vision-Language Model\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision-Language Model\"]}],[\"$\",\"span\",\"Multimodal Understanding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Understanding\"]}],[\"$\",\"span\",\"Mixture-of-Experts\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Mixture-of-Experts\"]}],[\"$\",\"span\",\"Progressive Training\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Progressive Training\"]}],[\"$\",\"span\",\"Data Curation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Curation\"]}],[\"$\",\"span\",\"Supervised Fine-tuning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Supervised Fine-tuning\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"SAIL-ViT\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"SAIL-ViT\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-18-PANORAMA_The_Rise_of_Omnidirectional_Vision_in_the_Embodied_AI_Era\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-18-PANORAMA_The_Rise_of_Omnidirectional_Vision_in_the_Embodied_AI_Era/\",\"children\":\"[논문리뷰] PANORAMA: The Rise of Omnidirectional Vision in the Embodied AI Era\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Zihao Dongfang이 [arXiv]에 게시한 'PANORAMA: The Rise of Omnidirectional Vision in the Embodied AI Era' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-18 13:07:00+0900\",\"children\":\"2025년 9월 18일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Omnidirectional Vision\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Omnidirectional Vision\"]}],[\"$\",\"span\",\"Embodied AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Embodied AI\"]}],[\"$\",\"span\",\"Panoramic Perception\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Panoramic Perception\"]}],[\"$\",\"span\",\"Multi-modal Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-modal Learning\"]}],[\"$\",\"span\",\"Dataset Development\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dataset Development\"]}],[\"$\",\"span\",\"Robot Navigation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Robot Navigation\"]}],[\"$\",\"span\",\"Spatial Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Spatial Reasoning\"]}],[\"$\",\"span\",\"System Architecture\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"System Architecture\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-18-MARS2_2025_Challenge_on_Multimodal_Reasoning_Datasets_Methods_Results_Discussion_and_Outlook\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-18-MARS2_2025_Challenge_on_Multimodal_Reasoning_Datasets_Methods_Results_Discussion_and_Outlook/\",\"children\":\"[논문리뷰] MARS2 2025 Challenge on Multimodal Reasoning: Datasets, Methods, Results, Discussion, and Outlook\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Bowen Zhou이 [arXiv]에 게시한 'MARS2 2025 Challenge on Multimodal Reasoning: Datasets, Methods, Results, Discussion, and Outlook' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-18 13:07:00+0900\",\"children\":\"2025년 9월 18일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Multimodal Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Reasoning\"]}],[\"$\",\"span\",\"Large Language Models (LLMs)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models (LLMs)\"]}],[\"$\",\"span\",\"Multimodal Large Language Models (MLLMs)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Large Language Models (MLLMs)\"]}],[\"$\",\"span\",\"Visual Grounding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Visual Grounding\"]}],[\"$\",\"span\",\"Visual Question Answering\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Visual Question Answering\"]}],[\"$\",\"span\",\"Advertisement Video Analysis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Advertisement Video Analysis\"]}],[\"$\",\"span\",\"Real-world Scenarios\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Real-world Scenarios\"]}],[\"$\",\"span\",\"Challenge Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Challenge Benchmark\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-18-Improving_Context_Fidelity_via_Native_Retrieval-Augmented_Reasoning\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-18-Improving_Context_Fidelity_via_Native_Retrieval-Augmented_Reasoning/\",\"children\":\"[논문리뷰] Improving Context Fidelity via Native Retrieval-Augmented Reasoning\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Xiangru Tang이 [arXiv]에 게시한 'Improving Context Fidelity via Native Retrieval-Augmented Reasoning' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-18 13:07:00+0900\",\"children\":\"2025년 9월 18일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Context Fidelity\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Context Fidelity\"]}],[\"$\",\"span\",\"Retrieval-Augmented Generation (RAG)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Retrieval-Augmented Generation (RAG)\"]}],[\"$\",\"span\",\"Large Language Models (LLMs)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models (LLMs)\"]}],[\"$\",\"span\",\"Reinforcement Learning (RL)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning (RL)\"]}],[\"$\",\"span\",\"Supervised Fine-Tuning (SFT)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Supervised Fine-Tuning (SFT)\"]}],[\"$\",\"span\",\"Hallucination\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Hallucination\"]}],[\"$\",\"span\",\"Question Answering\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Question Answering\"]}],[\"$\",\"span\",\"In-context Retrieval\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"In-context Retrieval\"]}],[\"$\",\"span\",\"Curriculum Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Curriculum Learning\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-18-Hala_Technical_Report_Building_Arabic-Centric_Instruction_Translation_Models_at_Scale\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-18-Hala_Technical_Report_Building_Arabic-Centric_Instruction_Translation_Models_at_Scale/\",\"children\":\"[논문리뷰] Hala Technical Report: Building Arabic-Centric Instruction \u0026 Translation Models at Scale\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Bernard Ghanem이 [arXiv]에 게시한 'Hala Technical Report: Building Arabic-Centric Instruction \u0026 Translation Models at Scale' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-18 13:07:00+0900\",\"children\":\"2025년 9월 18일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Arabic NLP\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Arabic NLP\"]}],[\"$\",\"span\",\"Instruction Tuning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Instruction Tuning\"]}],[\"$\",\"span\",\"Machine Translation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Machine Translation\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"FP8 Quantization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"FP8 Quantization\"]}],[\"$\",\"span\",\"Data Bootstrapping\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Bootstrapping\"]}],[\"$\",\"span\",\"Model Merging\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Model Merging\"]}],[\"$\",\"span\",\"Language-Centric AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Language-Centric AI\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-18-GenExam_A_Multidisciplinary_Text-to-Image_Exam\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-18-GenExam_A_Multidisciplinary_Text-to-Image_Exam/\",\"children\":\"[논문리뷰] GenExam: A Multidisciplinary Text-to-Image Exam\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yu Qiao이 [arXiv]에 게시한 'GenExam: A Multidisciplinary Text-to-Image Exam' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-18 13:07:00+0900\",\"children\":\"2025년 9월 18일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Text-to-Image Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Text-to-Image Generation\"]}],[\"$\",\"span\",\"Multidisciplinary\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multidisciplinary\"]}],[\"$\",\"span\",\"Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmark\"]}],[\"$\",\"span\",\"Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Evaluation\"]}],[\"$\",\"span\",\"AGI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"AGI\"]}],[\"$\",\"span\",\"Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reasoning\"]}],[\"$\",\"span\",\"Scoring System\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Scoring System\"]}],[\"$\",\"span\",\"Visual Question Answering\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Visual Question Answering\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-17-WebWeaver_Structuring_Web-Scale_Evidence_with_Dynamic_Outlines_for_Open-Ended_Deep_Research\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-17-WebWeaver_Structuring_Web-Scale_Evidence_with_Dynamic_Outlines_for_Open-Ended_Deep_Research/\",\"children\":\"[논문리뷰] WebWeaver: Structuring Web-Scale Evidence with Dynamic Outlines for Open-Ended Deep Research\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Houquan Zhou이 [arXiv]에 게시한 'WebWeaver: Structuring Web-Scale Evidence with Dynamic Outlines for Open-Ended Deep Research' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-17 13:16:01+0900\",\"children\":\"2025년 9월 17일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Open-Ended Deep Research\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Open-Ended Deep Research\"]}],[\"$\",\"span\",\"LLM Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Agents\"]}],[\"$\",\"span\",\"Dynamic Outline\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dynamic Outline\"]}],[\"$\",\"span\",\"Evidence Acquisition\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Evidence Acquisition\"]}],[\"$\",\"span\",\"Hierarchical Writing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Hierarchical Writing\"]}],[\"$\",\"span\",\"Memory Bank\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Memory Bank\"]}],[\"$\",\"span\",\"State-of-the-Art\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"State-of-the-Art\"]}],[\"$\",\"span\",\"Supervised Fine-Tuning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Supervised Fine-Tuning\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-17-WebSailor-V2_Bridging_the_Chasm_to_Proprietary_Agents_via_Synthetic_Data_and_Scalable_Reinforcement_Learning\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-17-WebSailor-V2_Bridging_the_Chasm_to_Proprietary_Agents_via_Synthetic_Data_and_Scalable_Reinforcement_Learning/\",\"children\":\"[논문리뷰] WebSailor-V2: Bridging the Chasm to Proprietary Agents via Synthetic Data and Scalable Reinforcement Learning\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Huifeng Yin이 [arXiv]에 게시한 'WebSailor-V2: Bridging the Chasm to Proprietary Agents via Synthetic Data and Scalable Reinforcement Learning' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-17 13:16:01+0900\",\"children\":\"2025년 9월 17일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Web Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Web Agents\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Synthetic Data\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Synthetic Data\"]}],[\"$\",\"span\",\"Knowledge Graphs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Knowledge Graphs\"]}],[\"$\",\"span\",\"LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLMs\"]}],[\"$\",\"span\",\"Supervised Fine-Tuning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Supervised Fine-Tuning\"]}],[\"$\",\"span\",\"Sim-to-Real Transfer\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Sim-to-Real Transfer\"]}],[\"$\",\"span\",\"Agentic AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Agentic AI\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-17-WebResearcher_Unleashing_unbounded_reasoning_capability_in_Long-Horizon_Agents\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-17-WebResearcher_Unleashing_unbounded_reasoning_capability_in_Long-Horizon_Agents/\",\"children\":\"[논문리뷰] WebResearcher: Unleashing unbounded reasoning capability in Long-Horizon Agents\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Wenbiao Yin이 [arXiv]에 게시한 'WebResearcher: Unleashing unbounded reasoning capability in Long-Horizon Agents' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-17 13:16:01+0900\",\"children\":\"2025년 9월 17일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Agentic AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Agentic AI\"]}],[\"$\",\"span\",\"Deep Research\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Deep Research\"]}],[\"$\",\"span\",\"Iterative Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Iterative Reasoning\"]}],[\"$\",\"span\",\"Long-Horizon Tasks\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Long-Horizon Tasks\"]}],[\"$\",\"span\",\"Context Management\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Context Management\"]}],[\"$\",\"span\",\"Data Synthesis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Synthesis\"]}],[\"$\",\"span\",\"Tool-Augmented LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Tool-Augmented LLMs\"]}],[\"$\",\"span\",\"Markov Decision Process\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Markov Decision Process\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-17-Towards_General_Agentic_Intelligence_via_Environment_Scaling\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-17-Towards_General_Agentic_Intelligence_via_Environment_Scaling/\",\"children\":\"[논문리뷰] Towards General Agentic Intelligence via Environment Scaling\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Guangyu Li이 [arXiv]에 게시한 'Towards General Agentic Intelligence via Environment Scaling' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-17 13:16:01+0900\",\"children\":\"2025년 9월 17일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Agentic AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Agentic AI\"]}],[\"$\",\"span\",\"Environment Scaling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Environment Scaling\"]}],[\"$\",\"span\",\"Function Calling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Function Calling\"]}],[\"$\",\"span\",\"Tool Use\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Tool Use\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Synthetic Data Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Synthetic Data Generation\"]}],[\"$\",\"span\",\"Supervised Fine-tuning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Supervised Fine-tuning\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-17-Single-stream_Policy_Optimization\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-17-Single-stream_Policy_Optimization/\",\"children\":\"[논문리뷰] Single-stream Policy Optimization\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Zihan Ding이 [arXiv]에 게시한 'Single-stream Policy Optimization' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-17 13:16:01+0900\",\"children\":\"2025년 9월 17일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"LLM Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Optimization\"]}],[\"$\",\"span\",\"Policy Gradient\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Policy Gradient\"]}],[\"$\",\"span\",\"Variance Reduction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Variance Reduction\"]}],[\"$\",\"span\",\"Adaptive Sampling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Adaptive Sampling\"]}],[\"$\",\"span\",\"Scalability\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Scalability\"]}],[\"$\",\"span\",\"Agentic Systems\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Agentic Systems\"]}],[\"$\",\"span\",\"RLVR\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"RLVR\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-17-Scaling_Agents_via_Continual_Pre-training\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-17-Scaling_Agents_via_Continual_Pre-training/\",\"children\":\"[논문리뷰] Scaling Agents via Continual Pre-training\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Guangyu Li이 [arXiv]에 게시한 'Scaling Agents via Continual Pre-training' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-17 13:16:01+0900\",\"children\":\"2025년 9월 17일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Agentic LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Agentic LLMs\"]}],[\"$\",\"span\",\"Continual Pre-training\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Continual Pre-training\"]}],[\"$\",\"span\",\"Deep Research Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Deep Research Agents\"]}],[\"$\",\"span\",\"Tool Use\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Tool Use\"]}],[\"$\",\"span\",\"Multi-step Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-step Reasoning\"]}],[\"$\",\"span\",\"Data Synthesis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Synthesis\"]}],[\"$\",\"span\",\"Scaling Laws\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Scaling Laws\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-17-ReSum_Unlocking_Long-Horizon_Search_Intelligence_via_Context_Summarization\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-17-ReSum_Unlocking_Long-Horizon_Search_Intelligence_via_Context_Summarization/\",\"children\":\"[논문리뷰] ReSum: Unlocking Long-Horizon Search Intelligence via Context Summarization\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Litu Ou이 [arXiv]에 게시한 'ReSum: Unlocking Long-Horizon Search Intelligence via Context Summarization' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-17 13:16:01+0900\",\"children\":\"2025년 9월 17일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLM Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Agents\"]}],[\"$\",\"span\",\"Context Management\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Context Management\"]}],[\"$\",\"span\",\"Summarization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Summarization\"]}],[\"$\",\"span\",\"ReAct\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"ReAct\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Web Search\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Web Search\"]}],[\"$\",\"span\",\"Long-Horizon Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Long-Horizon Reasoning\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-17-Optimal_Brain_Restoration_for_Joint_Quantization_and_Sparsification_of_LLMs\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-17-Optimal_Brain_Restoration_for_Joint_Quantization_and_Sparsification_of_LLMs/\",\"children\":\"[논문리뷰] Optimal Brain Restoration for Joint Quantization and Sparsification of LLMs\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Luca Benini이 [arXiv]에 게시한 'Optimal Brain Restoration for Joint Quantization and Sparsification of LLMs' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-17 13:16:01+0900\",\"children\":\"2025년 9월 17일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLM Compression\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Compression\"]}],[\"$\",\"span\",\"Quantization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Quantization\"]}],[\"$\",\"span\",\"Sparsification\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Sparsification\"]}],[\"$\",\"span\",\"Post-training Quantization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Post-training Quantization\"]}],[\"$\",\"span\",\"Hessian-based Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Hessian-based Optimization\"]}],[\"$\",\"span\",\"Error Compensation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Error Compensation\"]}],[\"$\",\"span\",\"Low-bit LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Low-bit LLMs\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-17-Multiple_Instance_Learning_Framework_with_Masked_Hard_Instance_Mining_for_Gigapixel_Histopathology_Image_Analysis\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-17-Multiple_Instance_Learning_Framework_with_Masked_Hard_Instance_Mining_for_Gigapixel_Histopathology_Image_Analysis/\",\"children\":\"[논문리뷰] Multiple Instance Learning Framework with Masked Hard Instance Mining for Gigapixel Histopathology Image Analysis\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Bo Liu이 [arXiv]에 게시한 'Multiple Instance Learning Framework with Masked Hard Instance Mining for Gigapixel Histopathology Image Analysis' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-17 13:16:01+0900\",\"children\":\"2025년 9월 17일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Multiple Instance Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multiple Instance Learning\"]}],[\"$\",\"span\",\"Hard Instance Mining\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Hard Instance Mining\"]}],[\"$\",\"span\",\"Computational Pathology\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Computational Pathology\"]}],[\"$\",\"span\",\"Whole Slide Images\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Whole Slide Images\"]}],[\"$\",\"span\",\"Masked Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Masked Learning\"]}],[\"$\",\"span\",\"Siamese Network\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Siamese Network\"]}],[\"$\",\"span\",\"Medical Image Analysis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Medical Image Analysis\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-17-Multimodal_Reasoning_for_Science_Technical_Report_and_1st_Place_Solution_to_the_ICML_2025_SeePhys_Challenge\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-17-Multimodal_Reasoning_for_Science_Technical_Report_and_1st_Place_Solution_to_the_ICML_2025_SeePhys_Challenge/\",\"children\":\"[논문리뷰] Multimodal Reasoning for Science: Technical Report and 1st Place Solution to the ICML 2025 SeePhys Challenge\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Wentao Zhang이 [arXiv]에 게시한 'Multimodal Reasoning for Science: Technical Report and 1st Place Solution to the ICML 2025 SeePhys Challenge' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-17 13:16:01+0900\",\"children\":\"2025년 9월 17일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Multimodal Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Reasoning\"]}],[\"$\",\"span\",\"Science AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Science AI\"]}],[\"$\",\"span\",\"Caption-assisted Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Caption-assisted Reasoning\"]}],[\"$\",\"span\",\"SeePhys Challenge\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"SeePhys Challenge\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Visual Question Answering\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Visual Question Answering\"]}],[\"$\",\"span\",\"Physics Problems\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Physics Problems\"]}],[\"$\",\"span\",\"Cross-modal Alignment\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Cross-modal Alignment\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-17-Hunyuan3D_Studio_End-to-End_AI_Pipeline_for_Game-Ready_3D_Asset_Generation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-17-Hunyuan3D_Studio_End-to-End_AI_Pipeline_for_Game-Ready_3D_Asset_Generation/\",\"children\":\"[논문리뷰] Hunyuan3D Studio: End-to-End AI Pipeline for Game-Ready 3D Asset Generation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Lixin Xu이 [arXiv]에 게시한 'Hunyuan3D Studio: End-to-End AI Pipeline for Game-Ready 3D Asset Generation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-17 13:16:01+0900\",\"children\":\"2025년 9월 17일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"3D Asset Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D Asset Generation\"]}],[\"$\",\"span\",\"AI Pipeline\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"AI Pipeline\"]}],[\"$\",\"span\",\"Generative AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generative AI\"]}],[\"$\",\"span\",\"Game Development\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Game Development\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}],[\"$\",\"span\",\"Neural Modules\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Neural Modules\"]}],[\"$\",\"span\",\"Retopology\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Retopology\"]}],[\"$\",\"span\",\"UV Unwrapping\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"UV Unwrapping\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-17-Exact_Coset_Sampling_for_Quantum_Lattice_Algorithms\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-17-Exact_Coset_Sampling_for_Quantum_Lattice_Algorithms/\",\"children\":\"[논문리뷰] Exact Coset Sampling for Quantum Lattice Algorithms\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yifan Zhang이 [arXiv]에 게시한 'Exact Coset Sampling for Quantum Lattice Algorithms' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-17 13:16:01+0900\",\"children\":\"2025년 9월 17일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Quantum Algorithms\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Quantum Algorithms\"]}],[\"$\",\"span\",\"Lattice Problems\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Lattice Problems\"]}],[\"$\",\"span\",\"Coset Sampling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Coset Sampling\"]}],[\"$\",\"span\",\"Quantum Fourier Transform (QFT)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Quantum Fourier Transform (QFT)\"]}],[\"$\",\"span\",\"Modular Arithmetic\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Modular Arithmetic\"]}],[\"$\",\"span\",\"Quantum Cryptography\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Quantum Cryptography\"]}],[\"$\",\"span\",\"Exact Sampling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Exact Sampling\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-17-EconProver_Towards_More_Economical_Test-Time_Scaling_for_Automated_Theorem_Proving\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-17-EconProver_Towards_More_Economical_Test-Time_Scaling_for_Automated_Theorem_Proving/\",\"children\":\"[논문리뷰] EconProver: Towards More Economical Test-Time Scaling for Automated Theorem Proving\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Shansan Gong이 [arXiv]에 게시한 'EconProver: Towards More Economical Test-Time Scaling for Automated Theorem Proving' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-17 13:16:01+0900\",\"children\":\"2025년 9월 17일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Automated Theorem Proving\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Automated Theorem Proving\"]}],[\"$\",\"span\",\"LLM\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM\"]}],[\"$\",\"span\",\"Test-Time Scaling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Test-Time Scaling\"]}],[\"$\",\"span\",\"Chain-of-Thought\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Chain-of-Thought\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Efficiency Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Efficiency Optimization\"]}],[\"$\",\"span\",\"Token Cost\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Token Cost\"]}],[\"$\",\"span\",\"Sampling Cost\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Sampling Cost\"]}],[\"$\",\"span\",\"Dynamic CoT Switching\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dynamic CoT Switching\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-17-3D_Aware_Region_Prompted_Vision_Language_Model\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-17-3D_Aware_Region_Prompted_Vision_Language_Model/\",\"children\":\"[논문리뷰] 3D Aware Region Prompted Vision Language Model\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Xiaolong Li이 [arXiv]에 게시한 '3D Aware Region Prompted Vision Language Model' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-17 13:16:01+0900\",\"children\":\"2025년 9월 17일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"3D Vision\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D Vision\"]}],[\"$\",\"span\",\"Vision-Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision-Language Models\"]}],[\"$\",\"span\",\"Spatial Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Spatial Reasoning\"]}],[\"$\",\"span\",\"Region Prompting\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Region Prompting\"]}],[\"$\",\"span\",\"Multi-view Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-view Learning\"]}],[\"$\",\"span\",\"Depth Estimation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Depth Estimation\"]}],[\"$\",\"span\",\"Unified Representation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Unified Representation\"]}],[\"$\",\"span\",\"Generative AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generative AI\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-16-UI-S1_Advancing_GUI_Automation_via_Semi-online_Reinforcement_Learning\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-16-UI-S1_Advancing_GUI_Automation_via_Semi-online_Reinforcement_Learning/\",\"children\":\"[논문리뷰] UI-S1: Advancing GUI Automation via Semi-online Reinforcement Learning\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yongliang Shen이 [arXiv]에 게시한 'UI-S1: Advancing GUI Automation via Semi-online Reinforcement Learning' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-16 13:16:41+0900\",\"children\":\"2025년 9월 16일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"GUI Automation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"GUI Automation\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Semi-online RL\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Semi-online RL\"]}],[\"$\",\"span\",\"Offline RL\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Offline RL\"]}],[\"$\",\"span\",\"Online RL\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Online RL\"]}],[\"$\",\"span\",\"Patch Module\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Patch Module\"]}],[\"$\",\"span\",\"Multi-turn Interaction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-turn Interaction\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-16-SearchInstruct_Enhancing_Domain_Adaptation_via_Retrieval-Based_Instruction_Dataset_Creation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-16-SearchInstruct_Enhancing_Domain_Adaptation_via_Retrieval-Based_Instruction_Dataset_Creation/\",\"children\":\"[논문리뷰] SearchInstruct: Enhancing Domain Adaptation via Retrieval-Based Instruction Dataset Creation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Heshaam Faili이 [arXiv]에 게시한 'SearchInstruct: Enhancing Domain Adaptation via Retrieval-Based Instruction Dataset Creation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-16 13:16:41+0900\",\"children\":\"2025년 9월 16일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLM\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM\"]}],[\"$\",\"span\",\"Instruction Tuning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Instruction Tuning\"]}],[\"$\",\"span\",\"Domain Adaptation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Domain Adaptation\"]}],[\"$\",\"span\",\"Retrieval-Augmented Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Retrieval-Augmented Generation\"]}],[\"$\",\"span\",\"Dataset Creation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dataset Creation\"]}],[\"$\",\"span\",\"Model Editing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Model Editing\"]}],[\"$\",\"span\",\"Supervised Fine-Tuning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Supervised Fine-Tuning\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-16-PersonaX_Multimodal_Datasets_with_LLM-Inferred_Behavior_Traits\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-16-PersonaX_Multimodal_Datasets_with_LLM-Inferred_Behavior_Traits/\",\"children\":\"[논문리뷰] PersonaX: Multimodal Datasets with LLM-Inferred Behavior Traits\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Zhenhao Chen이 [arXiv]에 게시한 'PersonaX: Multimodal Datasets with LLM-Inferred Behavior Traits' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-16 13:16:41+0900\",\"children\":\"2025년 9월 16일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Multimodal Dataset\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Dataset\"]}],[\"$\",\"span\",\"LLM Inference\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Inference\"]}],[\"$\",\"span\",\"Behavioral Traits\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Behavioral Traits\"]}],[\"$\",\"span\",\"Causal Representation Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Causal Representation Learning\"]}],[\"$\",\"span\",\"Big Five\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Big Five\"]}],[\"$\",\"span\",\"Multimodal AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal AI\"]}],[\"$\",\"span\",\"Causal Discovery\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Causal Discovery\"]}],[\"$\",\"span\",\"Human-Computer Interaction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Human-Computer Interaction\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-16-OmniWorld_A_Multi-Domain_and_Multi-Modal_Dataset_for_4D_World_Modeling\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-16-OmniWorld_A_Multi-Domain_and_Multi-Modal_Dataset_for_4D_World_Modeling/\",\"children\":\"[논문리뷰] OmniWorld: A Multi-Domain and Multi-Modal Dataset for 4D World Modeling\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yang Zhou이 [arXiv]에 게시한 'OmniWorld: A Multi-Domain and Multi-Modal Dataset for 4D World Modeling' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-16 13:16:41+0900\",\"children\":\"2025년 9월 16일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"4D World Modeling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"4D World Modeling\"]}],[\"$\",\"span\",\"Multi-Modal Dataset\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-Modal Dataset\"]}],[\"$\",\"span\",\"Multi-Domain Data\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-Domain Data\"]}],[\"$\",\"span\",\"Geometric Foundation Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Geometric Foundation Models\"]}],[\"$\",\"span\",\"Video Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video Generation\"]}],[\"$\",\"span\",\"Spatio-Temporal Data\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Spatio-Temporal Data\"]}],[\"$\",\"span\",\"Dataset Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dataset Benchmark\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-16-Measuring_Epistemic_Humility_in_Multimodal_Large_Language_Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-16-Measuring_Epistemic_Humility_in_Multimodal_Large_Language_Models/\",\"children\":\"[논문리뷰] Measuring Epistemic Humility in Multimodal Large Language Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Kaiyang Zhou이 [arXiv]에 게시한 'Measuring Epistemic Humility in Multimodal Large Language Models' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-16 13:16:41+0900\",\"children\":\"2025년 9월 16일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Multimodal Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Large Language Models\"]}],[\"$\",\"span\",\"Hallucination\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Hallucination\"]}],[\"$\",\"span\",\"Epistemic Humility\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Epistemic Humility\"]}],[\"$\",\"span\",\"Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmark\"]}],[\"$\",\"span\",\"False-Option Rejection\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"False-Option Rejection\"]}],[\"$\",\"span\",\"Visual Question Answering\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Visual Question Answering\"]}],[\"$\",\"span\",\"Scene Graph\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Scene Graph\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-16-Lost_in_Embeddings_Information_Loss_in_Vision-Language_Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-16-Lost_in_Embeddings_Information_Loss_in_Vision-Language_Models/\",\"children\":\"[논문리뷰] Lost in Embeddings: Information Loss in Vision-Language Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Ivan Vulić이 [arXiv]에 게시한 'Lost in Embeddings: Information Loss in Vision-Language Models' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-16 13:16:41+0900\",\"children\":\"2025년 9월 16일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Vision-Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision-Language Models\"]}],[\"$\",\"span\",\"Information Loss\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Information Loss\"]}],[\"$\",\"span\",\"Embeddings\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Embeddings\"]}],[\"$\",\"span\",\"Connectors\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Connectors\"]}],[\"$\",\"span\",\"k-NN Overlap Ratio\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"k-NN Overlap Ratio\"]}],[\"$\",\"span\",\"Embedding Reconstruction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Embedding Reconstruction\"]}],[\"$\",\"span\",\"Multimodal AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal AI\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-16-Look_Again_Think_Slowly_Enhancing_Visual_Reflection_in_Vision-Language_Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-16-Look_Again_Think_Slowly_Enhancing_Visual_Reflection_in_Vision-Language_Models/\",\"children\":\"[논문리뷰] Look Again, Think Slowly: Enhancing Visual Reflection in Vision-Language Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Shuo Ren이 [arXiv]에 게시한 'Look Again, Think Slowly: Enhancing Visual Reflection in Vision-Language Models' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-16 13:16:41+0900\",\"children\":\"2025년 9월 16일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Vision-Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision-Language Models\"]}],[\"$\",\"span\",\"Visual Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Visual Reasoning\"]}],[\"$\",\"span\",\"Reflection\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reflection\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Visual Attention\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Visual Attention\"]}],[\"$\",\"span\",\"Slow Thinking\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Slow Thinking\"]}],[\"$\",\"span\",\"Multimodal Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Agents\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-16-Locality_in_Image_Diffusion_Models_Emerges_from_Data_Statistics\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-16-Locality_in_Image_Diffusion_Models_Emerges_from_Data_Statistics/\",\"children\":\"[논문리뷰] Locality in Image Diffusion Models Emerges from Data Statistics\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Vincent Sitzmann이 [arXiv]에 게시한 'Locality in Image Diffusion Models Emerges from Data Statistics' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-16 13:16:41+0900\",\"children\":\"2025년 9월 16일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}],[\"$\",\"span\",\"Locality\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Locality\"]}],[\"$\",\"span\",\"Data Statistics\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Statistics\"]}],[\"$\",\"span\",\"Optimal Denoiser\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Optimal Denoiser\"]}],[\"$\",\"span\",\"Wiener Filter\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Wiener Filter\"]}],[\"$\",\"span\",\"Sensitivity Fields\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Sensitivity Fields\"]}],[\"$\",\"span\",\"Generative Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generative Models\"]}],[\"$\",\"span\",\"Inductive Bias\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Inductive Bias\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-16-Learning_to_Optimize_Multi-Objective_Alignment_Through_Dynamic_Reward_Weighting\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-16-Learning_to_Optimize_Multi-Objective_Alignment_Through_Dynamic_Reward_Weighting/\",\"children\":\"[논문리뷰] Learning to Optimize Multi-Objective Alignment Through Dynamic Reward Weighting\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Changlong Yu이 [arXiv]에 게시한 'Learning to Optimize Multi-Objective Alignment Through Dynamic Reward Weighting' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-16 13:16:41+0900\",\"children\":\"2025년 9월 16일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Multi-objective Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-objective Reinforcement Learning\"]}],[\"$\",\"span\",\"LLM Alignment\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Alignment\"]}],[\"$\",\"span\",\"Dynamic Reward Weighting\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dynamic Reward Weighting\"]}],[\"$\",\"span\",\"Pareto Front Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Pareto Front Optimization\"]}],[\"$\",\"span\",\"Hypervolume Indicator\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Hypervolume Indicator\"]}],[\"$\",\"span\",\"Gradient-based Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Gradient-based Optimization\"]}],[\"$\",\"span\",\"Online RL\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Online RL\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-16-LazyDrag_Enabling_Stable_Drag-Based_Editing_on_Multi-Modal_Diffusion_Transformers_via_Explicit_Correspondence\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-16-LazyDrag_Enabling_Stable_Drag-Based_Editing_on_Multi-Modal_Diffusion_Transformers_via_Explicit_Correspondence/\",\"children\":\"[논문리뷰] LazyDrag: Enabling Stable Drag-Based Editing on Multi-Modal Diffusion Transformers via Explicit Correspondence\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Lionel M. Ni이 [arXiv]에 게시한 'LazyDrag: Enabling Stable Drag-Based Editing on Multi-Modal Diffusion Transformers via Explicit Correspondence' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-16 13:16:41+0900\",\"children\":\"2025년 9월 16일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Image Editing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image Editing\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}],[\"$\",\"span\",\"Multi-Modal Transformers\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-Modal Transformers\"]}],[\"$\",\"span\",\"Drag-based Editing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Drag-based Editing\"]}],[\"$\",\"span\",\"Explicit Correspondence\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Explicit Correspondence\"]}],[\"$\",\"span\",\"Attention Control\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Attention Control\"]}],[\"$\",\"span\",\"Identity Preservation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Identity Preservation\"]}],[\"$\",\"span\",\"Training-Free\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Training-Free\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-16-InternScenes_A_Large-scale_Simulatable_Indoor_Scene_Dataset_with_Realistic_Layouts\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-16-InternScenes_A_Large-scale_Simulatable_Indoor_Scene_Dataset_with_Realistic_Layouts/\",\"children\":\"[논문리뷰] InternScenes: A Large-scale Simulatable Indoor Scene Dataset with Realistic Layouts\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Wenzhe Cai이 [arXiv]에 게시한 'InternScenes: A Large-scale Simulatable Indoor Scene Dataset with Realistic Layouts' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-16 13:16:41+0900\",\"children\":\"2025년 9월 16일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Embodied AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Embodied AI\"]}],[\"$\",\"span\",\"3D Scene Dataset\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D Scene Dataset\"]}],[\"$\",\"span\",\"Simulation Environment\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Simulation Environment\"]}],[\"$\",\"span\",\"Scene Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Scene Generation\"]}],[\"$\",\"span\",\"Point-Goal Navigation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Point-Goal Navigation\"]}],[\"$\",\"span\",\"Realistic Layouts\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Realistic Layouts\"]}],[\"$\",\"span\",\"Object Interaction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Object Interaction\"]}],[\"$\",\"span\",\"Real-to-Sim\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Real-to-Sim\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-16-GAPrune_Gradient-Alignment_Pruning_for_Domain-Aware_Embeddings\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-16-GAPrune_Gradient-Alignment_Pruning_for_Domain-Aware_Embeddings/\",\"children\":\"[논문리뷰] GAPrune: Gradient-Alignment Pruning for Domain-Aware Embeddings\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yixuan Tang이 [arXiv]에 게시한 'GAPrune: Gradient-Alignment Pruning for Domain-Aware Embeddings' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-16 13:16:41+0900\",\"children\":\"2025년 9월 16일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Model Pruning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Model Pruning\"]}],[\"$\",\"span\",\"Domain Adaptation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Domain Adaptation\"]}],[\"$\",\"span\",\"Embedding Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Embedding Models\"]}],[\"$\",\"span\",\"Gradient Alignment\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Gradient Alignment\"]}],[\"$\",\"span\",\"Fisher Information\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Fisher Information\"]}],[\"$\",\"span\",\"Model Compression\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Model Compression\"]}],[\"$\",\"span\",\"LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLMs\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-16-EthicsMH_A_Pilot_Benchmark_for_Ethical_Reasoning_in_Mental_Health_AI\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-16-EthicsMH_A_Pilot_Benchmark_for_Ethical_Reasoning_in_Mental_Health_AI/\",\"children\":\"[논문리뷰] EthicsMH: A Pilot Benchmark for Ethical Reasoning in Mental Health AI\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"UVSKKR이 [arXiv]에 게시한 'EthicsMH: A Pilot Benchmark for Ethical Reasoning in Mental Health AI' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-16 13:16:41+0900\",\"children\":\"2025년 9월 16일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Ethical Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Ethical Reasoning\"]}],[\"$\",\"span\",\"Mental Health AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Mental Health AI\"]}],[\"$\",\"span\",\"Benchmark Dataset\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmark Dataset\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"AI Ethics\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"AI Ethics\"]}],[\"$\",\"span\",\"Clinical Decision Support\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Clinical Decision Support\"]}],[\"$\",\"span\",\"Human-in-the-loop\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Human-in-the-loop\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-16-Dr.V_A_Hierarchical_Perception-Temporal-Cognition_Framework_to_Diagnose_Video_Hallucination_by_Fine-grained_Spatial-Temporal_Grounding\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-16-Dr.V_A_Hierarchical_Perception-Temporal-Cognition_Framework_to_Diagnose_Video_Hallucination_by_Fine-grained_Spatial-Temporal_Grounding/\",\"children\":\"[논문리뷰] Dr.V: A Hierarchical Perception-Temporal-Cognition Framework to Diagnose Video Hallucination by Fine-grained Spatial-Temporal Grounding\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Li Zheng이 [arXiv]에 게시한 'Dr.V: A Hierarchical Perception-Temporal-Cognition Framework to Diagnose Video Hallucination by Fine-grained Spatial-Temporal Grounding' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-16 13:16:41+0900\",\"children\":\"2025년 9월 16일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Video Hallucination\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video Hallucination\"]}],[\"$\",\"span\",\"Large Video Models (LVMs)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Video Models (LVMs)\"]}],[\"$\",\"span\",\"Hierarchical Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Hierarchical Reasoning\"]}],[\"$\",\"span\",\"Spatial-Temporal Grounding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Spatial-Temporal Grounding\"]}],[\"$\",\"span\",\"Diagnostic Framework\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diagnostic Framework\"]}],[\"$\",\"span\",\"Benchmark Dataset\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmark Dataset\"]}],[\"$\",\"span\",\"Multimodal AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal AI\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-16-CognitiveSky_Scalable_Sentiment_and_Narrative_Analysis_for_Decentralized_Social_Media\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-16-CognitiveSky_Scalable_Sentiment_and_Narrative_Analysis_for_Decentralized_Social_Media/\",\"children\":\"[논문리뷰] CognitiveSky: Scalable Sentiment and Narrative Analysis for Decentralized Social Media\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Subasish Das이 [arXiv]에 게시한 'CognitiveSky: Scalable Sentiment and Narrative Analysis for Decentralized Social Media' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-16 13:16:41+0900\",\"children\":\"2025년 9월 16일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Sentiment Analysis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Sentiment Analysis\"]}],[\"$\",\"span\",\"Narrative Analysis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Narrative Analysis\"]}],[\"$\",\"span\",\"Decentralized Social Media\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Decentralized Social Media\"]}],[\"$\",\"span\",\"Bluesky\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Bluesky\"]}],[\"$\",\"span\",\"Transformer Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Transformer Models\"]}],[\"$\",\"span\",\"Topic Modeling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Topic Modeling\"]}],[\"$\",\"span\",\"Real-time Processing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Real-time Processing\"]}],[\"$\",\"span\",\"Data Visualization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Visualization\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-15-X-Part_high_fidelity_and_structure_coherent_shape_decomposition\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-15-X-Part_high_fidelity_and_structure_coherent_shape_decomposition/\",\"children\":\"[논문리뷰] X-Part: high fidelity and structure coherent shape decomposition\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yunhan Yang이 [arXiv]에 게시한 'X-Part: high fidelity and structure coherent shape decomposition' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-15 13:12:08+0900\",\"children\":\"2025년 9월 15일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"3D Shape Decomposition\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D Shape Decomposition\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}],[\"$\",\"span\",\"Part-level Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Part-level Generation\"]}],[\"$\",\"span\",\"Controllable Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Controllable Generation\"]}],[\"$\",\"span\",\"Bounding Box Prompts\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Bounding Box Prompts\"]}],[\"$\",\"span\",\"Semantic Features\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Semantic Features\"]}],[\"$\",\"span\",\"Interactive Editing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Interactive Editing\"]}],[\"$\",\"span\",\"Generative AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generative AI\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-15-VStyle_A_Benchmark_for_Voice_Style_Adaptation_with_Spoken_Instructions\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-15-VStyle_A_Benchmark_for_Voice_Style_Adaptation_with_Spoken_Instructions/\",\"children\":\"[논문리뷰] VStyle: A Benchmark for Voice Style Adaptation with Spoken Instructions\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Dong Zhang이 [arXiv]에 게시한 'VStyle: A Benchmark for Voice Style Adaptation with Spoken Instructions' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-15 13:12:08+0900\",\"children\":\"2025년 9월 15일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Voice Style Adaptation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Voice Style Adaptation\"]}],[\"$\",\"span\",\"Spoken Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Spoken Language Models\"]}],[\"$\",\"span\",\"Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmark\"]}],[\"$\",\"span\",\"LALM-as-a-Judge\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LALM-as-a-Judge\"]}],[\"$\",\"span\",\"Speech Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Speech Generation\"]}],[\"$\",\"span\",\"Multilingual\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multilingual\"]}],[\"$\",\"span\",\"Evaluation Framework\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Evaluation Framework\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-15-Virtual_Agent_Economies\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-15-Virtual_Agent_Economies/\",\"children\":\"[논문리뷰] Virtual Agent Economies\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"William A. Cunningham이 [arXiv]에 게시한 'Virtual Agent Economies' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-15 13:12:08+0900\",\"children\":\"2025년 9월 15일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"AI Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"AI Agents\"]}],[\"$\",\"span\",\"Virtual Economy\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Virtual Economy\"]}],[\"$\",\"span\",\"Multi-Agent Systems\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-Agent Systems\"]}],[\"$\",\"span\",\"Economic Mechanisms\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Economic Mechanisms\"]}],[\"$\",\"span\",\"Governance\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Governance\"]}],[\"$\",\"span\",\"Blockchain\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Blockchain\"]}],[\"$\",\"span\",\"Resource Allocation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Resource Allocation\"]}],[\"$\",\"span\",\"Agent Alignment\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Agent Alignment\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-15-The_Illusion_of_Diminishing_Returns_Measuring_Long_Horizon_Execution_in_LLMs\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-15-The_Illusion_of_Diminishing_Returns_Measuring_Long_Horizon_Execution_in_LLMs/\",\"children\":\"[논문리뷰] The Illusion of Diminishing Returns: Measuring Long Horizon Execution in LLMs\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Jonas Geiping이 [arXiv]에 게시한 'The Illusion of Diminishing Returns: Measuring Long Horizon Execution in LLMs' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-15 13:12:08+0900\",\"children\":\"2025년 9월 15일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Long-Horizon Tasks\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Long-Horizon Tasks\"]}],[\"$\",\"span\",\"Execution Capability\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Execution Capability\"]}],[\"$\",\"span\",\"Scaling Laws\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Scaling Laws\"]}],[\"$\",\"span\",\"Self-Conditioning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Self-Conditioning\"]}],[\"$\",\"span\",\"Thinking Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Thinking Models\"]}],[\"$\",\"span\",\"Agentic AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Agentic AI\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-15-QuantAgent_Price-Driven_Multi-Agent_LLMs_for_High-Frequency_Trading\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-15-QuantAgent_Price-Driven_Multi-Agent_LLMs_for_High-Frequency_Trading/\",\"children\":\"[논문리뷰] QuantAgent: Price-Driven Multi-Agent LLMs for High-Frequency Trading\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Chenyu You이 [arXiv]에 게시한 'QuantAgent: Price-Driven Multi-Agent LLMs for High-Frequency Trading' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-15 13:12:08+0900\",\"children\":\"2025년 9월 15일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"High-Frequency Trading\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"High-Frequency Trading\"]}],[\"$\",\"span\",\"Multi-Agent Systems\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-Agent Systems\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Technical Analysis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Technical Analysis\"]}],[\"$\",\"span\",\"Algorithmic Trading\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Algorithmic Trading\"]}],[\"$\",\"span\",\"Financial Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Financial Reasoning\"]}],[\"$\",\"span\",\"Price-Driven Signals\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Price-Driven Signals\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-15-MCP-AgentBench_Evaluating_Real-World_Language_Agent_Performance_with_MCP-Mediated_Tools\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-15-MCP-AgentBench_Evaluating_Real-World_Language_Agent_Performance_with_MCP-Mediated_Tools/\",\"children\":\"[논문리뷰] MCP-AgentBench: Evaluating Real-World Language Agent Performance with MCP-Mediated Tools\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Xiaorui Wang이 [arXiv]에 게시한 'MCP-AgentBench: Evaluating Real-World Language Agent Performance with MCP-Mediated Tools' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-15 13:12:08+0900\",\"children\":\"2025년 9월 15일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Language Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Language Agents\"]}],[\"$\",\"span\",\"Tool Use\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Tool Use\"]}],[\"$\",\"span\",\"Benchmarks\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmarks\"]}],[\"$\",\"span\",\"Model Context Protocol (MCP)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Model Context Protocol (MCP)\"]}],[\"$\",\"span\",\"LLM Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Evaluation\"]}],[\"$\",\"span\",\"Agentic AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Agentic AI\"]}],[\"$\",\"span\",\"Real-World Performance\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Real-World Performance\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-15-LoFT_Parameter-Efficient_Fine-Tuning_for_Long-tailed_Semi-Supervised_Learning_in_Open-World_Scenarios\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-15-LoFT_Parameter-Efficient_Fine-Tuning_for_Long-tailed_Semi-Supervised_Learning_in_Open-World_Scenarios/\",\"children\":\"[논문리뷰] LoFT: Parameter-Efficient Fine-Tuning for Long-tailed Semi-Supervised Learning in Open-World Scenarios\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Bing Su이 [arXiv]에 게시한 'LoFT: Parameter-Efficient Fine-Tuning for Long-tailed Semi-Supervised Learning in Open-World Scenarios' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-15 13:12:08+0900\",\"children\":\"2025년 9월 15일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Long-tailed Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Long-tailed Learning\"]}],[\"$\",\"span\",\"Semi-Supervised Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Semi-Supervised Learning\"]}],[\"$\",\"span\",\"Parameter-Efficient Fine-Tuning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Parameter-Efficient Fine-Tuning\"]}],[\"$\",\"span\",\"Foundation Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Foundation Models\"]}],[\"$\",\"span\",\"Open-World Scenarios\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Open-World Scenarios\"]}],[\"$\",\"span\",\"OOD Detection\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"OOD Detection\"]}],[\"$\",\"span\",\"Confidence Calibration\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Confidence Calibration\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-15-IntrEx_A_Dataset_for_Modeling_Engagement_in_Educational_Conversations\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-15-IntrEx_A_Dataset_for_Modeling_Engagement_in_Educational_Conversations/\",\"children\":\"[논문리뷰] IntrEx: A Dataset for Modeling Engagement in Educational Conversations\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Gabriele Pergola이 [arXiv]에 게시한 'IntrEx: A Dataset for Modeling Engagement in Educational Conversations' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-15 13:12:08+0900\",\"children\":\"2025년 9월 15일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Educational Dialogue\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Educational Dialogue\"]}],[\"$\",\"span\",\"Engagement Modeling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Engagement Modeling\"]}],[\"$\",\"span\",\"Dataset Annotation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dataset Annotation\"]}],[\"$\",\"span\",\"Second Language Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Second Language Learning\"]}],[\"$\",\"span\",\"Human Feedback\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Human Feedback\"]}],[\"$\",\"span\",\"LLM Alignment\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Alignment\"]}],[\"$\",\"span\",\"Readability Metrics\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Readability Metrics\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-15-Inpainting-Guided_Policy_Optimization_for_Diffusion_Large_Language_Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-15-Inpainting-Guided_Policy_Optimization_for_Diffusion_Large_Language_Models/\",\"children\":\"[논문리뷰] Inpainting-Guided Policy Optimization for Diffusion Large Language Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Chenyu Wang이 [arXiv]에 게시한 'Inpainting-Guided Policy Optimization for Diffusion Large Language Models' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-15 13:12:08+0900\",\"children\":\"2025년 9월 15일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Diffusion LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion LLMs\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Inpainting\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Inpainting\"]}],[\"$\",\"span\",\"Policy Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Policy Optimization\"]}],[\"$\",\"span\",\"Exploration\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Exploration\"]}],[\"$\",\"span\",\"Mathematical Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Mathematical Reasoning\"]}],[\"$\",\"span\",\"GRPO\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"GRPO\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-15-InfGen_A_Resolution-Agnostic_Paradigm_for_Scalable_Image_Synthesis\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-15-InfGen_A_Resolution-Agnostic_Paradigm_for_Scalable_Image_Synthesis/\",\"children\":\"[논문리뷰] InfGen: A Resolution-Agnostic Paradigm for Scalable Image Synthesis\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Song Guo이 [arXiv]에 게시한 'InfGen: A Resolution-Agnostic Paradigm for Scalable Image Synthesis' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-15 13:12:08+0900\",\"children\":\"2025년 9월 15일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Image Synthesis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image Synthesis\"]}],[\"$\",\"span\",\"Resolution-Agnostic\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Resolution-Agnostic\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}],[\"$\",\"span\",\"Latent Space\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Latent Space\"]}],[\"$\",\"span\",\"VAE Decoder\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"VAE Decoder\"]}],[\"$\",\"span\",\"High-Resolution Image Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"High-Resolution Image Generation\"]}],[\"$\",\"span\",\"Generative AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generative AI\"]}],[\"$\",\"span\",\"Transformer Architecture\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Transformer Architecture\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-15-HANRAG_Heuristic_Accurate_Noise-resistant_Retrieval-Augmented_Generation_for_Multi-hop_Question_Answering\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-15-HANRAG_Heuristic_Accurate_Noise-resistant_Retrieval-Augmented_Generation_for_Multi-hop_Question_Answering/\",\"children\":\"[논문리뷰] HANRAG: Heuristic Accurate Noise-resistant Retrieval-Augmented Generation for Multi-hop Question Answering\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Zhehao Tan이 [arXiv]에 게시한 'HANRAG: Heuristic Accurate Noise-resistant Retrieval-Augmented Generation for Multi-hop Question Answering' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-15 13:12:08+0900\",\"children\":\"2025년 9월 15일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Retrieval-Augmented Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Retrieval-Augmented Generation\"]}],[\"$\",\"span\",\"Multi-hop QA\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-hop QA\"]}],[\"$\",\"span\",\"Noise Resistance\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Noise Resistance\"]}],[\"$\",\"span\",\"LLM\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM\"]}],[\"$\",\"span\",\"Query Decomposition\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Query Decomposition\"]}],[\"$\",\"span\",\"Adaptive Retrieval\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Adaptive Retrieval\"]}],[\"$\",\"span\",\"Heuristic Framework\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Heuristic Framework\"]}],[\"$\",\"span\",\"Revelator\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Revelator\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-15-FLOWER_Democratizing_Generalist_Robot_Policies_with_Efficient_Vision-Language-Action_Flow_Policies\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-15-FLOWER_Democratizing_Generalist_Robot_Policies_with_Efficient_Vision-Language-Action_Flow_Policies/\",\"children\":\"[논문리뷰] FLOWER: Democratizing Generalist Robot Policies with Efficient Vision-Language-Action Flow Policies\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Fabian Otto이 [arXiv]에 게시한 'FLOWER: Democratizing Generalist Robot Policies with Efficient Vision-Language-Action Flow Policies' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-15 13:12:08+0900\",\"children\":\"2025년 9월 15일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Generalist Robot Policies\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generalist Robot Policies\"]}],[\"$\",\"span\",\"Vision-Language-Action Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision-Language-Action Models\"]}],[\"$\",\"span\",\"Efficient AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Efficient AI\"]}],[\"$\",\"span\",\"Imitation Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Imitation Learning\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}],[\"$\",\"span\",\"Intermediate Fusion\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Intermediate Fusion\"]}],[\"$\",\"span\",\"Robotics\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Robotics\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-15-CMHG_A_Dataset_and_Benchmark_for_Headline_Generation_of_Minority_Languages_in_China\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-15-CMHG_A_Dataset_and_Benchmark_for_Headline_Generation_of_Minority_Languages_in_China/\",\"children\":\"[논문리뷰] CMHG: A Dataset and Benchmark for Headline Generation of Minority Languages in China\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"XU Han이 [arXiv]에 게시한 'CMHG: A Dataset and Benchmark for Headline Generation of Minority Languages in China' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-15 13:12:08+0900\",\"children\":\"2025년 9월 15일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Headline Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Headline Generation\"]}],[\"$\",\"span\",\"Minority Languages\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Minority Languages\"]}],[\"$\",\"span\",\"Low-Resource NLP\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Low-Resource NLP\"]}],[\"$\",\"span\",\"Dataset\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dataset\"]}],[\"$\",\"span\",\"Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmark\"]}],[\"$\",\"span\",\"Natural Language Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Natural Language Generation\"]}],[\"$\",\"span\",\"Chinese Minority Languages\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Chinese Minority Languages\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-12-VLA-Adapter_An_Effective_Paradigm_for_Tiny-Scale_Vision-Language-Action_Model\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-12-VLA-Adapter_An_Effective_Paradigm_for_Tiny-Scale_Vision-Language-Action_Model/\",\"children\":\"[논문리뷰] VLA-Adapter: An Effective Paradigm for Tiny-Scale Vision-Language-Action Model\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Zirui Ge이 [arXiv]에 게시한 'VLA-Adapter: An Effective Paradigm for Tiny-Scale Vision-Language-Action Model' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-12 13:12:46+0900\",\"children\":\"2025년 9월 12일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Vision-Language-Action Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision-Language-Action Models\"]}],[\"$\",\"span\",\"Robotics\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Robotics\"]}],[\"$\",\"span\",\"Multimodal Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Learning\"]}],[\"$\",\"span\",\"Efficient AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Efficient AI\"]}],[\"$\",\"span\",\"Model Adaptation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Model Adaptation\"]}],[\"$\",\"span\",\"Bridge Attention\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Bridge Attention\"]}],[\"$\",\"span\",\"Low-resource Training\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Low-resource Training\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-12-Visual_Programmability_A_Guide_for_Code-as-Thought_in_Chart_Understanding\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-12-Visual_Programmability_A_Guide_for_Code-as-Thought_in_Chart_Understanding/\",\"children\":\"[논문리뷰] Visual Programmability: A Guide for Code-as-Thought in Chart Understanding\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Ethan Chern이 [arXiv]에 게시한 'Visual Programmability: A Guide for Code-as-Thought in Chart Understanding' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-12 13:12:46+0900\",\"children\":\"2025년 9월 12일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Visual Programmability\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Visual Programmability\"]}],[\"$\",\"span\",\"Code-as-Thought (CaT)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Code-as-Thought (CaT)\"]}],[\"$\",\"span\",\"Chart Understanding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Chart Understanding\"]}],[\"$\",\"span\",\"Vision-Language Models (VLMs)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision-Language Models (VLMs)\"]}],[\"$\",\"span\",\"Reinforcement Learning (RL)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning (RL)\"]}],[\"$\",\"span\",\"Adaptive Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Adaptive Reasoning\"]}],[\"$\",\"span\",\"Dual-Reward System\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dual-Reward System\"]}],[\"$\",\"span\",\"Multimodal AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal AI\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-12-The_Choice_of_Divergence_A_Neglected_Key_to_Mitigating_Diversity_Collapse_in_Reinforcement_Learning_with_Verifiable_Reward\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-12-The_Choice_of_Divergence_A_Neglected_Key_to_Mitigating_Diversity_Collapse_in_Reinforcement_Learning_with_Verifiable_Reward/\",\"children\":\"[논문리뷰] The Choice of Divergence: A Neglected Key to Mitigating Diversity Collapse in Reinforcement Learning with Verifiable Reward\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Xiaoyu Tan이 [arXiv]에 게시한 'The Choice of Divergence: A Neglected Key to Mitigating Diversity Collapse in Reinforcement Learning with Verifiable Reward' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-12 13:12:46+0900\",\"children\":\"2025년 9월 12일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Large Language Models (LLMs)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models (LLMs)\"]}],[\"$\",\"span\",\"Diversity Collapse\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diversity Collapse\"]}],[\"$\",\"span\",\"f-divergence\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"f-divergence\"]}],[\"$\",\"span\",\"Forward-KL\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Forward-KL\"]}],[\"$\",\"span\",\"JS-divergence\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"JS-divergence\"]}],[\"$\",\"span\",\"Pass@k\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Pass@k\"]}],[\"$\",\"span\",\"Catastrophic Forgetting\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Catastrophic Forgetting\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-12-SpatialVID_A_Large-Scale_Video_Dataset_with_Spatial_Annotations\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-12-SpatialVID_A_Large-Scale_Video_Dataset_with_Spatial_Annotations/\",\"children\":\"[논문리뷰] SpatialVID: A Large-Scale Video Dataset with Spatial Annotations\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Jian Gao이 [arXiv]에 게시한 'SpatialVID: A Large-Scale Video Dataset with Spatial Annotations' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-12 13:12:46+0900\",\"children\":\"2025년 9월 12일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Video Dataset\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video Dataset\"]}],[\"$\",\"span\",\"Spatial Annotation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Spatial Annotation\"]}],[\"$\",\"span\",\"Camera Pose Estimation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Camera Pose Estimation\"]}],[\"$\",\"span\",\"Depth Map\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Depth Map\"]}],[\"$\",\"span\",\"Structured Caption\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Structured Caption\"]}],[\"$\",\"span\",\"Motion Instruction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Motion Instruction\"]}],[\"$\",\"span\",\"3D Vision\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D Vision\"]}],[\"$\",\"span\",\"World Modeling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"World Modeling\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-12-SimpleVLA-RL_Scaling_VLA_Training_via_Reinforcement_Learning\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-12-SimpleVLA-RL_Scaling_VLA_Training_via_Reinforcement_Learning/\",\"children\":\"[논문리뷰] SimpleVLA-RL: Scaling VLA Training via Reinforcement Learning\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Zhaohui Yang이 [arXiv]에 게시한 'SimpleVLA-RL: Scaling VLA Training via Reinforcement Learning' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-12 13:12:46+0900\",\"children\":\"2025년 9월 12일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Reinforcement Learning (RL)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning (RL)\"]}],[\"$\",\"span\",\"Vision-Language-Action (VLA) Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision-Language-Action (VLA) Models\"]}],[\"$\",\"span\",\"Robotic Manipulation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Robotic Manipulation\"]}],[\"$\",\"span\",\"Data Scarcity\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Scarcity\"]}],[\"$\",\"span\",\"Generalization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generalization\"]}],[\"$\",\"span\",\"Sim-to-Real Transfer\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Sim-to-Real Transfer\"]}],[\"$\",\"span\",\"Online RL\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Online RL\"]}],[\"$\",\"span\",\"Long-Horizon Planning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Long-Horizon Planning\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-12-Reasoning_Introduces_New_Poisoning_Attacks_Yet_Makes_Them_More_Complicated\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-12-Reasoning_Introduces_New_Poisoning_Attacks_Yet_Makes_Them_More_Complicated/\",\"children\":\"[논문리뷰] Reasoning Introduces New Poisoning Attacks Yet Makes Them More Complicated\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Jamie Hayes이 [arXiv]에 게시한 'Reasoning Introduces New Poisoning Attacks Yet Makes Them More Complicated' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-12 13:12:46+0900\",\"children\":\"2025년 9월 12일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLM Security\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Security\"]}],[\"$\",\"span\",\"Data Poisoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Poisoning\"]}],[\"$\",\"span\",\"Chain-of-Thought\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Chain-of-Thought\"]}],[\"$\",\"span\",\"Reasoning Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reasoning Models\"]}],[\"$\",\"span\",\"Backdoor Attacks\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Backdoor Attacks\"]}],[\"$\",\"span\",\"CoT Unfaithfulness\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"CoT Unfaithfulness\"]}],[\"$\",\"span\",\"Emergent Robustness\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Emergent Robustness\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-12-OmniEVA_Embodied_Versatile_Planner_via_Task-Adaptive_3D-Grounded_and_Embodiment-aware_Reasoning\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-12-OmniEVA_Embodied_Versatile_Planner_via_Task-Adaptive_3D-Grounded_and_Embodiment-aware_Reasoning/\",\"children\":\"[논문리뷰] OmniEVA: Embodied Versatile Planner via Task-Adaptive 3D-Grounded and Embodiment-aware Reasoning\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yuzheng Zhuang이 [arXiv]에 게시한 'OmniEVA: Embodied Versatile Planner via Task-Adaptive 3D-Grounded and Embodiment-aware Reasoning' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-12 13:12:46+0900\",\"children\":\"2025년 9월 12일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Embodied AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Embodied AI\"]}],[\"$\",\"span\",\"Multimodal LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal LLMs\"]}],[\"$\",\"span\",\"3D Grounding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D Grounding\"]}],[\"$\",\"span\",\"Task-Adaptive Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Task-Adaptive Reasoning\"]}],[\"$\",\"span\",\"Embodiment-Aware Planning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Embodiment-Aware Planning\"]}],[\"$\",\"span\",\"Robotics\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Robotics\"]}],[\"$\",\"span\",\"Spatial Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Spatial Reasoning\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-12-Modality_Alignment_with_Multi-scale_Bilateral_Attention_for_Multimodal_Recommendation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-12-Modality_Alignment_with_Multi-scale_Bilateral_Attention_for_Multimodal_Recommendation/\",\"children\":\"[논문리뷰] Modality Alignment with Multi-scale Bilateral Attention for Multimodal Recommendation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Dong-Ho Lee이 [arXiv]에 게시한 'Modality Alignment with Multi-scale Bilateral Attention for Multimodal Recommendation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-12 13:12:46+0900\",\"children\":\"2025년 9월 12일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Multimodal Recommendation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Recommendation\"]}],[\"$\",\"span\",\"Modality Alignment\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Modality Alignment\"]}],[\"$\",\"span\",\"Attention Mechanism\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Attention Mechanism\"]}],[\"$\",\"span\",\"Dilated Convolution\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dilated Convolution\"]}],[\"$\",\"span\",\"Maximum Mean Discrepancy\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Maximum Mean Discrepancy\"]}],[\"$\",\"span\",\"Contrastive Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Contrastive Learning\"]}],[\"$\",\"span\",\"Dimensionality Reduction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dimensionality Reduction\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-12-LoCoBench_A_Benchmark_for_Long-Context_Large_Language_Models_in_Complex_Software_Engineering\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-12-LoCoBench_A_Benchmark_for_Long-Context_Large_Language_Models_in_Complex_Software_Engineering/\",\"children\":\"[논문리뷰] LoCoBench: A Benchmark for Long-Context Large Language Models in Complex Software Engineering\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Jianguo Zhang이 [arXiv]에 게시한 'LoCoBench: A Benchmark for Long-Context Large Language Models in Complex Software Engineering' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-12 13:12:46+0900\",\"children\":\"2025년 9월 12일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Long-Context LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Long-Context LLMs\"]}],[\"$\",\"span\",\"Software Engineering\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Software Engineering\"]}],[\"$\",\"span\",\"Code Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Code Evaluation\"]}],[\"$\",\"span\",\"Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmark\"]}],[\"$\",\"span\",\"Multi-file Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-file Reasoning\"]}],[\"$\",\"span\",\"Architectural Understanding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Architectural Understanding\"]}],[\"$\",\"span\",\"Context Length\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Context Length\"]}],[\"$\",\"span\",\"Software Development Lifecycle\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Software Development Lifecycle\"]}],[\"$\",\"span\",\"Metrics\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Metrics\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-12-Kling-Avatar_Grounding_Multimodal_Instructions_for_Cascaded_Long-Duration_Avatar_Animation_Synthesis\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-12-Kling-Avatar_Grounding_Multimodal_Instructions_for_Cascaded_Long-Duration_Avatar_Animation_Synthesis/\",\"children\":\"[논문리뷰] Kling-Avatar: Grounding Multimodal Instructions for Cascaded Long-Duration Avatar Animation Synthesis\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Wentao Hu이 [arXiv]에 게시한 'Kling-Avatar: Grounding Multimodal Instructions for Cascaded Long-Duration Avatar Animation Synthesis' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-12 13:12:46+0900\",\"children\":\"2025년 9월 12일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Avatar Animation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Avatar Animation\"]}],[\"$\",\"span\",\"Multimodal Instructions\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Instructions\"]}],[\"$\",\"span\",\"Long-Duration Video Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Long-Duration Video Generation\"]}],[\"$\",\"span\",\"MLLM Director\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"MLLM Director\"]}],[\"$\",\"span\",\"Cascaded Framework\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Cascaded Framework\"]}],[\"$\",\"span\",\"Lip Synchronization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Lip Synchronization\"]}],[\"$\",\"span\",\"Instruction Grounding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Instruction Grounding\"]}],[\"$\",\"span\",\"Video Diffusion Transformers\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video Diffusion Transformers\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-12-HuMo_Human-Centric_Video_Generation_via_Collaborative_Multi-Modal_Conditioning\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-12-HuMo_Human-Centric_Video_Generation_via_Collaborative_Multi-Modal_Conditioning/\",\"children\":\"[논문리뷰] HuMo: Human-Centric Video Generation via Collaborative Multi-Modal Conditioning\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Zhuowei Chen이 [arXiv]에 게시한 'HuMo: Human-Centric Video Generation via Collaborative Multi-Modal Conditioning' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-12 13:12:46+0900\",\"children\":\"2025년 9월 12일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Human-Centric Video Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Human-Centric Video Generation\"]}],[\"$\",\"span\",\"Multimodal Conditioning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Conditioning\"]}],[\"$\",\"span\",\"Text-to-Video\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Text-to-Video\"]}],[\"$\",\"span\",\"Image-to-Video\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image-to-Video\"]}],[\"$\",\"span\",\"Audio-to-Video\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Audio-to-Video\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}],[\"$\",\"span\",\"Subject Preservation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Subject Preservation\"]}],[\"$\",\"span\",\"Audio-Visual Synchronization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Audio-Visual Synchronization\"]}],[\"$\",\"span\",\"Progressive Training\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Progressive Training\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-12-Harnessing_Uncertainty_Entropy-Modulated_Policy_Gradients_for_Long-Horizon_LLM_Agents\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-12-Harnessing_Uncertainty_Entropy-Modulated_Policy_Gradients_for_Long-Horizon_LLM_Agents/\",\"children\":\"[논문리뷰] Harnessing Uncertainty: Entropy-Modulated Policy Gradients for Long-Horizon LLM Agents\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Xintao Wang이 [arXiv]에 게시한 'Harnessing Uncertainty: Entropy-Modulated Policy Gradients for Long-Horizon LLM Agents' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-12 13:12:46+0900\",\"children\":\"2025년 9월 12일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLM Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Agents\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Policy Gradients\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Policy Gradients\"]}],[\"$\",\"span\",\"Entropy Modulation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Entropy Modulation\"]}],[\"$\",\"span\",\"Credit Assignment\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Credit Assignment\"]}],[\"$\",\"span\",\"Uncertainty\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Uncertainty\"]}],[\"$\",\"span\",\"Long-Horizon Tasks\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Long-Horizon Tasks\"]}],[\"$\",\"span\",\"Self-Calibrating Gradient Scaling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Self-Calibrating Gradient Scaling\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-12-Gradient-Attention_Guided_Dual-Masking_Synergetic_Framework_for_Robust_Text-based_Person_Retrieval\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-12-Gradient-Attention_Guided_Dual-Masking_Synergetic_Framework_for_Robust_Text-based_Person_Retrieval/\",\"children\":\"[논문리뷰] Gradient-Attention Guided Dual-Masking Synergetic Framework for Robust Text-based Person Retrieval\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Kaicheng Yang이 [arXiv]에 게시한 'Gradient-Attention Guided Dual-Masking Synergetic Framework for Robust Text-based Person Retrieval' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-12 13:12:46+0900\",\"children\":\"2025년 9월 12일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Text-based Person Retrieval\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Text-based Person Retrieval\"]}],[\"$\",\"span\",\"CLIP\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"CLIP\"]}],[\"$\",\"span\",\"MLLM\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"MLLM\"]}],[\"$\",\"span\",\"Data Curation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Curation\"]}],[\"$\",\"span\",\"Dual-Masking\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dual-Masking\"]}],[\"$\",\"span\",\"Gradient-Attention\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Gradient-Attention\"]}],[\"$\",\"span\",\"WebPerson Dataset\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"WebPerson Dataset\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-12-FLUX-Reason-6M_PRISM-Bench_A_Million-Scale_Text-to-Image_Reasoning_Dataset_and_Comprehensive_Benchmark\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-12-FLUX-Reason-6M_PRISM-Bench_A_Million-Scale_Text-to-Image_Reasoning_Dataset_and_Comprehensive_Benchmark/\",\"children\":\"[논문리뷰] FLUX-Reason-6M \u0026 PRISM-Bench: A Million-Scale Text-to-Image Reasoning Dataset and Comprehensive Benchmark\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Shuai Bai이 [arXiv]에 게시한 'FLUX-Reason-6M \u0026 PRISM-Bench: A Million-Scale Text-to-Image Reasoning Dataset and Comprehensive Benchmark' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-12 13:12:46+0900\",\"children\":\"2025년 9월 12일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Text-to-Image Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Text-to-Image Generation\"]}],[\"$\",\"span\",\"Reasoning Dataset\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reasoning Dataset\"]}],[\"$\",\"span\",\"Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmark\"]}],[\"$\",\"span\",\"Generation Chain-of-Thought\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generation Chain-of-Thought\"]}],[\"$\",\"span\",\"Vision-Language Model\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision-Language Model\"]}],[\"$\",\"span\",\"Image Aesthetics\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image Aesthetics\"]}],[\"$\",\"span\",\"Prompt Alignment\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Prompt Alignment\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-12-EchoX_Towards_Mitigating_Acoustic-Semantic_Gap_via_Echo_Training_for_Speech-to-Speech_LLMs\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-12-EchoX_Towards_Mitigating_Acoustic-Semantic_Gap_via_Echo_Training_for_Speech-to-Speech_LLMs/\",\"children\":\"[논문리뷰] EchoX: Towards Mitigating Acoustic-Semantic Gap via Echo Training for Speech-to-Speech LLMs\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Kaiqi Kou이 [arXiv]에 게시한 'EchoX: Towards Mitigating Acoustic-Semantic Gap via Echo Training for Speech-to-Speech LLMs' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-12 13:12:46+0900\",\"children\":\"2025년 9월 12일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Speech-to-Speech LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Speech-to-Speech LLMs\"]}],[\"$\",\"span\",\"Acoustic-Semantic Gap\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Acoustic-Semantic Gap\"]}],[\"$\",\"span\",\"Echo Training\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Echo Training\"]}],[\"$\",\"span\",\"Unit Language\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Unit Language\"]}],[\"$\",\"span\",\"Streaming Inference\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Streaming Inference\"]}],[\"$\",\"span\",\"Knowledge-based QA\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Knowledge-based QA\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-12-Can_Understanding_and_Generation_Truly_Benefit_Together_--_or_Just_Coexist\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-12-Can_Understanding_and_Generation_Truly_Benefit_Together_--_or_Just_Coexist/\",\"children\":\"[논문리뷰] Can Understanding and Generation Truly Benefit Together -- or Just Coexist?\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Hui Han이 [arXiv]에 게시한 'Can Understanding and Generation Truly Benefit Together -- or Just Coexist?' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-12 13:12:46+0900\",\"children\":\"2025년 9월 12일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Multimodal Understanding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Understanding\"]}],[\"$\",\"span\",\"Multimodal Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Generation\"]}],[\"$\",\"span\",\"Unified Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Unified Models\"]}],[\"$\",\"span\",\"Auto-Encoder\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Auto-Encoder\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Image-to-Text\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image-to-Text\"]}],[\"$\",\"span\",\"Text-to-Image\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Text-to-Image\"]}],[\"$\",\"span\",\"Reconstruction Fidelity\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reconstruction Fidelity\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-12-2D_Gaussian_Splatting_with_Semantic_Alignment_for_Image_Inpainting\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-12-2D_Gaussian_Splatting_with_Semantic_Alignment_for_Image_Inpainting/\",\"children\":\"[논문리뷰] 2D Gaussian Splatting with Semantic Alignment for Image Inpainting\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Guangming Lu이 [arXiv]에 게시한 '2D Gaussian Splatting with Semantic Alignment for Image Inpainting' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-12 13:12:46+0900\",\"children\":\"2025년 9월 12일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Image Inpainting\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image Inpainting\"]}],[\"$\",\"span\",\"2D Gaussian Splatting\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"2D Gaussian Splatting\"]}],[\"$\",\"span\",\"Semantic Alignment\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Semantic Alignment\"]}],[\"$\",\"span\",\"DINO Features\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"DINO Features\"]}],[\"$\",\"span\",\"Patch-level Rasterization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Patch-level Rasterization\"]}],[\"$\",\"span\",\"Continuous Representation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Continuous Representation\"]}],[\"$\",\"span\",\"Generative Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generative Models\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-11-think_So_lets_replace_this_phrase_with_insult..._think_Lessons_learned_from_generation_of_toxic_texts_with_LLMs\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-11-think_So_lets_replace_this_phrase_with_insult..._think_Lessons_learned_from_generation_of_toxic_texts_with_LLMs/\",\"children\":\"[논문리뷰] \u003cthink\u003e So let's replace this phrase with insult... \u003c/think\u003e Lessons learned from generation of toxic texts with LLMs\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Alexander Panchenko이 [arXiv]에 게시한 '\u003cthink\u003e So let's replace this phrase with insult... \u003c/think\u003e Lessons learned from generation of toxic texts with LLMs' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-11 13:02:36+0900\",\"children\":\"2025년 9월 11일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Toxic Text Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Toxic Text Generation\"]}],[\"$\",\"span\",\"LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLMs\"]}],[\"$\",\"span\",\"Text Detoxification\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Text Detoxification\"]}],[\"$\",\"span\",\"Lexical Diversity\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Lexical Diversity\"]}],[\"$\",\"span\",\"Synthetic Data\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Synthetic Data\"]}],[\"$\",\"span\",\"Human Annotation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Human Annotation\"]}],[\"$\",\"span\",\"Style Transfer\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Style Transfer\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-11-RewardDance_Reward_Scaling_in_Visual_Generation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-11-RewardDance_Reward_Scaling_in_Visual_Generation/\",\"children\":\"[논문리뷰] RewardDance: Reward Scaling in Visual Generation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Liang Li이 [arXiv]에 게시한 'RewardDance: Reward Scaling in Visual Generation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-11 13:02:36+0900\",\"children\":\"2025년 9월 11일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Reward Model\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reward Model\"]}],[\"$\",\"span\",\"Visual Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Visual Generation\"]}],[\"$\",\"span\",\"RLHF\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"RLHF\"]}],[\"$\",\"span\",\"VLM\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"VLM\"]}],[\"$\",\"span\",\"Reward Scaling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reward Scaling\"]}],[\"$\",\"span\",\"Reward Hacking\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reward Hacking\"]}],[\"$\",\"span\",\"Generative Paradigm\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generative Paradigm\"]}],[\"$\",\"span\",\"Context Scaling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Context Scaling\"]}],[\"$\",\"span\",\"Text-to-Image\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Text-to-Image\"]}],[\"$\",\"span\",\"Text-to-Video\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Text-to-Video\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-11-P3-SAM_Native_3D_Part_Segmentation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-11-P3-SAM_Native_3D_Part_Segmentation/\",\"children\":\"[논문리뷰] P3-SAM: Native 3D Part Segmentation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yunhan Yang이 [arXiv]에 게시한 'P3-SAM: Native 3D Part Segmentation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-11 13:02:36+0900\",\"children\":\"2025년 9월 11일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"3D Part Segmentation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D Part Segmentation\"]}],[\"$\",\"span\",\"Point Cloud Segmentation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Point Cloud Segmentation\"]}],[\"$\",\"span\",\"Prompt-based Segmentation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Prompt-based Segmentation\"]}],[\"$\",\"span\",\"Deep Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Deep Learning\"]}],[\"$\",\"span\",\"Transformer\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Transformer\"]}],[\"$\",\"span\",\"Interactive Segmentation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Interactive Segmentation\"]}],[\"$\",\"span\",\"Automatic Segmentation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Automatic Segmentation\"]}],[\"$\",\"span\",\"Native 3D\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Native 3D\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-11-Hunyuan-MT_Technical_Report\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-11-Hunyuan-MT_Technical_Report/\",\"children\":\"[논문리뷰] Hunyuan-MT Technical Report\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yang Du이 [arXiv]에 게시한 'Hunyuan-MT Technical Report' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-11 13:02:36+0900\",\"children\":\"2025년 9월 11일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Machine Translation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Machine Translation\"]}],[\"$\",\"span\",\"Large Language Model\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Model\"]}],[\"$\",\"span\",\"Multilingual\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multilingual\"]}],[\"$\",\"span\",\"Low-Resource Languages\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Low-Resource Languages\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Weak-to-Strong Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Weak-to-Strong Learning\"]}],[\"$\",\"span\",\"Slow Thinking\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Slow Thinking\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-11-HumanAgencyBench_Scalable_Evaluation_of_Human_Agency_Support_in_AI_Assistants\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-11-HumanAgencyBench_Scalable_Evaluation_of_Human_Agency_Support_in_AI_Assistants/\",\"children\":\"[논문리뷰] HumanAgencyBench: Scalable Evaluation of Human Agency Support in AI Assistants\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Jacy Reese Anthis이 [arXiv]에 게시한 'HumanAgencyBench: Scalable Evaluation of Human Agency Support in AI Assistants' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-11 13:02:36+0900\",\"children\":\"2025년 9월 11일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Human Agency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Human Agency\"]}],[\"$\",\"span\",\"AI Assistants\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"AI Assistants\"]}],[\"$\",\"span\",\"LLM Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Evaluation\"]}],[\"$\",\"span\",\"Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmark\"]}],[\"$\",\"span\",\"Sociotechnical AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Sociotechnical AI\"]}],[\"$\",\"span\",\"AI Alignment\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"AI Alignment\"]}],[\"$\",\"span\",\"Scalable Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Scalable Evaluation\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-11-EnvX_Agentize_Everything_with_Agentic_AI\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-11-EnvX_Agentize_Everything_with_Agentic_AI/\",\"children\":\"[논문리뷰] EnvX: Agentize Everything with Agentic AI\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Wenzheng Tom Tang이 [arXiv]에 게시한 'EnvX: Agentize Everything with Agentic AI' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-11 13:02:36+0900\",\"children\":\"2025년 9월 11일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Agentic AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Agentic AI\"]}],[\"$\",\"span\",\"Multi-Agent Systems\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-Agent Systems\"]}],[\"$\",\"span\",\"Code Repository\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Code Repository\"]}],[\"$\",\"span\",\"Agentization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Agentization\"]}],[\"$\",\"span\",\"Natural Language Interaction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Natural Language Interaction\"]}],[\"$\",\"span\",\"Agent-to-Agent Protocol\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Agent-to-Agent Protocol\"]}],[\"$\",\"span\",\"LLM-based Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM-based Agents\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-11-A_Survey_of_Reinforcement_Learning_for_Large_Reasoning_Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-11-A_Survey_of_Reinforcement_Learning_for_Large_Reasoning_Models/\",\"children\":\"[논문리뷰] A Survey of Reinforcement Learning for Large Reasoning Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Runze Liu이 [arXiv]에 게시한 'A Survey of Reinforcement Learning for Large Reasoning Models' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-11 13:02:36+0900\",\"children\":\"2025년 9월 11일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Large Reasoning Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Reasoning Models\"]}],[\"$\",\"span\",\"LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLMs\"]}],[\"$\",\"span\",\"Reward Design\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reward Design\"]}],[\"$\",\"span\",\"Policy Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Policy Optimization\"]}],[\"$\",\"span\",\"Verifiable Rewards\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Verifiable Rewards\"]}],[\"$\",\"span\",\"Agentic AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Agentic AI\"]}],[\"$\",\"span\",\"Multimodal AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal AI\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-11-AgentGym-RL_Training_LLM_Agents_for_Long-Horizon_Decision_Making_through_Multi-Turn_Reinforcement_Learning\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-11-AgentGym-RL_Training_LLM_Agents_for_Long-Horizon_Decision_Making_through_Multi-Turn_Reinforcement_Learning/\",\"children\":\"[논문리뷰] AgentGym-RL: Training LLM Agents for Long-Horizon Decision Making through Multi-Turn Reinforcement Learning\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Honglin Guo이 [arXiv]에 게시한 'AgentGym-RL: Training LLM Agents for Long-Horizon Decision Making through Multi-Turn Reinforcement Learning' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-11 13:02:36+0900\",\"children\":\"2025년 9월 11일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLM Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Agents\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Multi-Turn Interaction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-Turn Interaction\"]}],[\"$\",\"span\",\"Long-Horizon Decision Making\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Long-Horizon Decision Making\"]}],[\"$\",\"span\",\"Agent Framework\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Agent Framework\"]}],[\"$\",\"span\",\"Exploration-Exploitation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Exploration-Exploitation\"]}],[\"$\",\"span\",\"Progressive Scaling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Progressive Scaling\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-11-3D_and_4D_World_Modeling_A_Survey\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-11-3D_and_4D_World_Modeling_A_Survey/\",\"children\":\"[논문리뷰] 3D and 4D World Modeling: A Survey\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Ao Liang이 [arXiv]에 게시한 '3D and 4D World Modeling: A Survey' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-11 13:02:36+0900\",\"children\":\"2025년 9월 11일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"3D World Modeling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D World Modeling\"]}],[\"$\",\"span\",\"4D World Modeling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"4D World Modeling\"]}],[\"$\",\"span\",\"Generative Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generative Models\"]}],[\"$\",\"span\",\"Predictive Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Predictive Models\"]}],[\"$\",\"span\",\"LiDAR\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LiDAR\"]}],[\"$\",\"span\",\"Occupancy Grids\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Occupancy Grids\"]}],[\"$\",\"span\",\"Video Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video Generation\"]}],[\"$\",\"span\",\"Autonomous Driving\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Autonomous Driving\"]}],[\"$\",\"span\",\"Robotics\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Robotics\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-10-ΔL_Normalization_Rethink_Loss_Aggregation_in_RLVR\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-10-ΔL_Normalization_Rethink_Loss_Aggregation_in_RLVR/\",\"children\":\"[논문리뷰] ΔL Normalization: Rethink Loss Aggregation in RLVR\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Lili Qiu이 [arXiv]에 게시한 'ΔL Normalization: Rethink Loss Aggregation in RLVR' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-10 13:11:01+0900\",\"children\":\"2025년 9월 10일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLMs\"]}],[\"$\",\"span\",\"Gradient Variance\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Gradient Variance\"]}],[\"$\",\"span\",\"Loss Aggregation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Loss Aggregation\"]}],[\"$\",\"span\",\"Unbiased Estimator\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Unbiased Estimator\"]}],[\"$\",\"span\",\"RLVR\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"RLVR\"]}],[\"$\",\"span\",\"Policy Gradient\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Policy Gradient\"]}],[\"$\",\"span\",\"Normalization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Normalization\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-10-Visual_Representation_Alignment_for_Multimodal_Large_Language_Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-10-Visual_Representation_Alignment_for_Multimodal_Large_Language_Models/\",\"children\":\"[논문리뷰] Visual Representation Alignment for Multimodal Large Language Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Heeseong Shin이 [arXiv]에 게시한 'Visual Representation Alignment for Multimodal Large Language Models' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-10 13:11:01+0900\",\"children\":\"2025년 9월 10일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Multimodal LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal LLMs\"]}],[\"$\",\"span\",\"Visual Representation Alignment\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Visual Representation Alignment\"]}],[\"$\",\"span\",\"Foundation Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Foundation Models\"]}],[\"$\",\"span\",\"Regularization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Regularization\"]}],[\"$\",\"span\",\"Fine-grained Visual Understanding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Fine-grained Visual Understanding\"]}],[\"$\",\"span\",\"Spatial Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Spatial Reasoning\"]}],[\"$\",\"span\",\"Object Counting\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Object Counting\"]}],[\"$\",\"span\",\"Vision-Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision-Language Models\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-10-UMO_Scaling_Multi-Identity_Consistency_for_Image_Customization_via_Matching_Reward\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-10-UMO_Scaling_Multi-Identity_Consistency_for_Image_Customization_via_Matching_Reward/\",\"children\":\"[논문리뷰] UMO: Scaling Multi-Identity Consistency for Image Customization via Matching Reward\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Fei Ding이 [arXiv]에 게시한 'UMO: Scaling Multi-Identity Consistency for Image Customization via Matching Reward' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-10 13:11:01+0900\",\"children\":\"2025년 9월 10일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Image Customization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image Customization\"]}],[\"$\",\"span\",\"Multi-Identity Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-Identity Generation\"]}],[\"$\",\"span\",\"Identity Consistency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Identity Consistency\"]}],[\"$\",\"span\",\"Identity Confusion\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Identity Confusion\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}],[\"$\",\"span\",\"Matching Reward\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Matching Reward\"]}],[\"$\",\"span\",\"Global Assignment\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Global Assignment\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-10-Staying_in_the_Sweet_Spot_Responsive_Reasoning_Evolution_via_Capability-Adaptive_Hint_Scaffolding\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-10-Staying_in_the_Sweet_Spot_Responsive_Reasoning_Evolution_via_Capability-Adaptive_Hint_Scaffolding/\",\"children\":\"[논문리뷰] Staying in the Sweet Spot: Responsive Reasoning Evolution via Capability-Adaptive Hint Scaffolding\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yongcheng Zeng이 [arXiv]에 게시한 'Staying in the Sweet Spot: Responsive Reasoning Evolution via Capability-Adaptive Hint Scaffolding' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-10 13:11:01+0900\",\"children\":\"2025년 9월 10일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"RLVR\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"RLVR\"]}],[\"$\",\"span\",\"LLM Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Reasoning\"]}],[\"$\",\"span\",\"Adaptive Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Adaptive Learning\"]}],[\"$\",\"span\",\"Hint Scaffolding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Hint Scaffolding\"]}],[\"$\",\"span\",\"Item Response Theory\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Item Response Theory\"]}],[\"$\",\"span\",\"Exploration Efficiency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Exploration Efficiency\"]}],[\"$\",\"span\",\"Problem Difficulty\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Problem Difficulty\"]}],[\"$\",\"span\",\"Policy Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Policy Optimization\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-10-SimpleQA_Verified_A_Reliable_Factuality_Benchmark_to_Measure_Parametric_Knowledge\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-10-SimpleQA_Verified_A_Reliable_Factuality_Benchmark_to_Measure_Parametric_Knowledge/\",\"children\":\"[논문리뷰] SimpleQA Verified: A Reliable Factuality Benchmark to Measure Parametric Knowledge\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Dipanjan Das이 [arXiv]에 게시한 'SimpleQA Verified: A Reliable Factuality Benchmark to Measure Parametric Knowledge' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-10 13:11:01+0900\",\"children\":\"2025년 9월 10일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLM Factuality\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Factuality\"]}],[\"$\",\"span\",\"Parametric Knowledge\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Parametric Knowledge\"]}],[\"$\",\"span\",\"Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmark\"]}],[\"$\",\"span\",\"Question Answering\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Question Answering\"]}],[\"$\",\"span\",\"Data Curation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Curation\"]}],[\"$\",\"span\",\"Evaluation Metrics\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Evaluation Metrics\"]}],[\"$\",\"span\",\"Hallucination Mitigation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Hallucination Mitigation\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-10-Reconstruction_Alignment_Improves_Unified_Multimodal_Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-10-Reconstruction_Alignment_Improves_Unified_Multimodal_Models/\",\"children\":\"[논문리뷰] Reconstruction Alignment Improves Unified Multimodal Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"XuDong Wang이 [arXiv]에 게시한 'Reconstruction Alignment Improves Unified Multimodal Models' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-10 13:11:01+0900\",\"children\":\"2025년 9월 10일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Unified Multimodal Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Unified Multimodal Models\"]}],[\"$\",\"span\",\"Image Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image Generation\"]}],[\"$\",\"span\",\"Image Editing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image Editing\"]}],[\"$\",\"span\",\"Post-training\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Post-training\"]}],[\"$\",\"span\",\"Self-supervised Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Self-supervised Learning\"]}],[\"$\",\"span\",\"Reconstruction Alignment\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reconstruction Alignment\"]}],[\"$\",\"span\",\"Visual Embeddings\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Visual Embeddings\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-10-Q-Sched_Pushing_the_Boundaries_of_Few-Step_Diffusion_Models_with_Quantization-Aware_Scheduling\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-10-Q-Sched_Pushing_the_Boundaries_of_Few-Step_Diffusion_Models_with_Quantization-Aware_Scheduling/\",\"children\":\"[논문리뷰] Q-Sched: Pushing the Boundaries of Few-Step Diffusion Models with Quantization-Aware Scheduling\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Diana Marculescu이 [arXiv]에 게시한 'Q-Sched: Pushing the Boundaries of Few-Step Diffusion Models with Quantization-Aware Scheduling' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-10 13:11:01+0900\",\"children\":\"2025년 9월 10일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}],[\"$\",\"span\",\"Quantization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Quantization\"]}],[\"$\",\"span\",\"Few-Step Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Few-Step Generation\"]}],[\"$\",\"span\",\"Model Compression\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Model Compression\"]}],[\"$\",\"span\",\"Noise Scheduling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Noise Scheduling\"]}],[\"$\",\"span\",\"Post-Training Quantization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Post-Training Quantization\"]}],[\"$\",\"span\",\"Image Quality Metrics\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image Quality Metrics\"]}],[\"$\",\"span\",\"Latent Consistency Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Latent Consistency Models\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-10-Parallel-R1_Towards_Parallel_Thinking_via_Reinforcement_Learning\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-10-Parallel-R1_Towards_Parallel_Thinking_via_Reinforcement_Learning/\",\"children\":\"[논문리뷰] Parallel-R1: Towards Parallel Thinking via Reinforcement Learning\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Xinyu Yang이 [arXiv]에 게시한 'Parallel-R1: Towards Parallel Thinking via Reinforcement Learning' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-10 13:11:01+0900\",\"children\":\"2025년 9월 10일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Parallel Thinking\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Parallel Thinking\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Mathematical Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Mathematical Reasoning\"]}],[\"$\",\"span\",\"Progressive Curriculum\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Progressive Curriculum\"]}],[\"$\",\"span\",\"Reward Design\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reward Design\"]}],[\"$\",\"span\",\"Exploration Scaffold\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Exploration Scaffold\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-10-Mini-o3_Scaling_Up_Reasoning_Patterns_and_Interaction_Turns_for_Visual_Search\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-10-Mini-o3_Scaling_Up_Reasoning_Patterns_and_Interaction_Turns_for_Visual_Search/\",\"children\":\"[논문리뷰] Mini-o3: Scaling Up Reasoning Patterns and Interaction Turns for Visual Search\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Tianjian Li이 [arXiv]에 게시한 'Mini-o3: Scaling Up Reasoning Patterns and Interaction Turns for Visual Search' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-10 13:11:01+0900\",\"children\":\"2025년 9월 10일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Visual Search\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Visual Search\"]}],[\"$\",\"span\",\"Multi-Turn Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-Turn Reasoning\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Tool-Integrated Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Tool-Integrated Agents\"]}],[\"$\",\"span\",\"Exploratory Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Exploratory Reasoning\"]}],[\"$\",\"span\",\"Data Augmentation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Augmentation\"]}],[\"$\",\"span\",\"Over-turn Masking\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Over-turn Masking\"]}],[\"$\",\"span\",\"Visual Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Visual Language Models\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-10-Language_Self-Play_For_Data-Free_Training\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-10-Language_Self-Play_For_Data-Free_Training/\",\"children\":\"[논문리뷰] Language Self-Play For Data-Free Training\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Vijai Mohan이 [arXiv]에 게시한 'Language Self-Play For Data-Free Training' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-10 13:11:01+0900\",\"children\":\"2025년 9월 10일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Self-Play\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Self-Play\"]}],[\"$\",\"span\",\"Data-Free Training\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data-Free Training\"]}],[\"$\",\"span\",\"Instruction Following\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Instruction Following\"]}],[\"$\",\"span\",\"Adversarial Training\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Adversarial Training\"]}],[\"$\",\"span\",\"Reward Modeling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reward Modeling\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-10-F1_A_Vision-Language-Action_Model_Bridging_Understanding_and_Generation_to_Actions\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-10-F1_A_Vision-Language-Action_Model_Bridging_Understanding_and_Generation_to_Actions/\",\"children\":\"[논문리뷰] F1: A Vision-Language-Action Model Bridging Understanding and Generation to Actions\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Zherui Qiu이 [arXiv]에 게시한 'F1: A Vision-Language-Action Model Bridging Understanding and Generation to Actions' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-10 13:11:01+0900\",\"children\":\"2025년 9월 10일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Vision-Language-Action\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision-Language-Action\"]}],[\"$\",\"span\",\"Embodied AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Embodied AI\"]}],[\"$\",\"span\",\"Visual Foresight\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Visual Foresight\"]}],[\"$\",\"span\",\"Predictive Inverse Dynamics\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Predictive Inverse Dynamics\"]}],[\"$\",\"span\",\"Mixture-of-Transformer\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Mixture-of-Transformer\"]}],[\"$\",\"span\",\"Robot Manipulation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Robot Manipulation\"]}],[\"$\",\"span\",\"Multi-stage Training\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-stage Training\"]}],[\"$\",\"span\",\"Generalization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generalization\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-10-Directly_Aligning_the_Full_Diffusion_Trajectory_with_Fine-Grained_Human_Preference\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-10-Directly_Aligning_the_Full_Diffusion_Trajectory_with_Fine-Grained_Human_Preference/\",\"children\":\"[논문리뷰] Directly Aligning the Full Diffusion Trajectory with Fine-Grained Human Preference\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yingfang Zhang이 [arXiv]에 게시한 'Directly Aligning the Full Diffusion Trajectory with Fine-Grained Human Preference' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-10 13:11:01+0900\",\"children\":\"2025년 9월 10일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Human Preference\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Human Preference\"]}],[\"$\",\"span\",\"Text-to-Image Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Text-to-Image Generation\"]}],[\"$\",\"span\",\"Reward Hacking\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reward Hacking\"]}],[\"$\",\"span\",\"Direct-Align\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Direct-Align\"]}],[\"$\",\"span\",\"SRPO\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"SRPO\"]}],[\"$\",\"span\",\"Fine-Grained Control\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Fine-Grained Control\"]}],[\"$\",\"span\",\"Flow Matching Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Flow Matching Models\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-10-Curia_A_Multi-Modal_Foundation_Model_for_Radiology\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-10-Curia_A_Multi-Modal_Foundation_Model_for_Radiology/\",\"children\":\"[논문리뷰] Curia: A Multi-Modal Foundation Model for Radiology\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Elodie Ferreres이 [arXiv]에 게시한 'Curia: A Multi-Modal Foundation Model for Radiology' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-10 13:11:01+0900\",\"children\":\"2025년 9월 10일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Foundation Model\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Foundation Model\"]}],[\"$\",\"span\",\"Radiology\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Radiology\"]}],[\"$\",\"span\",\"Computed Tomography (CT)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Computed Tomography (CT)\"]}],[\"$\",\"span\",\"Magnetic Resonance Imaging (MRI)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Magnetic Resonance Imaging (MRI)\"]}],[\"$\",\"span\",\"Self-supervised Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Self-supervised Learning\"]}],[\"$\",\"span\",\"Vision Transformer\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision Transformer\"]}],[\"$\",\"span\",\"Cross-Modality Generalization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Cross-Modality Generalization\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-10-Causal_Attention_with_Lookahead_Keys\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-10-Causal_Attention_with_Lookahead_Keys/\",\"children\":\"[논문리뷰] Causal Attention with Lookahead Keys\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Quanquan Gu이 [arXiv]에 게시한 'Causal Attention with Lookahead Keys' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-10 13:11:01+0900\",\"children\":\"2025년 9월 10일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Causal Attention\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Causal Attention\"]}],[\"$\",\"span\",\"Lookahead Keys\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Lookahead Keys\"]}],[\"$\",\"span\",\"Autoregressive Modeling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Autoregressive Modeling\"]}],[\"$\",\"span\",\"Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Language Models\"]}],[\"$\",\"span\",\"Transformer\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Transformer\"]}],[\"$\",\"span\",\"Perplexity Reduction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Perplexity Reduction\"]}],[\"$\",\"span\",\"Parallel Training\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Parallel Training\"]}],[\"$\",\"span\",\"Efficient Inference\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Efficient Inference\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-9-WebExplorer_Explore_and_Evolve_for_Training_Long-Horizon_Web_Agents\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-9-WebExplorer_Explore_and_Evolve_for_Training_Long-Horizon_Web_Agents/\",\"children\":\"[논문리뷰] WebExplorer: Explore and Evolve for Training Long-Horizon Web Agents\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Aili Chen이 [arXiv]에 게시한 'WebExplorer: Explore and Evolve for Training Long-Horizon Web Agents' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-09 13:19:09+0900\",\"children\":\"2025년 9월 9일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Web Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Web Agents\"]}],[\"$\",\"span\",\"Long-Horizon Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Long-Horizon Reasoning\"]}],[\"$\",\"span\",\"Large Language Models (LLMs)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models (LLMs)\"]}],[\"$\",\"span\",\"Data Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Generation\"]}],[\"$\",\"span\",\"Reinforcement Learning (RL)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning (RL)\"]}],[\"$\",\"span\",\"Supervised Fine-tuning (SFT)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Supervised Fine-tuning (SFT)\"]}],[\"$\",\"span\",\"Web Navigation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Web Navigation\"]}],[\"$\",\"span\",\"Information Retrieval\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Information Retrieval\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-9-UniVerse-1_Unified_Audio-Video_Generation_via_Stitching_of_Experts\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-9-UniVerse-1_Unified_Audio-Video_Generation_via_Stitching_of_Experts/\",\"children\":\"[논문리뷰] UniVerse-1: Unified Audio-Video Generation via Stitching of Experts\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Xinyao Liao이 [arXiv]에 게시한 'UniVerse-1: Unified Audio-Video Generation via Stitching of Experts' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-09 13:19:09+0900\",\"children\":\"2025년 9월 9일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Unified Audio-Video Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Unified Audio-Video Generation\"]}],[\"$\",\"span\",\"Stitching of Experts (SoE)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Stitching of Experts (SoE)\"]}],[\"$\",\"span\",\"Multimodal Diffusion\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Diffusion\"]}],[\"$\",\"span\",\"Online Annotation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Online Annotation\"]}],[\"$\",\"span\",\"Cross-modal Noise Correlation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Cross-modal Noise Correlation\"]}],[\"$\",\"span\",\"Foundation Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Foundation Models\"]}],[\"$\",\"span\",\"Verse-Bench\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Verse-Bench\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-9-Test-Time_Scaling_in_Reasoning_Models_Is_Not_Effective_for_Knowledge-Intensive_Tasks_Yet\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-9-Test-Time_Scaling_in_Reasoning_Models_Is_Not_Effective_for_Knowledge-Intensive_Tasks_Yet/\",\"children\":\"[논문리뷰] Test-Time Scaling in Reasoning Models Is Not Effective for Knowledge-Intensive Tasks Yet\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"See-Kiong Ng이 [arXiv]에 게시한 'Test-Time Scaling in Reasoning Models Is Not Effective for Knowledge-Intensive Tasks Yet' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-09 13:19:09+0900\",\"children\":\"2025년 9월 9일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Test-Time Scaling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Test-Time Scaling\"]}],[\"$\",\"span\",\"Reasoning Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reasoning Models\"]}],[\"$\",\"span\",\"Knowledge-Intensive Tasks\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Knowledge-Intensive Tasks\"]}],[\"$\",\"span\",\"Hallucinations\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Hallucinations\"]}],[\"$\",\"span\",\"Factual Accuracy\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Factual Accuracy\"]}],[\"$\",\"span\",\"Chain-of-Thought\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Chain-of-Thought\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-9-Scaling_up_Multi-Turn_Off-Policy_RL_and_Multi-Agent_Tree_Search_for_LLM_Step-Provers\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-9-Scaling_up_Multi-Turn_Off-Policy_RL_and_Multi-Agent_Tree_Search_for_LLM_Step-Provers/\",\"children\":\"[논문리뷰] Scaling up Multi-Turn Off-Policy RL and Multi-Agent Tree Search for LLM Step-Provers\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Xia Xiao이 [arXiv]에 게시한 'Scaling up Multi-Turn Off-Policy RL and Multi-Agent Tree Search for LLM Step-Provers' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-09 13:19:09+0900\",\"children\":\"2025년 9월 9일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLM Step-Provers\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Step-Provers\"]}],[\"$\",\"span\",\"Reinforcement Learning (RL)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning (RL)\"]}],[\"$\",\"span\",\"Off-Policy RL\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Off-Policy RL\"]}],[\"$\",\"span\",\"Multi-Agent Systems\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-Agent Systems\"]}],[\"$\",\"span\",\"Tree Search\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Tree Search\"]}],[\"$\",\"span\",\"Automated Theorem Proving (ATP)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Automated Theorem Proving (ATP)\"]}],[\"$\",\"span\",\"Formal Mathematics\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Formal Mathematics\"]}],[\"$\",\"span\",\"AlphaZero\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"AlphaZero\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-9-Saturation-Driven_Dataset_Generation_for_LLM_Mathematical_Reasoning_in_the_TPTP_Ecosystem\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-9-Saturation-Driven_Dataset_Generation_for_LLM_Mathematical_Reasoning_in_the_TPTP_Ecosystem/\",\"children\":\"[논문리뷰] Saturation-Driven Dataset Generation for LLM Mathematical Reasoning in the TPTP Ecosystem\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Damien Sileo이 [arXiv]에 게시한 'Saturation-Driven Dataset Generation for LLM Mathematical Reasoning in the TPTP Ecosystem' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-09 13:19:09+0900\",\"children\":\"2025년 9월 9일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Automated Theorem Proving\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Automated Theorem Proving\"]}],[\"$\",\"span\",\"LLM\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM\"]}],[\"$\",\"span\",\"Mathematical Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Mathematical Reasoning\"]}],[\"$\",\"span\",\"Synthetic Data Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Synthetic Data Generation\"]}],[\"$\",\"span\",\"TPTP Ecosystem\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"TPTP Ecosystem\"]}],[\"$\",\"span\",\"Saturation Proving\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Saturation Proving\"]}],[\"$\",\"span\",\"Proof Graph Reconstruction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Proof Graph Reconstruction\"]}],[\"$\",\"span\",\"Data Augmentation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Augmentation\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-9-Rtextbf2AI_Towards_Resistant_and_Resilient_AI_in_an_Evolving_World\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-9-Rtextbf2AI_Towards_Resistant_and_Resilient_AI_in_an_Evolving_World/\",\"children\":\"[논문리뷰] R^textbf{2AI}: Towards Resistant and Resilient AI in an Evolving World\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Bowen Zhou이 [arXiv]에 게시한 'R^textbf{2AI}: Towards Resistant and Resilient AI in an Evolving World' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-09 13:19:09+0900\",\"children\":\"2025년 9월 9일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"AI Safety\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"AI Safety\"]}],[\"$\",\"span\",\"Resistant AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Resistant AI\"]}],[\"$\",\"span\",\"Resilient AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Resilient AI\"]}],[\"$\",\"span\",\"Coevolution\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Coevolution\"]}],[\"$\",\"span\",\"Fast-Slow Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Fast-Slow Models\"]}],[\"$\",\"span\",\"Adversarial Training\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Adversarial Training\"]}],[\"$\",\"span\",\"Continual Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Continual Learning\"]}],[\"$\",\"span\",\"AGI Alignment\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"AGI Alignment\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-9-Revolutionizing_Reinforcement_Learning_Framework_for_Diffusion_Large_Language_Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-9-Revolutionizing_Reinforcement_Learning_Framework_for_Diffusion_Large_Language_Models/\",\"children\":\"[논문리뷰] Revolutionizing Reinforcement Learning Framework for Diffusion Large Language Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Ke Shen이 [arXiv]에 게시한 'Revolutionizing Reinforcement Learning Framework for Diffusion Large Language Models' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-09 13:19:09+0900\",\"children\":\"2025년 9월 9일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Diffusion Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Language Models\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Trajectory-aware RL\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Trajectory-aware RL\"]}],[\"$\",\"span\",\"Value Model\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Value Model\"]}],[\"$\",\"span\",\"Masked Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Masked Diffusion Models\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Reasoning Tasks\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reasoning Tasks\"]}],[\"$\",\"span\",\"Code Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Code Generation\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-9-Reverse-Engineered_Reasoning_for_Open-Ended_Generation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-9-Reverse-Engineered_Reasoning_for_Open-Ended_Generation/\",\"children\":\"[논문리뷰] Reverse-Engineered Reasoning for Open-Ended Generation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Wangchunshu Zhou이 [arXiv]에 게시한 'Reverse-Engineered Reasoning for Open-Ended Generation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-09 13:19:09+0900\",\"children\":\"2025년 9월 9일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Deep Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Deep Reasoning\"]}],[\"$\",\"span\",\"Open-Ended Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Open-Ended Generation\"]}],[\"$\",\"span\",\"Reverse-Engineered Reasoning (REER)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reverse-Engineered Reasoning (REER)\"]}],[\"$\",\"span\",\"LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLMs\"]}],[\"$\",\"span\",\"Synthetic Data\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Synthetic Data\"]}],[\"$\",\"span\",\"Iterative Refinement\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Iterative Refinement\"]}],[\"$\",\"span\",\"Perplexity Minimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Perplexity Minimization\"]}],[\"$\",\"span\",\"DeepWriting-20K\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"DeepWriting-20K\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-9-Reinforcement_Learning_Foundations_for_Deep_Research_Systems_A_Survey\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-9-Reinforcement_Learning_Foundations_for_Deep_Research_Systems_A_Survey/\",\"children\":\"[논문리뷰] Reinforcement Learning Foundations for Deep Research Systems: A Survey\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Wei Han이 [arXiv]에 게시한 'Reinforcement Learning Foundations for Deep Research Systems: A Survey' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-09 13:19:09+0900\",\"children\":\"2025년 9월 9일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Deep Research Systems\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Deep Research Systems\"]}],[\"$\",\"span\",\"Agentic AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Agentic AI\"]}],[\"$\",\"span\",\"Tool Use\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Tool Use\"]}],[\"$\",\"span\",\"Hierarchical Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Hierarchical Agents\"]}],[\"$\",\"span\",\"Reward Design\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reward Design\"]}],[\"$\",\"span\",\"Multimodal AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal AI\"]}],[\"$\",\"span\",\"RL Frameworks\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"RL Frameworks\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-9-Reinforced_Visual_Perception_with_Tools\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-9-Reinforced_Visual_Perception_with_Tools/\",\"children\":\"[논문리뷰] Reinforced Visual Perception with Tools\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Mingyang Fu이 [arXiv]에 게시한 'Reinforced Visual Perception with Tools' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-09 13:19:09+0900\",\"children\":\"2025년 9월 9일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Visual Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Visual Reasoning\"]}],[\"$\",\"span\",\"Multimodal LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal LLMs\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Tool Usage\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Tool Usage\"]}],[\"$\",\"span\",\"Perception-heavy Benchmarks\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Perception-heavy Benchmarks\"]}],[\"$\",\"span\",\"GRPO\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"GRPO\"]}],[\"$\",\"span\",\"Vision Tools\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision Tools\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-9-Paper2Agent_Reimagining_Research_Papers_As_Interactive_and_Reliable_AI_Agents\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-9-Paper2Agent_Reimagining_Research_Papers_As_Interactive_and_Reliable_AI_Agents/\",\"children\":\"[논문리뷰] Paper2Agent: Reimagining Research Papers As Interactive and Reliable AI Agents\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"James Zou이 [arXiv]에 게시한 'Paper2Agent: Reimagining Research Papers As Interactive and Reliable AI Agents' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-09 13:19:09+0900\",\"children\":\"2025년 9월 9일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"AI Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"AI Agents\"]}],[\"$\",\"span\",\"Research Reproducibility\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Research Reproducibility\"]}],[\"$\",\"span\",\"Scientific Communication\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Scientific Communication\"]}],[\"$\",\"span\",\"Model Context Protocol (MCP)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Model Context Protocol (MCP)\"]}],[\"$\",\"span\",\"Natural Language Interaction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Natural Language Interaction\"]}],[\"$\",\"span\",\"Genomics\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Genomics\"]}],[\"$\",\"span\",\"Single-Cell Analysis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Single-Cell Analysis\"]}],[\"$\",\"span\",\"Spatial Transcriptomics\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Spatial Transcriptomics\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-9-MAS-Bench_A_Unified_Benchmark_for_Shortcut-Augmented_Hybrid_Mobile_GUI_Agents\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-9-MAS-Bench_A_Unified_Benchmark_for_Shortcut-Augmented_Hybrid_Mobile_GUI_Agents/\",\"children\":\"[논문리뷰] MAS-Bench: A Unified Benchmark for Shortcut-Augmented Hybrid Mobile GUI Agents\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Zhengxi Lu이 [arXiv]에 게시한 'MAS-Bench: A Unified Benchmark for Shortcut-Augmented Hybrid Mobile GUI Agents' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-09 13:19:09+0900\",\"children\":\"2025년 9월 9일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Mobile GUI Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Mobile GUI Agents\"]}],[\"$\",\"span\",\"Hybrid Automation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Hybrid Automation\"]}],[\"$\",\"span\",\"Shortcut Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Shortcut Generation\"]}],[\"$\",\"span\",\"Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmark\"]}],[\"$\",\"span\",\"Task Efficiency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Task Efficiency\"]}],[\"$\",\"span\",\"LLM-based Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM-based Agents\"]}],[\"$\",\"span\",\"Mobile Robotics\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Mobile Robotics\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-9-Llama-GENBA-10B_A_Trilingual_Large_Language_Model_for_German_English_and_Bavarian\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-9-Llama-GENBA-10B_A_Trilingual_Large_Language_Model_for_German_English_and_Bavarian/\",\"children\":\"[논문리뷰] Llama-GENBA-10B: A Trilingual Large Language Model for German, English and Bavarian\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Hoi-Fong Mak이 [arXiv]에 게시한 'Llama-GENBA-10B: A Trilingual Large Language Model for German, English and Bavarian' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-09 13:19:09+0900\",\"children\":\"2025년 9월 9일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Multilingual LLM\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multilingual LLM\"]}],[\"$\",\"span\",\"Low-Resource Language\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Low-Resource Language\"]}],[\"$\",\"span\",\"German\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"German\"]}],[\"$\",\"span\",\"Bavarian Dialect\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Bavarian Dialect\"]}],[\"$\",\"span\",\"Cross-Lingual Transfer\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Cross-Lingual Transfer\"]}],[\"$\",\"span\",\"Continuous Pretraining\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Continuous Pretraining\"]}],[\"$\",\"span\",\"Llama-3.1\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Llama-3.1\"]}],[\"$\",\"span\",\"Model Expansion\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Model Expansion\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-9-Interleaving_Reasoning_for_Better_Text-to-Image_Generation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-9-Interleaving_Reasoning_for_Better_Text-to-Image_Generation/\",\"children\":\"[논문리뷰] Interleaving Reasoning for Better Text-to-Image Generation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Shixiang Tang이 [arXiv]에 게시한 'Interleaving Reasoning for Better Text-to-Image Generation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-09 13:19:09+0900\",\"children\":\"2025년 9월 9일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Text-to-Image Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Text-to-Image Generation\"]}],[\"$\",\"span\",\"Interleaving Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Interleaving Reasoning\"]}],[\"$\",\"span\",\"Multimodal Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Learning\"]}],[\"$\",\"span\",\"Visual Quality\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Visual Quality\"]}],[\"$\",\"span\",\"Fine-grained Detail\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Fine-grained Detail\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}],[\"$\",\"span\",\"Self-Correction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Self-Correction\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-9-Focusing_by_Contrastive_Attention_Enhancing_VLMs_Visual_Reasoning\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-9-Focusing_by_Contrastive_Attention_Enhancing_VLMs_Visual_Reasoning/\",\"children\":\"[논문리뷰] Focusing by Contrastive Attention: Enhancing VLMs' Visual Reasoning\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Baolong Bi이 [arXiv]에 게시한 'Focusing by Contrastive Attention: Enhancing VLMs' Visual Reasoning' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-09 13:19:09+0900\",\"children\":\"2025년 9월 9일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Vision-Language Models (VLMs)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision-Language Models (VLMs)\"]}],[\"$\",\"span\",\"Visual Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Visual Reasoning\"]}],[\"$\",\"span\",\"Attention Mechanisms\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Attention Mechanisms\"]}],[\"$\",\"span\",\"Contrastive Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Contrastive Learning\"]}],[\"$\",\"span\",\"Noise Suppression\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Noise Suppression\"]}],[\"$\",\"span\",\"Visual Complexity\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Visual Complexity\"]}],[\"$\",\"span\",\"Training-Free\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Training-Free\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-9-Easier_Painting_Than_Thinking_Can_Text-to-Image_Models_Set_the_Stage_but_Not_Direct_the_Play\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-9-Easier_Painting_Than_Thinking_Can_Text-to-Image_Models_Set_the_Stage_but_Not_Direct_the_Play/\",\"children\":\"[논문리뷰] Easier Painting Than Thinking: Can Text-to-Image Models Set the Stage, but Not Direct the Play?\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Rui Chen이 [arXiv]에 게시한 'Easier Painting Than Thinking: Can Text-to-Image Models Set the Stage, but Not Direct the Play?' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-09 13:19:09+0900\",\"children\":\"2025년 9월 9일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Text-to-Image Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Text-to-Image Generation\"]}],[\"$\",\"span\",\"T2I Benchmarking\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"T2I Benchmarking\"]}],[\"$\",\"span\",\"Compositional Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Compositional Reasoning\"]}],[\"$\",\"span\",\"Deductive Inference\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Deductive Inference\"]}],[\"$\",\"span\",\"Inductive Inference\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Inductive Inference\"]}],[\"$\",\"span\",\"Abductive Inference\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Abductive Inference\"]}],[\"$\",\"span\",\"MLLM Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"MLLM Evaluation\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-9-Does_DINOv3_Set_a_New_Medical_Vision_Standard\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-9-Does_DINOv3_Set_a_New_Medical_Vision_Standard/\",\"children\":\"[논문리뷰] Does DINOv3 Set a New Medical Vision Standard?\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Bailiang Jian이 [arXiv]에 게시한 'Does DINOv3 Set a New Medical Vision Standard?' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-09 13:19:09+0900\",\"children\":\"2025년 9월 9일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Medical Imaging\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Medical Imaging\"]}],[\"$\",\"span\",\"Foundation Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Foundation Models\"]}],[\"$\",\"span\",\"DINOv3\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"DINOv3\"]}],[\"$\",\"span\",\"Self-Supervised Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Self-Supervised Learning\"]}],[\"$\",\"span\",\"Vision Transformer\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision Transformer\"]}],[\"$\",\"span\",\"2D/3D Classification\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"2D/3D Classification\"]}],[\"$\",\"span\",\"Segmentation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Segmentation\"]}],[\"$\",\"span\",\"Domain Adaptation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Domain Adaptation\"]}],[\"$\",\"span\",\"Scaling Laws\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Scaling Laws\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-9-D-HUMOR_Dark_Humor_Understanding_via_Multimodal_Open-ended_Reasoning\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-9-D-HUMOR_Dark_Humor_Understanding_via_Multimodal_Open-ended_Reasoning/\",\"children\":\"[논문리뷰] D-HUMOR: Dark Humor Understanding via Multimodal Open-ended Reasoning\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Dhanvin Sanjay Namboodiri이 [arXiv]에 게시한 'D-HUMOR: Dark Humor Understanding via Multimodal Open-ended Reasoning' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-09 13:19:09+0900\",\"children\":\"2025년 9월 9일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Dark Humor Detection\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dark Humor Detection\"]}],[\"$\",\"span\",\"Multimodal Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Reasoning\"]}],[\"$\",\"span\",\"Vision-Language Models (VLMs)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision-Language Models (VLMs)\"]}],[\"$\",\"span\",\"Iterative Reasoning Refinement\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Iterative Reasoning Refinement\"]}],[\"$\",\"span\",\"Meme Analysis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Meme Analysis\"]}],[\"$\",\"span\",\"Content Moderation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Content Moderation\"]}],[\"$\",\"span\",\"Cross-Modal Attention\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Cross-Modal Attention\"]}],[\"$\",\"span\",\"Dataset Annotation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dataset Annotation\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-8-WinT3R_Window-Based_Streaming_Reconstruction_with_Camera_Token_Pool\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-8-WinT3R_Window-Based_Streaming_Reconstruction_with_Camera_Token_Pool/\",\"children\":\"[논문리뷰] WinT3R: Window-Based Streaming Reconstruction with Camera Token Pool\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Wenzheng Chang이 [arXiv]에 게시한 'WinT3R: Window-Based Streaming Reconstruction with Camera Token Pool' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-08 13:10:18+0900\",\"children\":\"2025년 9월 8일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Online 3D Reconstruction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Online 3D Reconstruction\"]}],[\"$\",\"span\",\"Camera Pose Estimation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Camera Pose Estimation\"]}],[\"$\",\"span\",\"Streaming Reconstruction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Streaming Reconstruction\"]}],[\"$\",\"span\",\"Sliding Window\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Sliding Window\"]}],[\"$\",\"span\",\"Camera Token Pool\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Camera Token Pool\"]}],[\"$\",\"span\",\"Real-time Performance\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Real-time Performance\"]}],[\"$\",\"span\",\"Computer Vision\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Computer Vision\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-8-WildScore_Benchmarking_MLLMs_in-the-Wild_Symbolic_Music_Reasoning\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-8-WildScore_Benchmarking_MLLMs_in-the-Wild_Symbolic_Music_Reasoning/\",\"children\":\"[논문리뷰] WildScore: Benchmarking MLLMs in-the-Wild Symbolic Music Reasoning\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Amit Namburi이 [arXiv]에 게시한 'WildScore: Benchmarking MLLMs in-the-Wild Symbolic Music Reasoning' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-08 13:10:18+0900\",\"children\":\"2025년 9월 8일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Multimodal Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Large Language Models\"]}],[\"$\",\"span\",\"Symbolic Music Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Symbolic Music Reasoning\"]}],[\"$\",\"span\",\"Music Score Analysis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Music Score Analysis\"]}],[\"$\",\"span\",\"Benchmarking\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmarking\"]}],[\"$\",\"span\",\"Visual Question Answering\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Visual Question Answering\"]}],[\"$\",\"span\",\"In-the-Wild Data\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"In-the-Wild Data\"]}],[\"$\",\"span\",\"Music Theory\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Music Theory\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-8-Why_Language_Models_Hallucinate\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-8-Why_Language_Models_Hallucinate/\",\"children\":\"[논문리뷰] Why Language Models Hallucinate\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Edwin Zhang이 [arXiv]에 게시한 'Why Language Models Hallucinate' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-08 13:10:18+0900\",\"children\":\"2025년 9월 8일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Language Models\"]}],[\"$\",\"span\",\"Hallucination\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Hallucination\"]}],[\"$\",\"span\",\"Pretraining\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Pretraining\"]}],[\"$\",\"span\",\"Post-training\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Post-training\"]}],[\"$\",\"span\",\"Evaluation Metrics\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Evaluation Metrics\"]}],[\"$\",\"span\",\"Binary Classification\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Binary Classification\"]}],[\"$\",\"span\",\"Uncertainty Quantification\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Uncertainty Quantification\"]}],[\"$\",\"span\",\"Calibration\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Calibration\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-8-U-ARM_Ultra_low-cost_general_teleoperation_interface_for_robot_manipulation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-8-U-ARM_Ultra_low-cost_general_teleoperation_interface_for_robot_manipulation/\",\"children\":\"[논문리뷰] U-ARM : Ultra low-cost general teleoperation interface for robot manipulation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Junda Huang이 [arXiv]에 게시한 'U-ARM : Ultra low-cost general teleoperation interface for robot manipulation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-08 13:10:18+0900\",\"children\":\"2025년 9월 8일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Teleoperation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Teleoperation\"]}],[\"$\",\"span\",\"Robot Manipulation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Robot Manipulation\"]}],[\"$\",\"span\",\"Low-Cost Hardware\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Low-Cost Hardware\"]}],[\"$\",\"span\",\"3D Printing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D Printing\"]}],[\"$\",\"span\",\"Leader-Follower System\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Leader-Follower System\"]}],[\"$\",\"span\",\"Data Collection\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Collection\"]}],[\"$\",\"span\",\"Robotics Interface\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Robotics Interface\"]}],[\"$\",\"span\",\"Open Source\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Open Source\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-8-Symbolic_Graphics_Programming_with_Large_Language_Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-8-Symbolic_Graphics_Programming_with_Large_Language_Models/\",\"children\":\"[논문리뷰] Symbolic Graphics Programming with Large Language Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Kaipeng Zhang이 [arXiv]에 게시한 'Symbolic Graphics Programming with Large Language Models' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-08 13:10:18+0900\",\"children\":\"2025년 9월 8일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Symbolic Graphics Programming\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Symbolic Graphics Programming\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"SVG Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"SVG Generation\"]}],[\"$\",\"span\",\"Text-to-Image Synthesis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Text-to-Image Synthesis\"]}],[\"$\",\"span\",\"Cross-Modal Alignment\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Cross-Modal Alignment\"]}],[\"$\",\"span\",\"Program Synthesis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Program Synthesis\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-8-Set_Block_Decoding_is_a_Language_Model_Inference_Accelerator\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-8-Set_Block_Decoding_is_a_Language_Model_Inference_Accelerator/\",\"children\":\"[논문리뷰] Set Block Decoding is a Language Model Inference Accelerator\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Jeremy Reizenstein이 [arXiv]에 게시한 'Set Block Decoding is a Language Model Inference Accelerator' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-08 13:10:18+0900\",\"children\":\"2025년 9월 8일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Language Model Inference\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Language Model Inference\"]}],[\"$\",\"span\",\"Acceleration\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Acceleration\"]}],[\"$\",\"span\",\"Set Block Decoding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Set Block Decoding\"]}],[\"$\",\"span\",\"Next Token Prediction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Next Token Prediction\"]}],[\"$\",\"span\",\"Masked Token Prediction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Masked Token Prediction\"]}],[\"$\",\"span\",\"Parallel Decoding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Parallel Decoding\"]}],[\"$\",\"span\",\"KV-caching\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"KV-caching\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-8-On_Robustness_and_Reliability_of_Benchmark-Based_Evaluation_of_LLMs\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-8-On_Robustness_and_Reliability_of_Benchmark-Based_Evaluation_of_LLMs/\",\"children\":\"[논문리뷰] On Robustness and Reliability of Benchmark-Based Evaluation of LLMs\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Kevin Roitero이 [arXiv]에 게시한 'On Robustness and Reliability of Benchmark-Based Evaluation of LLMs' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-08 13:10:18+0900\",\"children\":\"2025년 9월 8일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLM Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Evaluation\"]}],[\"$\",\"span\",\"Model Robustness\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Model Robustness\"]}],[\"$\",\"span\",\"Benchmark Reliability\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmark Reliability\"]}],[\"$\",\"span\",\"Paraphrasing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Paraphrasing\"]}],[\"$\",\"span\",\"Linguistic Variability\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Linguistic Variability\"]}],[\"$\",\"span\",\"Generalization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generalization\"]}],[\"$\",\"span\",\"Question Answering\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Question Answering\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-8-MedVista3D_Vision-Language_Modeling_for_Reducing_Diagnostic_Errors_in_3D_CT_Disease_Detection_Understanding_and_Reporting\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-8-MedVista3D_Vision-Language_Modeling_for_Reducing_Diagnostic_Errors_in_3D_CT_Disease_Detection_Understanding_and_Reporting/\",\"children\":\"[논문리뷰] MedVista3D: Vision-Language Modeling for Reducing Diagnostic Errors in 3D CT Disease Detection, Understanding and Reporting\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Vanessa Wildman이 [arXiv]에 게시한 'MedVista3D: Vision-Language Modeling for Reducing Diagnostic Errors in 3D CT Disease Detection, Understanding and Reporting' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-08 13:10:18+0900\",\"children\":\"2025년 9월 8일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"3D CT\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D CT\"]}],[\"$\",\"span\",\"Vision-Language Model\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision-Language Model\"]}],[\"$\",\"span\",\"Medical Imaging\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Medical Imaging\"]}],[\"$\",\"span\",\"Diagnostic Error Reduction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diagnostic Error Reduction\"]}],[\"$\",\"span\",\"Multi-scale Alignment\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-scale Alignment\"]}],[\"$\",\"span\",\"Semantic Enrichment\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Semantic Enrichment\"]}],[\"$\",\"span\",\"Radiology Reporting\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Radiology Reporting\"]}],[\"$\",\"span\",\"Zero-shot Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Zero-shot Learning\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-8-LuxDiT_Lighting_Estimation_with_Video_Diffusion_Transformer\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-8-LuxDiT_Lighting_Estimation_with_Video_Diffusion_Transformer/\",\"children\":\"[논문리뷰] LuxDiT: Lighting Estimation with Video Diffusion Transformer\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Sanja Fidler이 [arXiv]에 게시한 'LuxDiT: Lighting Estimation with Video Diffusion Transformer' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-08 13:10:18+0900\",\"children\":\"2025년 9월 8일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Lighting Estimation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Lighting Estimation\"]}],[\"$\",\"span\",\"HDR Environment Map\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"HDR Environment Map\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}],[\"$\",\"span\",\"Video Transformer\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video Transformer\"]}],[\"$\",\"span\",\"Low-Rank Adaptation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Low-Rank Adaptation\"]}],[\"$\",\"span\",\"Generative Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generative Models\"]}],[\"$\",\"span\",\"Synthetic Data\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Synthetic Data\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-8-LatticeWorld_A_Multimodal_Large_Language_Model-Empowered_Framework_for_Interactive_Complex_World_Generation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-8-LatticeWorld_A_Multimodal_Large_Language_Model-Empowered_Framework_for_Interactive_Complex_World_Generation/\",\"children\":\"[논문리뷰] LatticeWorld: A Multimodal Large Language Model-Empowered Framework for Interactive Complex World Generation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Zhan Zhao이 [arXiv]에 게시한 'LatticeWorld: A Multimodal Large Language Model-Empowered Framework for Interactive Complex World Generation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-08 13:10:18+0900\",\"children\":\"2025년 9월 8일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Multimodal LLM\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal LLM\"]}],[\"$\",\"span\",\"3D World Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D World Generation\"]}],[\"$\",\"span\",\"Unreal Engine 5\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Unreal Engine 5\"]}],[\"$\",\"span\",\"Procedural Content Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Procedural Content Generation\"]}],[\"$\",\"span\",\"Interactive Environments\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Interactive Environments\"]}],[\"$\",\"span\",\"Sim-to-Real\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Sim-to-Real\"]}],[\"$\",\"span\",\"Spatial Understanding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Spatial Understanding\"]}],[\"$\",\"span\",\"Multimodal Input\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Input\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-8-Bootstrapping_Task_Spaces_for_Self-Improvement\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-8-Bootstrapping_Task_Spaces_for_Self-Improvement/\",\"children\":\"[논문리뷰] Bootstrapping Task Spaces for Self-Improvement\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yoram Bachrach이 [arXiv]에 게시한 'Bootstrapping Task Spaces for Self-Improvement' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-08 13:10:18+0900\",\"children\":\"2025년 9월 8일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Reinforcement Learning (RL)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning (RL)\"]}],[\"$\",\"span\",\"Large Language Models (LLMs)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models (LLMs)\"]}],[\"$\",\"span\",\"Self-Improvement\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Self-Improvement\"]}],[\"$\",\"span\",\"Autocurriculum\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Autocurriculum\"]}],[\"$\",\"span\",\"Task-Space Exploration\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Task-Space Exploration\"]}],[\"$\",\"span\",\"Inference-Time Iteration\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Inference-Time Iteration\"]}],[\"$\",\"span\",\"Policy Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Policy Optimization\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-8-Behavioral_Fingerprinting_of_Large_Language_Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-8-Behavioral_Fingerprinting_of_Large_Language_Models/\",\"children\":\"[논문리뷰] Behavioral Fingerprinting of Large Language Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Xing Li이 [arXiv]에 게시한 'Behavioral Fingerprinting of Large Language Models' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-08 13:10:18+0900\",\"children\":\"2025년 9월 8일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Behavioral Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Behavioral Evaluation\"]}],[\"$\",\"span\",\"Model Alignment\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Model Alignment\"]}],[\"$\",\"span\",\"Sycophancy\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Sycophancy\"]}],[\"$\",\"span\",\"World Model Brittleness\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"World Model Brittleness\"]}],[\"$\",\"span\",\"Metacognition\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Metacognition\"]}],[\"$\",\"span\",\"Personality Profiling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Personality Profiling\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-5-Video-MTR_Reinforced_Multi-Turn_Reasoning_for_Long_Video_Understanding\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-5-Video-MTR_Reinforced_Multi-Turn_Reasoning_for_Long_Video_Understanding/\",\"children\":\"[논문리뷰] Video-MTR: Reinforced Multi-Turn Reasoning for Long Video Understanding\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Lionel Ni이 [arXiv]에 게시한 'Video-MTR: Reinforced Multi-Turn Reasoning for Long Video Understanding' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-05 13:07:20+0900\",\"children\":\"2025년 9월 5일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Long Video Understanding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Long Video Understanding\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Multi-Turn Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-Turn Reasoning\"]}],[\"$\",\"span\",\"MLLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"MLLMs\"]}],[\"$\",\"span\",\"Video Segment Selection\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video Segment Selection\"]}],[\"$\",\"span\",\"Bi-level Reward\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Bi-level Reward\"]}],[\"$\",\"span\",\"Question Answering\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Question Answering\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-5-Transition_Models_Rethinking_the_Generative_Learning_Objective\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-5-Transition_Models_Rethinking_the_Generative_Learning_Objective/\",\"children\":\"[논문리뷰] Transition Models: Rethinking the Generative Learning Objective\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yangguang Li이 [arXiv]에 게시한 'Transition Models: Rethinking the Generative Learning Objective' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-05 13:07:20+0900\",\"children\":\"2025년 9월 5일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Generative Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generative Models\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}],[\"$\",\"span\",\"Training Objective\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Training Objective\"]}],[\"$\",\"span\",\"Continuous-Time Dynamics\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Continuous-Time Dynamics\"]}],[\"$\",\"span\",\"State Transition\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"State Transition\"]}],[\"$\",\"span\",\"Few-Step Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Few-Step Generation\"]}],[\"$\",\"span\",\"Scalable Training\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Scalable Training\"]}],[\"$\",\"span\",\"Image Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image Generation\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-5-Towards_a_Unified_View_of_Large_Language_Model_Post-Training\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-5-Towards_a_Unified_View_of_Large_Language_Model_Post-Training/\",\"children\":\"[논문리뷰] Towards a Unified View of Large Language Model Post-Training\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Hongyi Liu이 [arXiv]에 게시한 'Towards a Unified View of Large Language Model Post-Training' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-05 13:07:20+0900\",\"children\":\"2025년 9월 5일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Large Language Models (LLMs)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models (LLMs)\"]}],[\"$\",\"span\",\"Post-Training\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Post-Training\"]}],[\"$\",\"span\",\"Reinforcement Learning (RL)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning (RL)\"]}],[\"$\",\"span\",\"Supervised Fine-Tuning (SFT)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Supervised Fine-Tuning (SFT)\"]}],[\"$\",\"span\",\"Policy Gradient\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Policy Gradient\"]}],[\"$\",\"span\",\"Unified Framework\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Unified Framework\"]}],[\"$\",\"span\",\"Hybrid Algorithms\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Hybrid Algorithms\"]}],[\"$\",\"span\",\"Bias-Variance Tradeoff\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Bias-Variance Tradeoff\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-5-NER_Retriever_Zero-Shot_Named_Entity_Retrieval_with_Type-Aware_Embeddings\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-5-NER_Retriever_Zero-Shot_Named_Entity_Retrieval_with_Type-Aware_Embeddings/\",\"children\":\"[논문리뷰] NER Retriever: Zero-Shot Named Entity Retrieval with Type-Aware Embeddings\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Oren Glickman이 [arXiv]에 게시한 'NER Retriever: Zero-Shot Named Entity Retrieval with Type-Aware Embeddings' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-05 13:07:20+0900\",\"children\":\"2025년 9월 5일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Named Entity Retrieval\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Named Entity Retrieval\"]}],[\"$\",\"span\",\"Zero-Shot Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Zero-Shot Learning\"]}],[\"$\",\"span\",\"Type-Aware Embeddings\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Type-Aware Embeddings\"]}],[\"$\",\"span\",\"Large Language Models (LLMs)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models (LLMs)\"]}],[\"$\",\"span\",\"Contrastive Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Contrastive Learning\"]}],[\"$\",\"span\",\"Internal Representations\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Internal Representations\"]}],[\"$\",\"span\",\"Information Retrieval\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Information Retrieval\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-5-Inverse_IFEval_Can_LLMs_Unlearn_Stubborn_Training_Conventions_to_Follow_Real_Instructions\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-5-Inverse_IFEval_Can_LLMs_Unlearn_Stubborn_Training_Conventions_to_Follow_Real_Instructions/\",\"children\":\"[논문리뷰] Inverse IFEval: Can LLMs Unlearn Stubborn Training Conventions to Follow Real Instructions?\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yu Fu이 [arXiv]에 게시한 'Inverse IFEval: Can LLMs Unlearn Stubborn Training Conventions to Follow Real Instructions?' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-05 13:07:20+0900\",\"children\":\"2025년 9월 5일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLMs\"]}],[\"$\",\"span\",\"Instruction Following\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Instruction Following\"]}],[\"$\",\"span\",\"Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmark\"]}],[\"$\",\"span\",\"Cognitive Inertia\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Cognitive Inertia\"]}],[\"$\",\"span\",\"Out-of-Distribution\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Out-of-Distribution\"]}],[\"$\",\"span\",\"Supervised Fine-Tuning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Supervised Fine-Tuning\"]}],[\"$\",\"span\",\"Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Evaluation\"]}],[\"$\",\"span\",\"Robustness\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Robustness\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-5-From_Editor_to_Dense_Geometry_Estimator\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-5-From_Editor_to_Dense_Geometry_Estimator/\",\"children\":\"[논문리뷰] From Editor to Dense Geometry Estimator\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Lang Nie이 [arXiv]에 게시한 'From Editor to Dense Geometry Estimator' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-05 13:07:20+0900\",\"children\":\"2025년 9월 5일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Dense Geometry Estimation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dense Geometry Estimation\"]}],[\"$\",\"span\",\"Diffusion Transformer\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Transformer\"]}],[\"$\",\"span\",\"Image Editing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image Editing\"]}],[\"$\",\"span\",\"Zero-shot Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Zero-shot Learning\"]}],[\"$\",\"span\",\"Depth Estimation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Depth Estimation\"]}],[\"$\",\"span\",\"Normal Estimation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Normal Estimation\"]}],[\"$\",\"span\",\"Flow Matching\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Flow Matching\"]}],[\"$\",\"span\",\"Logarithmic Quantization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Logarithmic Quantization\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-5-Few-step_Flow_for_3D_Generation_via_Marginal-Data_Transport_Distillation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-5-Few-step_Flow_for_3D_Generation_via_Marginal-Data_Transport_Distillation/\",\"children\":\"[논문리뷰] Few-step Flow for 3D Generation via Marginal-Data Transport Distillation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Lingxi Xie이 [arXiv]에 게시한 'Few-step Flow for 3D Generation via Marginal-Data Transport Distillation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-05 13:07:20+0900\",\"children\":\"2025년 9월 5일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"3D Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D Generation\"]}],[\"$\",\"span\",\"Flow-based Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Flow-based Models\"]}],[\"$\",\"span\",\"Model Distillation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Model Distillation\"]}],[\"$\",\"span\",\"Few-step Sampling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Few-step Sampling\"]}],[\"$\",\"span\",\"Marginal-Data Transport\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Marginal-Data Transport\"]}],[\"$\",\"span\",\"Velocity Matching\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Velocity Matching\"]}],[\"$\",\"span\",\"Velocity Distillation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Velocity Distillation\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-5-False_Sense_of_Security_Why_Probing-based_Malicious_Input_Detection_Fails_to_Generalize\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-5-False_Sense_of_Security_Why_Probing-based_Malicious_Input_Detection_Fails_to_Generalize/\",\"children\":\"[논문리뷰] False Sense of Security: Why Probing-based Malicious Input Detection Fails to Generalize\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Muhao Chen이 [arXiv]에 게시한 'False Sense of Security: Why Probing-based Malicious Input Detection Fails to Generalize' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-05 13:07:20+0900\",\"children\":\"2025년 9월 5일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLM Safety\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Safety\"]}],[\"$\",\"span\",\"Malicious Input Detection\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Malicious Input Detection\"]}],[\"$\",\"span\",\"Probing Classifiers\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Probing Classifiers\"]}],[\"$\",\"span\",\"Out-of-Distribution Generalization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Out-of-Distribution Generalization\"]}],[\"$\",\"span\",\"Superficial Patterns\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Superficial Patterns\"]}],[\"$\",\"span\",\"Instructional Patterns\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Instructional Patterns\"]}],[\"$\",\"span\",\"Trigger Words\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Trigger Words\"]}],[\"$\",\"span\",\"AI Safety\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"AI Safety\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-5-Durian_Dual_Reference-guided_Portrait_Animation_with_Attribute_Transfer\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-5-Durian_Dual_Reference-guided_Portrait_Animation_with_Attribute_Transfer/\",\"children\":\"[논문리뷰] Durian: Dual Reference-guided Portrait Animation with Attribute Transfer\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Hanbyul Joo이 [arXiv]에 게시한 'Durian: Dual Reference-guided Portrait Animation with Attribute Transfer' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-05 13:07:20+0900\",\"children\":\"2025년 9월 5일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Portrait Animation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Portrait Animation\"]}],[\"$\",\"span\",\"Attribute Transfer\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Attribute Transfer\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}],[\"$\",\"span\",\"Dual Reference Networks\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dual Reference Networks\"]}],[\"$\",\"span\",\"Zero-shot Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Zero-shot Learning\"]}],[\"$\",\"span\",\"Self-Reconstruction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Self-Reconstruction\"]}],[\"$\",\"span\",\"Facial Editing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Facial Editing\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-5-Drivel-ology_Challenging_LLMs_with_Interpreting_Nonsense_with_Depth\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-5-Drivel-ology_Challenging_LLMs_with_Interpreting_Nonsense_with_Depth/\",\"children\":\"[논문리뷰] Drivel-ology: Challenging LLMs with Interpreting Nonsense with Depth\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Chi-Li Chen이 [arXiv]에 게시한 'Drivel-ology: Challenging LLMs with Interpreting Nonsense with Depth' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-05 13:07:20+0900\",\"children\":\"2025년 9월 5일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Pragmatic Understanding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Pragmatic Understanding\"]}],[\"$\",\"span\",\"Drivelology\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Drivelology\"]}],[\"$\",\"span\",\"Benchmark Dataset\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmark Dataset\"]}],[\"$\",\"span\",\"Multilingual NLP\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multilingual NLP\"]}],[\"$\",\"span\",\"Semantic Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Semantic Reasoning\"]}],[\"$\",\"span\",\"Contextual Inference\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Contextual Inference\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-5-Drawing2CAD_Sequence-to-Sequence_Learning_for_CAD_Generation_from_Vector_Drawings\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-5-Drawing2CAD_Sequence-to-Sequence_Learning_for_CAD_Generation_from_Vector_Drawings/\",\"children\":\"[논문리뷰] Drawing2CAD: Sequence-to-Sequence Learning for CAD Generation from Vector Drawings\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Meie Fang이 [arXiv]에 게시한 'Drawing2CAD: Sequence-to-Sequence Learning for CAD Generation from Vector Drawings' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-05 13:07:20+0900\",\"children\":\"2025년 9월 5일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"CAD Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"CAD Generation\"]}],[\"$\",\"span\",\"Vector Graphics\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vector Graphics\"]}],[\"$\",\"span\",\"Sequence-to-Sequence Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Sequence-to-Sequence Learning\"]}],[\"$\",\"span\",\"Transformer Architecture\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Transformer Architecture\"]}],[\"$\",\"span\",\"Engineering Drawings\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Engineering Drawings\"]}],[\"$\",\"span\",\"Multi-modal Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-modal Learning\"]}],[\"$\",\"span\",\"Soft Target Loss\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Soft Target Loss\"]}],[\"$\",\"span\",\"Dual Decoder\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dual Decoder\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-5-Delta_Activations_A_Representation_for_Finetuned_Large_Language_Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-5-Delta_Activations_A_Representation_for_Finetuned_Large_Language_Models/\",\"children\":\"[논문리뷰] Delta Activations: A Representation for Finetuned Large Language Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Ser-Nam Lim이 [arXiv]에 게시한 'Delta Activations: A Representation for Finetuned Large Language Models' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-05 13:07:20+0900\",\"children\":\"2025년 9월 5일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLM Embedding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Embedding\"]}],[\"$\",\"span\",\"Delta Activations\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Delta Activations\"]}],[\"$\",\"span\",\"Finetuned Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Finetuned Models\"]}],[\"$\",\"span\",\"Model Representation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Model Representation\"]}],[\"$\",\"span\",\"Model Clustering\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Model Clustering\"]}],[\"$\",\"span\",\"Additive Property\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Additive Property\"]}],[\"$\",\"span\",\"Task Embedding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Task Embedding\"]}],[\"$\",\"span\",\"Model Merging\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Model Merging\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-5-DeepResearch_Arena_The_First_Exam_of_LLMs_Research_Abilities_via_Seminar-Grounded_Tasks\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-5-DeepResearch_Arena_The_First_Exam_of_LLMs_Research_Abilities_via_Seminar-Grounded_Tasks/\",\"children\":\"[논문리뷰] DeepResearch Arena: The First Exam of LLMs' Research Abilities via Seminar-Grounded Tasks\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Jiaxuan Lu이 [arXiv]에 게시한 'DeepResearch Arena: The First Exam of LLMs' Research Abilities via Seminar-Grounded Tasks' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-05 13:07:20+0900\",\"children\":\"2025년 9월 5일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLM Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Evaluation\"]}],[\"$\",\"span\",\"Research Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Research Agents\"]}],[\"$\",\"span\",\"Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmark\"]}],[\"$\",\"span\",\"Multi-Agent System\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-Agent System\"]}],[\"$\",\"span\",\"Seminar-Grounded Tasks\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Seminar-Grounded Tasks\"]}],[\"$\",\"span\",\"Data Leakage Prevention\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Leakage Prevention\"]}],[\"$\",\"span\",\"Ill-Structured Problems\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Ill-Structured Problems\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-4-Robix_A_Unified_Model_for_Robot_Interaction_Reasoning_and_Planning\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-4-Robix_A_Unified_Model_for_Robot_Interaction_Reasoning_and_Planning/\",\"children\":\"[논문리뷰] Robix: A Unified Model for Robot Interaction, Reasoning and Planning\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Zixuan Wang이 [arXiv]에 게시한 'Robix: A Unified Model for Robot Interaction, Reasoning and Planning' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-04 12:56:15+0900\",\"children\":\"2025년 9월 4일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Robot Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Robot Learning\"]}],[\"$\",\"span\",\"Vision-Language Models (VLMs)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision-Language Models (VLMs)\"]}],[\"$\",\"span\",\"Embodied AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Embodied AI\"]}],[\"$\",\"span\",\"Human-Robot Interaction (HRI)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Human-Robot Interaction (HRI)\"]}],[\"$\",\"span\",\"Task Planning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Task Planning\"]}],[\"$\",\"span\",\"Reinforcement Learning (RL)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning (RL)\"]}],[\"$\",\"span\",\"Chain-of-Thought (CoT) Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Chain-of-Thought (CoT) Reasoning\"]}],[\"$\",\"span\",\"Robotics\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Robotics\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-4-Open_Data_Synthesis_For_Deep_Research\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-4-Open_Data_Synthesis_For_Deep_Research/\",\"children\":\"[논문리뷰] Open Data Synthesis For Deep Research\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Zheng Liu이 [arXiv]에 게시한 'Open Data Synthesis For Deep Research' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-04 12:56:15+0900\",\"children\":\"2025년 9월 4일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Data Synthesis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Synthesis\"]}],[\"$\",\"span\",\"Deep Research\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Deep Research\"]}],[\"$\",\"span\",\"Hierarchical Constraint Satisfaction Problems\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Hierarchical Constraint Satisfaction Problems\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Agentic AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Agentic AI\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Question Answering\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Question Answering\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-4-MOSAIC_Multi-Subject_Personalized_Generation_via_Correspondence-Aware_Alignment_and_Disentanglement\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-4-MOSAIC_Multi-Subject_Personalized_Generation_via_Correspondence-Aware_Alignment_and_Disentanglement/\",\"children\":\"[논문리뷰] MOSAIC: Multi-Subject Personalized Generation via Correspondence-Aware Alignment and Disentanglement\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Hualiang Wang이 [arXiv]에 게시한 'MOSAIC: Multi-Subject Personalized Generation via Correspondence-Aware Alignment and Disentanglement' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-04 12:56:15+0900\",\"children\":\"2025년 9월 4일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Multi-Subject Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-Subject Generation\"]}],[\"$\",\"span\",\"Personalized Image Synthesis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Personalized Image Synthesis\"]}],[\"$\",\"span\",\"Semantic Correspondence\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Semantic Correspondence\"]}],[\"$\",\"span\",\"Attention Disentanglement\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Attention Disentanglement\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}],[\"$\",\"span\",\"Identity Preservation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Identity Preservation\"]}],[\"$\",\"span\",\"Dataset\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dataset\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-4-Mixture_of_Global_and_Local_Experts_with_Diffusion_Transformer_for_Controllable_Face_Generation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-4-Mixture_of_Global_and_Local_Experts_with_Diffusion_Transformer_for_Controllable_Face_Generation/\",\"children\":\"[논문리뷰] Mixture of Global and Local Experts with Diffusion Transformer for Controllable Face Generation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Kai Li이 [arXiv]에 게시한 'Mixture of Global and Local Experts with Diffusion Transformer for Controllable Face Generation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-04 12:56:15+0900\",\"children\":\"2025년 9월 4일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Diffusion Transformer\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Transformer\"]}],[\"$\",\"span\",\"Mixture of Experts\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Mixture of Experts\"]}],[\"$\",\"span\",\"Controllable Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Controllable Generation\"]}],[\"$\",\"span\",\"Face Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Face Generation\"]}],[\"$\",\"span\",\"Multimodal Synthesis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Synthesis\"]}],[\"$\",\"span\",\"Semantic Control\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Semantic Control\"]}],[\"$\",\"span\",\"Image Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image Generation\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-4-LMEnt_A_Suite_for_Analyzing_Knowledge_in_Language_Models_from_Pretraining_Data_to_Representations\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-4-LMEnt_A_Suite_for_Analyzing_Knowledge_in_Language_Models_from_Pretraining_Data_to_Representations/\",\"children\":\"[논문리뷰] LMEnt: A Suite for Analyzing Knowledge in Language Models from Pretraining Data to Representations\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yoav Gur-Arieh이 [arXiv]에 게시한 'LMEnt: A Suite for Analyzing Knowledge in Language Models from Pretraining Data to Representations' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-04 12:56:15+0900\",\"children\":\"2025년 9월 4일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Language Models\"]}],[\"$\",\"span\",\"Knowledge Acquisition\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Knowledge Acquisition\"]}],[\"$\",\"span\",\"Pretraining Data\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Pretraining Data\"]}],[\"$\",\"span\",\"Entity Linking\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Entity Linking\"]}],[\"$\",\"span\",\"Coreference Resolution\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Coreference Resolution\"]}],[\"$\",\"span\",\"Information Retrieval\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Information Retrieval\"]}],[\"$\",\"span\",\"Model Analysis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Model Analysis\"]}],[\"$\",\"span\",\"Checkpoints\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Checkpoints\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-3-ViSTA-SLAM_Visual_SLAM_with_Symmetric_Two-view_Association\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-3-ViSTA-SLAM_Visual_SLAM_with_Symmetric_Two-view_Association/\",\"children\":\"[논문리뷰] ViSTA-SLAM: Visual SLAM with Symmetric Two-view Association\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Daniel Cremers이 [arXiv]에 게시한 'ViSTA-SLAM: Visual SLAM with Symmetric Two-view Association' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-03 13:36:21+0900\",\"children\":\"2025년 9월 3일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Monocular SLAM\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Monocular SLAM\"]}],[\"$\",\"span\",\"Dense Reconstruction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dense Reconstruction\"]}],[\"$\",\"span\",\"Neural Networks\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Neural Networks\"]}],[\"$\",\"span\",\"Pose Graph Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Pose Graph Optimization\"]}],[\"$\",\"span\",\"Intrinsics-free\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Intrinsics-free\"]}],[\"$\",\"span\",\"Real-time\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Real-time\"]}],[\"$\",\"span\",\"Two-view Association\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Two-view Association\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-3-VerlTool_Towards_Holistic_Agentic_Reinforcement_Learning_with_Tool_Use\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-3-VerlTool_Towards_Holistic_Agentic_Reinforcement_Learning_with_Tool_Use/\",\"children\":\"[논문리뷰] VerlTool: Towards Holistic Agentic Reinforcement Learning with Tool Use\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Zhiheng Lyu이 [arXiv]에 게시한 'VerlTool: Towards Holistic Agentic Reinforcement Learning with Tool Use' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-03 13:36:21+0900\",\"children\":\"2025년 9월 3일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Agentic Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Agentic Reinforcement Learning\"]}],[\"$\",\"span\",\"Tool Use\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Tool Use\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Reinforcement Learning from Verifiable Rewards (RLVR)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning from Verifiable Rewards (RLVR)\"]}],[\"$\",\"span\",\"Asynchronous Execution\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Asynchronous Execution\"]}],[\"$\",\"span\",\"Multi-modal AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-modal AI\"]}],[\"$\",\"span\",\"Framework\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Framework\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-3-Universal_Deep_Research_Bring_Your_Own_Model_and_Strategy\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-3-Universal_Deep_Research_Bring_Your_Own_Model_and_Strategy/\",\"children\":\"[논문리뷰] Universal Deep Research: Bring Your Own Model and Strategy\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Pavlo Molchanov이 [arXiv]에 게시한 'Universal Deep Research: Bring Your Own Model and Strategy' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-03 13:36:21+0900\",\"children\":\"2025년 9월 3일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Agentic Systems\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Agentic Systems\"]}],[\"$\",\"span\",\"Language Models (LLMs)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Language Models (LLMs)\"]}],[\"$\",\"span\",\"Research Automation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Research Automation\"]}],[\"$\",\"span\",\"Customizable Strategies\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Customizable Strategies\"]}],[\"$\",\"span\",\"Code Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Code Generation\"]}],[\"$\",\"span\",\"Deep Research\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Deep Research\"]}],[\"$\",\"span\",\"User-Defined Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"User-Defined Agents\"]}],[\"$\",\"span\",\"Sandboxed Execution\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Sandboxed Execution\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-3-UI-TARS-2_Technical_Report_Advancing_GUI_Agent_with_Multi-Turn_Reinforcement_Learning\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-3-UI-TARS-2_Technical_Report_Advancing_GUI_Agent_with_Multi-Turn_Reinforcement_Learning/\",\"children\":\"[논문리뷰] UI-TARS-2 Technical Report: Advancing GUI Agent with Multi-Turn Reinforcement Learning\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Haoyang Zou이 [arXiv]에 게시한 'UI-TARS-2 Technical Report: Advancing GUI Agent with Multi-Turn Reinforcement Learning' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-03 13:36:21+0900\",\"children\":\"2025년 9월 3일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"GUI Agent\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"GUI Agent\"]}],[\"$\",\"span\",\"Multi-Turn RL\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-Turn RL\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Data Flywheel\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Flywheel\"]}],[\"$\",\"span\",\"Agent Framework\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Agent Framework\"]}],[\"$\",\"span\",\"Hybrid Environments\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Hybrid Environments\"]}],[\"$\",\"span\",\"Parameter Interpolation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Parameter Interpolation\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-3-Towards_More_Diverse_and_Challenging_Pre-training_for_Point_Cloud_Learning_Self-Supervised_Cross_Reconstruction_with_Decoupled_Views\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-3-Towards_More_Diverse_and_Challenging_Pre-training_for_Point_Cloud_Learning_Self-Supervised_Cross_Reconstruction_with_Decoupled_Views/\",\"children\":\"[논문리뷰] Towards More Diverse and Challenging Pre-training for Point Cloud Learning: Self-Supervised Cross Reconstruction with Decoupled Views\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Junchi Yan이 [arXiv]에 게시한 'Towards More Diverse and Challenging Pre-training for Point Cloud Learning: Self-Supervised Cross Reconstruction with Decoupled Views' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-03 13:36:21+0900\",\"children\":\"2025년 9월 3일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Point Cloud Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Point Cloud Learning\"]}],[\"$\",\"span\",\"Self-Supervised Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Self-Supervised Learning\"]}],[\"$\",\"span\",\"Cross Reconstruction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Cross Reconstruction\"]}],[\"$\",\"span\",\"Decoupled Views\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Decoupled Views\"]}],[\"$\",\"span\",\"Generative Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generative Models\"]}],[\"$\",\"span\",\"Positional Encoding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Positional Encoding\"]}],[\"$\",\"span\",\"3D Vision\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D Vision\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-3-The_Landscape_of_Agentic_Reinforcement_Learning_for_LLMs_A_Survey\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-3-The_Landscape_of_Agentic_Reinforcement_Learning_for_LLMs_A_Survey/\",\"children\":\"[논문리뷰] The Landscape of Agentic Reinforcement Learning for LLMs: A Survey\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Hejia Geng이 [arXiv]에 게시한 'The Landscape of Agentic Reinforcement Learning for LLMs: A Survey' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-03 13:36:21+0900\",\"children\":\"2025년 9월 3일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Agentic Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Agentic Reinforcement Learning\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"LLM Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Agents\"]}],[\"$\",\"span\",\"Sequential Decision Making\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Sequential Decision Making\"]}],[\"$\",\"span\",\"Policy Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Policy Optimization\"]}],[\"$\",\"span\",\"Tool Use\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Tool Use\"]}],[\"$\",\"span\",\"Dynamic Environments\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dynamic Environments\"]}],[\"$\",\"span\",\"Autonomous AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Autonomous AI\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-3-The_Gold_Medals_in_an_Empty_Room_Diagnosing_Metalinguistic_Reasoning_in_LLMs_with_Camlang\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-3-The_Gold_Medals_in_an_Empty_Room_Diagnosing_Metalinguistic_Reasoning_in_LLMs_with_Camlang/\",\"children\":\"[논문리뷰] The Gold Medals in an Empty Room: Diagnosing Metalinguistic Reasoning in LLMs with Camlang\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Solomon Tsai이 [arXiv]에 게시한 'The Gold Medals in an Empty Room: Diagnosing Metalinguistic Reasoning in LLMs with Camlang' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-03 13:36:21+0900\",\"children\":\"2025년 9월 3일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLMs\"]}],[\"$\",\"span\",\"Metalinguistic Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Metalinguistic Reasoning\"]}],[\"$\",\"span\",\"Constructed Language\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Constructed Language\"]}],[\"$\",\"span\",\"Camlang\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Camlang\"]}],[\"$\",\"span\",\"Second Language Acquisition\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Second Language Acquisition\"]}],[\"$\",\"span\",\"Zero-shot Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Zero-shot Learning\"]}],[\"$\",\"span\",\"Natural Language Understanding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Natural Language Understanding\"]}],[\"$\",\"span\",\"Commonsense Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Commonsense Reasoning\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-3-SQL-of-Thought_Multi-agentic_Text-to-SQL_with_Guided_Error_Correction\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-3-SQL-of-Thought_Multi-agentic_Text-to-SQL_with_Guided_Error_Correction/\",\"children\":\"[논문리뷰] SQL-of-Thought: Multi-agentic Text-to-SQL with Guided Error Correction\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"bindsch이 [arXiv]에 게시한 'SQL-of-Thought: Multi-agentic Text-to-SQL with Guided Error Correction' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-03 13:36:21+0900\",\"children\":\"2025년 9월 3일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Text-to-SQL\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Text-to-SQL\"]}],[\"$\",\"span\",\"Multi-agent Systems\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-agent Systems\"]}],[\"$\",\"span\",\"Chain-of-Thought\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Chain-of-Thought\"]}],[\"$\",\"span\",\"Error Correction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Error Correction\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Query Planning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Query Planning\"]}],[\"$\",\"span\",\"Database Interaction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Database Interaction\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-3-SimpleTIR_End-to-End_Reinforcement_Learning_for_Multi-Turn_Tool-Integrated_Reasoning\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-3-SimpleTIR_End-to-End_Reinforcement_Learning_for_Multi-Turn_Tool-Integrated_Reasoning/\",\"children\":\"[논문리뷰] SimpleTIR: End-to-End Reinforcement Learning for Multi-Turn Tool-Integrated Reasoning\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Qian Liu이 [arXiv]에 게시한 'SimpleTIR: End-to-End Reinforcement Learning for Multi-Turn Tool-Integrated Reasoning' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-03 13:36:21+0900\",\"children\":\"2025년 9월 3일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Tool-Integrated Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Tool-Integrated Reasoning\"]}],[\"$\",\"span\",\"Multi-turn Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-turn Reasoning\"]}],[\"$\",\"span\",\"Gradient Explosion\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Gradient Explosion\"]}],[\"$\",\"span\",\"Training Stability\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Training Stability\"]}],[\"$\",\"span\",\"Trajectory Filtering\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Trajectory Filtering\"]}],[\"$\",\"span\",\"Zero RL\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Zero RL\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-3-Reasoning_Vectors_Transferring_Chain-of-Thought_Capabilities_via_Task_Arithmetic\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-3-Reasoning_Vectors_Transferring_Chain-of-Thought_Capabilities_via_Task_Arithmetic/\",\"children\":\"[논문리뷰] Reasoning Vectors: Transferring Chain-of-Thought Capabilities via Task Arithmetic\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Bernard Ghanem이 [arXiv]에 게시한 'Reasoning Vectors: Transferring Chain-of-Thought Capabilities via Task Arithmetic' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-03 13:36:21+0900\",\"children\":\"2025년 9월 3일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Reasoning Vectors\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reasoning Vectors\"]}],[\"$\",\"span\",\"Task Arithmetic\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Task Arithmetic\"]}],[\"$\",\"span\",\"Chain-of-Thought\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Chain-of-Thought\"]}],[\"$\",\"span\",\"LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLMs\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Model Merging\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Model Merging\"]}],[\"$\",\"span\",\"Parameter Transfer\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Parameter Transfer\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-3-POINTS-Reader_Distillation-Free_Adaptation_of_Vision-Language_Models_for_Document_Conversion\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-3-POINTS-Reader_Distillation-Free_Adaptation_of_Vision-Language_Models_for_Document_Conversion/\",\"children\":\"[논문리뷰] POINTS-Reader: Distillation-Free Adaptation of Vision-Language Models for Document Conversion\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Haicheng Wang이 [arXiv]에 게시한 'POINTS-Reader: Distillation-Free Adaptation of Vision-Language Models for Document Conversion' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-03 13:36:21+0900\",\"children\":\"2025년 9월 3일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"문서 변환\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"문서 변환\"]}],[\"$\",\"span\",\"시각-언어 모델\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"시각-언어 모델\"]}],[\"$\",\"span\",\"자가 개선\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"자가 개선\"]}],[\"$\",\"span\",\"합성 데이터\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"합성 데이터\"]}],[\"$\",\"span\",\"증류 없는 학습\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"증류 없는 학습\"]}],[\"$\",\"span\",\"OCR\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"OCR\"]}],[\"$\",\"span\",\"멀티모달 AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"멀티모달 AI\"]}],[\"$\",\"span\",\"데이터 필터링\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"데이터 필터링\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-3-OpenVision_2_A_Family_of_Generative_Pretrained_Visual_Encoders_for_Multimodal_Learning\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-3-OpenVision_2_A_Family_of_Generative_Pretrained_Visual_Encoders_for_Multimodal_Learning/\",\"children\":\"[논문리뷰] OpenVision 2: A Family of Generative Pretrained Visual Encoders for Multimodal Learning\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Zirui Wang이 [arXiv]에 게시한 'OpenVision 2: A Family of Generative Pretrained Visual Encoders for Multimodal Learning' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-03 13:36:21+0900\",\"children\":\"2025년 9월 3일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Multimodal Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Learning\"]}],[\"$\",\"span\",\"Vision Encoder\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision Encoder\"]}],[\"$\",\"span\",\"Generative Pretraining\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generative Pretraining\"]}],[\"$\",\"span\",\"Captioning Loss\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Captioning Loss\"]}],[\"$\",\"span\",\"Training Efficiency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Training Efficiency\"]}],[\"$\",\"span\",\"Image-Text Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image-Text Models\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-3-MobiAgent_A_Systematic_Framework_for_Customizable_Mobile_Agents\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-3-MobiAgent_A_Systematic_Framework_for_Customizable_Mobile_Agents/\",\"children\":\"[논문리뷰] MobiAgent: A Systematic Framework for Customizable Mobile Agents\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Wangbo Gong이 [arXiv]에 게시한 'MobiAgent: A Systematic Framework for Customizable Mobile Agents' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-03 13:36:21+0900\",\"children\":\"2025년 9월 3일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Mobile Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Mobile Agents\"]}],[\"$\",\"span\",\"GUI Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"GUI Agents\"]}],[\"$\",\"span\",\"Vision-Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision-Language Models\"]}],[\"$\",\"span\",\"Agent Acceleration\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Agent Acceleration\"]}],[\"$\",\"span\",\"Benchmarking\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmarking\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Data Collection\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Collection\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-3-Metis_Training_Large_Language_Models_with_Advanced_Low-Bit_Quantization\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-3-Metis_Training_Large_Language_Models_with_Advanced_Low-Bit_Quantization/\",\"children\":\"[논문리뷰] Metis: Training Large Language Models with Advanced Low-Bit Quantization\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Hengjie Cao이 [arXiv]에 게시한 'Metis: Training Large Language Models with Advanced Low-Bit Quantization' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-03 13:36:21+0900\",\"children\":\"2025년 9월 3일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Low-Bit Quantization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Low-Bit Quantization\"]}],[\"$\",\"span\",\"LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLMs\"]}],[\"$\",\"span\",\"Spectral Decomposition\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Spectral Decomposition\"]}],[\"$\",\"span\",\"Anisotropy\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Anisotropy\"]}],[\"$\",\"span\",\"Adaptive Learning Rate\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Adaptive Learning Rate\"]}],[\"$\",\"span\",\"Regularization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Regularization\"]}],[\"$\",\"span\",\"FP8 Training\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"FP8 Training\"]}],[\"$\",\"span\",\"FP4 Training\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"FP4 Training\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-3-MedDINOv3_How_to_adapt_vision_foundation_models_for_medical_image_segmentation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-3-MedDINOv3_How_to_adapt_vision_foundation_models_for_medical_image_segmentation/\",\"children\":\"[논문리뷰] MedDINOv3: How to adapt vision foundation models for medical image segmentation?\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Xiaofeng Yang이 [arXiv]에 게시한 'MedDINOv3: How to adapt vision foundation models for medical image segmentation?' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-03 13:36:21+0900\",\"children\":\"2025년 9월 3일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Medical Image Segmentation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Medical Image Segmentation\"]}],[\"$\",\"span\",\"Vision Foundation Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision Foundation Models\"]}],[\"$\",\"span\",\"Self-supervised Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Self-supervised Learning\"]}],[\"$\",\"span\",\"Vision Transformers (ViT)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision Transformers (ViT)\"]}],[\"$\",\"span\",\"Domain Adaptation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Domain Adaptation\"]}],[\"$\",\"span\",\"DINOv3\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"DINOv3\"]}],[\"$\",\"span\",\"CT Imaging\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"CT Imaging\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-3-M3Ret_Unleashing_Zero-shot_Multimodal_Medical_Image_Retrieval_via_Self-Supervision\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-3-M3Ret_Unleashing_Zero-shot_Multimodal_Medical_Image_Retrieval_via_Self-Supervision/\",\"children\":\"[논문리뷰] M3Ret: Unleashing Zero-shot Multimodal Medical Image Retrieval via Self-Supervision\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yan-Jie Zhou이 [arXiv]에 게시한 'M3Ret: Unleashing Zero-shot Multimodal Medical Image Retrieval via Self-Supervision' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-03 13:36:21+0900\",\"children\":\"2025년 9월 3일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Medical Image Retrieval\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Medical Image Retrieval\"]}],[\"$\",\"span\",\"Self-Supervised Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Self-Supervised Learning\"]}],[\"$\",\"span\",\"Multimodal\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal\"]}],[\"$\",\"span\",\"Zero-shot\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Zero-shot\"]}],[\"$\",\"span\",\"Foundation Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Foundation Models\"]}],[\"$\",\"span\",\"MAE\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"MAE\"]}],[\"$\",\"span\",\"SimDINO\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"SimDINO\"]}],[\"$\",\"span\",\"Vision Transformer\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision Transformer\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-3-LLaVA-Critic-R1_Your_Critic_Model_is_Secretly_a_Strong_Policy_Model\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-3-LLaVA-Critic-R1_Your_Critic_Model_is_Secretly_a_Strong_Policy_Model/\",\"children\":\"[논문리뷰] LLaVA-Critic-R1: Your Critic Model is Secretly a Strong Policy Model\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Jianwei Yang이 [arXiv]에 게시한 'LLaVA-Critic-R1: Your Critic Model is Secretly a Strong Policy Model' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-03 13:36:21+0900\",\"children\":\"2025년 9월 3일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Vision-Language Models (VLMs)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision-Language Models (VLMs)\"]}],[\"$\",\"span\",\"Critic Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Critic Models\"]}],[\"$\",\"span\",\"Policy Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Policy Models\"]}],[\"$\",\"span\",\"Reinforcement Learning (RL)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning (RL)\"]}],[\"$\",\"span\",\"Self-Criticism\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Self-Criticism\"]}],[\"$\",\"span\",\"Multimodal Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Reasoning\"]}],[\"$\",\"span\",\"Preference Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Preference Learning\"]}],[\"$\",\"span\",\"Generative Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generative Models\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-3-Kwai_Keye-VL_1.5_Technical_Report\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-3-Kwai_Keye-VL_1.5_Technical_Report/\",\"children\":\"[논문리뷰] Kwai Keye-VL 1.5 Technical Report\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"SXxtyz이 [arXiv]에 게시한 'Kwai Keye-VL 1.5 Technical Report' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-03 13:36:21+0900\",\"children\":\"2025년 9월 3일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Multimodal LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal LLMs\"]}],[\"$\",\"span\",\"Video Understanding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video Understanding\"]}],[\"$\",\"span\",\"Slow-Fast Encoding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Slow-Fast Encoding\"]}],[\"$\",\"span\",\"Long Context\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Long Context\"]}],[\"$\",\"span\",\"Chain-of-Thought\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Chain-of-Thought\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Human Alignment\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Human Alignment\"]}],[\"$\",\"span\",\"Native-Resolution Vision Encoder\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Native-Resolution Vision Encoder\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-3-Jointly_Reinforcing_Diversity_and_Quality_in_Language_Model_Generations\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-3-Jointly_Reinforcing_Diversity_and_Quality_in_Language_Model_Generations/\",\"children\":\"[논문리뷰] Jointly Reinforcing Diversity and Quality in Language Model Generations\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Tianlu이 [arXiv]에 게시한 'Jointly Reinforcing Diversity and Quality in Language Model Generations' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-03 13:36:21+0900\",\"children\":\"2025년 9월 3일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Language Models\"]}],[\"$\",\"span\",\"Diversity Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diversity Optimization\"]}],[\"$\",\"span\",\"Quality Enhancement\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Quality Enhancement\"]}],[\"$\",\"span\",\"Semantic Clustering\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Semantic Clustering\"]}],[\"$\",\"span\",\"Post-training\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Post-training\"]}],[\"$\",\"span\",\"Generative AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generative AI\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-3-Improving_Large_Vision_and_Language_Models_by_Learning_from_a_Panel_of_Peers\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-3-Improving_Large_Vision_and_Language_Models_by_Learning_from_a_Panel_of_Peers/\",\"children\":\"[논문리뷰] Improving Large Vision and Language Models by Learning from a Panel of Peers\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Simon Jenni이 [arXiv]에 게시한 'Improving Large Vision and Language Models by Learning from a Panel of Peers' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-03 13:36:21+0900\",\"children\":\"2025년 9월 3일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Large Vision and Language Models (LVLMs)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Vision and Language Models (LVLMs)\"]}],[\"$\",\"span\",\"Self-Improvement\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Self-Improvement\"]}],[\"$\",\"span\",\"Peer Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Peer Learning\"]}],[\"$\",\"span\",\"Preference Alignment\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Preference Alignment\"]}],[\"$\",\"span\",\"Reward Modeling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reward Modeling\"]}],[\"$\",\"span\",\"Multimodal Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Learning\"]}],[\"$\",\"span\",\"Knowledge Transfer\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Knowledge Transfer\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-3-Implicit_Actor_Critic_Coupling_via_a_Supervised_Learning_Framework_for_RLVR\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-3-Implicit_Actor_Critic_Coupling_via_a_Supervised_Learning_Framework_for_RLVR/\",\"children\":\"[논문리뷰] Implicit Actor Critic Coupling via a Supervised Learning Framework for RLVR\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Lu Wang이 [arXiv]에 게시한 'Implicit Actor Critic Coupling via a Supervised Learning Framework for RLVR' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-03 13:36:21+0900\",\"children\":\"2025년 9월 3일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"RLVR\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"RLVR\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Actor-Critic\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Actor-Critic\"]}],[\"$\",\"span\",\"Supervised Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Supervised Learning\"]}],[\"$\",\"span\",\"Mathematical Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Mathematical Reasoning\"]}],[\"$\",\"span\",\"Policy Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Policy Optimization\"]}],[\"$\",\"span\",\"Cross-Entropy Loss\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Cross-Entropy Loss\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-3-GenCompositor_Generative_Video_Compositing_with_Diffusion_Transformer\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-3-GenCompositor_Generative_Video_Compositing_with_Diffusion_Transformer/\",\"children\":\"[논문리뷰] GenCompositor: Generative Video Compositing with Diffusion Transformer\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Lingen Li이 [arXiv]에 게시한 'GenCompositor: Generative Video Compositing with Diffusion Transformer' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-03 13:36:21+0900\",\"children\":\"2025년 9월 3일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Video Compositing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video Compositing\"]}],[\"$\",\"span\",\"Diffusion Transformer\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Transformer\"]}],[\"$\",\"span\",\"Generative Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generative Models\"]}],[\"$\",\"span\",\"Video Editing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video Editing\"]}],[\"$\",\"span\",\"Position Embedding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Position Embedding\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}],[\"$\",\"span\",\"Masked Token Injection\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Masked Token Injection\"]}],[\"$\",\"span\",\"Video Harmonization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video Harmonization\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-3-FlashAdventure_A_Benchmark_for_GUI_Agents_Solving_Full_Story_Arcs_in_Diverse_Adventure_Games\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-3-FlashAdventure_A_Benchmark_for_GUI_Agents_Solving_Full_Story_Arcs_in_Diverse_Adventure_Games/\",\"children\":\"[논문리뷰] FlashAdventure: A Benchmark for GUI Agents Solving Full Story Arcs in Diverse Adventure Games\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Dongmin Park이 [arXiv]에 게시한 'FlashAdventure: A Benchmark for GUI Agents Solving Full Story Arcs in Diverse Adventure Games' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-03 13:36:21+0900\",\"children\":\"2025년 9월 3일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"GUI Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"GUI Agents\"]}],[\"$\",\"span\",\"Adventure Games\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Adventure Games\"]}],[\"$\",\"span\",\"Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmark\"]}],[\"$\",\"span\",\"Full Story Arc\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Full Story Arc\"]}],[\"$\",\"span\",\"Observation-Behavior Gap\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Observation-Behavior Gap\"]}],[\"$\",\"span\",\"LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLMs\"]}],[\"$\",\"span\",\"Automated Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Automated Evaluation\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-3-FastFit_Accelerating_Multi-Reference_Virtual_Try-On_via_Cacheable_Diffusion_Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-3-FastFit_Accelerating_Multi-Reference_Virtual_Try-On_via_Cacheable_Diffusion_Models/\",\"children\":\"[논문리뷰] FastFit: Accelerating Multi-Reference Virtual Try-On via Cacheable Diffusion Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Zhen Wang이 [arXiv]에 게시한 'FastFit: Accelerating Multi-Reference Virtual Try-On via Cacheable Diffusion Models' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-03 13:36:21+0900\",\"children\":\"2025년 9월 3일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Virtual Try-On\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Virtual Try-On\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}],[\"$\",\"span\",\"Cacheable Architecture\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Cacheable Architecture\"]}],[\"$\",\"span\",\"Multi-Reference\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-Reference\"]}],[\"$\",\"span\",\"Semi-Attention\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Semi-Attention\"]}],[\"$\",\"span\",\"Efficiency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Efficiency\"]}],[\"$\",\"span\",\"Image Synthesis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image Synthesis\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-3-Fantastic_Pretraining_Optimizers_and_Where_to_Find_Them\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-3-Fantastic_Pretraining_Optimizers_and_Where_to_Find_Them/\",\"children\":\"[논문리뷰] Fantastic Pretraining Optimizers and Where to Find Them\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Percy Liang이 [arXiv]에 게시한 'Fantastic Pretraining Optimizers and Where to Find Them' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-03 13:36:21+0900\",\"children\":\"2025년 9월 3일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Deep Learning Optimizers\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Deep Learning Optimizers\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Hyperparameter Tuning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Hyperparameter Tuning\"]}],[\"$\",\"span\",\"Pretraining Speedup\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Pretraining Speedup\"]}],[\"$\",\"span\",\"Scaling Laws\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Scaling Laws\"]}],[\"$\",\"span\",\"AdamW\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"AdamW\"]}],[\"$\",\"span\",\"Matrix-based Optimizers\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Matrix-based Optimizers\"]}],[\"$\",\"span\",\"Data-to-Model Ratio\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data-to-Model Ratio\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-3-ELV-Halluc_Benchmarking_Semantic_Aggregation_Hallucinations_in_Long_Video_Understanding\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-3-ELV-Halluc_Benchmarking_Semantic_Aggregation_Hallucinations_in_Long_Video_Understanding/\",\"children\":\"[논문리뷰] ELV-Halluc: Benchmarking Semantic Aggregation Hallucinations in Long Video Understanding\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Xuanyu Zheng이 [arXiv]에 게시한 'ELV-Halluc: Benchmarking Semantic Aggregation Hallucinations in Long Video Understanding' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-03 13:36:21+0900\",\"children\":\"2025년 9월 3일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Long Video Understanding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Long Video Understanding\"]}],[\"$\",\"span\",\"Hallucination\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Hallucination\"]}],[\"$\",\"span\",\"Semantic Aggregation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Semantic Aggregation\"]}],[\"$\",\"span\",\"Video MLLM\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video MLLM\"]}],[\"$\",\"span\",\"Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmark\"]}],[\"$\",\"span\",\"DPO\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"DPO\"]}],[\"$\",\"span\",\"Positional Encoding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Positional Encoding\"]}],[\"$\",\"span\",\"VideoQA\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"VideoQA\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-3-Discrete_Noise_Inversion_for_Next-scale_Autoregressive_Text-based_Image_Editing\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-3-Discrete_Noise_Inversion_for_Next-scale_Autoregressive_Text-based_Image_Editing/\",\"children\":\"[논문리뷰] Discrete Noise Inversion for Next-scale Autoregressive Text-based Image Editing\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Amin Heyrani Nobar이 [arXiv]에 게시한 'Discrete Noise Inversion for Next-scale Autoregressive Text-based Image Editing' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-03 13:36:21+0900\",\"children\":\"2025년 9월 3일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Image Editing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image Editing\"]}],[\"$\",\"span\",\"Autoregressive Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Autoregressive Models\"]}],[\"$\",\"span\",\"Noise Inversion\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Noise Inversion\"]}],[\"$\",\"span\",\"Text-to-Image\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Text-to-Image\"]}],[\"$\",\"span\",\"Gumbel-max Trick\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Gumbel-max Trick\"]}],[\"$\",\"span\",\"Training-free\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Training-free\"]}],[\"$\",\"span\",\"Location-aware Argmax Inversion\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Location-aware Argmax Inversion\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-3-DCPO_Dynamic_Clipping_Policy_Optimization\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-3-DCPO_Dynamic_Clipping_Policy_Optimization/\",\"children\":\"[논문리뷰] DCPO: Dynamic Clipping Policy Optimization\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Kai Lu이 [arXiv]에 게시한 'DCPO: Dynamic Clipping Policy Optimization' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-03 13:36:21+0900\",\"children\":\"2025년 9월 3일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"LLM\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM\"]}],[\"$\",\"span\",\"Policy Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Policy Optimization\"]}],[\"$\",\"span\",\"Dynamic Clipping\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dynamic Clipping\"]}],[\"$\",\"span\",\"Advantage Standardization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Advantage Standardization\"]}],[\"$\",\"span\",\"RLVR\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"RLVR\"]}],[\"$\",\"span\",\"Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reasoning\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-3-C-DiffDet_Fusing_Global_Scene_Context_with_Generative_Denoising_for_High-Fidelity_Object_Detection\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-3-C-DiffDet_Fusing_Global_Scene_Context_with_Generative_Denoising_for_High-Fidelity_Object_Detection/\",\"children\":\"[논문리뷰] C-DiffDet+: Fusing Global Scene Context with Generative Denoising for High-Fidelity Object Detection\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Vito Renó이 [arXiv]에 게시한 'C-DiffDet+: Fusing Global Scene Context with Generative Denoising for High-Fidelity Object Detection' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-03 13:36:21+0900\",\"children\":\"2025년 9월 3일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Object Detection\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Object Detection\"]}],[\"$\",\"span\",\"Diffusion Model\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Model\"]}],[\"$\",\"span\",\"Global Scene Context\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Global Scene Context\"]}],[\"$\",\"span\",\"Context-Aware Fusion\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Context-Aware Fusion\"]}],[\"$\",\"span\",\"Fine-grained Detection\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Fine-grained Detection\"]}],[\"$\",\"span\",\"Automotive Damage Assessment\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Automotive Damage Assessment\"]}],[\"$\",\"span\",\"Generative Denoising\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generative Denoising\"]}],[\"$\",\"span\",\"Cross-Attention\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Cross-Attention\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-3-Benchmarking_Optimizers_for_Large_Language_Model_Pretraining\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-3-Benchmarking_Optimizers_for_Large_Language_Model_Pretraining/\",\"children\":\"[논문리뷰] Benchmarking Optimizers for Large Language Model Pretraining\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"mjaggi이 [arXiv]에 게시한 'Benchmarking Optimizers for Large Language Model Pretraining' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-03 13:36:21+0900\",\"children\":\"2025년 9월 3일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLM Optimizers\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Optimizers\"]}],[\"$\",\"span\",\"Benchmarking\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmarking\"]}],[\"$\",\"span\",\"Hyperparameter Tuning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Hyperparameter Tuning\"]}],[\"$\",\"span\",\"AdamW\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"AdamW\"]}],[\"$\",\"span\",\"AdEMAMix\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"AdEMAMix\"]}],[\"$\",\"span\",\"MARS\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"MARS\"]}],[\"$\",\"span\",\"Mixture of Experts (MoE)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Mixture of Experts (MoE)\"]}],[\"$\",\"span\",\"Weight Decay\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Weight Decay\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-3-Baichuan-M2_Scaling_Medical_Capability_with_Large_Verifier_System\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-3-Baichuan-M2_Scaling_Medical_Capability_with_Large_Verifier_System/\",\"children\":\"[논문리뷰] Baichuan-M2: Scaling Medical Capability with Large Verifier System\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Jayok6이 [arXiv]에 게시한 'Baichuan-M2: Scaling Medical Capability with Large Verifier System' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-03 13:36:21+0900\",\"children\":\"2025년 9월 3일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Medical AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Medical AI\"]}],[\"$\",\"span\",\"LLM\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Verifier System\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Verifier System\"]}],[\"$\",\"span\",\"Patient Simulator\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Patient Simulator\"]}],[\"$\",\"span\",\"Clinical Rubrics\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Clinical Rubrics\"]}],[\"$\",\"span\",\"Baichuan-M2\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Baichuan-M2\"]}],[\"$\",\"span\",\"HealthBench\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"HealthBench\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-3-Attributes_as_Textual_Genes_Leveraging_LLMs_as_Genetic_Algorithm_Simulators_for_Conditional_Synthetic_Data_Generation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-3-Attributes_as_Textual_Genes_Leveraging_LLMs_as_Genetic_Algorithm_Simulators_for_Conditional_Synthetic_Data_Generation/\",\"children\":\"[논문리뷰] Attributes as Textual Genes: Leveraging LLMs as Genetic Algorithm Simulators for Conditional Synthetic Data Generation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Xiaolei Huang이 [arXiv]에 게시한 'Attributes as Textual Genes: Leveraging LLMs as Genetic Algorithm Simulators for Conditional Synthetic Data Generation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-03 13:36:21+0900\",\"children\":\"2025년 9월 3일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Synthetic Data Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Synthetic Data Generation\"]}],[\"$\",\"span\",\"Large Language Models (LLMs)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models (LLMs)\"]}],[\"$\",\"span\",\"Genetic Algorithms\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Genetic Algorithms\"]}],[\"$\",\"span\",\"Textual Data Augmentation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Textual Data Augmentation\"]}],[\"$\",\"span\",\"Active Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Active Learning\"]}],[\"$\",\"span\",\"NLP\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"NLP\"]}],[\"$\",\"span\",\"Data Diversity\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Diversity\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-3-AMBEDKAR-A_Multi-level_Bias_Elimination_through_a_Decoding_Approach_with_Knowledge_Augmentation_for_Robust_Constitutional_Alignment_of_Language_Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-3-AMBEDKAR-A_Multi-level_Bias_Elimination_through_a_Decoding_Approach_with_Knowledge_Augmentation_for_Robust_Constitutional_Alignment_of_Language_Models/\",\"children\":\"[논문리뷰] AMBEDKAR-A Multi-level Bias Elimination through a Decoding Approach with Knowledge Augmentation for Robust Constitutional Alignment of Language Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Rahul Karthikeyan이 [arXiv]에 게시한 'AMBEDKAR-A Multi-level Bias Elimination through a Decoding Approach with Knowledge Augmentation for Robust Constitutional Alignment of Language Models' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-03 13:36:21+0900\",\"children\":\"2025년 9월 3일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Bias Mitigation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Bias Mitigation\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Speculative Decoding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Speculative Decoding\"]}],[\"$\",\"span\",\"Constitutional AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Constitutional AI\"]}],[\"$\",\"span\",\"Fairness\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Fairness\"]}],[\"$\",\"span\",\"Inference-Time Control\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Inference-Time Control\"]}],[\"$\",\"span\",\"Indian Sociocultural Context\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Indian Sociocultural Context\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-2-UI-Level_Evaluation_of_ALLaM_34B_Measuring_an_Arabic-Centric_LLM_via_HUMAIN_Chat\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-2-UI-Level_Evaluation_of_ALLaM_34B_Measuring_an_Arabic-Centric_LLM_via_HUMAIN_Chat/\",\"children\":\"[논문리뷰] UI-Level Evaluation of ALLaM 34B: Measuring an Arabic-Centric LLM via HUMAIN Chat\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Omartificial-Intelligence-Space이 [arXiv]에 게시한 'UI-Level Evaluation of ALLaM 34B: Measuring an Arabic-Centric LLM via HUMAIN Chat' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-02 13:01:41+0900\",\"children\":\"2025년 9월 2일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Arabic LLM\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Arabic LLM\"]}],[\"$\",\"span\",\"UI-level Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"UI-level Evaluation\"]}],[\"$\",\"span\",\"ALLaM 34B\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"ALLaM 34B\"]}],[\"$\",\"span\",\"HUMAIN Chat\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"HUMAIN Chat\"]}],[\"$\",\"span\",\"Dialectal Arabic\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dialectal Arabic\"]}],[\"$\",\"span\",\"LLM as a Judge\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM as a Judge\"]}],[\"$\",\"span\",\"Safety Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Safety Evaluation\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-2-T2R-bench_A_Benchmark_for_Generating_Article-Level_Reports_from_Real_World_Industrial_Tables\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-2-T2R-bench_A_Benchmark_for_Generating_Article-Level_Reports_from_Real_World_Industrial_Tables/\",\"children\":\"[논문리뷰] T2R-bench: A Benchmark for Generating Article-Level Reports from Real World Industrial Tables\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yu Zhao이 [arXiv]에 게시한 'T2R-bench: A Benchmark for Generating Article-Level Reports from Real World Industrial Tables' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-02 13:01:41+0900\",\"children\":\"2025년 9월 2일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Table-to-Report Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Table-to-Report Generation\"]}],[\"$\",\"span\",\"Large Language Models (LLMs)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models (LLMs)\"]}],[\"$\",\"span\",\"Benchmark Dataset\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmark Dataset\"]}],[\"$\",\"span\",\"Industrial Applications\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Industrial Applications\"]}],[\"$\",\"span\",\"Table Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Table Reasoning\"]}],[\"$\",\"span\",\"Evaluation Metrics\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Evaluation Metrics\"]}],[\"$\",\"span\",\"Real-world Data\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Real-world Data\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-2-PVPO_Pre-Estimated_Value-Based_Policy_Optimization_for_Agentic_Reasoning\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-2-PVPO_Pre-Estimated_Value-Based_Policy_Optimization_for_Agentic_Reasoning/\",\"children\":\"[논문리뷰] PVPO: Pre-Estimated Value-Based Policy Optimization for Agentic Reasoning\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yuewei Zhang이 [arXiv]에 게시한 'PVPO: Pre-Estimated Value-Based Policy Optimization for Agentic Reasoning' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-02 13:01:41+0900\",\"children\":\"2025년 9월 2일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Critic-Free RL\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Critic-Free RL\"]}],[\"$\",\"span\",\"Agentic Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Agentic Reasoning\"]}],[\"$\",\"span\",\"Policy Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Policy Optimization\"]}],[\"$\",\"span\",\"Large Language Models (LLMs)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models (LLMs)\"]}],[\"$\",\"span\",\"Advantage Estimation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Advantage Estimation\"]}],[\"$\",\"span\",\"Group Sampling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Group Sampling\"]}],[\"$\",\"span\",\"Static Value Estimation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Static Value Estimation\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-2-No_Label_Left_Behind_A_Unified_Surface_Defect_Detection_Model_for_all_Supervision_Regimes\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-2-No_Label_Left_Behind_A_Unified_Surface_Defect_Detection_Model_for_all_Supervision_Regimes/\",\"children\":\"[논문리뷰] No Label Left Behind: A Unified Surface Defect Detection Model for all Supervision Regimes\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Danijel Skočaj이 [arXiv]에 게시한 'No Label Left Behind: A Unified Surface Defect Detection Model for all Supervision Regimes' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-02 13:01:41+0900\",\"children\":\"2025년 9월 2일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Surface Defect Detection\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Surface Defect Detection\"]}],[\"$\",\"span\",\"Anomaly Detection\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Anomaly Detection\"]}],[\"$\",\"span\",\"Mixed Supervision\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Mixed Supervision\"]}],[\"$\",\"span\",\"Deep Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Deep Learning\"]}],[\"$\",\"span\",\"Industrial Inspection\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Industrial Inspection\"]}],[\"$\",\"span\",\"Unified Model\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Unified Model\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-2-How_Can_Input_Reformulation_Improve_Tool_Usage_Accuracy_in_a_Complex_Dynamic_Environment_A_Study_on_τ-bench\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-2-How_Can_Input_Reformulation_Improve_Tool_Usage_Accuracy_in_a_Complex_Dynamic_Environment_A_Study_on_τ-bench/\",\"children\":\"[논문리뷰] How Can Input Reformulation Improve Tool Usage Accuracy in a Complex Dynamic Environment? A Study on τ-bench\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Jayanth Srinivasa이 [arXiv]에 게시한 'How Can Input Reformulation Improve Tool Usage Accuracy in a Complex Dynamic Environment? A Study on τ-bench' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-02 13:01:41+0900\",\"children\":\"2025년 9월 2일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLM Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Agents\"]}],[\"$\",\"span\",\"Tool Use\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Tool Use\"]}],[\"$\",\"span\",\"Function Calling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Function Calling\"]}],[\"$\",\"span\",\"Input Reformulation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Input Reformulation\"]}],[\"$\",\"span\",\"Dynamic Environments\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dynamic Environments\"]}],[\"$\",\"span\",\"τ-bench\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"τ-bench\"]}],[\"$\",\"span\",\"Context Engineering\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Context Engineering\"]}],[\"$\",\"span\",\"Multi-Agent Framework\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-Agent Framework\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-2-From_reactive_to_cognitive_brain-inspired_spatial_intelligence_for_embodied_agents\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-2-From_reactive_to_cognitive_brain-inspired_spatial_intelligence_for_embodied_agents/\",\"children\":\"[논문리뷰] From reactive to cognitive: brain-inspired spatial intelligence for embodied agents\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Songming Liu이 [arXiv]에 게시한 'From reactive to cognitive: brain-inspired spatial intelligence for embodied agents' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-02 13:01:41+0900\",\"children\":\"2025년 9월 2일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Spatial Cognition\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Spatial Cognition\"]}],[\"$\",\"span\",\"Embodied Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Embodied Agents\"]}],[\"$\",\"span\",\"Brain-inspired AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Brain-inspired AI\"]}],[\"$\",\"span\",\"Cognitive Map\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Cognitive Map\"]}],[\"$\",\"span\",\"Spatial Memory\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Spatial Memory\"]}],[\"$\",\"span\",\"MLLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"MLLMs\"]}],[\"$\",\"span\",\"Navigation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Navigation\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-1-UItron_Foundational_GUI_Agent_with_Advanced_Perception_and_Planning\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-1-UItron_Foundational_GUI_Agent_with_Advanced_Perception_and_Planning/\",\"children\":\"[논문리뷰] UItron: Foundational GUI Agent with Advanced Perception and Planning\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yufeng Zhong이 [arXiv]에 게시한 'UItron: Foundational GUI Agent with Advanced Perception and Planning' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-01 13:14:34+0900\",\"children\":\"2025년 9월 1일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"GUI Agent\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"GUI Agent\"]}],[\"$\",\"span\",\"Foundational Model\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Foundational Model\"]}],[\"$\",\"span\",\"Multimodal LLM\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal LLM\"]}],[\"$\",\"span\",\"Perception\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Perception\"]}],[\"$\",\"span\",\"Planning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Planning\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Data Engineering\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Engineering\"]}],[\"$\",\"span\",\"Chinese App Scenarios\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Chinese App Scenarios\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-1-TiKMiX_Take_Data_Influence_into_Dynamic_Mixture_for_Language_Model_Pre-training\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-1-TiKMiX_Take_Data_Influence_into_Dynamic_Mixture_for_Language_Model_Pre-training/\",\"children\":\"[논문리뷰] TiKMiX: Take Data Influence into Dynamic Mixture for Language Model Pre-training\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Jiyao Deng이 [arXiv]에 게시한 'TiKMiX: Take Data Influence into Dynamic Mixture for Language Model Pre-training' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-01 13:14:34+0900\",\"children\":\"2025년 9월 1일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Language Model Pre-training\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Language Model Pre-training\"]}],[\"$\",\"span\",\"Dynamic Data Mixing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dynamic Data Mixing\"]}],[\"$\",\"span\",\"Data Influence\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Influence\"]}],[\"$\",\"span\",\"Group Influence\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Group Influence\"]}],[\"$\",\"span\",\"Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Optimization\"]}],[\"$\",\"span\",\"Regression Model\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Regression Model\"]}],[\"$\",\"span\",\"LLM Training\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Training\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-1-Think_in_Games_Learning_to_Reason_in_Games_via_Reinforcement_Learning_with_Large_Language_Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-1-Think_in_Games_Learning_to_Reason_in_Games_via_Reinforcement_Learning_with_Large_Language_Models/\",\"children\":\"[논문리뷰] Think in Games: Learning to Reason in Games via Reinforcement Learning with Large Language Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yifan Lu이 [arXiv]에 게시한 'Think in Games: Learning to Reason in Games via Reinforcement Learning with Large Language Models' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-01 13:14:34+0900\",\"children\":\"2025년 9월 1일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Game AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Game AI\"]}],[\"$\",\"span\",\"Procedural Knowledge\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Procedural Knowledge\"]}],[\"$\",\"span\",\"Declarative Knowledge\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Declarative Knowledge\"]}],[\"$\",\"span\",\"Explainable AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Explainable AI\"]}],[\"$\",\"span\",\"Strategic Decision-Making\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Strategic Decision-Making\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-1-TalkVid_A_Large-Scale_Diversified_Dataset_for_Audio-Driven_Talking_Head_Synthesis\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-1-TalkVid_A_Large-Scale_Diversified_Dataset_for_Audio-Driven_Talking_Head_Synthesis/\",\"children\":\"[논문리뷰] TalkVid: A Large-Scale Diversified Dataset for Audio-Driven Talking Head Synthesis\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Pengcheng Chen이 [arXiv]에 게시한 'TalkVid: A Large-Scale Diversified Dataset for Audio-Driven Talking Head Synthesis' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-01 13:14:34+0900\",\"children\":\"2025년 9월 1일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Audio-Driven Talking Head Synthesis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Audio-Driven Talking Head Synthesis\"]}],[\"$\",\"span\",\"Large-Scale Dataset\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large-Scale Dataset\"]}],[\"$\",\"span\",\"Data Diversity\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Diversity\"]}],[\"$\",\"span\",\"Data Curation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Curation\"]}],[\"$\",\"span\",\"Evaluation Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Evaluation Benchmark\"]}],[\"$\",\"span\",\"Generalization Gap\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generalization Gap\"]}],[\"$\",\"span\",\"Algorithmic Fairness\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Algorithmic Fairness\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-1-R-4B_Incentivizing_General-Purpose_Auto-Thinking_Capability_in_MLLMs_via_Bi-Mode_Annealing_and_Reinforce_Learning\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-1-R-4B_Incentivizing_General-Purpose_Auto-Thinking_Capability_in_MLLMs_via_Bi-Mode_Annealing_and_Reinforce_Learning/\",\"children\":\"[논문리뷰] R-4B: Incentivizing General-Purpose Auto-Thinking Capability in MLLMs via Bi-Mode Annealing and Reinforce Learning\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Han Hu이 [arXiv]에 게시한 'R-4B: Incentivizing General-Purpose Auto-Thinking Capability in MLLMs via Bi-Mode Annealing and Reinforce Learning' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-01 13:14:34+0900\",\"children\":\"2025년 9월 1일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Multimodal Large Language Models (MLLMs)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Large Language Models (MLLMs)\"]}],[\"$\",\"span\",\"Auto-Thinking\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Auto-Thinking\"]}],[\"$\",\"span\",\"Reinforcement Learning (RL)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning (RL)\"]}],[\"$\",\"span\",\"Bi-mode Annealing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Bi-mode Annealing\"]}],[\"$\",\"span\",\"Bi-mode Policy Optimization (BPO)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Bi-mode Policy Optimization (BPO)\"]}],[\"$\",\"span\",\"General-Purpose AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"General-Purpose AI\"]}],[\"$\",\"span\",\"Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reasoning\"]}],[\"$\",\"span\",\"Efficiency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Efficiency\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-1-Morae_Proactively_Pausing_UI_Agents_for_User_Choices\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-1-Morae_Proactively_Pausing_UI_Agents_for_User_Choices/\",\"children\":\"[논문리뷰] Morae: Proactively Pausing UI Agents for User Choices\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Amy Pavel이 [arXiv]에 게시한 'Morae: Proactively Pausing UI Agents for User Choices' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-01 13:14:34+0900\",\"children\":\"2025년 9월 1일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"UI Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"UI Agents\"]}],[\"$\",\"span\",\"Accessibility\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Accessibility\"]}],[\"$\",\"span\",\"Human-Agent Interaction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Human-Agent Interaction\"]}],[\"$\",\"span\",\"Mixed-Initiative AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Mixed-Initiative AI\"]}],[\"$\",\"span\",\"Large Multimodal Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Multimodal Models\"]}],[\"$\",\"span\",\"Proactive AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Proactive AI\"]}],[\"$\",\"span\",\"User Choice\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"User Choice\"]}],[\"$\",\"span\",\"Blind and Low-Vision Users\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Blind and Low-Vision Users\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-1-Mimicking_the_Physicists_EyeA_VLM-centric_Approach_for_Physics_Formula_Discovery\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-1-Mimicking_the_Physicists_EyeA_VLM-centric_Approach_for_Physics_Formula_Discovery/\",\"children\":\"[논문리뷰] Mimicking the Physicist's Eye:A VLM-centric Approach for Physics Formula Discovery\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Wenjie Zhou이 [arXiv]에 게시한 'Mimicking the Physicist's Eye:A VLM-centric Approach for Physics Formula Discovery' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-01 13:14:34+0900\",\"children\":\"2025년 9월 1일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Physics Formula Discovery\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Physics Formula Discovery\"]}],[\"$\",\"span\",\"Multimodal AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal AI\"]}],[\"$\",\"span\",\"Vision-Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision-Language Models\"]}],[\"$\",\"span\",\"Symbolic Regression\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Symbolic Regression\"]}],[\"$\",\"span\",\"Causal Chain of Thought\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Causal Chain of Thought\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Agentic AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Agentic AI\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-1-HERMES_Human-to-Robot_Embodied_Learning_from_Multi-Source_Motion_Data_for_Mobile_Dexterous_Manipulation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-1-HERMES_Human-to-Robot_Embodied_Learning_from_Multi-Source_Motion_Data_for_Mobile_Dexterous_Manipulation/\",\"children\":\"[논문리뷰] HERMES: Human-to-Robot Embodied Learning from Multi-Source Motion Data for Mobile Dexterous Manipulation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Tianhai Liang이 [arXiv]에 게시한 'HERMES: Human-to-Robot Embodied Learning from Multi-Source Motion Data for Mobile Dexterous Manipulation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-01 13:14:34+0900\",\"children\":\"2025년 9월 1일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Dexterous Manipulation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dexterous Manipulation\"]}],[\"$\",\"span\",\"Mobile Manipulation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Mobile Manipulation\"]}],[\"$\",\"span\",\"Human-to-Robot Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Human-to-Robot Learning\"]}],[\"$\",\"span\",\"Sim2Real\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Sim2Real\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Depth Image\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Depth Image\"]}],[\"$\",\"span\",\"Visual Localization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Visual Localization\"]}],[\"$\",\"span\",\"Bimanual Control\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Bimanual Control\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-1-EmbodiedOneVision_Interleaved_Vision-Text-Action_Pretraining_for_General_Robot_Control\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-1-EmbodiedOneVision_Interleaved_Vision-Text-Action_Pretraining_for_General_Robot_Control/\",\"children\":\"[논문리뷰] EmbodiedOneVision: Interleaved Vision-Text-Action Pretraining for General Robot Control\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Zhaoqing Chen이 [arXiv]에 게시한 'EmbodiedOneVision: Interleaved Vision-Text-Action Pretraining for General Robot Control' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-01 13:14:34+0900\",\"children\":\"2025년 9월 1일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Embodied AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Embodied AI\"]}],[\"$\",\"span\",\"Robot Control\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Robot Control\"]}],[\"$\",\"span\",\"Vision-Language-Action Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision-Language-Action Models\"]}],[\"$\",\"span\",\"Multimodal Pretraining\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Pretraining\"]}],[\"$\",\"span\",\"Flow Matching\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Flow Matching\"]}],[\"$\",\"span\",\"Foundation Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Foundation Models\"]}],[\"$\",\"span\",\"Generalization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generalization\"]}],[\"$\",\"span\",\"Real-world Robotics\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Real-world Robotics\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-1-Efficient_Code_Embeddings_from_Code_Generation_Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-1-Efficient_Code_Embeddings_from_Code_Generation_Models/\",\"children\":\"[논문리뷰] Efficient Code Embeddings from Code Generation Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Han Xiao이 [arXiv]에 게시한 'Efficient Code Embeddings from Code Generation Models' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-01 13:14:34+0900\",\"children\":\"2025년 9월 1일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Code Embeddings\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Code Embeddings\"]}],[\"$\",\"span\",\"Code Generation Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Code Generation Models\"]}],[\"$\",\"span\",\"Autoregressive Backbones\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Autoregressive Backbones\"]}],[\"$\",\"span\",\"Last-Token Pooling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Last-Token Pooling\"]}],[\"$\",\"span\",\"Instruction Tuning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Instruction Tuning\"]}],[\"$\",\"span\",\"Contrastive Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Contrastive Learning\"]}],[\"$\",\"span\",\"Retrieval-Augmented Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Retrieval-Augmented Generation\"]}],[\"$\",\"span\",\"MTEB Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"MTEB Benchmark\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-1-Droplet3D_Commonsense_Priors_from_Videos_Facilitate_3D_Generation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-1-Droplet3D_Commonsense_Priors_from_Videos_Facilitate_3D_Generation/\",\"children\":\"[논문리뷰] Droplet3D: Commonsense Priors from Videos Facilitate 3D Generation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Qi Jia이 [arXiv]에 게시한 'Droplet3D: Commonsense Priors from Videos Facilitate 3D Generation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-01 13:14:34+0900\",\"children\":\"2025년 9월 1일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"3D Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D Generation\"]}],[\"$\",\"span\",\"Video Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video Diffusion Models\"]}],[\"$\",\"span\",\"Spatial Consistency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Spatial Consistency\"]}],[\"$\",\"span\",\"Semantic Knowledge\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Semantic Knowledge\"]}],[\"$\",\"span\",\"Multi-view Synthesis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-view Synthesis\"]}],[\"$\",\"span\",\"Large-scale Dataset\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large-scale Dataset\"]}],[\"$\",\"span\",\"Image-to-3D\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image-to-3D\"]}],[\"$\",\"span\",\"Text-to-3D\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Text-to-3D\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-1-CLIPSym_Delving_into_Symmetry_Detection_with_CLIP\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-1-CLIPSym_Delving_into_Symmetry_Detection_with_CLIP/\",\"children\":\"[논문리뷰] CLIPSym: Delving into Symmetry Detection with CLIP\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Raymond A. Yeh이 [arXiv]에 게시한 'CLIPSym: Delving into Symmetry Detection with CLIP' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-01 13:14:34+0900\",\"children\":\"2025년 9월 1일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Symmetry Detection\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Symmetry Detection\"]}],[\"$\",\"span\",\"Vision-Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision-Language Models\"]}],[\"$\",\"span\",\"CLIP\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"CLIP\"]}],[\"$\",\"span\",\"Equivariant Networks\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Equivariant Networks\"]}],[\"$\",\"span\",\"Prompt Engineering\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Prompt Engineering\"]}],[\"$\",\"span\",\"Geometric Deep Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Geometric Deep Learning\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-1-A_Survey_of_Scientific_Large_Language_Models_From_Data_Foundations_to_Agent_Frontiers\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-1-A_Survey_of_Scientific_Large_Language_Models_From_Data_Foundations_to_Agent_Frontiers/\",\"children\":\"[논문리뷰] A Survey of Scientific Large Language Models: From Data Foundations to Agent Frontiers\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Jiamin Wu이 [arXiv]에 게시한 'A Survey of Scientific Large Language Models: From Data Foundations to Agent Frontiers' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-01 13:14:34+0900\",\"children\":\"2025년 9월 1일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Scientific LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Scientific LLMs\"]}],[\"$\",\"span\",\"AI for Science\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"AI for Science\"]}],[\"$\",\"span\",\"Scientific Data\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Scientific Data\"]}],[\"$\",\"span\",\"Agentic AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Agentic AI\"]}],[\"$\",\"span\",\"Multimodal Integration\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Integration\"]}],[\"$\",\"span\",\"Knowledge Representation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Knowledge Representation\"]}],[\"$\",\"span\",\"Autonomous Discovery\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Autonomous Discovery\"]}],[\"$\",\"span\",\"Data Ecosystems\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Ecosystems\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-1-AHELM_A_Holistic_Evaluation_of_Audio-Language_Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-1-AHELM_A_Holistic_Evaluation_of_Audio-Language_Models/\",\"children\":\"[논문리뷰] AHELM: A Holistic Evaluation of Audio-Language Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Siwei Yang이 [arXiv]에 게시한 'AHELM: A Holistic Evaluation of Audio-Language Models' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-01 13:14:34+0900\",\"children\":\"2025년 9월 1일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Audio-Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Audio-Language Models\"]}],[\"$\",\"span\",\"Holistic Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Holistic Evaluation\"]}],[\"$\",\"span\",\"Benchmarking\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmarking\"]}],[\"$\",\"span\",\"Multimodality\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodality\"]}],[\"$\",\"span\",\"Fairness\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Fairness\"]}],[\"$\",\"span\",\"Robustness\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Robustness\"]}],[\"$\",\"span\",\"Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reasoning\"]}],[\"$\",\"span\",\"Bias Detection\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Bias Detection\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-9-1-A.S.E_A_Repository-Level_Benchmark_for_Evaluating_Security_in_AI-Generated_Code\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-9-1-A.S.E_A_Repository-Level_Benchmark_for_Evaluating_Security_in_AI-Generated_Code/\",\"children\":\"[논문리뷰] A.S.E: A Repository-Level Benchmark for Evaluating Security in AI-Generated Code\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Libo Chen이 [arXiv]에 게시한 'A.S.E: A Repository-Level Benchmark for Evaluating Security in AI-Generated Code' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-01 13:14:34+0900\",\"children\":\"2025년 9월 1일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"AI-Generated Code Security\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"AI-Generated Code Security\"]}],[\"$\",\"span\",\"LLM Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Evaluation\"]}],[\"$\",\"span\",\"Repository-Level Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Repository-Level Benchmark\"]}],[\"$\",\"span\",\"Code Security\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Code Security\"]}],[\"$\",\"span\",\"Vulnerability Detection\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vulnerability Detection\"]}],[\"$\",\"span\",\"Static Analysis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Static Analysis\"]}],[\"$\",\"span\",\"Reproducibility\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reproducibility\"]}],[\"$\",\"span\",\"Context-Awareness\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Context-Awareness\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-29-USO_Unified_Style_and_Subject-Driven_Generation_via_Disentangled_and_Reward_Learning\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-29-USO_Unified_Style_and_Subject-Driven_Generation_via_Disentangled_and_Reward_Learning/\",\"children\":\"[논문리뷰] USO: Unified Style and Subject-Driven Generation via Disentangled and Reward Learning\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Jiahe Tian이 [arXiv]에 게시한 'USO: Unified Style and Subject-Driven Generation via Disentangled and Reward Learning' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-29 13:14:44+0900\",\"children\":\"2025년 8월 29일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Style-Driven Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Style-Driven Generation\"]}],[\"$\",\"span\",\"Subject-Driven Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Subject-Driven Generation\"]}],[\"$\",\"span\",\"Disentangled Representation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Disentangled Representation\"]}],[\"$\",\"span\",\"Reward Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reward Learning\"]}],[\"$\",\"span\",\"Cross-Task Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Cross-Task Learning\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}],[\"$\",\"span\",\"Image Customization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image Customization\"]}],[\"$\",\"span\",\"Unified Framework\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Unified Framework\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-29-Turning_the_Spell_Around_Lightweight_Alignment_Amplification_via_Rank-One_Safety_Injection\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-29-Turning_the_Spell_Around_Lightweight_Alignment_Amplification_via_Rank-One_Safety_Injection/\",\"children\":\"[논문리뷰] Turning the Spell Around: Lightweight Alignment Amplification via Rank-One Safety Injection\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Bernard Ghanem이 [arXiv]에 게시한 'Turning the Spell Around: Lightweight Alignment Amplification via Rank-One Safety Injection' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-29 13:14:44+0900\",\"children\":\"2025년 8월 29일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLM Safety\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Safety\"]}],[\"$\",\"span\",\"Alignment Amplification\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Alignment Amplification\"]}],[\"$\",\"span\",\"Rank-One Update\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Rank-One Update\"]}],[\"$\",\"span\",\"Mechanistic Interpretability\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Mechanistic Interpretability\"]}],[\"$\",\"span\",\"Weight Steering\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Weight Steering\"]}],[\"$\",\"span\",\"Jailbreak Robustness\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Jailbreak Robustness\"]}],[\"$\",\"span\",\"Fine-tuning-free\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Fine-tuning-free\"]}],[\"$\",\"span\",\"Safety Injection\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Safety Injection\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-29-TCIA_A_Task-Centric_Instruction_Augmentation_Method_for_Instruction_Finetuning\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-29-TCIA_A_Task-Centric_Instruction_Augmentation_Method_for_Instruction_Finetuning/\",\"children\":\"[논문리뷰] TCIA: A Task-Centric Instruction Augmentation Method for Instruction Finetuning\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Simin Ma이 [arXiv]에 게시한 'TCIA: A Task-Centric Instruction Augmentation Method for Instruction Finetuning' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-29 13:14:44+0900\",\"children\":\"2025년 8월 29일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Instruction Augmentation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Instruction Augmentation\"]}],[\"$\",\"span\",\"Fine-tuning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Fine-tuning\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Task-Centric\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Task-Centric\"]}],[\"$\",\"span\",\"Data Diversity\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Diversity\"]}],[\"$\",\"span\",\"Task Alignment\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Task Alignment\"]}],[\"$\",\"span\",\"Breadth-First Search\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Breadth-First Search\"]}],[\"$\",\"span\",\"Constraint Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Constraint Generation\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-29-rStar2-Agent_Agentic_Reasoning_Technical_Report\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-29-rStar2-Agent_Agentic_Reasoning_Technical_Report/\",\"children\":\"[논문리뷰] rStar2-Agent: Agentic Reasoning Technical Report\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Weijiang Xu이 [arXiv]에 게시한 'rStar2-Agent: Agentic Reasoning Technical Report' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-29 13:14:44+0900\",\"children\":\"2025년 8월 29일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Agentic Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Agentic Reinforcement Learning\"]}],[\"$\",\"span\",\"Math Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Math Reasoning\"]}],[\"$\",\"span\",\"Code Interpreter\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Code Interpreter\"]}],[\"$\",\"span\",\"Tool Use\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Tool Use\"]}],[\"$\",\"span\",\"GRPO-RoC\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"GRPO-RoC\"]}],[\"$\",\"span\",\"LLM Training Efficiency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Training Efficiency\"]}],[\"$\",\"span\",\"Self-Reflection\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Self-Reflection\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-29-ROSE_Remove_Objects_with_Side_Effects_in_Videos\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-29-ROSE_Remove_Objects_with_Side_Effects_in_Videos/\",\"children\":\"[논문리뷰] ROSE: Remove Objects with Side Effects in Videos\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Hantang Liu이 [arXiv]에 게시한 'ROSE: Remove Objects with Side Effects in Videos' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-29 13:14:44+0900\",\"children\":\"2025년 8월 29일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Video Object Removal\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video Object Removal\"]}],[\"$\",\"span\",\"Side Effects\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Side Effects\"]}],[\"$\",\"span\",\"3D Rendering\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D Rendering\"]}],[\"$\",\"span\",\"Diffusion Transformer\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Transformer\"]}],[\"$\",\"span\",\"Video Inpainting\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video Inpainting\"]}],[\"$\",\"span\",\"Synthetic Data\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Synthetic Data\"]}],[\"$\",\"span\",\"Difference Mask\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Difference Mask\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-29-Provable_Benefits_of_In-Tool_Learning_for_Large_Language_Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-29-Provable_Benefits_of_In-Tool_Learning_for_Large_Language_Models/\",\"children\":\"[논문리뷰] Provable Benefits of In-Tool Learning for Large Language Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Vivien Cabannes이 [arXiv]에 게시한 'Provable Benefits of In-Tool Learning for Large Language Models' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-29 13:14:44+0900\",\"children\":\"2025년 8월 29일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"In-Tool Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"In-Tool Learning\"]}],[\"$\",\"span\",\"In-Weight Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"In-Weight Learning\"]}],[\"$\",\"span\",\"Factual Recall\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Factual Recall\"]}],[\"$\",\"span\",\"Retrieval-Augmented Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Retrieval-Augmented Generation\"]}],[\"$\",\"span\",\"Scaling Laws\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Scaling Laws\"]}],[\"$\",\"span\",\"Parameter Efficiency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Parameter Efficiency\"]}],[\"$\",\"span\",\"Catastrophic Forgetting\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Catastrophic Forgetting\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-29-Pref-GRPO_Pairwise_Preference_Reward-based_GRPO_for_Stable_Text-to-Image_Reinforcement_Learning\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-29-Pref-GRPO_Pairwise_Preference_Reward-based_GRPO_for_Stable_Text-to-Image_Reinforcement_Learning/\",\"children\":\"[논문리뷰] Pref-GRPO: Pairwise Preference Reward-based GRPO for Stable Text-to-Image Reinforcement Learning\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Jiazi Bu이 [arXiv]에 게시한 'Pref-GRPO: Pairwise Preference Reward-based GRPO for Stable Text-to-Image Reinforcement Learning' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-29 13:14:44+0900\",\"children\":\"2025년 8월 29일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Text-to-Image Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Text-to-Image Generation\"]}],[\"$\",\"span\",\"GRPO\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"GRPO\"]}],[\"$\",\"span\",\"Reward Hacking\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reward Hacking\"]}],[\"$\",\"span\",\"Pairwise Preference\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Pairwise Preference\"]}],[\"$\",\"span\",\"Reward Model\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reward Model\"]}],[\"$\",\"span\",\"Stable Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Stable Optimization\"]}],[\"$\",\"span\",\"UniGenBench\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"UniGenBench\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-29-Persuasion_Dynamics_in_LLMs_Investigating_Robustness_and_Adaptability_in_Knowledge_and_Safety_with_DuET-PD\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-29-Persuasion_Dynamics_in_LLMs_Investigating_Robustness_and_Adaptability_in_Knowledge_and_Safety_with_DuET-PD/\",\"children\":\"[논문리뷰] Persuasion Dynamics in LLMs: Investigating Robustness and Adaptability in Knowledge and Safety with DuET-PD\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Roy Ka-Wei Lee이 [arXiv]에 게시한 'Persuasion Dynamics in LLMs: Investigating Robustness and Adaptability in Knowledge and Safety with DuET-PD' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-29 13:14:44+0900\",\"children\":\"2025년 8월 29일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Persuasion Dynamics\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Persuasion Dynamics\"]}],[\"$\",\"span\",\"Large Language Models (LLMs)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models (LLMs)\"]}],[\"$\",\"span\",\"Robustness\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Robustness\"]}],[\"$\",\"span\",\"Gullibility\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Gullibility\"]}],[\"$\",\"span\",\"Receptiveness\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Receptiveness\"]}],[\"$\",\"span\",\"Direct Preference Optimization (DPO)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Direct Preference Optimization (DPO)\"]}],[\"$\",\"span\",\"Safety Alignment\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Safety Alignment\"]}],[\"$\",\"span\",\"Multi-turn Dialogue\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-turn Dialogue\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-29-OnGoal_Tracking_and_Visualizing_Conversational_Goals_in_Multi-Turn_Dialogue_with_Large_Language_Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-29-OnGoal_Tracking_and_Visualizing_Conversational_Goals_in_Multi-Turn_Dialogue_with_Large_Language_Models/\",\"children\":\"[논문리뷰] OnGoal: Tracking and Visualizing Conversational Goals in Multi-Turn Dialogue with Large Language Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Alex Endert이 [arXiv]에 게시한 'OnGoal: Tracking and Visualizing Conversational Goals in Multi-Turn Dialogue with Large Language Models' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-29 13:14:44+0900\",\"children\":\"2025년 8월 29일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Large Language Models (LLMs)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models (LLMs)\"]}],[\"$\",\"span\",\"Human-Computer Interaction (HCI)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Human-Computer Interaction (HCI)\"]}],[\"$\",\"span\",\"Conversational AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Conversational AI\"]}],[\"$\",\"span\",\"Goal Tracking\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Goal Tracking\"]}],[\"$\",\"span\",\"Visualization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Visualization\"]}],[\"$\",\"span\",\"Multi-Turn Dialogue\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-Turn Dialogue\"]}],[\"$\",\"span\",\"User Interface Design\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"User Interface Design\"]}],[\"$\",\"span\",\"Sensemaking\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Sensemaking\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-29-OneReward_Unified_Mask-Guided_Image_Generation_via_Multi-Task_Human_Preference_Learning\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-29-OneReward_Unified_Mask-Guided_Image_Generation_via_Multi-Task_Human_Preference_Learning/\",\"children\":\"[논문리뷰] OneReward: Unified Mask-Guided Image Generation via Multi-Task Human Preference Learning\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yitong Wang이 [arXiv]에 게시한 'OneReward: Unified Mask-Guided Image Generation via Multi-Task Human Preference Learning' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-29 13:14:44+0900\",\"children\":\"2025년 8월 29일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Image Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image Generation\"]}],[\"$\",\"span\",\"Mask-Guided Editing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Mask-Guided Editing\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Human Preference Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Human Preference Learning\"]}],[\"$\",\"span\",\"Vision-Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision-Language Models\"]}],[\"$\",\"span\",\"Multi-Task Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-Task Learning\"]}],[\"$\",\"span\",\"Flow Matching\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Flow Matching\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-29-Multi-View_3D_Point_Tracking\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-29-Multi-View_3D_Point_Tracking/\",\"children\":\"[논문리뷰] Multi-View 3D Point Tracking\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Irem Demir이 [arXiv]에 게시한 'Multi-View 3D Point Tracking' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-29 13:14:44+0900\",\"children\":\"2025년 8월 29일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"3D Point Tracking\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D Point Tracking\"]}],[\"$\",\"span\",\"Multi-View\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-View\"]}],[\"$\",\"span\",\"Transformer\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Transformer\"]}],[\"$\",\"span\",\"kNN Correlation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"kNN Correlation\"]}],[\"$\",\"span\",\"Depth Estimation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Depth Estimation\"]}],[\"$\",\"span\",\"Dynamic Scenes\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dynamic Scenes\"]}],[\"$\",\"span\",\"Occlusion Handling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Occlusion Handling\"]}],[\"$\",\"span\",\"Feature Fusion\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Feature Fusion\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-29-Mixture_of_Contexts_for_Long_Video_Generation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-29-Mixture_of_Contexts_for_Long_Video_Generation/\",\"children\":\"[논문리뷰] Mixture of Contexts for Long Video Generation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Junfei Xiao이 [arXiv]에 게시한 'Mixture of Contexts for Long Video Generation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-29 13:14:44+0900\",\"children\":\"2025년 8월 29일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Long Video Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Long Video Generation\"]}],[\"$\",\"span\",\"Diffusion Transformers (DiT)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Transformers (DiT)\"]}],[\"$\",\"span\",\"Sparse Attention\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Sparse Attention\"]}],[\"$\",\"span\",\"Context Routing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Context Routing\"]}],[\"$\",\"span\",\"Memory Management\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Memory Management\"]}],[\"$\",\"span\",\"Generative Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generative Models\"]}],[\"$\",\"span\",\"Video Synthesis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video Synthesis\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-29-MCP-Bench_Benchmarking_Tool-Using_LLM_Agents_with_Complex_Real-World_Tasks_via_MCP_Servers\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-29-MCP-Bench_Benchmarking_Tool-Using_LLM_Agents_with_Complex_Real-World_Tasks_via_MCP_Servers/\",\"children\":\"[논문리뷰] MCP-Bench: Benchmarking Tool-Using LLM Agents with Complex Real-World Tasks via MCP Servers\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Shashank Biju이 [arXiv]에 게시한 'MCP-Bench: Benchmarking Tool-Using LLM Agents with Complex Real-World Tasks via MCP Servers' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-29 13:14:44+0900\",\"children\":\"2025년 8월 29일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLM Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Agents\"]}],[\"$\",\"span\",\"Tool Use\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Tool Use\"]}],[\"$\",\"span\",\"Benchmarking\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmarking\"]}],[\"$\",\"span\",\"Model Context Protocol (MCP)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Model Context Protocol (MCP)\"]}],[\"$\",\"span\",\"Cross-Domain Orchestration\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Cross-Domain Orchestration\"]}],[\"$\",\"span\",\"Fuzzy Instructions\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Fuzzy Instructions\"]}],[\"$\",\"span\",\"Multi-Step Tasks\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-Step Tasks\"]}],[\"$\",\"span\",\"Real-World Scenarios\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Real-World Scenarios\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-29-FakeParts_a_New_Family_of_AI-Generated_DeepFakes\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-29-FakeParts_a_New_Family_of_AI-Generated_DeepFakes/\",\"children\":\"[논문리뷰] FakeParts: a New Family of AI-Generated DeepFakes\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Xi Wang이 [arXiv]에 게시한 'FakeParts: a New Family of AI-Generated DeepFakes' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-29 13:14:44+0900\",\"children\":\"2025년 8월 29일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Deepfake Detection\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Deepfake Detection\"]}],[\"$\",\"span\",\"Partial Deepfakes\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Partial Deepfakes\"]}],[\"$\",\"span\",\"AI-Generated Video\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"AI-Generated Video\"]}],[\"$\",\"span\",\"Benchmark Dataset\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmark Dataset\"]}],[\"$\",\"span\",\"Video Forensics\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video Forensics\"]}],[\"$\",\"span\",\"Generative Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generative Models\"]}],[\"$\",\"span\",\"Manipulation Detection\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Manipulation Detection\"]}],[\"$\",\"span\",\"Human Perception\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Human Perception\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-29-DressDance_Dress_up_and_Dance_as_You_Like_It_-_Technical_Preview\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-29-DressDance_Dress_up_and_Dance_as_You_Like_It_-_Technical_Preview/\",\"children\":\"[논문리뷰] Dress\u0026Dance: Dress up and Dance as You Like It - Technical Preview\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yu-Xiong Wang이 [arXiv]에 게시한 'Dress\u0026Dance: Dress up and Dance as You Like It - Technical Preview' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-29 13:14:44+0900\",\"children\":\"2025년 8월 29일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Virtual Try-On\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Virtual Try-On\"]}],[\"$\",\"span\",\"Video Diffusion\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video Diffusion\"]}],[\"$\",\"span\",\"Multi-modal Conditioning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-modal Conditioning\"]}],[\"$\",\"span\",\"Garment Transfer\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Garment Transfer\"]}],[\"$\",\"span\",\"Pose Animation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Pose Animation\"]}],[\"$\",\"span\",\"Generative AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generative AI\"]}],[\"$\",\"span\",\"Fashion Tech\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Fashion Tech\"]}],[\"$\",\"span\",\"CondNet\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"CondNet\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-29-Collaborative_Multi-Modal_Coding_for_High-Quality_3D_Generation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-29-Collaborative_Multi-Modal_Coding_for_High-Quality_3D_Generation/\",\"children\":\"[논문리뷰] Collaborative Multi-Modal Coding for High-Quality 3D Generation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Ziwei Liu이 [arXiv]에 게시한 'Collaborative Multi-Modal Coding for High-Quality 3D Generation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-29 13:14:44+0900\",\"children\":\"2025년 8월 29일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"3D Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D Generation\"]}],[\"$\",\"span\",\"Multi-modal Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-modal Learning\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}],[\"$\",\"span\",\"Triplane Representation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Triplane Representation\"]}],[\"$\",\"span\",\"Collaborative Coding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Collaborative Coding\"]}],[\"$\",\"span\",\"Image-to-3D\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image-to-3D\"]}],[\"$\",\"span\",\"Latent Space\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Latent Space\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-29-CogVLA_Cognition-Aligned_Vision-Language-Action_Model_via_Instruction-Driven_Routing_Sparsification\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-29-CogVLA_Cognition-Aligned_Vision-Language-Action_Model_via_Instruction-Driven_Routing_Sparsification/\",\"children\":\"[논문리뷰] CogVLA: Cognition-Aligned Vision-Language-Action Model via Instruction-Driven Routing \u0026 Sparsification\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Liqiang Nie이 [arXiv]에 게시한 'CogVLA: Cognition-Aligned Vision-Language-Action Model via Instruction-Driven Routing \u0026 Sparsification' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-29 13:14:44+0900\",\"children\":\"2025년 8월 29일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Vision-Language-Action Model\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision-Language-Action Model\"]}],[\"$\",\"span\",\"Sparsification\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Sparsification\"]}],[\"$\",\"span\",\"Instruction-Driven Routing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Instruction-Driven Routing\"]}],[\"$\",\"span\",\"Cognition-Aligned AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Cognition-Aligned AI\"]}],[\"$\",\"span\",\"Robotics\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Robotics\"]}],[\"$\",\"span\",\"Computational Efficiency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Computational Efficiency\"]}],[\"$\",\"span\",\"Multimodal AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal AI\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-29-AWorld_Orchestrating_the_Training_Recipe_for_Agentic_AI\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-29-AWorld_Orchestrating_the_Training_Recipe_for_Agentic_AI/\",\"children\":\"[논문리뷰] AWorld: Orchestrating the Training Recipe for Agentic AI\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Qintong Wu이 [arXiv]에 게시한 'AWorld: Orchestrating the Training Recipe for Agentic AI' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-29 13:14:44+0900\",\"children\":\"2025년 8월 29일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Agentic AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Agentic AI\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Distributed Systems\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Distributed Systems\"]}],[\"$\",\"span\",\"Experience Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Experience Generation\"]}],[\"$\",\"span\",\"LLM Fine-tuning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Fine-tuning\"]}],[\"$\",\"span\",\"GAIA Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"GAIA Benchmark\"]}],[\"$\",\"span\",\"Scalability\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Scalability\"]}],[\"$\",\"span\",\"AWORLD Framework\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"AWORLD Framework\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-28-Taming_the_Chaos_Coordinated_Autoscaling_for_Heterogeneous_and_Disaggregated_LLM_Inference\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-28-Taming_the_Chaos_Coordinated_Autoscaling_for_Heterogeneous_and_Disaggregated_LLM_Inference/\",\"children\":\"[논문리뷰] Taming the Chaos: Coordinated Autoscaling for Heterogeneous and Disaggregated LLM Inference\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Chunlei Han이 [arXiv]에 게시한 'Taming the Chaos: Coordinated Autoscaling for Heterogeneous and Disaggregated LLM Inference' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-28 13:10:39+0900\",\"children\":\"2025년 8월 28일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLM Inference\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Inference\"]}],[\"$\",\"span\",\"Autoscaling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Autoscaling\"]}],[\"$\",\"span\",\"Disaggregated Architecture\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Disaggregated Architecture\"]}],[\"$\",\"span\",\"Heterogeneous Hardware\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Heterogeneous Hardware\"]}],[\"$\",\"span\",\"Resource Management\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Resource Management\"]}],[\"$\",\"span\",\"Topology-aware Scheduling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Topology-aware Scheduling\"]}],[\"$\",\"span\",\"GPU Utilization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"GPU Utilization\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-28-StepWiser_Stepwise_Generative_Judges_for_Wiser_Reasoning\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-28-StepWiser_Stepwise_Generative_Judges_for_Wiser_Reasoning/\",\"children\":\"[논문리뷰] StepWiser: Stepwise Generative Judges for Wiser Reasoning\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Olga Golovneva이 [arXiv]에 게시한 'StepWiser: Stepwise Generative Judges for Wiser Reasoning' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-28 13:10:39+0900\",\"children\":\"2025년 8월 28일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLM Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Reasoning\"]}],[\"$\",\"span\",\"Process Reward Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Process Reward Models\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Generative Judges\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generative Judges\"]}],[\"$\",\"span\",\"Stepwise Feedback\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Stepwise Feedback\"]}],[\"$\",\"span\",\"Chain-of-Thought\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Chain-of-Thought\"]}],[\"$\",\"span\",\"Meta-Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Meta-Reasoning\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-28-Self-Rewarding_Vision-Language_Model_via_Reasoning_Decomposition\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-28-Self-Rewarding_Vision-Language_Model_via_Reasoning_Decomposition/\",\"children\":\"[논문리뷰] Self-Rewarding Vision-Language Model via Reasoning Decomposition\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Zhenwen Liang이 [arXiv]에 게시한 'Self-Rewarding Vision-Language Model via Reasoning Decomposition' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-28 13:10:39+0900\",\"children\":\"2025년 8월 28일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Vision-Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision-Language Models\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Self-Rewarding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Self-Rewarding\"]}],[\"$\",\"span\",\"Reasoning Decomposition\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reasoning Decomposition\"]}],[\"$\",\"span\",\"Visual Perception\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Visual Perception\"]}],[\"$\",\"span\",\"Language Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Language Reasoning\"]}],[\"$\",\"span\",\"Hallucinations\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Hallucinations\"]}],[\"$\",\"span\",\"Language Shortcuts\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Language Shortcuts\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-28-Predicting_the_Order_of_Upcoming_Tokens_Improves_Language_Modeling\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-28-Predicting_the_Order_of_Upcoming_Tokens_Improves_Language_Modeling/\",\"children\":\"[논문리뷰] Predicting the Order of Upcoming Tokens Improves Language Modeling\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Alham Fikri Aji이 [arXiv]에 게시한 'Predicting the Order of Upcoming Tokens Improves Language Modeling' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-28 13:10:39+0900\",\"children\":\"2025년 8월 28일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Language Modeling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Language Modeling\"]}],[\"$\",\"span\",\"Next-Token Prediction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Next-Token Prediction\"]}],[\"$\",\"span\",\"Multi-Token Prediction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-Token Prediction\"]}],[\"$\",\"span\",\"Token Order Prediction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Token Order Prediction\"]}],[\"$\",\"span\",\"Auxiliary Objective\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Auxiliary Objective\"]}],[\"$\",\"span\",\"Learning-to-Rank\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Learning-to-Rank\"]}],[\"$\",\"span\",\"Transformer\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Transformer\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-28-MotionFlux_Efficient_Text-Guided_Motion_Generation_through_Rectified_Flow_Matching_and_Preference_Alignment\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-28-MotionFlux_Efficient_Text-Guided_Motion_Generation_through_Rectified_Flow_Matching_and_Preference_Alignment/\",\"children\":\"[논문리뷰] MotionFlux: Efficient Text-Guided Motion Generation through Rectified Flow Matching and Preference Alignment\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"An-An Liu이 [arXiv]에 게시한 'MotionFlux: Efficient Text-Guided Motion Generation through Rectified Flow Matching and Preference Alignment' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-28 13:10:39+0900\",\"children\":\"2025년 8월 28일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Text-Guided Motion Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Text-Guided Motion Generation\"]}],[\"$\",\"span\",\"Rectified Flow Matching\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Rectified Flow Matching\"]}],[\"$\",\"span\",\"Preference Alignment\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Preference Alignment\"]}],[\"$\",\"span\",\"Human Motion Synthesis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Human Motion Synthesis\"]}],[\"$\",\"span\",\"Real-time AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Real-time AI\"]}],[\"$\",\"span\",\"Transformer Architecture\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Transformer Architecture\"]}],[\"$\",\"span\",\"Self-supervised Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Self-supervised Learning\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-28-Mind_the_Third_Eye_Benchmarking_Privacy_Awareness_in_MLLM-powered_Smartphone_Agents\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-28-Mind_the_Third_Eye_Benchmarking_Privacy_Awareness_in_MLLM-powered_Smartphone_Agents/\",\"children\":\"[논문리뷰] Mind the Third Eye! Benchmarking Privacy Awareness in MLLM-powered Smartphone Agents\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yue Yao이 [arXiv]에 게시한 'Mind the Third Eye! Benchmarking Privacy Awareness in MLLM-powered Smartphone Agents' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-28 13:10:39+0900\",\"children\":\"2025년 8월 28일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Multimodal LLMs (MLLMs)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal LLMs (MLLMs)\"]}],[\"$\",\"span\",\"Smartphone Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Smartphone Agents\"]}],[\"$\",\"span\",\"Privacy Awareness\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Privacy Awareness\"]}],[\"$\",\"span\",\"Benchmarking\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmarking\"]}],[\"$\",\"span\",\"Sensitive Data Detection\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Sensitive Data Detection\"]}],[\"$\",\"span\",\"Risk Assessment\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Risk Assessment\"]}],[\"$\",\"span\",\"UI Automation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"UI Automation\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-28-MIDAS_Multimodal_Interactive_Digital-human_Synthesis_via_Real-time_Autoregressive_Video_Generation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-28-MIDAS_Multimodal_Interactive_Digital-human_Synthesis_via_Real-time_Autoregressive_Video_Generation/\",\"children\":\"[논문리뷰] MIDAS: Multimodal Interactive Digital-human Synthesis via Real-time Autoregressive Video Generation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yan Zhou이 [arXiv]에 게시한 'MIDAS: Multimodal Interactive Digital-human Synthesis via Real-time Autoregressive Video Generation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-28 13:10:39+0900\",\"children\":\"2025년 8월 28일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Multimodal Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Generation\"]}],[\"$\",\"span\",\"Digital Human Synthesis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Digital Human Synthesis\"]}],[\"$\",\"span\",\"Real-time Video Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Real-time Video Generation\"]}],[\"$\",\"span\",\"Autoregressive LLM\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Autoregressive LLM\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}],[\"$\",\"span\",\"Deep Compression Autoencoder\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Deep Compression Autoencoder\"]}],[\"$\",\"span\",\"Exposure Bias Mitigation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Exposure Bias Mitigation\"]}],[\"$\",\"span\",\"Streaming Inference\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Streaming Inference\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-28-Gaze_into_the_Heart_A_Multi-View_Video_Dataset_for_rPPG_and_Health_Biomarkers_Estimation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-28-Gaze_into_the_Heart_A_Multi-View_Video_Dataset_for_rPPG_and_Health_Biomarkers_Estimation/\",\"children\":\"[논문리뷰] Gaze into the Heart: A Multi-View Video Dataset for rPPG and Health Biomarkers Estimation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Anton Ivaschenko이 [arXiv]에 게시한 'Gaze into the Heart: A Multi-View Video Dataset for rPPG and Health Biomarkers Estimation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-28 13:10:39+0900\",\"children\":\"2025년 8월 28일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"rPPG\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"rPPG\"]}],[\"$\",\"span\",\"Multi-View Video Dataset\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-View Video Dataset\"]}],[\"$\",\"span\",\"Health Biomarkers\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Health Biomarkers\"]}],[\"$\",\"span\",\"Physiological Monitoring\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Physiological Monitoring\"]}],[\"$\",\"span\",\"Deep Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Deep Learning\"]}],[\"$\",\"span\",\"Telemedicine\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Telemedicine\"]}],[\"$\",\"span\",\"Biosignals\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Biosignals\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-28-Discrete_Diffusion_VLA_Bringing_Discrete_Diffusion_to_Action_Decoding_in_Vision-Language-Action_Policies\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-28-Discrete_Diffusion_VLA_Bringing_Discrete_Diffusion_to_Action_Decoding_in_Vision-Language-Action_Policies/\",\"children\":\"[논문리뷰] Discrete Diffusion VLA: Bringing Discrete Diffusion to Action Decoding in Vision-Language-Action Policies\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Sitong Mao이 [arXiv]에 게시한 'Discrete Diffusion VLA: Bringing Discrete Diffusion to Action Decoding in Vision-Language-Action Policies' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-28 13:10:39+0900\",\"children\":\"2025년 8월 28일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Vision-Language-Action (VLA)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision-Language-Action (VLA)\"]}],[\"$\",\"span\",\"Discrete Diffusion\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Discrete Diffusion\"]}],[\"$\",\"span\",\"Action Decoding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Action Decoding\"]}],[\"$\",\"span\",\"Transformer\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Transformer\"]}],[\"$\",\"span\",\"Robot Control\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Robot Control\"]}],[\"$\",\"span\",\"Masked Modeling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Masked Modeling\"]}],[\"$\",\"span\",\"Adaptive Decoding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Adaptive Decoding\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-28-Diffusion_Language_Models_Know_the_Answer_Before_Decoding\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-28-Diffusion_Language_Models_Know_the_Answer_Before_Decoding/\",\"children\":\"[논문리뷰] Diffusion Language Models Know the Answer Before Decoding\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Shilin Yan이 [arXiv]에 게시한 'Diffusion Language Models Know the Answer Before Decoding' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-28 13:10:39+0900\",\"children\":\"2025년 8월 28일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Diffusion Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Language Models\"]}],[\"$\",\"span\",\"DLM Acceleration\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"DLM Acceleration\"]}],[\"$\",\"span\",\"Early Answer Convergence\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Early Answer Convergence\"]}],[\"$\",\"span\",\"Early Commit Decoding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Early Commit Decoding\"]}],[\"$\",\"span\",\"Confidence Gap\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Confidence Gap\"]}],[\"$\",\"span\",\"Inference Speedup\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Inference Speedup\"]}],[\"$\",\"span\",\"Training-Free\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Training-Free\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-28-DeepScholar-Bench_A_Live_Benchmark_and_Automated_Evaluation_for_Generative_Research_Synthesis\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-28-DeepScholar-Bench_A_Live_Benchmark_and_Automated_Evaluation_for_Generative_Research_Synthesis/\",\"children\":\"[논문리뷰] DeepScholar-Bench: A Live Benchmark and Automated Evaluation for Generative Research Synthesis\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Ion Stoica이 [arXiv]에 게시한 'DeepScholar-Bench: A Live Benchmark and Automated Evaluation for Generative Research Synthesis' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-28 13:10:39+0900\",\"children\":\"2025년 8월 28일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Generative Research Synthesis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generative Research Synthesis\"]}],[\"$\",\"span\",\"Live Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Live Benchmark\"]}],[\"$\",\"span\",\"Automated Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Automated Evaluation\"]}],[\"$\",\"span\",\"LLM-as-a-judge\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM-as-a-judge\"]}],[\"$\",\"span\",\"Related Work Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Related Work Generation\"]}],[\"$\",\"span\",\"Retrieval-Augmented Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Retrieval-Augmented Generation\"]}],[\"$\",\"span\",\"Verifiability\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Verifiability\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-28-CODA_Coordinating_the_Cerebrum_and_Cerebellum_for_a_Dual-Brain_Computer_Use_Agent_with_Decoupled_Reinforcement_Learning\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-28-CODA_Coordinating_the_Cerebrum_and_Cerebellum_for_a_Dual-Brain_Computer_Use_Agent_with_Decoupled_Reinforcement_Learning/\",\"children\":\"[논문리뷰] CODA: Coordinating the Cerebrum and Cerebellum for a Dual-Brain Computer Use Agent with Decoupled Reinforcement Learning\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Jianze Liang이 [arXiv]에 게시한 'CODA: Coordinating the Cerebrum and Cerebellum for a Dual-Brain Computer Use Agent with Decoupled Reinforcement Learning' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-28 13:10:39+0900\",\"children\":\"2025년 8월 28일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"GUI Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"GUI Agents\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Planner-Executor Architecture\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Planner-Executor Architecture\"]}],[\"$\",\"span\",\"Decoupled Training\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Decoupled Training\"]}],[\"$\",\"span\",\"Large Vision-Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Vision-Language Models\"]}],[\"$\",\"span\",\"Specialization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Specialization\"]}],[\"$\",\"span\",\"Generalization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generalization\"]}],[\"$\",\"span\",\"Computer Use Agent\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Computer Use Agent\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-28-Beyond_Transcription_Mechanistic_Interpretability_in_ASR\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-28-Beyond_Transcription_Mechanistic_Interpretability_in_ASR/\",\"children\":\"[논문리뷰] Beyond Transcription: Mechanistic Interpretability in ASR\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Aviv Shamsian이 [arXiv]에 게시한 'Beyond Transcription: Mechanistic Interpretability in ASR' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-28 13:10:39+0900\",\"children\":\"2025년 8월 28일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"ASR\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"ASR\"]}],[\"$\",\"span\",\"Mechanistic Interpretability\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Mechanistic Interpretability\"]}],[\"$\",\"span\",\"Logit Lens\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Logit Lens\"]}],[\"$\",\"span\",\"Linear Probing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Linear Probing\"]}],[\"$\",\"span\",\"Activation Patching\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Activation Patching\"]}],[\"$\",\"span\",\"Hallucinations\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Hallucinations\"]}],[\"$\",\"span\",\"Repetitions\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Repetitions\"]}],[\"$\",\"span\",\"Encoder-Decoder\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Encoder-Decoder\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-28-AudioStory_Generating_Long-Form_Narrative_Audio_with_Large_Language_Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-28-AudioStory_Generating_Long-Form_Narrative_Audio_with_Large_Language_Models/\",\"children\":\"[논문리뷰] AudioStory: Generating Long-Form Narrative Audio with Large Language Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yixiao Ge이 [arXiv]에 게시한 'AudioStory: Generating Long-Form Narrative Audio with Large Language Models' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-28 13:10:39+0900\",\"children\":\"2025년 8월 28일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Text-to-Audio\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Text-to-Audio\"]}],[\"$\",\"span\",\"Long-Form Audio Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Long-Form Audio Generation\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Narrative Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Narrative Reasoning\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}],[\"$\",\"span\",\"Multimodal AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal AI\"]}],[\"$\",\"span\",\"Progressive Training\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Progressive Training\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-27-Wan-S2V_Audio-Driven_Cinematic_Video_Generation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-27-Wan-S2V_Audio-Driven_Cinematic_Video_Generation/\",\"children\":\"[논문리뷰] Wan-S2V: Audio-Driven Cinematic Video Generation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Chaonan Ji이 [arXiv]에 게시한 'Wan-S2V: Audio-Driven Cinematic Video Generation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-27 13:22:18+0900\",\"children\":\"2025년 8월 27일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Audio-Driven Video Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Audio-Driven Video Generation\"]}],[\"$\",\"span\",\"Cinematic Video\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Cinematic Video\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}],[\"$\",\"span\",\"Transformer Architecture\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Transformer Architecture\"]}],[\"$\",\"span\",\"Long Video Consistency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Long Video Consistency\"]}],[\"$\",\"span\",\"Human Animation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Human Animation\"]}],[\"$\",\"span\",\"Multimodal Control\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Control\"]}],[\"$\",\"span\",\"Data Curation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Curation\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-27-VoxHammer_Training-Free_Precise_and_Coherent_3D_Editing_in_Native_3D_Space\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-27-VoxHammer_Training-Free_Precise_and_Coherent_3D_Editing_in_Native_3D_Space/\",\"children\":\"[논문리뷰] VoxHammer: Training-Free Precise and Coherent 3D Editing in Native 3D Space\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Rui Chen이 [arXiv]에 게시한 'VoxHammer: Training-Free Precise and Coherent 3D Editing in Native 3D Space' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-27 13:22:18+0900\",\"children\":\"2025년 8월 27일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"3D Editing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D Editing\"]}],[\"$\",\"span\",\"Training-Free\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Training-Free\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}],[\"$\",\"span\",\"Latent Space\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Latent Space\"]}],[\"$\",\"span\",\"3D Inversion\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D Inversion\"]}],[\"$\",\"span\",\"Contextual Feature Replacement\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Contextual Feature Replacement\"]}],[\"$\",\"span\",\"3D Consistency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D Consistency\"]}],[\"$\",\"span\",\"Edit3D-Bench\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Edit3D-Bench\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-27-VibeVoice_Technical_Report\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-27-VibeVoice_Technical_Report/\",\"children\":\"[논문리뷰] VibeVoice Technical Report\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yaoyao Chang이 [arXiv]에 게시한 'VibeVoice Technical Report' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-27 13:22:18+0900\",\"children\":\"2025년 8월 27일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Speech Synthesis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Speech Synthesis\"]}],[\"$\",\"span\",\"Long-form Audio\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Long-form Audio\"]}],[\"$\",\"span\",\"Multi-speaker\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-speaker\"]}],[\"$\",\"span\",\"Next-token Diffusion\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Next-token Diffusion\"]}],[\"$\",\"span\",\"Speech Tokenizer\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Speech Tokenizer\"]}],[\"$\",\"span\",\"Large Language Model\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Model\"]}],[\"$\",\"span\",\"Variational Autoencoder\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Variational Autoencoder\"]}],[\"$\",\"span\",\"Audio Compression\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Audio Compression\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-27-Unraveling_the_cognitive_patterns_of_Large_Language_Models_through_module_communities\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-27-Unraveling_the_cognitive_patterns_of_Large_Language_Models_through_module_communities/\",\"children\":\"[논문리뷰] Unraveling the cognitive patterns of Large Language Models through module communities\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Jianxi Gao이 [arXiv]에 게시한 'Unraveling the cognitive patterns of Large Language Models through module communities' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-27 13:22:18+0900\",\"children\":\"2025년 8월 27일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Network Community Structure\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Network Community Structure\"]}],[\"$\",\"span\",\"Cognitive Skills\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Cognitive Skills\"]}],[\"$\",\"span\",\"AI Interpretability\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"AI Interpretability\"]}],[\"$\",\"span\",\"Module Communities\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Module Communities\"]}],[\"$\",\"span\",\"Fine-tuning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Fine-tuning\"]}],[\"$\",\"span\",\"Neural Plasticity\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Neural Plasticity\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-27-UltraMemV2_Memory_Networks_Scaling_to_120B_Parameters_with_Superior_Long-Context_Learning\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-27-UltraMemV2_Memory_Networks_Scaling_to_120B_Parameters_with_Superior_Long-Context_Learning/\",\"children\":\"[논문리뷰] UltraMemV2: Memory Networks Scaling to 120B Parameters with Superior Long-Context Learning\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Ran Guo이 [arXiv]에 게시한 'UltraMemV2: Memory Networks Scaling to 120B Parameters with Superior Long-Context Learning' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-27 13:22:18+0900\",\"children\":\"2025년 8월 27일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Memory Networks\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Memory Networks\"]}],[\"$\",\"span\",\"Mixture of Experts (MoE)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Mixture of Experts (MoE)\"]}],[\"$\",\"span\",\"Long-Context Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Long-Context Learning\"]}],[\"$\",\"span\",\"Sparse Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Sparse Models\"]}],[\"$\",\"span\",\"Transformer Architecture\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Transformer Architecture\"]}],[\"$\",\"span\",\"LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLMs\"]}],[\"$\",\"span\",\"Efficient Inference\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Efficient Inference\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-27-TreePO_Bridging_the_Gap_of_Policy_Optimization_and_Efficacy_and_Inference_Efficiency_with_Heuristic_Tree-based_Modeling\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-27-TreePO_Bridging_the_Gap_of_Policy_Optimization_and_Efficacy_and_Inference_Efficiency_with_Heuristic_Tree-based_Modeling/\",\"children\":\"[논문리뷰] TreePO: Bridging the Gap of Policy Optimization and Efficacy and Inference Efficiency with Heuristic Tree-based Modeling\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Zhoufutu Wen이 [arXiv]에 게시한 'TreePO: Bridging the Gap of Policy Optimization and Efficacy and Inference Efficiency with Heuristic Tree-based Modeling' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-27 13:22:18+0900\",\"children\":\"2025년 8월 27일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Policy Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Policy Optimization\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Inference Efficiency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Inference Efficiency\"]}],[\"$\",\"span\",\"Tree Search\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Tree Search\"]}],[\"$\",\"span\",\"Segment-level Decoding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Segment-level Decoding\"]}],[\"$\",\"span\",\"Advantage Estimation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Advantage Estimation\"]}],[\"$\",\"span\",\"Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reasoning\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-27-Training_Language_Model_Agents_to_Find_Vulnerabilities_with_CTF-Dojo\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-27-Training_Language_Model_Agents_to_Find_Vulnerabilities_with_CTF-Dojo/\",\"children\":\"[논문리뷰] Training Language Model Agents to Find Vulnerabilities with CTF-Dojo\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Zijian Wang이 [arXiv]에 게시한 'Training Language Model Agents to Find Vulnerabilities with CTF-Dojo' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-27 13:22:18+0900\",\"children\":\"2025년 8월 27일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLM Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Agents\"]}],[\"$\",\"span\",\"Cybersecurity\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Cybersecurity\"]}],[\"$\",\"span\",\"CTF Challenges\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"CTF Challenges\"]}],[\"$\",\"span\",\"Vulnerability Detection\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vulnerability Detection\"]}],[\"$\",\"span\",\"Execution Environments\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Execution Environments\"]}],[\"$\",\"span\",\"Docker\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Docker\"]}],[\"$\",\"span\",\"Automated Training\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Automated Training\"]}],[\"$\",\"span\",\"Verifiable Feedback\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Verifiable Feedback\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-27-ThinkDial_An_Open_Recipe_for_Controlling_Reasoning_Effort_in_Large_Language_Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-27-ThinkDial_An_Open_Recipe_for_Controlling_Reasoning_Effort_in_Large_Language_Models/\",\"children\":\"[논문리뷰] ThinkDial: An Open Recipe for Controlling Reasoning Effort in Large Language Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Jiangjie Chen이 [arXiv]에 게시한 'ThinkDial: An Open Recipe for Controlling Reasoning Effort in Large Language Models' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-27 13:22:18+0900\",\"children\":\"2025년 8월 27일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLMs\"]}],[\"$\",\"span\",\"Controllable Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Controllable Reasoning\"]}],[\"$\",\"span\",\"Computational Efficiency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Computational Efficiency\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Supervised Fine-tuning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Supervised Fine-tuning\"]}],[\"$\",\"span\",\"Reasoning Compression\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reasoning Compression\"]}],[\"$\",\"span\",\"Budget-Aware Training\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Budget-Aware Training\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-27-Spacer_Towards_Engineered_Scientific_Inspiration\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-27-Spacer_Towards_Engineered_Scientific_Inspiration/\",\"children\":\"[논문리뷰] Spacer: Towards Engineered Scientific Inspiration\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"zerojun48이 [arXiv]에 게시한 'Spacer: Towards Engineered Scientific Inspiration' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-27 13:22:18+0900\",\"children\":\"2025년 8월 27일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Scientific Discovery\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Scientific Discovery\"]}],[\"$\",\"span\",\"Large Language Models (LLMs)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models (LLMs)\"]}],[\"$\",\"span\",\"Decontextualization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Decontextualization\"]}],[\"$\",\"span\",\"Keyword Graph\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Keyword Graph\"]}],[\"$\",\"span\",\"Multi-Agent System\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-Agent System\"]}],[\"$\",\"span\",\"Scientific Ideation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Scientific Ideation\"]}],[\"$\",\"span\",\"Research Automation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Research Automation\"]}],[\"$\",\"span\",\"Inspiration Engine\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Inspiration Engine\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-27-ReportBench_Evaluating_Deep_Research_Agents_via_Academic_Survey_Tasks\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-27-ReportBench_Evaluating_Deep_Research_Agents_via_Academic_Survey_Tasks/\",\"children\":\"[논문리뷰] ReportBench: Evaluating Deep Research Agents via Academic Survey Tasks\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Kai Jia이 [arXiv]에 게시한 'ReportBench: Evaluating Deep Research Agents via Academic Survey Tasks' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-27 13:22:18+0900\",\"children\":\"2025년 8월 27일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Deep Research Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Deep Research Agents\"]}],[\"$\",\"span\",\"LLM Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Evaluation\"]}],[\"$\",\"span\",\"Academic Survey\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Academic Survey\"]}],[\"$\",\"span\",\"Factual Accuracy\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Factual Accuracy\"]}],[\"$\",\"span\",\"Citation Verification\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Citation Verification\"]}],[\"$\",\"span\",\"Report Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Report Generation\"]}],[\"$\",\"span\",\"Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmark\"]}],[\"$\",\"span\",\"Hallucination\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Hallucination\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-27-QueryBandits_for_Hallucination_Mitigation_Exploiting_Semantic_Features_for_No-Regret_Rewriting\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-27-QueryBandits_for_Hallucination_Mitigation_Exploiting_Semantic_Features_for_No-Regret_Rewriting/\",\"children\":\"[논문리뷰] QueryBandits for Hallucination Mitigation: Exploiting Semantic Features for No-Regret Rewriting\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Manuela Veloso이 [arXiv]에 게시한 'QueryBandits for Hallucination Mitigation: Exploiting Semantic Features for No-Regret Rewriting' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-27 13:22:18+0900\",\"children\":\"2025년 8월 27일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Hallucination Mitigation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Hallucination Mitigation\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Contextual Bandits\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Contextual Bandits\"]}],[\"$\",\"span\",\"Query Rewriting\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Query Rewriting\"]}],[\"$\",\"span\",\"Semantic Features\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Semantic Features\"]}],[\"$\",\"span\",\"No-Regret Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"No-Regret Learning\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-27-Pixie_Fast_and_Generalizable_Supervised_Learning_of_3D_Physics_from_Pixels\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-27-Pixie_Fast_and_Generalizable_Supervised_Learning_of_3D_Physics_from_Pixels/\",\"children\":\"[논문리뷰] Pixie: Fast and Generalizable Supervised Learning of 3D Physics from Pixels\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Dinesh Jayaraman이 [arXiv]에 게시한 'Pixie: Fast and Generalizable Supervised Learning of 3D Physics from Pixels' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-27 13:22:18+0900\",\"children\":\"2025년 8월 27일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"3D Physics Prediction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D Physics Prediction\"]}],[\"$\",\"span\",\"Supervised Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Supervised Learning\"]}],[\"$\",\"span\",\"CLIP Features\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"CLIP Features\"]}],[\"$\",\"span\",\"Neural Radiance Fields\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Neural Radiance Fields\"]}],[\"$\",\"span\",\"Material Point Method\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Material Point Method\"]}],[\"$\",\"span\",\"PIXIEVERSE Dataset\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"PIXIEVERSE Dataset\"]}],[\"$\",\"span\",\"Zero-Shot Generalization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Zero-Shot Generalization\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-27-Optimal_Sparsity_of_Mixture-of-Experts_Language_Models_for_Reasoning_Tasks\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-27-Optimal_Sparsity_of_Mixture-of-Experts_Language_Models_for_Reasoning_Tasks/\",\"children\":\"[논문리뷰] Optimal Sparsity of Mixture-of-Experts Language Models for Reasoning Tasks\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Daisuke Nohara이 [arXiv]에 게시한 'Optimal Sparsity of Mixture-of-Experts Language Models for Reasoning Tasks' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-27 13:22:18+0900\",\"children\":\"2025년 8월 27일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Mixture-of-Experts (MoE)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Mixture-of-Experts (MoE)\"]}],[\"$\",\"span\",\"Sparsity\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Sparsity\"]}],[\"$\",\"span\",\"Scaling Laws\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Scaling Laws\"]}],[\"$\",\"span\",\"Reasoning Tasks\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reasoning Tasks\"]}],[\"$\",\"span\",\"Memorization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Memorization\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Generalization Gap\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generalization Gap\"]}],[\"$\",\"span\",\"Top-k Routing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Top-k Routing\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-27-OmniHuman-1.5_Instilling_an_Active_Mind_in_Avatars_via_Cognitive_Simulation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-27-OmniHuman-1.5_Instilling_an_Active_Mind_in_Avatars_via_Cognitive_Simulation/\",\"children\":\"[논문리뷰] OmniHuman-1.5: Instilling an Active Mind in Avatars via Cognitive Simulation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Jiaqi Yang이 [arXiv]에 게시한 'OmniHuman-1.5: Instilling an Active Mind in Avatars via Cognitive Simulation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-27 13:22:18+0900\",\"children\":\"2025년 8월 27일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Video Avatar Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video Avatar Generation\"]}],[\"$\",\"span\",\"Cognitive Simulation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Cognitive Simulation\"]}],[\"$\",\"span\",\"Multimodal Large Language Models (MLLMs)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Large Language Models (MLLMs)\"]}],[\"$\",\"span\",\"Diffusion Transformers (DiT)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Transformers (DiT)\"]}],[\"$\",\"span\",\"Multimodal Fusion\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Fusion\"]}],[\"$\",\"span\",\"Human Motion Synthesis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Human Motion Synthesis\"]}],[\"$\",\"span\",\"Contextual Animation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Contextual Animation\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-27-ObjFiller-3D_Consistent_Multi-view_3D_Inpainting_via_Video_Diffusion_Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-27-ObjFiller-3D_Consistent_Multi-view_3D_Inpainting_via_Video_Diffusion_Models/\",\"children\":\"[논문리뷰] ObjFiller-3D: Consistent Multi-view 3D Inpainting via Video Diffusion Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Beiqi Chen이 [arXiv]에 게시한 'ObjFiller-3D: Consistent Multi-view 3D Inpainting via Video Diffusion Models' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-27 13:22:18+0900\",\"children\":\"2025년 8월 27일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"3D Inpainting\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D Inpainting\"]}],[\"$\",\"span\",\"Multi-view Consistency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-view Consistency\"]}],[\"$\",\"span\",\"Video Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video Diffusion Models\"]}],[\"$\",\"span\",\"3D Object Completion\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D Object Completion\"]}],[\"$\",\"span\",\"Generative Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generative Models\"]}],[\"$\",\"span\",\"LoRA\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LoRA\"]}],[\"$\",\"span\",\"3D Gaussian Splatting\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D Gaussian Splatting\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-27-MovieCORE_COgnitive_REasoning_in_Movies\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-27-MovieCORE_COgnitive_REasoning_in_Movies/\",\"children\":\"[논문리뷰] MovieCORE: COgnitive REasoning in Movies\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Hung-Ting Su이 [arXiv]에 게시한 'MovieCORE: COgnitive REasoning in Movies' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-27 13:22:18+0900\",\"children\":\"2025년 8월 27일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Video Question Answering (VQA)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video Question Answering (VQA)\"]}],[\"$\",\"span\",\"Cognitive Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Cognitive Reasoning\"]}],[\"$\",\"span\",\"System-2 Thinking\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"System-2 Thinking\"]}],[\"$\",\"span\",\"Multi-agent LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-agent LLMs\"]}],[\"$\",\"span\",\"Dataset Creation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dataset Creation\"]}],[\"$\",\"span\",\"Movie Understanding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Movie Understanding\"]}],[\"$\",\"span\",\"Cinematic Content\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Cinematic Content\"]}],[\"$\",\"span\",\"Agentic Enhancement\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Agentic Enhancement\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-27-FastMeshEfficient_Artistic_Mesh_Generation_via_Component_Decoupling\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-27-FastMeshEfficient_Artistic_Mesh_Generation_via_Component_Decoupling/\",\"children\":\"[논문리뷰] FastMesh:Efficient Artistic Mesh Generation via Component Decoupling\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Xingang Pan이 [arXiv]에 게시한 'FastMesh:Efficient Artistic Mesh Generation via Component Decoupling' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-27 13:22:18+0900\",\"children\":\"2025년 8월 27일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"3D Mesh Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D Mesh Generation\"]}],[\"$\",\"span\",\"Component Decoupling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Component Decoupling\"]}],[\"$\",\"span\",\"Autoregressive Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Autoregressive Models\"]}],[\"$\",\"span\",\"Bidirectional Transformer\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Bidirectional Transformer\"]}],[\"$\",\"span\",\"Fidelity Enhancement\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Fidelity Enhancement\"]}],[\"$\",\"span\",\"Prediction Filtering\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Prediction Filtering\"]}],[\"$\",\"span\",\"Token Efficiency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Token Efficiency\"]}],[\"$\",\"span\",\"Artistic Meshes\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Artistic Meshes\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-27-Demystifying_Scientific_Problem-Solving_in_LLMs_by_Probing_Knowledge_and_Reasoning\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-27-Demystifying_Scientific_Problem-Solving_in_LLMs_by_Probing_Knowledge_and_Reasoning/\",\"children\":\"[논문리뷰] Demystifying Scientific Problem-Solving in LLMs by Probing Knowledge and Reasoning\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Arman Cohan이 [arXiv]에 게시한 'Demystifying Scientific Problem-Solving in LLMs by Probing Knowledge and Reasoning' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-27 13:22:18+0900\",\"children\":\"2025년 8월 27일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Scientific Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Scientific Reasoning\"]}],[\"$\",\"span\",\"Knowledge Retrieval\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Knowledge Retrieval\"]}],[\"$\",\"span\",\"Reasoning Probing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reasoning Probing\"]}],[\"$\",\"span\",\"Benchmarks\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmarks\"]}],[\"$\",\"span\",\"Chain-of-Thought\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Chain-of-Thought\"]}],[\"$\",\"span\",\"Fine-tuning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Fine-tuning\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-27-CMPhysBench_A_Benchmark_for_Evaluating_Large_Language_Models_in_Condensed_Matter_Physics\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-27-CMPhysBench_A_Benchmark_for_Evaluating_Large_Language_Models_in_Condensed_Matter_Physics/\",\"children\":\"[논문리뷰] CMPhysBench: A Benchmark for Evaluating Large Language Models in Condensed Matter Physics\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Dongchen Huang이 [arXiv]에 게시한 'CMPhysBench: A Benchmark for Evaluating Large Language Models in Condensed Matter Physics' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-27 13:22:18+0900\",\"children\":\"2025년 8월 27일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Condensed Matter Physics\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Condensed Matter Physics\"]}],[\"$\",\"span\",\"Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmark\"]}],[\"$\",\"span\",\"Scientific Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Scientific Reasoning\"]}],[\"$\",\"span\",\"Evaluation Metric\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Evaluation Metric\"]}],[\"$\",\"span\",\"Expression Edit Distance\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Expression Edit Distance\"]}],[\"$\",\"span\",\"Problem Solving\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Problem Solving\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-27-ClaimGen-CN_A_Large-scale_Chinese_Dataset_for_Legal_Claim_Generation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-27-ClaimGen-CN_A_Large-scale_Chinese_Dataset_for_Legal_Claim_Generation/\",\"children\":\"[논문리뷰] ClaimGen-CN: A Large-scale Chinese Dataset for Legal Claim Generation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Kun Kuang이 [arXiv]에 게시한 'ClaimGen-CN: A Large-scale Chinese Dataset for Legal Claim Generation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-27 13:22:18+0900\",\"children\":\"2025년 8월 27일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Legal AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Legal AI\"]}],[\"$\",\"span\",\"Natural Language Processing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Natural Language Processing\"]}],[\"$\",\"span\",\"Claim Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Claim Generation\"]}],[\"$\",\"span\",\"Chinese Legal Dataset\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Chinese Legal Dataset\"]}],[\"$\",\"span\",\"Factuality\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Factuality\"]}],[\"$\",\"span\",\"Clarity\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Clarity\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Zero-shot Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Zero-shot Evaluation\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-27-CineScale_Free_Lunch_in_High-Resolution_Cinematic_Visual_Generation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-27-CineScale_Free_Lunch_in_High-Resolution_Cinematic_Visual_Generation/\",\"children\":\"[논문리뷰] CineScale: Free Lunch in High-Resolution Cinematic Visual Generation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Ziwei Liu이 [arXiv]에 게시한 'CineScale: Free Lunch in High-Resolution Cinematic Visual Generation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-27 13:22:18+0900\",\"children\":\"2025년 8월 27일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}],[\"$\",\"span\",\"High-Resolution Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"High-Resolution Generation\"]}],[\"$\",\"span\",\"Image Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image Generation\"]}],[\"$\",\"span\",\"Video Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video Generation\"]}],[\"$\",\"span\",\"UNet Architecture\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"UNet Architecture\"]}],[\"$\",\"span\",\"DiT Architecture\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"DiT Architecture\"]}],[\"$\",\"span\",\"Scale Fusion\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Scale Fusion\"]}],[\"$\",\"span\",\"LoRA Fine-tuning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LoRA Fine-tuning\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-27-Autoregressive_Universal_Video_Segmentation_Model\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-27-Autoregressive_Universal_Video_Segmentation_Model/\",\"children\":\"[논문리뷰] Autoregressive Universal Video Segmentation Model\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Albert Gu이 [arXiv]에 게시한 'Autoregressive Universal Video Segmentation Model' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-27 13:22:18+0900\",\"children\":\"2025년 8월 27일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Video Segmentation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video Segmentation\"]}],[\"$\",\"span\",\"Autoregressive Model\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Autoregressive Model\"]}],[\"$\",\"span\",\"Universal Model\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Universal Model\"]}],[\"$\",\"span\",\"State Space Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"State Space Models\"]}],[\"$\",\"span\",\"Mamba\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Mamba\"]}],[\"$\",\"span\",\"Parallel Training\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Parallel Training\"]}],[\"$\",\"span\",\"Streaming Video\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Streaming Video\"]}],[\"$\",\"span\",\"Deep Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Deep Learning\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-26-Visual-CoG_Stage-Aware_Reinforcement_Learning_with_Chain_of_Guidance_for_Text-to-Image_Generation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-26-Visual-CoG_Stage-Aware_Reinforcement_Learning_with_Chain_of_Guidance_for_Text-to-Image_Generation/\",\"children\":\"[논문리뷰] Visual-CoG: Stage-Aware Reinforcement Learning with Chain of Guidance for Text-to-Image Generation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Haoxiang Shi이 [arXiv]에 게시한 'Visual-CoG: Stage-Aware Reinforcement Learning with Chain of Guidance for Text-to-Image Generation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-26 13:21:57+0900\",\"children\":\"2025년 8월 26일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Text-to-Image Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Text-to-Image Generation\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Chain of Thought\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Chain of Thought\"]}],[\"$\",\"span\",\"Multimodal LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal LLMs\"]}],[\"$\",\"span\",\"Stage-Aware Rewards\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Stage-Aware Rewards\"]}],[\"$\",\"span\",\"Semantic Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Semantic Reasoning\"]}],[\"$\",\"span\",\"Generative AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generative AI\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-26-UQ_Assessing_Language_Models_on_Unsolved_Questions\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-26-UQ_Assessing_Language_Models_on_Unsolved_Questions/\",\"children\":\"[논문리뷰] UQ: Assessing Language Models on Unsolved Questions\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Wei Liu이 [arXiv]에 게시한 'UQ: Assessing Language Models on Unsolved Questions' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-26 13:21:57+0900\",\"children\":\"2025년 8월 26일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLM Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Evaluation\"]}],[\"$\",\"span\",\"Unsolved Questions\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Unsolved Questions\"]}],[\"$\",\"span\",\"AI Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"AI Benchmark\"]}],[\"$\",\"span\",\"Oracle-Free Validation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Oracle-Free Validation\"]}],[\"$\",\"span\",\"Generator-Validator Gap\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generator-Validator Gap\"]}],[\"$\",\"span\",\"Community Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Community Evaluation\"]}],[\"$\",\"span\",\"Stack Exchange\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Stack Exchange\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-26-TaDiCodec_Text-aware_Diffusion_Speech_Tokenizer_for_Speech_Language_Modeling\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-26-TaDiCodec_Text-aware_Diffusion_Speech_Tokenizer_for_Speech_Language_Modeling/\",\"children\":\"[논문리뷰] TaDiCodec: Text-aware Diffusion Speech Tokenizer for Speech Language Modeling\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Jiaqi Li이 [arXiv]에 게시한 'TaDiCodec: Text-aware Diffusion Speech Tokenizer for Speech Language Modeling' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-26 13:21:57+0900\",\"children\":\"2025년 8월 26일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Speech Tokenizer\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Speech Tokenizer\"]}],[\"$\",\"span\",\"Diffusion Model\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Model\"]}],[\"$\",\"span\",\"Text-to-Speech\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Text-to-Speech\"]}],[\"$\",\"span\",\"Speech Language Modeling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Speech Language Modeling\"]}],[\"$\",\"span\",\"Low Bitrate Codec\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Low Bitrate Codec\"]}],[\"$\",\"span\",\"End-to-End Training\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"End-to-End Training\"]}],[\"$\",\"span\",\"Binary Spherical Quantization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Binary Spherical Quantization\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-26-T2I-ReasonBench_Benchmarking_Reasoning-Informed_Text-to-Image_Generation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-26-T2I-ReasonBench_Benchmarking_Reasoning-Informed_Text-to-Image_Generation/\",\"children\":\"[논문리뷰] T2I-ReasonBench: Benchmarking Reasoning-Informed Text-to-Image Generation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Xihui Liu이 [arXiv]에 게시한 'T2I-ReasonBench: Benchmarking Reasoning-Informed Text-to-Image Generation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-26 13:21:57+0900\",\"children\":\"2025년 8월 26일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Text-to-Image Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Text-to-Image Generation\"]}],[\"$\",\"span\",\"Reasoning Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reasoning Benchmark\"]}],[\"$\",\"span\",\"Idiom Interpretation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Idiom Interpretation\"]}],[\"$\",\"span\",\"Textual Image Design\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Textual Image Design\"]}],[\"$\",\"span\",\"Entity Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Entity Reasoning\"]}],[\"$\",\"span\",\"Scientific Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Scientific Reasoning\"]}],[\"$\",\"span\",\"Multimodal LLM Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal LLM Evaluation\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-26-ST-Raptor_LLM-Powered_Semi-Structured_Table_Question_Answering\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-26-ST-Raptor_LLM-Powered_Semi-Structured_Table_Question_Answering/\",\"children\":\"[논문리뷰] ST-Raptor: LLM-Powered Semi-Structured Table Question Answering\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Wei Zhou이 [arXiv]에 게시한 'ST-Raptor: LLM-Powered Semi-Structured Table Question Answering' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-26 13:21:57+0900\",\"children\":\"2025년 8월 26일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Semi-structured Tables\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Semi-structured Tables\"]}],[\"$\",\"span\",\"Question Answering\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Question Answering\"]}],[\"$\",\"span\",\"LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLMs\"]}],[\"$\",\"span\",\"Hierarchical Orthogonal Tree\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Hierarchical Orthogonal Tree\"]}],[\"$\",\"span\",\"Table Layout Understanding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Table Layout Understanding\"]}],[\"$\",\"span\",\"Pipeline Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Pipeline Generation\"]}],[\"$\",\"span\",\"Verification Mechanism\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Verification Mechanism\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-26-SpotEdit_Evaluating_Visually-Guided_Image_Editing_Methods\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-26-SpotEdit_Evaluating_Visually-Guided_Image_Editing_Methods/\",\"children\":\"[논문리뷰] SpotEdit: Evaluating Visually-Guided Image Editing Methods\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Ersin Yumer이 [arXiv]에 게시한 'SpotEdit: Evaluating Visually-Guided Image Editing Methods' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-26 13:21:57+0900\",\"children\":\"2025년 8월 26일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Visually-Guided Image Editing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Visually-Guided Image Editing\"]}],[\"$\",\"span\",\"Multimodal Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Models\"]}],[\"$\",\"span\",\"Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmark\"]}],[\"$\",\"span\",\"Hallucination\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Hallucination\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}],[\"$\",\"span\",\"Autoregressive Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Autoregressive Models\"]}],[\"$\",\"span\",\"Evaluation Metrics\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Evaluation Metrics\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-26-PosterGen_Aesthetic-Aware_Paper-to-Poster_Generation_via_Multi-Agent_LLMs\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-26-PosterGen_Aesthetic-Aware_Paper-to-Poster_Generation_via_Multi-Agent_LLMs/\",\"children\":\"[논문리뷰] PosterGen: Aesthetic-Aware Paper-to-Poster Generation via Multi-Agent LLMs\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Chenyu You이 [arXiv]에 게시한 'PosterGen: Aesthetic-Aware Paper-to-Poster Generation via Multi-Agent LLMs' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-26 13:21:57+0900\",\"children\":\"2025년 8월 26일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Multi-Agent LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-Agent LLMs\"]}],[\"$\",\"span\",\"Academic Poster Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Academic Poster Generation\"]}],[\"$\",\"span\",\"Aesthetic Design\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Aesthetic Design\"]}],[\"$\",\"span\",\"Layout Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Layout Optimization\"]}],[\"$\",\"span\",\"Typography\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Typography\"]}],[\"$\",\"span\",\"Color Palette\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Color Palette\"]}],[\"$\",\"span\",\"VLM-as-Judge\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"VLM-as-Judge\"]}],[\"$\",\"span\",\"Content Fidelity\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Content Fidelity\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-26-Neither_Valid_nor_Reliable_Investigating_the_Use_of_LLMs_as_Judges\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-26-Neither_Valid_nor_Reliable_Investigating_the_Use_of_LLMs_as_Judges/\",\"children\":\"[논문리뷰] Neither Valid nor Reliable? Investigating the Use of LLMs as Judges\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Golnoosh Farnadi이 [arXiv]에 게시한 'Neither Valid nor Reliable? Investigating the Use of LLMs as Judges' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-26 13:21:57+0900\",\"children\":\"2025년 8월 26일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLMs as Judges\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLMs as Judges\"]}],[\"$\",\"span\",\"NLG Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"NLG Evaluation\"]}],[\"$\",\"span\",\"Measurement Theory\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Measurement Theory\"]}],[\"$\",\"span\",\"Validity\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Validity\"]}],[\"$\",\"span\",\"Reliability\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reliability\"]}],[\"$\",\"span\",\"Evaluation Bias\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Evaluation Bias\"]}],[\"$\",\"span\",\"Scalability\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Scalability\"]}],[\"$\",\"span\",\"Responsible AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Responsible AI\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-26-MV-RAG_Retrieval_Augmented_Multiview_Diffusion\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-26-MV-RAG_Retrieval_Augmented_Multiview_Diffusion/\",\"children\":\"[논문리뷰] MV-RAG: Retrieval Augmented Multiview Diffusion\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"sagiebenaim이 [arXiv]에 게시한 'MV-RAG: Retrieval Augmented Multiview Diffusion' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-26 13:21:57+0900\",\"children\":\"2025년 8월 26일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Retrieval Augmented Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Retrieval Augmented Generation\"]}],[\"$\",\"span\",\"Multiview Diffusion\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multiview Diffusion\"]}],[\"$\",\"span\",\"Text-to-3D Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Text-to-3D Generation\"]}],[\"$\",\"span\",\"Out-of-Domain\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Out-of-Domain\"]}],[\"$\",\"span\",\"Image Retrieval\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image Retrieval\"]}],[\"$\",\"span\",\"3D Consistency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D Consistency\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}],[\"$\",\"span\",\"Hybrid Training\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Hybrid Training\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-26-MeshSplat_Generalizable_Sparse-View_Surface_Reconstruction_via_Gaussian_Splatting\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-26-MeshSplat_Generalizable_Sparse-View_Surface_Reconstruction_via_Gaussian_Splatting/\",\"children\":\"[논문리뷰] MeshSplat: Generalizable Sparse-View Surface Reconstruction via Gaussian Splatting\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yanzhe Liang이 [arXiv]에 게시한 'MeshSplat: Generalizable Sparse-View Surface Reconstruction via Gaussian Splatting' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-26 13:21:57+0900\",\"children\":\"2025년 8월 26일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Sparse-View\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Sparse-View\"]}],[\"$\",\"span\",\"Surface Reconstruction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Surface Reconstruction\"]}],[\"$\",\"span\",\"Gaussian Splatting\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Gaussian Splatting\"]}],[\"$\",\"span\",\"2DGS\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"2DGS\"]}],[\"$\",\"span\",\"Novel View Synthesis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Novel View Synthesis\"]}],[\"$\",\"span\",\"Generalizable\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generalizable\"]}],[\"$\",\"span\",\"Mesh Extraction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Mesh Extraction\"]}],[\"$\",\"span\",\"3D Vision\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D Vision\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-26-MEENA_PersianMMMU_Multimodal-Multilingual_Educational_Exams_for_N-level_Assessment\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-26-MEENA_PersianMMMU_Multimodal-Multilingual_Educational_Exams_for_N-level_Assessment/\",\"children\":\"[논문리뷰] MEENA (PersianMMMU): Multimodal-Multilingual Educational Exams for N-level Assessment\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Doratossadat Dastgheib이 [arXiv]에 게시한 'MEENA (PersianMMMU): Multimodal-Multilingual Educational Exams for N-level Assessment' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-26 13:21:57+0900\",\"children\":\"2025년 8월 26일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Multimodal Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Language Models\"]}],[\"$\",\"span\",\"Multilingual Benchmarking\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multilingual Benchmarking\"]}],[\"$\",\"span\",\"Persian Language\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Persian Language\"]}],[\"$\",\"span\",\"Educational Assessment\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Educational Assessment\"]}],[\"$\",\"span\",\"Vision-Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision-Language Models\"]}],[\"$\",\"span\",\"Cultural Nuance\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Cultural Nuance\"]}],[\"$\",\"span\",\"Reasoning Tasks\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reasoning Tasks\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-26-Limitations_of_Normalization_in_Attention_Mechanism\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-26-Limitations_of_Normalization_in_Attention_Mechanism/\",\"children\":\"[논문리뷰] Limitations of Normalization in Attention Mechanism\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Radu State이 [arXiv]에 게시한 'Limitations of Normalization in Attention Mechanism' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-26 13:21:57+0900\",\"children\":\"2025년 8월 26일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Attention Mechanism\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Attention Mechanism\"]}],[\"$\",\"span\",\"Normalization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Normalization\"]}],[\"$\",\"span\",\"Softmax\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Softmax\"]}],[\"$\",\"span\",\"Transformer Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Transformer Models\"]}],[\"$\",\"span\",\"Gradient Sensitivity\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Gradient Sensitivity\"]}],[\"$\",\"span\",\"Token Separability\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Token Separability\"]}],[\"$\",\"span\",\"Context Length\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Context Length\"]}],[\"$\",\"span\",\"GPT-2\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"GPT-2\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-26-InternVL3.5_Advancing_Open-Source_Multimodal_Models_in_Versatility_Reasoning_and_Efficiency\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-26-InternVL3.5_Advancing_Open-Source_Multimodal_Models_in_Versatility_Reasoning_and_Efficiency/\",\"children\":\"[논문리뷰] InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"jinglinglin이 [arXiv]에 게시한 'InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-26 13:21:57+0900\",\"children\":\"2025년 8월 26일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Multimodal Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Large Language Models\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Inference Efficiency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Inference Efficiency\"]}],[\"$\",\"span\",\"Vision-Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision-Language Models\"]}],[\"$\",\"span\",\"Open-Source\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Open-Source\"]}],[\"$\",\"span\",\"Versatility\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Versatility\"]}],[\"$\",\"span\",\"Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reasoning\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-26-German4All_-_A_Dataset_and_Model_for_Readability-Controlled_Paraphrasing_in_German\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-26-German4All_-_A_Dataset_and_Model_for_Readability-Controlled_Paraphrasing_in_German/\",\"children\":\"[논문리뷰] German4All - A Dataset and Model for Readability-Controlled Paraphrasing in German\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Cristian-George Craciun이 [arXiv]에 게시한 'German4All - A Dataset and Model for Readability-Controlled Paraphrasing in German' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-26 13:21:57+0900\",\"children\":\"2025년 8월 26일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Text Simplification\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Text Simplification\"]}],[\"$\",\"span\",\"Paraphrasing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Paraphrasing\"]}],[\"$\",\"span\",\"Readability Control\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Readability Control\"]}],[\"$\",\"span\",\"German NLP\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"German NLP\"]}],[\"$\",\"span\",\"Dataset Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dataset Generation\"]}],[\"$\",\"span\",\"LLM Distillation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Distillation\"]}],[\"$\",\"span\",\"Multi-level Text Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-level Text Generation\"]}],[\"$\",\"span\",\"Accessibility\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Accessibility\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-26-Explain_Before_You_Answer_A_Survey_on_Compositional_Visual_Reasoning\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-26-Explain_Before_You_Answer_A_Survey_on_Compositional_Visual_Reasoning/\",\"children\":\"[논문리뷰] Explain Before You Answer: A Survey on Compositional Visual Reasoning\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Xin Zheng이 [arXiv]에 게시한 'Explain Before You Answer: A Survey on Compositional Visual Reasoning' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-26 13:21:57+0900\",\"children\":\"2025년 8월 26일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Compositional Visual Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Compositional Visual Reasoning\"]}],[\"$\",\"span\",\"Multimodal AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal AI\"]}],[\"$\",\"span\",\"Vision-Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision-Language Models\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Chain-of-Thought\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Chain-of-Thought\"]}],[\"$\",\"span\",\"Tool Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Tool Learning\"]}],[\"$\",\"span\",\"Agentic AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Agentic AI\"]}],[\"$\",\"span\",\"Survey\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Survey\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-26-Breaking_the_Exploration_Bottleneck_Rubric-Scaffolded_Reinforcement_Learning_for_General_LLM_Reasoning\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-26-Breaking_the_Exploration_Bottleneck_Rubric-Scaffolded_Reinforcement_Learning_for_General_LLM_Reasoning/\",\"children\":\"[논문리뷰] Breaking the Exploration Bottleneck: Rubric-Scaffolded Reinforcement Learning for General LLM Reasoning\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Jiale Zhao이 [arXiv]에 게시한 'Breaking the Exploration Bottleneck: Rubric-Scaffolded Reinforcement Learning for General LLM Reasoning' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-26 13:21:57+0900\",\"children\":\"2025년 8월 26일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Exploration Bottleneck\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Exploration Bottleneck\"]}],[\"$\",\"span\",\"Instructional Scaffolding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Instructional Scaffolding\"]}],[\"$\",\"span\",\"Rubric-based Rewards\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Rubric-based Rewards\"]}],[\"$\",\"span\",\"General Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"General Reasoning\"]}],[\"$\",\"span\",\"RL with Verifiable Rewards\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"RL with Verifiable Rewards\"]}],[\"$\",\"span\",\"Policy Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Policy Optimization\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-26-Beyond_Memorization_Extending_Reasoning_Depth_with_Recurrence_Memory_and_Test-Time_Compute_Scaling\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-26-Beyond_Memorization_Extending_Reasoning_Depth_with_Recurrence_Memory_and_Test-Time_Compute_Scaling/\",\"children\":\"[논문리뷰] Beyond Memorization: Extending Reasoning Depth with Recurrence, Memory and Test-Time Compute Scaling\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Daniil Orel이 [arXiv]에 게시한 'Beyond Memorization: Extending Reasoning Depth with Recurrence, Memory and Test-Time Compute Scaling' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-26 13:21:57+0900\",\"children\":\"2025년 8월 26일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Reasoning Depth\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reasoning Depth\"]}],[\"$\",\"span\",\"Cellular Automata\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Cellular Automata\"]}],[\"$\",\"span\",\"Transformer Architectures\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Transformer Architectures\"]}],[\"$\",\"span\",\"Recurrence\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Recurrence\"]}],[\"$\",\"span\",\"Adaptive Computation Time\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Adaptive Computation Time\"]}],[\"$\",\"span\",\"Chain-of-Thought\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Chain-of-Thought\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Generalization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generalization\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-25-TPLA_Tensor_Parallel_Latent_Attention_for_Efficient_Disaggregated_Prefill_Decode_Inference\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-25-TPLA_Tensor_Parallel_Latent_Attention_for_Efficient_Disaggregated_Prefill_Decode_Inference/\",\"children\":\"[논문리뷰] TPLA: Tensor Parallel Latent Attention for Efficient Disaggregated Prefill \u0026 Decode Inference\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Di Yin이 [arXiv]에 게시한 'TPLA: Tensor Parallel Latent Attention for Efficient Disaggregated Prefill \u0026 Decode Inference' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-25 13:13:07+0900\",\"children\":\"2025년 8월 25일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLM Inference\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Inference\"]}],[\"$\",\"span\",\"Tensor Parallelism\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Tensor Parallelism\"]}],[\"$\",\"span\",\"KV Cache Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"KV Cache Optimization\"]}],[\"$\",\"span\",\"Latent Attention\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Latent Attention\"]}],[\"$\",\"span\",\"Memory Efficiency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Memory Efficiency\"]}],[\"$\",\"span\",\"Decoding Speedup\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Decoding Speedup\"]}],[\"$\",\"span\",\"Prefill/Decode Separation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Prefill/Decode Separation\"]}],[\"$\",\"span\",\"Reparameterization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reparameterization\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-25-Selective_Contrastive_Learning_for_Weakly_Supervised_Affordance_Grounding\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-25-Selective_Contrastive_Learning_for_Weakly_Supervised_Affordance_Grounding/\",\"children\":\"[논문리뷰] Selective Contrastive Learning for Weakly Supervised Affordance Grounding\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Jae-Pil Heo이 [arXiv]에 게시한 'Selective Contrastive Learning for Weakly Supervised Affordance Grounding' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-25 13:13:07+0900\",\"children\":\"2025년 8월 25일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Weakly Supervised Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Weakly Supervised Learning\"]}],[\"$\",\"span\",\"Affordance Grounding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Affordance Grounding\"]}],[\"$\",\"span\",\"Contrastive Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Contrastive Learning\"]}],[\"$\",\"span\",\"CLIP\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"CLIP\"]}],[\"$\",\"span\",\"Part Discovery\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Part Discovery\"]}],[\"$\",\"span\",\"Object Localization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Object Localization\"]}],[\"$\",\"span\",\"DINO\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"DINO\"]}],[\"$\",\"span\",\"Generative Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generative Models\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-25-Learnable_SMPLify_A_Neural_Solution_for_Optimization-Free_Human_Pose_Inverse_Kinematics\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-25-Learnable_SMPLify_A_Neural_Solution_for_Optimization-Free_Human_Pose_Inverse_Kinematics/\",\"children\":\"[논문리뷰] Learnable SMPLify: A Neural Solution for Optimization-Free Human Pose Inverse Kinematics\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Xiao Sun이 [arXiv]에 게시한 'Learnable SMPLify: A Neural Solution for Optimization-Free Human Pose Inverse Kinematics' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-25 13:13:07+0900\",\"children\":\"2025년 8월 25일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Inverse Kinematics\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Inverse Kinematics\"]}],[\"$\",\"span\",\"Human Pose Estimation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Human Pose Estimation\"]}],[\"$\",\"span\",\"SMPL Model\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"SMPL Model\"]}],[\"$\",\"span\",\"Neural Networks\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Neural Networks\"]}],[\"$\",\"span\",\"Optimization-Free\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Optimization-Free\"]}],[\"$\",\"span\",\"Residual Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Residual Learning\"]}],[\"$\",\"span\",\"Data-Driven\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data-Driven\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-25-Jailbreaking_Commercial_Black-Box_LLMs_with_Explicitly_Harmful_Prompts\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-25-Jailbreaking_Commercial_Black-Box_LLMs_with_Explicitly_Harmful_Prompts/\",\"children\":\"[논문리뷰] Jailbreaking Commercial Black-Box LLMs with Explicitly Harmful Prompts\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Liming Fang이 [arXiv]에 게시한 'Jailbreaking Commercial Black-Box LLMs with Explicitly Harmful Prompts' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-25 13:13:07+0900\",\"children\":\"2025년 8월 25일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLM Jailbreaking\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Jailbreaking\"]}],[\"$\",\"span\",\"Red Teaming\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Red Teaming\"]}],[\"$\",\"span\",\"Malicious Content Detection\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Malicious Content Detection\"]}],[\"$\",\"span\",\"Developer Messages\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Developer Messages\"]}],[\"$\",\"span\",\"D-Attack\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"D-Attack\"]}],[\"$\",\"span\",\"DH-CoT\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"DH-CoT\"]}],[\"$\",\"span\",\"Adversarial Attacks\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Adversarial Attacks\"]}],[\"$\",\"span\",\"Dataset Cleaning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dataset Cleaning\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-25-InMind_Evaluating_LLMs_in_Capturing_and_Applying_Individual_Human_Reasoning_Styles\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-25-InMind_Evaluating_LLMs_in_Capturing_and_Applying_Individual_Human_Reasoning_Styles/\",\"children\":\"[논문리뷰] InMind: Evaluating LLMs in Capturing and Applying Individual Human Reasoning Styles\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Diping Song이 [arXiv]에 게시한 'InMind: Evaluating LLMs in Capturing and Applying Individual Human Reasoning Styles' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-25 13:13:07+0900\",\"children\":\"2025년 8월 25일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLM Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Evaluation\"]}],[\"$\",\"span\",\"Human Reasoning Styles\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Human Reasoning Styles\"]}],[\"$\",\"span\",\"Social Deduction Games\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Social Deduction Games\"]}],[\"$\",\"span\",\"Theory of Mind\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Theory of Mind\"]}],[\"$\",\"span\",\"Adaptive Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Adaptive Reasoning\"]}],[\"$\",\"span\",\"Avalon Game\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Avalon Game\"]}],[\"$\",\"span\",\"Cognitive Grounding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Cognitive Grounding\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-25-End-to-End_Agentic_RAG_System_Training_for_Traceable_Diagnostic_Reasoning\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-25-End-to-End_Agentic_RAG_System_Training_for_Traceable_Diagnostic_Reasoning/\",\"children\":\"[논문리뷰] End-to-End Agentic RAG System Training for Traceable Diagnostic Reasoning\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Pengcheng Qiu이 [arXiv]에 게시한 'End-to-End Agentic RAG System Training for Traceable Diagnostic Reasoning' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-25 13:13:07+0900\",\"children\":\"2025년 8월 25일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Agentic RAG\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Agentic RAG\"]}],[\"$\",\"span\",\"Medical Diagnosis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Medical Diagnosis\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Traceable AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Traceable AI\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Clinical Decision Support\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Clinical Decision Support\"]}],[\"$\",\"span\",\"Out-of-Distribution Generalization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Out-of-Distribution Generalization\"]}],[\"$\",\"span\",\"Reward Design\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reward Design\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-25-EgoTwin_Dreaming_Body_and_View_in_First_Person\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-25-EgoTwin_Dreaming_Body_and_View_in_First_Person/\",\"children\":\"[논문리뷰] EgoTwin: Dreaming Body and View in First Person\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Wentao Wang이 [arXiv]에 게시한 'EgoTwin: Dreaming Body and View in First Person' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-25 13:13:07+0900\",\"children\":\"2025년 8월 25일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Egocentric Video Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Egocentric Video Generation\"]}],[\"$\",\"span\",\"Human Motion Synthesis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Human Motion Synthesis\"]}],[\"$\",\"span\",\"Diffusion Transformers\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Transformers\"]}],[\"$\",\"span\",\"Multimodal Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Generation\"]}],[\"$\",\"span\",\"Viewpoint Alignment\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Viewpoint Alignment\"]}],[\"$\",\"span\",\"Causal Interplay\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Causal Interplay\"]}],[\"$\",\"span\",\"First-Person Vision\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"First-Person Vision\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-25-Do_What_Teaching_Vision-Language-Action_Models_to_Reject_the_Impossible\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-25-Do_What_Teaching_Vision-Language-Action_Models_to_Reject_the_Impossible/\",\"children\":\"[논문리뷰] Do What? Teaching Vision-Language-Action Models to Reject the Impossible\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Roei Herzig이 [arXiv]에 게시한 'Do What? Teaching Vision-Language-Action Models to Reject the Impossible' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-25 13:13:07+0900\",\"children\":\"2025년 8월 25일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Vision-Language-Action Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision-Language-Action Models\"]}],[\"$\",\"span\",\"Robotics\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Robotics\"]}],[\"$\",\"span\",\"False Premise Detection\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"False Premise Detection\"]}],[\"$\",\"span\",\"Instruction Following\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Instruction Following\"]}],[\"$\",\"span\",\"Human-Robot Interaction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Human-Robot Interaction\"]}],[\"$\",\"span\",\"Clarification\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Clarification\"]}],[\"$\",\"span\",\"Instruction Tuning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Instruction Tuning\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-25-CRISP_Persistent_Concept_Unlearning_via_Sparse_Autoencoders\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-25-CRISP_Persistent_Concept_Unlearning_via_Sparse_Autoencoders/\",\"children\":\"[논문리뷰] CRISP: Persistent Concept Unlearning via Sparse Autoencoders\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yonatan Belinkov이 [arXiv]에 게시한 'CRISP: Persistent Concept Unlearning via Sparse Autoencoders' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-25 13:13:07+0900\",\"children\":\"2025년 8월 25일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Concept Unlearning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Concept Unlearning\"]}],[\"$\",\"span\",\"Sparse Autoencoders (SAEs)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Sparse Autoencoders (SAEs)\"]}],[\"$\",\"span\",\"LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLMs\"]}],[\"$\",\"span\",\"Parameter-Efficient Fine-Tuning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Parameter-Efficient Fine-Tuning\"]}],[\"$\",\"span\",\"Model Interpretability\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Model Interpretability\"]}],[\"$\",\"span\",\"Safety-Critical AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Safety-Critical AI\"]}],[\"$\",\"span\",\"Feature Suppression\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Feature Suppression\"]}],[\"$\",\"span\",\"WMDP Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"WMDP Benchmark\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-25-CARFT_Boosting_LLM_Reasoning_via_Contrastive_Learning_with_Annotated_Chain-of-Thought-based_Reinforced_Fine-Tuning\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-25-CARFT_Boosting_LLM_Reasoning_via_Contrastive_Learning_with_Annotated_Chain-of-Thought-based_Reinforced_Fine-Tuning/\",\"children\":\"[논문리뷰] CARFT: Boosting LLM Reasoning via Contrastive Learning with Annotated Chain-of-Thought-based Reinforced Fine-Tuning\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yulun Zhang이 [arXiv]에 게시한 'CARFT: Boosting LLM Reasoning via Contrastive Learning with Annotated Chain-of-Thought-based Reinforced Fine-Tuning' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-25 13:13:07+0900\",\"children\":\"2025년 8월 25일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLM Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Reasoning\"]}],[\"$\",\"span\",\"Contrastive Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Contrastive Learning\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Fine-tuning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Fine-tuning\"]}],[\"$\",\"span\",\"Chain-of-Thought (CoT)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Chain-of-Thought (CoT)\"]}],[\"$\",\"span\",\"Annotated Data\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Annotated Data\"]}],[\"$\",\"span\",\"Model Stability\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Model Stability\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-25-Beyond_Pass1_Self-Play_with_Variational_Problem_Synthesis_Sustains_RLVR\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-25-Beyond_Pass1_Self-Play_with_Variational_Problem_Synthesis_Sustains_RLVR/\",\"children\":\"[논문리뷰] Beyond Pass@1: Self-Play with Variational Problem Synthesis Sustains RLVR\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Ying Nian Wu이 [arXiv]에 게시한 'Beyond Pass@1: Self-Play with Variational Problem Synthesis Sustains RLVR' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-25 13:13:07+0900\",\"children\":\"2025년 8월 25일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Self-Play\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Self-Play\"]}],[\"$\",\"span\",\"Variational Problem Synthesis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Variational Problem Synthesis\"]}],[\"$\",\"span\",\"Policy Entropy\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Policy Entropy\"]}],[\"$\",\"span\",\"Pass@k\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Pass@k\"]}],[\"$\",\"span\",\"Reasoning Benchmarks\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reasoning Benchmarks\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-25-AgentScope_1.0_A_Developer-Centric_Framework_for_Building_Agentic_Applications\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-25-AgentScope_1.0_A_Developer-Centric_Framework_for_Building_Agentic_Applications/\",\"children\":\"[논문리뷰] AgentScope 1.0: A Developer-Centric Framework for Building Agentic Applications\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Liuyi Yao이 [arXiv]에 게시한 'AgentScope 1.0: A Developer-Centric Framework for Building Agentic Applications' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-25 13:13:07+0900\",\"children\":\"2025년 8월 25일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLM Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Agents\"]}],[\"$\",\"span\",\"Agentic Applications\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Agentic Applications\"]}],[\"$\",\"span\",\"ReAct Paradigm\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"ReAct Paradigm\"]}],[\"$\",\"span\",\"Framework\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Framework\"]}],[\"$\",\"span\",\"Tool Use\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Tool Use\"]}],[\"$\",\"span\",\"Multi-Agent Systems\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-Agent Systems\"]}],[\"$\",\"span\",\"Developer Experience\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Developer Experience\"]}],[\"$\",\"span\",\"Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Evaluation\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-25-AetherCode_Evaluating_LLMs_Ability_to_Win_In_Premier_Programming_Competitions\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-25-AetherCode_Evaluating_LLMs_Ability_to_Win_In_Premier_Programming_Competitions/\",\"children\":\"[논문리뷰] AetherCode: Evaluating LLMs' Ability to Win In Premier Programming Competitions\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yidi Du이 [arXiv]에 게시한 'AetherCode: Evaluating LLMs' Ability to Win In Premier Programming Competitions' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-25 13:13:07+0900\",\"children\":\"2025년 8월 25일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Competitive Programming\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Competitive Programming\"]}],[\"$\",\"span\",\"LLM Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Evaluation\"]}],[\"$\",\"span\",\"Code Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Code Reasoning\"]}],[\"$\",\"span\",\"Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmark\"]}],[\"$\",\"span\",\"Test Case Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Test Case Generation\"]}],[\"$\",\"span\",\"Programming Competitions\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Programming Competitions\"]}],[\"$\",\"span\",\"Algorithmic Problems\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Algorithmic Problems\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-22-When_and_What_Diffusion-Grounded_VideoLLM_with_Entity_Aware_Segmentation_for_Long_Video_Understanding\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-22-When_and_What_Diffusion-Grounded_VideoLLM_with_Entity_Aware_Segmentation_for_Long_Video_Understanding/\",\"children\":\"[논문리뷰] When and What: Diffusion-Grounded VideoLLM with Entity Aware Segmentation for Long Video Understanding\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Rui Guo이 [arXiv]에 게시한 'When and What: Diffusion-Grounded VideoLLM with Entity Aware Segmentation for Long Video Understanding' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-22 13:10:52+0900\",\"children\":\"2025년 8월 22일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Video-LLM\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video-LLM\"]}],[\"$\",\"span\",\"Diffusion Model\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Model\"]}],[\"$\",\"span\",\"Temporal Grounding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Temporal Grounding\"]}],[\"$\",\"span\",\"Object Segmentation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Object Segmentation\"]}],[\"$\",\"span\",\"Long Video Understanding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Long Video Understanding\"]}],[\"$\",\"span\",\"Multimodal AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal AI\"]}],[\"$\",\"span\",\"Video Question Answering\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video Question Answering\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-22-Waver_Wave_Your_Way_to_Lifelike_Video_Generation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-22-Waver_Wave_Your_Way_to_Lifelike_Video_Generation/\",\"children\":\"[논문리뷰] Waver: Wave Your Way to Lifelike Video Generation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yifu Zhang이 [arXiv]에 게시한 'Waver: Wave Your Way to Lifelike Video Generation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-22 13:10:52+0900\",\"children\":\"2025년 8월 22일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Video Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video Generation\"]}],[\"$\",\"span\",\"Foundation Model\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Foundation Model\"]}],[\"$\",\"span\",\"Diffusion Model\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Model\"]}],[\"$\",\"span\",\"Transformer\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Transformer\"]}],[\"$\",\"span\",\"Text-to-Video\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Text-to-Video\"]}],[\"$\",\"span\",\"Image-to-Video\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image-to-Video\"]}],[\"$\",\"span\",\"Super-Resolution\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Super-Resolution\"]}],[\"$\",\"span\",\"Data Curation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Curation\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-22-Snap-Snap_Taking_Two_Images_to_Reconstruct_3D_Human_Gaussians_in_Milliseconds\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-22-Snap-Snap_Taking_Two_Images_to_Reconstruct_3D_Human_Gaussians_in_Milliseconds/\",\"children\":\"[논문리뷰] Snap-Snap: Taking Two Images to Reconstruct 3D Human Gaussians in Milliseconds\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Chuiyun Wu이 [arXiv]에 게시한 'Snap-Snap: Taking Two Images to Reconstruct 3D Human Gaussians in Milliseconds' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-22 13:10:52+0900\",\"children\":\"2025년 8월 22일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"3D Human Reconstruction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D Human Reconstruction\"]}],[\"$\",\"span\",\"Gaussian Splatting\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Gaussian Splatting\"]}],[\"$\",\"span\",\"Sparse View\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Sparse View\"]}],[\"$\",\"span\",\"Two-Image Input\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Two-Image Input\"]}],[\"$\",\"span\",\"Real-time Inference\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Real-time Inference\"]}],[\"$\",\"span\",\"Point Cloud Prediction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Point Cloud Prediction\"]}],[\"$\",\"span\",\"Feed-forward Network\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Feed-forward Network\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-22-SceneGen_Single-Image_3D_Scene_Generation_in_One_Feedforward_Pass\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-22-SceneGen_Single-Image_3D_Scene_Generation_in_One_Feedforward_Pass/\",\"children\":\"[논문리뷰] SceneGen: Single-Image 3D Scene Generation in One Feedforward Pass\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Ya Zhang이 [arXiv]에 게시한 'SceneGen: Single-Image 3D Scene Generation in One Feedforward Pass' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-22 13:10:52+0900\",\"children\":\"2025년 8월 22일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"3D Scene Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D Scene Generation\"]}],[\"$\",\"span\",\"Single-Image Input\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Single-Image Input\"]}],[\"$\",\"span\",\"Feedforward Networks\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Feedforward Networks\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}],[\"$\",\"span\",\"Geometric Modeling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Geometric Modeling\"]}],[\"$\",\"span\",\"Texture Synthesis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Texture Synthesis\"]}],[\"$\",\"span\",\"Transformer\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Transformer\"]}],[\"$\",\"span\",\"Feature Aggregation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Feature Aggregation\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-22-Mobile-Agent-v3_Foundamental_Agents_for_GUI_Automation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-22-Mobile-Agent-v3_Foundamental_Agents_for_GUI_Automation/\",\"children\":\"[논문리뷰] Mobile-Agent-v3: Foundamental Agents for GUI Automation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Haowei Liu이 [arXiv]에 게시한 'Mobile-Agent-v3: Foundamental Agents for GUI Automation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-22 13:10:52+0900\",\"children\":\"2025년 8월 22일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"GUI Automation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"GUI Automation\"]}],[\"$\",\"span\",\"Multimodal Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Agents\"]}],[\"$\",\"span\",\"Foundational Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Foundational Models\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Cross-Platform\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Cross-Platform\"]}],[\"$\",\"span\",\"Self-Supervised Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Self-Supervised Learning\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-22-LiveMCP-101_Stress_Testing_and_Diagnosing_MCP-enabled_Agents_on_Challenging_Queries\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-22-LiveMCP-101_Stress_Testing_and_Diagnosing_MCP-enabled_Agents_on_Challenging_Queries/\",\"children\":\"[논문리뷰] LiveMCP-101: Stress Testing and Diagnosing MCP-enabled Agents on Challenging Queries\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"huuuyeah이 [arXiv]에 게시한 'LiveMCP-101: Stress Testing and Diagnosing MCP-enabled Agents on Challenging Queries' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-22 13:10:52+0900\",\"children\":\"2025년 8월 22일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"AI Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"AI Agents\"]}],[\"$\",\"span\",\"Tool Use\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Tool Use\"]}],[\"$\",\"span\",\"Model Context Protocol (MCP)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Model Context Protocol (MCP)\"]}],[\"$\",\"span\",\"Benchmarking\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmarking\"]}],[\"$\",\"span\",\"Large Language Models (LLMs)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models (LLMs)\"]}],[\"$\",\"span\",\"Real-world Tasks\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Real-world Tasks\"]}],[\"$\",\"span\",\"Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Evaluation\"]}],[\"$\",\"span\",\"Error Analysis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Error Analysis\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-22-INTIMA_A_Benchmark_for_Human-AI_Companionship_Behavior\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-22-INTIMA_A_Benchmark_for_Human-AI_Companionship_Behavior/\",\"children\":\"[논문리뷰] INTIMA: A Benchmark for Human-AI Companionship Behavior\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yacine Jernite이 [arXiv]에 게시한 'INTIMA: A Benchmark for Human-AI Companionship Behavior' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-22 13:10:52+0900\",\"children\":\"2025년 8월 22일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"AI Companionship\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"AI Companionship\"]}],[\"$\",\"span\",\"Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmark\"]}],[\"$\",\"span\",\"Language Models (LLMs)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Language Models (LLMs)\"]}],[\"$\",\"span\",\"Human-AI Interaction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Human-AI Interaction\"]}],[\"$\",\"span\",\"Emotional AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Emotional AI\"]}],[\"$\",\"span\",\"Boundary Setting\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Boundary Setting\"]}],[\"$\",\"span\",\"Psychological Frameworks\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Psychological Frameworks\"]}],[\"$\",\"span\",\"Evaluation Metrics\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Evaluation Metrics\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-22-Intern-S1_A_Scientific_Multimodal_Foundation_Model\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-22-Intern-S1_A_Scientific_Multimodal_Foundation_Model/\",\"children\":\"[논문리뷰] Intern-S1: A Scientific Multimodal Foundation Model\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"xuhuang87이 [arXiv]에 게시한 'Intern-S1: A Scientific Multimodal Foundation Model' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-22 13:10:52+0900\",\"children\":\"2025년 8월 22일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Multimodal Foundation Model\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Foundation Model\"]}],[\"$\",\"span\",\"Scientific AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Scientific AI\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Mixture-of-Experts (MoE)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Mixture-of-Experts (MoE)\"]}],[\"$\",\"span\",\"Dynamic Tokenizer\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dynamic Tokenizer\"]}],[\"$\",\"span\",\"Data Curation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Curation\"]}],[\"$\",\"span\",\"Low-Resource Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Low-Resource Learning\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-22-Fin-PRM_A_Domain-Specialized_Process_Reward_Model_for_Financial_Reasoning_in_Large_Language_Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-22-Fin-PRM_A_Domain-Specialized_Process_Reward_Model_for_Financial_Reasoning_in_Large_Language_Models/\",\"children\":\"[논문리뷰] Fin-PRM: A Domain-Specialized Process Reward Model for Financial Reasoning in Large Language Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Lifan Guo이 [arXiv]에 게시한 'Fin-PRM: A Domain-Specialized Process Reward Model for Financial Reasoning in Large Language Models' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-22 13:10:52+0900\",\"children\":\"2025년 8월 22일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Process Reward Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Process Reward Models\"]}],[\"$\",\"span\",\"Financial Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Financial Reasoning\"]}],[\"$\",\"span\",\"Domain Specialization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Domain Specialization\"]}],[\"$\",\"span\",\"RLHF\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"RLHF\"]}],[\"$\",\"span\",\"Best-of-N Selection\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Best-of-N Selection\"]}],[\"$\",\"span\",\"Data Curation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Curation\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-22-Does_the_cafe_entrance_look_accessible_Where_is_the_door_Towards_Geospatial_AI_Agents_for_Visual_Inquiries\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-22-Does_the_cafe_entrance_look_accessible_Where_is_the_door_Towards_Geospatial_AI_Agents_for_Visual_Inquiries/\",\"children\":\"[논문리뷰] 'Does the cafe entrance look accessible? Where is the door?' Towards Geospatial AI Agents for Visual Inquiries\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Xia Su이 [arXiv]에 게시한 'Does the cafe entrance look accessible? Where is the door? Towards Geospatial AI Agents for Visual Inquiries' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-22 13:10:52+0900\",\"children\":\"2025년 8월 22일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Geospatial AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Geospatial AI\"]}],[\"$\",\"span\",\"Multimodal AI Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal AI Agents\"]}],[\"$\",\"span\",\"Visual Question Answering\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Visual Question Answering\"]}],[\"$\",\"span\",\"Accessibility\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Accessibility\"]}],[\"$\",\"span\",\"Street View Imagery\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Street View Imagery\"]}],[\"$\",\"span\",\"Spatial Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Spatial Reasoning\"]}],[\"$\",\"span\",\"Human-Computer Interaction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Human-Computer Interaction\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-22-Deep_Think_with_Confidence\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-22-Deep_Think_with_Confidence/\",\"children\":\"[논문리뷰] Deep Think with Confidence\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Xuewei Wang이 [arXiv]에 게시한 'Deep Think with Confidence' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-22 13:10:52+0900\",\"children\":\"2025년 8월 22일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLM Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Reasoning\"]}],[\"$\",\"span\",\"Confidence Filtering\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Confidence Filtering\"]}],[\"$\",\"span\",\"Self-Consistency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Self-Consistency\"]}],[\"$\",\"span\",\"Test-Time Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Test-Time Optimization\"]}],[\"$\",\"span\",\"Computational Efficiency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Computational Efficiency\"]}],[\"$\",\"span\",\"Adaptive Sampling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Adaptive Sampling\"]}],[\"$\",\"span\",\"Early Stopping\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Early Stopping\"]}],[\"$\",\"span\",\"Majority Voting\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Majority Voting\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-22-A_Survey_on_Large_Language_Model_Benchmarks\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-22-A_Survey_on_Large_Language_Model_Benchmarks/\",\"children\":\"[논문리뷰] A Survey on Large Language Model Benchmarks\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Siyi Li이 [arXiv]에 게시한 'A Survey on Large Language Model Benchmarks' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-22 13:10:52+0900\",\"children\":\"2025년 8월 22일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLM Benchmarks\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Benchmarks\"]}],[\"$\",\"span\",\"Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Evaluation\"]}],[\"$\",\"span\",\"Systematic Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Systematic Review\"]}],[\"$\",\"span\",\"General Capabilities\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"General Capabilities\"]}],[\"$\",\"span\",\"Domain-Specific Benchmarks\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Domain-Specific Benchmarks\"]}],[\"$\",\"span\",\"Target-Specific Benchmarks\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Target-Specific Benchmarks\"]}],[\"$\",\"span\",\"Data Contamination\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Contamination\"]}],[\"$\",\"span\",\"AI Ethics\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"AI Ethics\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-22-ATLAS_Decoupling_Skeletal_and_Shape_Parameters_for_Expressive_Parametric_Human_Modeling\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-22-ATLAS_Decoupling_Skeletal_and_Shape_Parameters_for_Expressive_Parametric_Human_Modeling/\",\"children\":\"[논문리뷰] ATLAS: Decoupling Skeletal and Shape Parameters for Expressive Parametric Human Modeling\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Shunsuke Saito이 [arXiv]에 게시한 'ATLAS: Decoupling Skeletal and Shape Parameters for Expressive Parametric Human Modeling' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-22 13:10:52+0900\",\"children\":\"2025년 8월 22일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Parametric Human Model\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Parametric Human Model\"]}],[\"$\",\"span\",\"3D Human Modeling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D Human Modeling\"]}],[\"$\",\"span\",\"Shape-Skeleton Decoupling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Shape-Skeleton Decoupling\"]}],[\"$\",\"span\",\"Pose Correctives\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Pose Correctives\"]}],[\"$\",\"span\",\"Single Image Mesh Fitting\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Single Image Mesh Fitting\"]}],[\"$\",\"span\",\"Expressive Modeling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Expressive Modeling\"]}],[\"$\",\"span\",\"Goliath Dataset\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Goliath Dataset\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-22-aiXiv_A_Next-Generation_Open_Access_Ecosystem_for_Scientific_Discovery_Generated_by_AI_Scientists\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-22-aiXiv_A_Next-Generation_Open_Access_Ecosystem_for_Scientific_Discovery_Generated_by_AI_Scientists/\",\"children\":\"[논문리뷰] aiXiv: A Next-Generation Open Access Ecosystem for Scientific Discovery Generated by AI Scientists\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Heng Zhang이 [arXiv]에 게시한 'aiXiv: A Next-Generation Open Access Ecosystem for Scientific Discovery Generated by AI Scientists' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-22 13:10:52+0900\",\"children\":\"2025년 8월 22일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"AI Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"AI Agents\"]}],[\"$\",\"span\",\"Open Access\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Open Access\"]}],[\"$\",\"span\",\"Scientific Discovery\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Scientific Discovery\"]}],[\"$\",\"span\",\"Peer Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Peer Review\"]}],[\"$\",\"span\",\"LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLMs\"]}],[\"$\",\"span\",\"Multi-agent Systems\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-agent Systems\"]}],[\"$\",\"span\",\"Prompt Injection\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Prompt Injection\"]}],[\"$\",\"span\",\"Iterative Refinement\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Iterative Refinement\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-21-ViExam_Are_Vision_Language_Models_Better_than_Humans_on_Vietnamese_Multimodal_Exam_Questions\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-21-ViExam_Are_Vision_Language_Models_Better_than_Humans_on_Vietnamese_Multimodal_Exam_Questions/\",\"children\":\"[논문리뷰] ViExam: Are Vision Language Models Better than Humans on Vietnamese Multimodal Exam Questions?\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Daeyoung Kim이 [arXiv]에 게시한 'ViExam: Are Vision Language Models Better than Humans on Vietnamese Multimodal Exam Questions?' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-21 13:15:28+0900\",\"children\":\"2025년 8월 21일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Vision Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision Language Models\"]}],[\"$\",\"span\",\"Multimodal AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal AI\"]}],[\"$\",\"span\",\"Vietnamese Language\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vietnamese Language\"]}],[\"$\",\"span\",\"Educational Assessment\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Educational Assessment\"]}],[\"$\",\"span\",\"Low-Resource Languages\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Low-Resource Languages\"]}],[\"$\",\"span\",\"Cross-Lingual Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Cross-Lingual Reasoning\"]}],[\"$\",\"span\",\"ViExam\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"ViExam\"]}],[\"$\",\"span\",\"Human-in-the-Loop\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Human-in-the-Loop\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-21-Tinker_Diffusions_Gift_to_3D--Multi-View_Consistent_Editing_From_Sparse_Inputs_without_Per-Scene_Optimization\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-21-Tinker_Diffusions_Gift_to_3D--Multi-View_Consistent_Editing_From_Sparse_Inputs_without_Per-Scene_Optimization/\",\"children\":\"[논문리뷰] Tinker: Diffusion's Gift to 3D--Multi-View Consistent Editing From Sparse Inputs without Per-Scene Optimization\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Hao Chen이 [arXiv]에 게시한 'Tinker: Diffusion's Gift to 3D--Multi-View Consistent Editing From Sparse Inputs without Per-Scene Optimization' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-21 13:15:28+0900\",\"children\":\"2025년 8월 21일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"3D Editing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D Editing\"]}],[\"$\",\"span\",\"Multi-View Consistency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-View Consistency\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}],[\"$\",\"span\",\"Sparse Input\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Sparse Input\"]}],[\"$\",\"span\",\"Zero-Shot Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Zero-Shot Learning\"]}],[\"$\",\"span\",\"Scene Completion\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Scene Completion\"]}],[\"$\",\"span\",\"Gaussian Splatting\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Gaussian Splatting\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-21-RynnEC_Bringing_MLLMs_into_Embodied_World\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-21-RynnEC_Bringing_MLLMs_into_Embodied_World/\",\"children\":\"[논문리뷰] RynnEC: Bringing MLLMs into Embodied World\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"jiangpinliu이 [arXiv]에 게시한 'RynnEC: Bringing MLLMs into Embodied World' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-21 13:15:28+0900\",\"children\":\"2025년 8월 21일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Multi-modal Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-modal Large Language Models\"]}],[\"$\",\"span\",\"Embodied AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Embodied AI\"]}],[\"$\",\"span\",\"Embodied Cognition\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Embodied Cognition\"]}],[\"$\",\"span\",\"Video Understanding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video Understanding\"]}],[\"$\",\"span\",\"Instance Segmentation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Instance Segmentation\"]}],[\"$\",\"span\",\"Spatial Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Spatial Reasoning\"]}],[\"$\",\"span\",\"Robotics\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Robotics\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-21-Refining_Contrastive_Learning_and_Homography_Relations_for_Multi-Modal_Recommendation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-21-Refining_Contrastive_Learning_and_Homography_Relations_for_Multi-Modal_Recommendation/\",\"children\":\"[논문리뷰] Refining Contrastive Learning and Homography Relations for Multi-Modal Recommendation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Shiqing Wu이 [arXiv]에 게시한 'Refining Contrastive Learning and Homography Relations for Multi-Modal Recommendation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-21 13:15:28+0900\",\"children\":\"2025년 8월 21일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Multi-modal Recommendation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-modal Recommendation\"]}],[\"$\",\"span\",\"Contrastive Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Contrastive Learning\"]}],[\"$\",\"span\",\"Graph Neural Network\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Graph Neural Network\"]}],[\"$\",\"span\",\"Homography Relations\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Homography Relations\"]}],[\"$\",\"span\",\"Meta-network\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Meta-network\"]}],[\"$\",\"span\",\"Orthogonal Constraint\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Orthogonal Constraint\"]}],[\"$\",\"span\",\"Data Sparsity\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Sparsity\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-21-Quantization_Meets_dLLMs_A_Systematic_Study_of_Post-training_Quantization_for_Diffusion_LLMs\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-21-Quantization_Meets_dLLMs_A_Systematic_Study_of_Post-training_Quantization_for_Diffusion_LLMs/\",\"children\":\"[논문리뷰] Quantization Meets dLLMs: A Systematic Study of Post-training Quantization for Diffusion LLMs\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Haobo Xu이 [arXiv]에 게시한 'Quantization Meets dLLMs: A Systematic Study of Post-training Quantization for Diffusion LLMs' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-21 13:15:28+0900\",\"children\":\"2025년 8월 21일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Diffusion LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion LLMs\"]}],[\"$\",\"span\",\"Post-training Quantization (PTQ)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Post-training Quantization (PTQ)\"]}],[\"$\",\"span\",\"Model Compression\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Model Compression\"]}],[\"$\",\"span\",\"Activation Outliers\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Activation Outliers\"]}],[\"$\",\"span\",\"Quantization Methods\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Quantization Methods\"]}],[\"$\",\"span\",\"Efficient Deployment\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Efficient Deployment\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-21-On-Policy_RL_Meets_Off-Policy_Experts_Harmonizing_Supervised_Fine-Tuning_and_Reinforcement_Learning_via_Dynamic_Weighting\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-21-On-Policy_RL_Meets_Off-Policy_Experts_Harmonizing_Supervised_Fine-Tuning_and_Reinforcement_Learning_via_Dynamic_Weighting/\",\"children\":\"[논문리뷰] On-Policy RL Meets Off-Policy Experts: Harmonizing Supervised Fine-Tuning and Reinforcement Learning via Dynamic Weighting\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Guoyin Wang이 [arXiv]에 게시한 'On-Policy RL Meets Off-Policy Experts: Harmonizing Supervised Fine-Tuning and Reinforcement Learning via Dynamic Weighting' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-21 13:15:28+0900\",\"children\":\"2025년 8월 21일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Supervised Fine-Tuning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Supervised Fine-Tuning\"]}],[\"$\",\"span\",\"On-Policy RL\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"On-Policy RL\"]}],[\"$\",\"span\",\"Off-Policy Experts\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Off-Policy Experts\"]}],[\"$\",\"span\",\"Dynamic Weighting\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dynamic Weighting\"]}],[\"$\",\"span\",\"LLM Alignment\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Alignment\"]}],[\"$\",\"span\",\"Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reasoning\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-21-NVIDIA_Nemotron_Nano_2_An_Accurate_and_Efficient_Hybrid_Mamba-Transformer_Reasoning_Model\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-21-NVIDIA_Nemotron_Nano_2_An_Accurate_and_Efficient_Hybrid_Mamba-Transformer_Reasoning_Model/\",\"children\":\"[논문리뷰] NVIDIA Nemotron Nano 2: An Accurate and Efficient Hybrid Mamba-Transformer Reasoning Model\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"abercovich이 [arXiv]에 게시한 'NVIDIA Nemotron Nano 2: An Accurate and Efficient Hybrid Mamba-Transformer Reasoning Model' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-21 13:15:28+0900\",\"children\":\"2025년 8월 21일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Hybrid Architecture\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Hybrid Architecture\"]}],[\"$\",\"span\",\"Mamba-Transformer\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Mamba-Transformer\"]}],[\"$\",\"span\",\"Reasoning LLM\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reasoning LLM\"]}],[\"$\",\"span\",\"Model Compression\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Model Compression\"]}],[\"$\",\"span\",\"Knowledge Distillation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Knowledge Distillation\"]}],[\"$\",\"span\",\"Long Context\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Long Context\"]}],[\"$\",\"span\",\"High Throughput\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"High Throughput\"]}],[\"$\",\"span\",\"FP8 Training\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"FP8 Training\"]}],[\"$\",\"span\",\"Instruction Following\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Instruction Following\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-21-mSCoRe_a_Multilingual_and_Scalable_Benchmark_for_Skill-based_Commonsense_Reasoning\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-21-mSCoRe_a_Multilingual_and_Scalable_Benchmark_for_Skill-based_Commonsense_Reasoning/\",\"children\":\"[논문리뷰] mSCoRe: a Multilingual and Scalable Benchmark for Skill-based Commonsense Reasoning\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"anoperson이 [arXiv]에 게시한 'mSCoRe: a Multilingual and Scalable Benchmark for Skill-based Commonsense Reasoning' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-21 13:15:28+0900\",\"children\":\"2025년 8월 21일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Multilingual Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multilingual Benchmark\"]}],[\"$\",\"span\",\"Commonsense Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Commonsense Reasoning\"]}],[\"$\",\"span\",\"LLM Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Evaluation\"]}],[\"$\",\"span\",\"Reasoning Taxonomy\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reasoning Taxonomy\"]}],[\"$\",\"span\",\"Benchmark Scaling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmark Scaling\"]}],[\"$\",\"span\",\"Data Synthesis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Synthesis\"]}],[\"$\",\"span\",\"Cultural Nuances\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Cultural Nuances\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-21-MeshCoder_LLM-Powered_Structured_Mesh_Code_Generation_from_Point_Clouds\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-21-MeshCoder_LLM-Powered_Structured_Mesh_Code_Generation_from_Point_Clouds/\",\"children\":\"[논문리뷰] MeshCoder: LLM-Powered Structured Mesh Code Generation from Point Clouds\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Jiangmiao이 [arXiv]에 게시한 'MeshCoder: LLM-Powered Structured Mesh Code Generation from Point Clouds' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-21 13:15:28+0900\",\"children\":\"2025년 8월 21일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLM\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM\"]}],[\"$\",\"span\",\"Point Clouds\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Point Clouds\"]}],[\"$\",\"span\",\"3D Reconstruction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D Reconstruction\"]}],[\"$\",\"span\",\"Structured Mesh\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Structured Mesh\"]}],[\"$\",\"span\",\"Blender Python\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Blender Python\"]}],[\"$\",\"span\",\"Shape Editing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Shape Editing\"]}],[\"$\",\"span\",\"Part-based Representation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Part-based Representation\"]}],[\"$\",\"span\",\"Large Language Model\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Model\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-21-MCP-Universe_Benchmarking_Large_Language_Models_with_Real-World_Model_Context_Protocol_Servers\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-21-MCP-Universe_Benchmarking_Large_Language_Models_with_Real-World_Model_Context_Protocol_Servers/\",\"children\":\"[논문리뷰] MCP-Universe: Benchmarking Large Language Models with Real-World Model Context Protocol Servers\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Prathyusha Jwalapuram이 [arXiv]에 게시한 'MCP-Universe: Benchmarking Large Language Models with Real-World Model Context Protocol Servers' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-21 13:15:28+0900\",\"children\":\"2025년 8월 21일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Benchmarking\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmarking\"]}],[\"$\",\"span\",\"Model Context Protocol\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Model Context Protocol\"]}],[\"$\",\"span\",\"Tool Use\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Tool Use\"]}],[\"$\",\"span\",\"Real-World Applications\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Real-World Applications\"]}],[\"$\",\"span\",\"Agent Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Agent Evaluation\"]}],[\"$\",\"span\",\"Long Context\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Long Context\"]}],[\"$\",\"span\",\"Unknown Tools\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Unknown Tools\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-21-Local_Scale_Equivariance_with_Latent_Deep_Equilibrium_Canonicalizer\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-21-Local_Scale_Equivariance_with_Latent_Deep_Equilibrium_Canonicalizer/\",\"children\":\"[논문리뷰] Local Scale Equivariance with Latent Deep Equilibrium Canonicalizer\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Jeremiah Jiang이 [arXiv]에 게시한 'Local Scale Equivariance with Latent Deep Equilibrium Canonicalizer' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-21 13:15:28+0900\",\"children\":\"2025년 8월 21일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Scale Equivariance\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Scale Equivariance\"]}],[\"$\",\"span\",\"Deep Equilibrium Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Deep Equilibrium Models\"]}],[\"$\",\"span\",\"Canonicalization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Canonicalization\"]}],[\"$\",\"span\",\"Computer Vision\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Computer Vision\"]}],[\"$\",\"span\",\"Image Classification\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image Classification\"]}],[\"$\",\"span\",\"Semantic Segmentation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Semantic Segmentation\"]}],[\"$\",\"span\",\"Latent Representation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Latent Representation\"]}],[\"$\",\"span\",\"Monotone Scaling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Monotone Scaling\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-21-Leuvenshtein_Efficient_FHE-based_Edit_Distance_Computation_with_Single_Bootstrap_per_Cell\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-21-Leuvenshtein_Efficient_FHE-based_Edit_Distance_Computation_with_Single_Bootstrap_per_Cell/\",\"children\":\"[논문리뷰] Leuvenshtein: Efficient FHE-based Edit Distance Computation with Single Bootstrap per Cell\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Ingrid Verbauwhede이 [arXiv]에 게시한 'Leuvenshtein: Efficient FHE-based Edit Distance Computation with Single Bootstrap per Cell' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-21 13:15:28+0900\",\"children\":\"2025년 8월 21일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Fully Homomorphic Encryption (FHE)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Fully Homomorphic Encryption (FHE)\"]}],[\"$\",\"span\",\"TFHE\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"TFHE\"]}],[\"$\",\"span\",\"Levenshtein Distance\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Levenshtein Distance\"]}],[\"$\",\"span\",\"Programmable Bootstrapping (PBS)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Programmable Bootstrapping (PBS)\"]}],[\"$\",\"span\",\"Privacy-Preserving Computation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Privacy-Preserving Computation\"]}],[\"$\",\"span\",\"String Similarity\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"String Similarity\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-21-FutureX_An_Advanced_Live_Benchmark_for_LLM_Agents_in_Future_Prediction\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-21-FutureX_An_Advanced_Live_Benchmark_for_LLM_Agents_in_Future_Prediction/\",\"children\":\"[논문리뷰] FutureX: An Advanced Live Benchmark for LLM Agents in Future Prediction\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"tianlecai이 [arXiv]에 게시한 'FutureX: An Advanced Live Benchmark for LLM Agents in Future Prediction' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-21 13:15:28+0900\",\"children\":\"2025년 8월 21일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLM Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Agents\"]}],[\"$\",\"span\",\"Future Prediction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Future Prediction\"]}],[\"$\",\"span\",\"Live Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Live Benchmark\"]}],[\"$\",\"span\",\"Dynamic Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dynamic Evaluation\"]}],[\"$\",\"span\",\"Data Contamination\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Contamination\"]}],[\"$\",\"span\",\"Tool Use\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Tool Use\"]}],[\"$\",\"span\",\"Web Search\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Web Search\"]}],[\"$\",\"span\",\"Financial Forecasting\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Financial Forecasting\"]}],[\"$\",\"span\",\"Misinformation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Misinformation\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-21-From_Scores_to_Skills_A_Cognitive_Diagnosis_Framework_for_Evaluating_Financial_Large_Language_Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-21-From_Scores_to_Skills_A_Cognitive_Diagnosis_Framework_for_Evaluating_Financial_Large_Language_Models/\",\"children\":\"[논문리뷰] From Scores to Skills: A Cognitive Diagnosis Framework for Evaluating Financial Large Language Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Ziyan Kuang이 [arXiv]에 게시한 'From Scores to Skills: A Cognitive Diagnosis Framework for Evaluating Financial Large Language Models' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-21 13:15:28+0900\",\"children\":\"2025년 8월 21일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Financial LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Financial LLMs\"]}],[\"$\",\"span\",\"Cognitive Diagnosis Model\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Cognitive Diagnosis Model\"]}],[\"$\",\"span\",\"LLM Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Evaluation\"]}],[\"$\",\"span\",\"Knowledge Assessment\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Knowledge Assessment\"]}],[\"$\",\"span\",\"Matrix Factorization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Matrix Factorization\"]}],[\"$\",\"span\",\"CPA-QKA\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"CPA-QKA\"]}],[\"$\",\"span\",\"Interpretability\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Interpretability\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-21-From_AI_for_Science_to_Agentic_Science_A_Survey_on_Autonomous_Scientific_Discovery\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-21-From_AI_for_Science_to_Agentic_Science_A_Survey_on_Autonomous_Scientific_Discovery/\",\"children\":\"[논문리뷰] From AI for Science to Agentic Science: A Survey on Autonomous Scientific Discovery\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"zijieqiu이 [arXiv]에 게시한 'From AI for Science to Agentic Science: A Survey on Autonomous Scientific Discovery' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-21 13:15:28+0900\",\"children\":\"2025년 8월 21일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Agentic AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Agentic AI\"]}],[\"$\",\"span\",\"Autonomous Scientific Discovery\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Autonomous Scientific Discovery\"]}],[\"$\",\"span\",\"AI for Science\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"AI for Science\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Multi-agent Systems\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-agent Systems\"]}],[\"$\",\"span\",\"Scientific Workflow Automation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Scientific Workflow Automation\"]}],[\"$\",\"span\",\"Natural Sciences\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Natural Sciences\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-21-DuPO_Enabling_Reliable_LLM_Self-Verification_via_Dual_Preference_Optimization\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-21-DuPO_Enabling_Reliable_LLM_Self-Verification_via_Dual_Preference_Optimization/\",\"children\":\"[논문리뷰] DuPO: Enabling Reliable LLM Self-Verification via Dual Preference Optimization\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yu Lu이 [arXiv]에 게시한 'DuPO: Enabling Reliable LLM Self-Verification via Dual Preference Optimization' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-21 13:15:28+0900\",\"children\":\"2025년 8월 21일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLM Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Optimization\"]}],[\"$\",\"span\",\"Self-Verification\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Self-Verification\"]}],[\"$\",\"span\",\"Dual Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dual Learning\"]}],[\"$\",\"span\",\"Preference Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Preference Optimization\"]}],[\"$\",\"span\",\"Self-Supervised Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Self-Supervised Learning\"]}],[\"$\",\"span\",\"Mathematical Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Mathematical Reasoning\"]}],[\"$\",\"span\",\"Multilingual Translation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multilingual Translation\"]}],[\"$\",\"span\",\"RLHF\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"RLHF\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-20-ZARA_Zero-shot_Motion_Time-Series_Analysis_via_Knowledge_and_Retrieval_Driven_LLM_Agents\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-20-ZARA_Zero-shot_Motion_Time-Series_Analysis_via_Knowledge_and_Retrieval_Driven_LLM_Agents/\",\"children\":\"[논문리뷰] ZARA: Zero-shot Motion Time-Series Analysis via Knowledge and Retrieval Driven LLM Agents\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Flora D. Salim이 [arXiv]에 게시한 'ZARA: Zero-shot Motion Time-Series Analysis via Knowledge and Retrieval Driven LLM Agents' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-20 13:26:54+0900\",\"children\":\"2025년 8월 20일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Zero-shot HAR\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Zero-shot HAR\"]}],[\"$\",\"span\",\"LLM Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Agents\"]}],[\"$\",\"span\",\"Time-Series Analysis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Time-Series Analysis\"]}],[\"$\",\"span\",\"Knowledge Base\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Knowledge Base\"]}],[\"$\",\"span\",\"Retrieval-Augmented Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Retrieval-Augmented Generation\"]}],[\"$\",\"span\",\"Multi-sensor Fusion\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-sensor Fusion\"]}],[\"$\",\"span\",\"Interpretability\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Interpretability\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-20-Training-Free_Text-Guided_Color_Editing_with_Multi-Modal_Diffusion_Transformer\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-20-Training-Free_Text-Guided_Color_Editing_with_Multi-Modal_Diffusion_Transformer/\",\"children\":\"[논문리뷰] Training-Free Text-Guided Color Editing with Multi-Modal Diffusion Transformer\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Deyu Zhou이 [arXiv]에 게시한 'Training-Free Text-Guided Color Editing with Multi-Modal Diffusion Transformer' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-20 13:26:54+0900\",\"children\":\"2025년 8월 20일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Text-Guided Editing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Text-Guided Editing\"]}],[\"$\",\"span\",\"Color Editing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Color Editing\"]}],[\"$\",\"span\",\"Diffusion Transformers\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Transformers\"]}],[\"$\",\"span\",\"Training-Free\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Training-Free\"]}],[\"$\",\"span\",\"Multi-Modal AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-Modal AI\"]}],[\"$\",\"span\",\"Attention Control\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Attention Control\"]}],[\"$\",\"span\",\"Image Manipulation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image Manipulation\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-20-TempFlow-GRPO_When_Timing_Matters_for_GRPO_in_Flow_Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-20-TempFlow-GRPO_When_Timing_Matters_for_GRPO_in_Flow_Models/\",\"children\":\"[논문리뷰] TempFlow-GRPO: When Timing Matters for GRPO in Flow Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Jian Yang이 [arXiv]에 게시한 'TempFlow-GRPO: When Timing Matters for GRPO in Flow Models' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-20 13:26:54+0900\",\"children\":\"2025년 8월 20일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Flow Matching\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Flow Matching\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Human Preference Alignment\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Human Preference Alignment\"]}],[\"$\",\"span\",\"GRPO\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"GRPO\"]}],[\"$\",\"span\",\"Temporal Credit Assignment\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Temporal Credit Assignment\"]}],[\"$\",\"span\",\"Generative AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generative AI\"]}],[\"$\",\"span\",\"Text-to-Image\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Text-to-Image\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-20-Semantic_IDs_for_Joint_Generative_Search_and_Recommendation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-20-Semantic_IDs_for_Joint_Generative_Search_and_Recommendation/\",\"children\":\"[논문리뷰] Semantic IDs for Joint Generative Search and Recommendation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Enrico Palumbo이 [arXiv]에 게시한 'Semantic IDs for Joint Generative Search and Recommendation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-20 13:26:54+0900\",\"children\":\"2025년 8월 20일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Generative Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generative Models\"]}],[\"$\",\"span\",\"Search and Recommendation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Search and Recommendation\"]}],[\"$\",\"span\",\"Semantic IDs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Semantic IDs\"]}],[\"$\",\"span\",\"Bi-Encoder\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Bi-Encoder\"]}],[\"$\",\"span\",\"Quantization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Quantization\"]}],[\"$\",\"span\",\"Multi-Task Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-Task Learning\"]}],[\"$\",\"span\",\"Retrieval Augmented Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Retrieval Augmented Generation\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-20-Radiance_Fields_in_XR_A_Survey_on_How_Radiance_Fields_are_Envisioned_and_Addressed_for_XR_Research\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-20-Radiance_Fields_in_XR_A_Survey_on_How_Radiance_Fields_are_Envisioned_and_Addressed_for_XR_Research/\",\"children\":\"[논문리뷰] Radiance Fields in XR: A Survey on How Radiance Fields are Envisioned and Addressed for XR Research\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Susanne Schmidt이 [arXiv]에 게시한 'Radiance Fields in XR: A Survey on How Radiance Fields are Envisioned and Addressed for XR Research' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-20 13:26:54+0900\",\"children\":\"2025년 8월 20일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Radiance Fields\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Radiance Fields\"]}],[\"$\",\"span\",\"XR\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"XR\"]}],[\"$\",\"span\",\"NeRF\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"NeRF\"]}],[\"$\",\"span\",\"3D Gaussian Splatting\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D Gaussian Splatting\"]}],[\"$\",\"span\",\"View Synthesis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"View Synthesis\"]}],[\"$\",\"span\",\"Systematic Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Systematic Review\"]}],[\"$\",\"span\",\"Immersive Technology\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Immersive Technology\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-20-Prompt_Orchestration_Markup_Language\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-20-Prompt_Orchestration_Markup_Language/\",\"children\":\"[논문리뷰] Prompt Orchestration Markup Language\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yuqing Yang이 [arXiv]에 게시한 'Prompt Orchestration Markup Language' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-20 13:26:54+0900\",\"children\":\"2025년 8월 20일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Prompt Engineering\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Prompt Engineering\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Markup Language\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Markup Language\"]}],[\"$\",\"span\",\"Structured Prompting\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Structured Prompting\"]}],[\"$\",\"span\",\"IDE Support\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"IDE Support\"]}],[\"$\",\"span\",\"Multimodal Data\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Data\"]}],[\"$\",\"span\",\"Styling System\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Styling System\"]}],[\"$\",\"span\",\"Development Toolkit\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Development Toolkit\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-20-OmniTry_Virtual_Try-On_Anything_without_Masks\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-20-OmniTry_Virtual_Try-On_Anything_without_Masks/\",\"children\":\"[논문리뷰] OmniTry: Virtual Try-On Anything without Masks\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Xiaoduan Feng이 [arXiv]에 게시한 'OmniTry: Virtual Try-On Anything without Masks' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-20 13:26:54+0900\",\"children\":\"2025년 8월 20일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Virtual Try-On\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Virtual Try-On\"]}],[\"$\",\"span\",\"Diffusion Model\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Model\"]}],[\"$\",\"span\",\"Mask-Free\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Mask-Free\"]}],[\"$\",\"span\",\"Image Inpainting\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image Inpainting\"]}],[\"$\",\"span\",\"ID Consistency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"ID Consistency\"]}],[\"$\",\"span\",\"Wearable Objects\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Wearable Objects\"]}],[\"$\",\"span\",\"Generative AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generative AI\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-20-MultiRef_Controllable_Image_Generation_with_Multiple_Visual_References\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-20-MultiRef_Controllable_Image_Generation_with_Multiple_Visual_References/\",\"children\":\"[논문리뷰] MultiRef: Controllable Image Generation with Multiple Visual References\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Shiyun Lang이 [arXiv]에 게시한 'MultiRef: Controllable Image Generation with Multiple Visual References' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-20 13:26:54+0900\",\"children\":\"2025년 8월 20일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Controllable Image Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Controllable Image Generation\"]}],[\"$\",\"span\",\"Multi-modal Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-modal Generation\"]}],[\"$\",\"span\",\"Visual References\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Visual References\"]}],[\"$\",\"span\",\"Image-to-Image\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image-to-Image\"]}],[\"$\",\"span\",\"Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmark\"]}],[\"$\",\"span\",\"Dataset\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dataset\"]}],[\"$\",\"span\",\"MLLM-as-a-Judge\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"MLLM-as-a-Judge\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-20-Motion2Motion_Cross-topology_Motion_Transfer_with_Sparse_Correspondence\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-20-Motion2Motion_Cross-topology_Motion_Transfer_with_Sparse_Correspondence/\",\"children\":\"[논문리뷰] Motion2Motion: Cross-topology Motion Transfer with Sparse Correspondence\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Xin Chen이 [arXiv]에 게시한 'Motion2Motion: Cross-topology Motion Transfer with Sparse Correspondence' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-20 13:26:54+0900\",\"children\":\"2025년 8월 20일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Motion Transfer\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Motion Transfer\"]}],[\"$\",\"span\",\"Cross-topology\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Cross-topology\"]}],[\"$\",\"span\",\"Sparse Correspondence\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Sparse Correspondence\"]}],[\"$\",\"span\",\"Motion Matching\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Motion Matching\"]}],[\"$\",\"span\",\"Animation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Animation\"]}],[\"$\",\"span\",\"Training-free\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Training-free\"]}],[\"$\",\"span\",\"Few-shot Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Few-shot Learning\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-20-MMAU-Pro_A_Challenging_and_Comprehensive_Benchmark_for_Holistic_Evaluation_of_Audio_General_Intelligence\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-20-MMAU-Pro_A_Challenging_and_Comprehensive_Benchmark_for_Holistic_Evaluation_of_Audio_General_Intelligence/\",\"children\":\"[논문리뷰] MMAU-Pro: A Challenging and Comprehensive Benchmark for Holistic Evaluation of Audio General Intelligence\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Fernando López이 [arXiv]에 게시한 'MMAU-Pro: A Challenging and Comprehensive Benchmark for Holistic Evaluation of Audio General Intelligence' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-20 13:26:54+0900\",\"children\":\"2025년 8월 20일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Audio Intelligence\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Audio Intelligence\"]}],[\"$\",\"span\",\"Multimodal AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal AI\"]}],[\"$\",\"span\",\"Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmark\"]}],[\"$\",\"span\",\"Audio-Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Audio-Language Models\"]}],[\"$\",\"span\",\"Holistic Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Holistic Evaluation\"]}],[\"$\",\"span\",\"Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reasoning\"]}],[\"$\",\"span\",\"Long-Form Audio\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Long-Form Audio\"]}],[\"$\",\"span\",\"Multicultural Music\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multicultural Music\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-20-MM-BrowseComp_A_Comprehensive_Benchmark_for_Multimodal_Browsing_Agents\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-20-MM-BrowseComp_A_Comprehensive_Benchmark_for_Multimodal_Browsing_Agents/\",\"children\":\"[논문리뷰] MM-BrowseComp: A Comprehensive Benchmark for Multimodal Browsing Agents\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Jun Dong이 [arXiv]에 게시한 'MM-BrowseComp: A Comprehensive Benchmark for Multimodal Browsing Agents' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-20 13:26:54+0900\",\"children\":\"2025년 8월 20일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Multimodal Browsing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Browsing\"]}],[\"$\",\"span\",\"AI Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"AI Agents\"]}],[\"$\",\"span\",\"Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmark\"]}],[\"$\",\"span\",\"Vision-Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision-Language Models\"]}],[\"$\",\"span\",\"Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reasoning\"]}],[\"$\",\"span\",\"Tool Use\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Tool Use\"]}],[\"$\",\"span\",\"Deep Search\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Deep Search\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-20-Mind_the_Generation_Process_Fine-Grained_Confidence_Estimation_During_LLM_Generation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-20-Mind_the_Generation_Process_Fine-Grained_Confidence_Estimation_During_LLM_Generation/\",\"children\":\"[논문리뷰] Mind the Generation Process: Fine-Grained Confidence Estimation During LLM Generation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Xinyi Wang이 [arXiv]에 게시한 'Mind the Generation Process: Fine-Grained Confidence Estimation During LLM Generation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-20 13:26:54+0900\",\"children\":\"2025년 8월 20일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLMs\"]}],[\"$\",\"span\",\"Confidence Estimation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Confidence Estimation\"]}],[\"$\",\"span\",\"Fine-Grained\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Fine-Grained\"]}],[\"$\",\"span\",\"Generation Process\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generation Process\"]}],[\"$\",\"span\",\"Calibration\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Calibration\"]}],[\"$\",\"span\",\"Monte Carlo Sampling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Monte Carlo Sampling\"]}],[\"$\",\"span\",\"Backward Confidence Integration\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Backward Confidence Integration\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-20-MedSAMix_A_Training-Free_Model_Merging_Approach_for_Medical_Image_Segmentation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-20-MedSAMix_A_Training-Free_Model_Merging_Approach_for_Medical_Image_Segmentation/\",\"children\":\"[논문리뷰] MedSAMix: A Training-Free Model Merging Approach for Medical Image Segmentation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Jonas Geiping이 [arXiv]에 게시한 'MedSAMix: A Training-Free Model Merging Approach for Medical Image Segmentation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-20 13:26:54+0900\",\"children\":\"2025년 8월 20일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Medical Image Segmentation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Medical Image Segmentation\"]}],[\"$\",\"span\",\"Model Merging\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Model Merging\"]}],[\"$\",\"span\",\"Training-Free\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Training-Free\"]}],[\"$\",\"span\",\"SAM\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"SAM\"]}],[\"$\",\"span\",\"Generalization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generalization\"]}],[\"$\",\"span\",\"Zero-Order Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Zero-Order Optimization\"]}],[\"$\",\"span\",\"Bayesian Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Bayesian Optimization\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-20-LongSplat_Robust_Unposed_3D_Gaussian_Splatting_for_Casual_Long_Videos\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-20-LongSplat_Robust_Unposed_3D_Gaussian_Splatting_for_Casual_Long_Videos/\",\"children\":\"[논문리뷰] LongSplat: Robust Unposed 3D Gaussian Splatting for Casual Long Videos\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yen-Yu Lin이 [arXiv]에 게시한 'LongSplat: Robust Unposed 3D Gaussian Splatting for Casual Long Videos' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-20 13:26:54+0900\",\"children\":\"2025년 8월 20일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Novel View Synthesis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Novel View Synthesis\"]}],[\"$\",\"span\",\"3D Gaussian Splatting\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D Gaussian Splatting\"]}],[\"$\",\"span\",\"Unposed Reconstruction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Unposed Reconstruction\"]}],[\"$\",\"span\",\"Camera Pose Estimation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Camera Pose Estimation\"]}],[\"$\",\"span\",\"Incremental Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Incremental Optimization\"]}],[\"$\",\"span\",\"Octree\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Octree\"]}],[\"$\",\"span\",\"Long Videos\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Long Videos\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-20-Leveraging_Large_Language_Models_for_Predictive_Analysis_of_Human_Misery\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-20-Leveraging_Large_Language_Models_for_Predictive_Analysis_of_Human_Misery/\",\"children\":\"[논문리뷰] Leveraging Large Language Models for Predictive Analysis of Human Misery\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Abhilash Nandy이 [arXiv]에 게시한 'Leveraging Large Language Models for Predictive Analysis of Human Misery' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-20 13:26:54+0900\",\"children\":\"2025년 8월 20일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Large Language Models (LLMs)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models (LLMs)\"]}],[\"$\",\"span\",\"Affective Computing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Affective Computing\"]}],[\"$\",\"span\",\"Misery Score Prediction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Misery Score Prediction\"]}],[\"$\",\"span\",\"Prompt Engineering\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Prompt Engineering\"]}],[\"$\",\"span\",\"Few-shot Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Few-shot Learning\"]}],[\"$\",\"span\",\"Gamified Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Gamified Evaluation\"]}],[\"$\",\"span\",\"Feedback-driven Adaptation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Feedback-driven Adaptation\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-20-Evaluating_Podcast_Recommendations_with_Profile-Aware_LLM-as-a-Judge\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-20-Evaluating_Podcast_Recommendations_with_Profile-Aware_LLM-as-a-Judge/\",\"children\":\"[논문리뷰] Evaluating Podcast Recommendations with Profile-Aware LLM-as-a-Judge\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Alice Wang이 [arXiv]에 게시한 'Evaluating Podcast Recommendations with Profile-Aware LLM-as-a-Judge' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-20 13:26:54+0900\",\"children\":\"2025년 8월 20일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Podcast Recommendation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Podcast Recommendation\"]}],[\"$\",\"span\",\"LLM-as-a-Judge\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM-as-a-Judge\"]}],[\"$\",\"span\",\"Offline Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Offline Evaluation\"]}],[\"$\",\"span\",\"User Profiling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"User Profiling\"]}],[\"$\",\"span\",\"Recommender Systems\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Recommender Systems\"]}],[\"$\",\"span\",\"Natural Language Processing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Natural Language Processing\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-20-Embodied-R1_Reinforced_Embodied_Reasoning_for_General_Robotic_Manipulation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-20-Embodied-R1_Reinforced_Embodied_Reasoning_for_General_Robotic_Manipulation/\",\"children\":\"[논문리뷰] Embodied-R1: Reinforced Embodied Reasoning for General Robotic Manipulation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Fei Ni이 [arXiv]에 게시한 'Embodied-R1: Reinforced Embodied Reasoning for General Robotic Manipulation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-20 13:26:54+0900\",\"children\":\"2025년 8월 20일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Embodied AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Embodied AI\"]}],[\"$\",\"span\",\"Robotic Manipulation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Robotic Manipulation\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Vision-Language Model\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision-Language Model\"]}],[\"$\",\"span\",\"Pointing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Pointing\"]}],[\"$\",\"span\",\"Zero-shot Generalization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Zero-shot Generalization\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-20-Describe_What_You_See_with_Multimodal_Large_Language_Models_to_Enhance_Video_Recommendations\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-20-Describe_What_You_See_with_Multimodal_Large_Language_Models_to_Enhance_Video_Recommendations/\",\"children\":\"[논문리뷰] Describe What You See with Multimodal Large Language Models to Enhance Video Recommendations\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Mounia Lalmas이 [arXiv]에 게시한 'Describe What You See with Multimodal Large Language Models to Enhance Video Recommendations' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-20 13:26:54+0900\",\"children\":\"2025년 8월 20일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Multimodal Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Large Language Models\"]}],[\"$\",\"span\",\"Video Recommendation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video Recommendation\"]}],[\"$\",\"span\",\"Zero-Shot Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Zero-Shot Learning\"]}],[\"$\",\"span\",\"Content-Based Filtering\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Content-Based Filtering\"]}],[\"$\",\"span\",\"Natural Language Processing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Natural Language Processing\"]}],[\"$\",\"span\",\"Foundation Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Foundation Models\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-20-CorrSteer_Steering_Improves_Task_Performance_and_Safety_in_LLMs_through_Correlation-based_Sparse_Autoencoder_Feature_Selection\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-20-CorrSteer_Steering_Improves_Task_Performance_and_Safety_in_LLMs_through_Correlation-based_Sparse_Autoencoder_Feature_Selection/\",\"children\":\"[논문리뷰] CorrSteer: Steering Improves Task Performance and Safety in LLMs through Correlation-based Sparse Autoencoder Feature Selection\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Adriano Koshiyama이 [arXiv]에 게시한 'CorrSteer: Steering Improves Task Performance and Safety in LLMs through Correlation-based Sparse Autoencoder Feature Selection' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-20 13:26:54+0900\",\"children\":\"2025년 8월 20일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Sparse Autoencoders\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Sparse Autoencoders\"]}],[\"$\",\"span\",\"LLM Steering\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Steering\"]}],[\"$\",\"span\",\"Feature Selection\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Feature Selection\"]}],[\"$\",\"span\",\"Correlation Analysis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Correlation Analysis\"]}],[\"$\",\"span\",\"AI Safety\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"AI Safety\"]}],[\"$\",\"span\",\"Bias Mitigation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Bias Mitigation\"]}],[\"$\",\"span\",\"Mechanistic Interpretability\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Mechanistic Interpretability\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-20-Copyright_Protection_for_Large_Language_Models_A_Survey_of_Methods_Challenges_and_Trends\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-20-Copyright_Protection_for_Large_Language_Models_A_Survey_of_Methods_Challenges_and_Trends/\",\"children\":\"[논문리뷰] Copyright Protection for Large Language Models: A Survey of Methods, Challenges, and Trends\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Xixiang Zhao이 [arXiv]에 게시한 'Copyright Protection for Large Language Models: A Survey of Methods, Challenges, and Trends' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-20 13:26:54+0900\",\"children\":\"2025년 8월 20일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLM Copyright Protection\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Copyright Protection\"]}],[\"$\",\"span\",\"Model Fingerprinting\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Model Fingerprinting\"]}],[\"$\",\"span\",\"Text Watermarking\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Text Watermarking\"]}],[\"$\",\"span\",\"Invasive Fingerprinting\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Invasive Fingerprinting\"]}],[\"$\",\"span\",\"Intrinsic Fingerprinting\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Intrinsic Fingerprinting\"]}],[\"$\",\"span\",\"Intellectual Property\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Intellectual Property\"]}],[\"$\",\"span\",\"Digital Rights Management\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Digital Rights Management\"]}],[\"$\",\"span\",\"Backdoor Watermarking\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Backdoor Watermarking\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-20-Chain-of-Agents_End-to-End_Agent_Foundation_Models_via_Multi-Agent_Distillation_and_Agentic_RL\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-20-Chain-of-Agents_End-to-End_Agent_Foundation_Models_via_Multi-Agent_Distillation_and_Agentic_RL/\",\"children\":\"[논문리뷰] Chain-of-Agents: End-to-End Agent Foundation Models via Multi-Agent Distillation and Agentic RL\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Liam-Liu이 [arXiv]에 게시한 'Chain-of-Agents: End-to-End Agent Foundation Models via Multi-Agent Distillation and Agentic RL' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-20 13:26:54+0900\",\"children\":\"2025년 8월 20일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Chain-of-Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Chain-of-Agents\"]}],[\"$\",\"span\",\"Agent Foundation Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Agent Foundation Models\"]}],[\"$\",\"span\",\"Multi-Agent Systems\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-Agent Systems\"]}],[\"$\",\"span\",\"Tool-Integrated Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Tool-Integrated Reasoning\"]}],[\"$\",\"span\",\"Multi-agent Distillation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-agent Distillation\"]}],[\"$\",\"span\",\"Agentic Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Agentic Reinforcement Learning\"]}],[\"$\",\"span\",\"LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLMs\"]}],[\"$\",\"span\",\"End-to-End Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"End-to-End Learning\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-20-CAMAR_Continuous_Actions_Multi-Agent_Routing\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-20-CAMAR_Continuous_Actions_Multi-Agent_Routing/\",\"children\":\"[논문리뷰] CAMAR: Continuous Actions Multi-Agent Routing\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Alexey Skrynnik이 [arXiv]에 게시한 'CAMAR: Continuous Actions Multi-Agent Routing' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-20 13:26:54+0900\",\"children\":\"2025년 8월 20일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Multi-Agent Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-Agent Reinforcement Learning\"]}],[\"$\",\"span\",\"Continuous Control\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Continuous Control\"]}],[\"$\",\"span\",\"Pathfinding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Pathfinding\"]}],[\"$\",\"span\",\"MARL Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"MARL Benchmark\"]}],[\"$\",\"span\",\"GPU Acceleration\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"GPU Acceleration\"]}],[\"$\",\"span\",\"Robotics Simulation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Robotics Simulation\"]}],[\"$\",\"span\",\"Scalability\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Scalability\"]}],[\"$\",\"span\",\"Heterogeneous Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Heterogeneous Agents\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-20-Beyond_Human_Judgment_A_Bayesian_Evaluation_of_LLMs_Moral_Values_Understanding\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-20-Beyond_Human_Judgment_A_Bayesian_Evaluation_of_LLMs_Moral_Values_Understanding/\",\"children\":\"[논문리뷰] Beyond Human Judgment: A Bayesian Evaluation of LLMs' Moral Values Understanding\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Alina Landowska이 [arXiv]에 게시한 'Beyond Human Judgment: A Bayesian Evaluation of LLMs' Moral Values Understanding' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-20 13:26:54+0900\",\"children\":\"2025년 8월 20일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Moral Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Moral Reasoning\"]}],[\"$\",\"span\",\"Bayesian Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Bayesian Evaluation\"]}],[\"$\",\"span\",\"Uncertainty Quantification\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Uncertainty Quantification\"]}],[\"$\",\"span\",\"Natural Language Processing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Natural Language Processing\"]}],[\"$\",\"span\",\"Soft Labels\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Soft Labels\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-20-A_Stitch_in_Time_Saves_Nine_Proactive_Self-Refinement_for_Language_Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-20-A_Stitch_in_Time_Saves_Nine_Proactive_Self-Refinement_for_Language_Models/\",\"children\":\"[논문리뷰] A Stitch in Time Saves Nine: Proactive Self-Refinement for Language Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Zishang Jiang이 [arXiv]에 게시한 'A Stitch in Time Saves Nine: Proactive Self-Refinement for Language Models' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-20 13:26:54+0900\",\"children\":\"2025년 8월 20일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Self-Refinement\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Self-Refinement\"]}],[\"$\",\"span\",\"Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Language Models\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Proactive AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Proactive AI\"]}],[\"$\",\"span\",\"Generation Process\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generation Process\"]}],[\"$\",\"span\",\"Markov Decision Process\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Markov Decision Process\"]}],[\"$\",\"span\",\"Adaptive Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Adaptive Learning\"]}],[\"$\",\"span\",\"LLM Efficiency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Efficiency\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-20-Advances_in_Speech_Separation_Techniques_Challenges_and_Future_Trends\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-20-Advances_in_Speech_Separation_Techniques_Challenges_and_Future_Trends/\",\"children\":\"[논문리뷰] Advances in Speech Separation: Techniques, Challenges, and Future Trends\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Zhuo Chen이 [arXiv]에 게시한 'Advances in Speech Separation: Techniques, Challenges, and Future Trends' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-20 13:26:54+0900\",\"children\":\"2025년 8월 20일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Speech Separation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Speech Separation\"]}],[\"$\",\"span\",\"Deep Neural Networks\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Deep Neural Networks\"]}],[\"$\",\"span\",\"Cocktail Party Problem\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Cocktail Party Problem\"]}],[\"$\",\"span\",\"Transformer Architecture\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Transformer Architecture\"]}],[\"$\",\"span\",\"Unsupervised Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Unsupervised Learning\"]}],[\"$\",\"span\",\"Supervised Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Supervised Learning\"]}],[\"$\",\"span\",\"Evaluation Metrics\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Evaluation Metrics\"]}],[\"$\",\"span\",\"Datasets\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Datasets\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-19-When_Punctuation_Matters_A_Large-Scale_Comparison_of_Prompt_Robustness_Methods_for_LLMs\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-19-When_Punctuation_Matters_A_Large-Scale_Comparison_of_Prompt_Robustness_Methods_for_LLMs/\",\"children\":\"[논문리뷰] When Punctuation Matters: A Large-Scale Comparison of Prompt Robustness Methods for LLMs\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Elena Tutubalina이 [arXiv]에 게시한 'When Punctuation Matters: A Large-Scale Comparison of Prompt Robustness Methods for LLMs' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-19 13:15:01+0900\",\"children\":\"2025년 8월 19일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLM Robustness\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Robustness\"]}],[\"$\",\"span\",\"Prompt Sensitivity\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Prompt Sensitivity\"]}],[\"$\",\"span\",\"In-Context Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"In-Context Learning\"]}],[\"$\",\"span\",\"Fine-Tuning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Fine-Tuning\"]}],[\"$\",\"span\",\"Batch Calibration\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Batch Calibration\"]}],[\"$\",\"span\",\"Template Ensembles\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Template Ensembles\"]}],[\"$\",\"span\",\"Distribution Shift\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Distribution Shift\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-19-Speed_Always_Wins_A_Survey_on_Efficient_Architectures_for_Large_Language_Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-19-Speed_Always_Wins_A_Survey_on_Efficient_Architectures_for_Large_Language_Models/\",\"children\":\"[논문리뷰] Speed Always Wins: A Survey on Efficient Architectures for Large Language Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Jusen Du이 [arXiv]에 게시한 'Speed Always Wins: A Survey on Efficient Architectures for Large Language Models' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-19 13:15:01+0900\",\"children\":\"2025년 8월 19일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Efficient Architectures\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Efficient Architectures\"]}],[\"$\",\"span\",\"Transformer Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Transformer Optimization\"]}],[\"$\",\"span\",\"Linear Attention\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Linear Attention\"]}],[\"$\",\"span\",\"State Space Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"State Space Models\"]}],[\"$\",\"span\",\"Mixture-of-Experts\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Mixture-of-Experts\"]}],[\"$\",\"span\",\"Sparse Attention\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Sparse Attention\"]}],[\"$\",\"span\",\"Diffusion LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion LLMs\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-19-S2-Guidance_Stochastic_Self_Guidance_for_Training-Free_Enhancement_of_Diffusion_Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-19-S2-Guidance_Stochastic_Self_Guidance_for_Training-Free_Enhancement_of_Diffusion_Models/\",\"children\":\"[논문리뷰] S^2-Guidance: Stochastic Self Guidance for Training-Free Enhancement of Diffusion Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Meiqi Wu이 [arXiv]에 게시한 'S^2-Guidance: Stochastic Self Guidance for Training-Free Enhancement of Diffusion Models' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-19 13:15:01+0900\",\"children\":\"2025년 8월 19일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}],[\"$\",\"span\",\"Classifier-free Guidance\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Classifier-free Guidance\"]}],[\"$\",\"span\",\"Self-Guidance\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Self-Guidance\"]}],[\"$\",\"span\",\"Training-Free\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Training-Free\"]}],[\"$\",\"span\",\"Stochastic Block-Dropping\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Stochastic Block-Dropping\"]}],[\"$\",\"span\",\"Generative Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generative Models\"]}],[\"$\",\"span\",\"Text-to-Image\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Text-to-Image\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-19-Representing_Speech_Through_Autoregressive_Prediction_of_Cochlear_Tokens\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-19-Representing_Speech_Through_Autoregressive_Prediction_of_Cochlear_Tokens/\",\"children\":\"[논문리뷰] Representing Speech Through Autoregressive Prediction of Cochlear Tokens\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Daniel L. K. Yamins이 [arXiv]에 게시한 'Representing Speech Through Autoregressive Prediction of Cochlear Tokens' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-19 13:15:01+0900\",\"children\":\"2025년 8월 19일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Speech Representation Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Speech Representation Learning\"]}],[\"$\",\"span\",\"Autoregressive Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Autoregressive Models\"]}],[\"$\",\"span\",\"Cochlear Tokens\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Cochlear Tokens\"]}],[\"$\",\"span\",\"Biologically Inspired AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Biologically Inspired AI\"]}],[\"$\",\"span\",\"Self-Supervised Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Self-Supervised Learning\"]}],[\"$\",\"span\",\"Audio Processing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Audio Processing\"]}],[\"$\",\"span\",\"Transformer Networks\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Transformer Networks\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-19-Reinforcement_Learning_with_Rubric_Anchors\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-19-Reinforcement_Learning_with_Rubric_Anchors/\",\"children\":\"[논문리뷰] Reinforcement Learning with Rubric Anchors\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Haokai Xu이 [arXiv]에 게시한 'Reinforcement Learning with Rubric Anchors' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-19 13:15:01+0900\",\"children\":\"2025년 8월 19일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Rubric-based Reward\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Rubric-based Reward\"]}],[\"$\",\"span\",\"RLVR Extension\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"RLVR Extension\"]}],[\"$\",\"span\",\"Human-centric AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Human-centric AI\"]}],[\"$\",\"span\",\"Controllable Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Controllable Generation\"]}],[\"$\",\"span\",\"Reward Hacking Mitigation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reward Hacking Mitigation\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-19-Precise_Action-to-Video_Generation_Through_Visual_Action_Prompts\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-19-Precise_Action-to-Video_Generation_Through_Visual_Action_Prompts/\",\"children\":\"[논문리뷰] Precise Action-to-Video Generation Through Visual Action Prompts\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Minghan Qin이 [arXiv]에 게시한 'Precise Action-to-Video Generation Through Visual Action Prompts' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-19 13:15:01+0900\",\"children\":\"2025년 8월 19일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Action-to-Video Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Action-to-Video Generation\"]}],[\"$\",\"span\",\"Visual Action Prompts\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Visual Action Prompts\"]}],[\"$\",\"span\",\"Skeleton Representation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Skeleton Representation\"]}],[\"$\",\"span\",\"Human-Object Interaction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Human-Object Interaction\"]}],[\"$\",\"span\",\"Robotic Manipulation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Robotic Manipulation\"]}],[\"$\",\"span\",\"Cross-Domain Transfer\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Cross-Domain Transfer\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-19-Ovis2.5_Technical_Report\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-19-Ovis2.5_Technical_Report/\",\"children\":\"[논문리뷰] Ovis2.5 Technical Report\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yang Li이 [arXiv]에 게시한 'Ovis2.5 Technical Report' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-19 13:15:01+0900\",\"children\":\"2025년 8월 19일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Multimodal LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal LLMs\"]}],[\"$\",\"span\",\"Native Resolution Vision\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Native Resolution Vision\"]}],[\"$\",\"span\",\"Deep Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Deep Reasoning\"]}],[\"$\",\"span\",\"Chart Analysis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Chart Analysis\"]}],[\"$\",\"span\",\"OCR\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"OCR\"]}],[\"$\",\"span\",\"Visual Grounding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Visual Grounding\"]}],[\"$\",\"span\",\"Training Efficiency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Training Efficiency\"]}],[\"$\",\"span\",\"Preference Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Preference Optimization\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-19-Next_Visual_Granularity_Generation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-19-Next_Visual_Granularity_Generation/\",\"children\":\"[논문리뷰] Next Visual Granularity Generation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Kang Liao이 [arXiv]에 게시한 'Next Visual Granularity Generation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-19 13:15:01+0900\",\"children\":\"2025년 8월 19일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Image Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image Generation\"]}],[\"$\",\"span\",\"Granularity Control\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Granularity Control\"]}],[\"$\",\"span\",\"Structured Representation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Structured Representation\"]}],[\"$\",\"span\",\"Hierarchical Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Hierarchical Generation\"]}],[\"$\",\"span\",\"Coarse-to-fine\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Coarse-to-fine\"]}],[\"$\",\"span\",\"Visual Tokenization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Visual Tokenization\"]}],[\"$\",\"span\",\"Latent Space\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Latent Space\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-19-Matrix-Game_2.0_An_Open-Source_Real-Time_and_Streaming_Interactive_World_Model\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-19-Matrix-Game_2.0_An_Open-Source_Real-Time_and_Streaming_Interactive_World_Model/\",\"children\":\"[논문리뷰] Matrix-Game 2.0: An Open-Source, Real-Time, and Streaming Interactive World Model\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yifan Zhang이 [arXiv]에 게시한 'Matrix-Game 2.0: An Open-Source, Real-Time, and Streaming Interactive World Model' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-19 13:15:01+0900\",\"children\":\"2025년 8월 19일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"World Model\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"World Model\"]}],[\"$\",\"span\",\"Interactive Video Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Interactive Video Generation\"]}],[\"$\",\"span\",\"Real-Time AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Real-Time AI\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}],[\"$\",\"span\",\"Auto-Regressive Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Auto-Regressive Generation\"]}],[\"$\",\"span\",\"Data Pipeline\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Pipeline\"]}],[\"$\",\"span\",\"Self-Forcing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Self-Forcing\"]}],[\"$\",\"span\",\"KV Caching\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"KV Caching\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-19-Lumen_Consistent_Video_Relighting_and_Harmonious_Background_Replacement_with_Video_Generative_Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-19-Lumen_Consistent_Video_Relighting_and_Harmonious_Background_Replacement_with_Video_Generative_Models/\",\"children\":\"[논문리뷰] Lumen: Consistent Video Relighting and Harmonious Background Replacement with Video Generative Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Zixiang Gao이 [arXiv]에 게시한 'Lumen: Consistent Video Relighting and Harmonious Background Replacement with Video Generative Models' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-19 13:15:01+0900\",\"children\":\"2025년 8월 19일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Video Relighting\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video Relighting\"]}],[\"$\",\"span\",\"Background Replacement\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Background Replacement\"]}],[\"$\",\"span\",\"Generative Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generative Models\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}],[\"$\",\"span\",\"Temporal Consistency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Temporal Consistency\"]}],[\"$\",\"span\",\"Dataset Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dataset Generation\"]}],[\"$\",\"span\",\"Video Editing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video Editing\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-19-Inverse-LLaVA_Eliminating_Alignment_Pre-training_Through_Text-to-Vision_Mapping\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-19-Inverse-LLaVA_Eliminating_Alignment_Pre-training_Through_Text-to-Vision_Mapping/\",\"children\":\"[논문리뷰] Inverse-LLaVA: Eliminating Alignment Pre-training Through Text-to-Vision Mapping\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Tyler Derr이 [arXiv]에 게시한 'Inverse-LLaVA: Eliminating Alignment Pre-training Through Text-to-Vision Mapping' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-19 13:15:01+0900\",\"children\":\"2025년 8월 19일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Multimodal Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Learning\"]}],[\"$\",\"span\",\"Vision-Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision-Language Models\"]}],[\"$\",\"span\",\"Alignment Pre-training\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Alignment Pre-training\"]}],[\"$\",\"span\",\"Text-to-Vision Mapping\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Text-to-Vision Mapping\"]}],[\"$\",\"span\",\"Continuous Representations\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Continuous Representations\"]}],[\"$\",\"span\",\"Computational Efficiency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Computational Efficiency\"]}],[\"$\",\"span\",\"LLM\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-19-HeroBench_A_Benchmark_for_Long-Horizon_Planning_and_Structured_Reasoning_in_Virtual_Worlds\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-19-HeroBench_A_Benchmark_for_Long-Horizon_Planning_and_Structured_Reasoning_in_Virtual_Worlds/\",\"children\":\"[논문리뷰] HeroBench: A Benchmark for Long-Horizon Planning and Structured Reasoning in Virtual Worlds\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Artyom Sorokin이 [arXiv]에 게시한 'HeroBench: A Benchmark for Long-Horizon Planning and Structured Reasoning in Virtual Worlds' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-19 13:15:01+0900\",\"children\":\"2025년 8월 19일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Long-Horizon Planning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Long-Horizon Planning\"]}],[\"$\",\"span\",\"Structured Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Structured Reasoning\"]}],[\"$\",\"span\",\"LLM Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Evaluation\"]}],[\"$\",\"span\",\"Virtual Worlds\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Virtual Worlds\"]}],[\"$\",\"span\",\"RPG\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"RPG\"]}],[\"$\",\"span\",\"Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmark\"]}],[\"$\",\"span\",\"Agent Systems\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Agent Systems\"]}],[\"$\",\"span\",\"Combat Simulation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Combat Simulation\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-19-Has_GPT-5_Achieved_Spatial_Intelligence_An_Empirical_Study\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-19-Has_GPT-5_Achieved_Spatial_Intelligence_An_Empirical_Study/\",\"children\":\"[논문리뷰] Has GPT-5 Achieved Spatial Intelligence? An Empirical Study\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Ruisi Wang이 [arXiv]에 게시한 'Has GPT-5 Achieved Spatial Intelligence? An Empirical Study' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-19 13:15:01+0900\",\"children\":\"2025년 8월 19일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Spatial Intelligence\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Spatial Intelligence\"]}],[\"$\",\"span\",\"Multimodal LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal LLMs\"]}],[\"$\",\"span\",\"Benchmark Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmark Evaluation\"]}],[\"$\",\"span\",\"GPT-5\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"GPT-5\"]}],[\"$\",\"span\",\"Cognitive AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Cognitive AI\"]}],[\"$\",\"span\",\"AGI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"AGI\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-19-G-CUT3R_Guided_3D_Reconstruction_with_Camera_and_Depth_Prior_Integration\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-19-G-CUT3R_Guided_3D_Reconstruction_with_Camera_and_Depth_Prior_Integration/\",\"children\":\"[논문리뷰] G-CUT3R: Guided 3D Reconstruction with Camera and Depth Prior Integration\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Evgeny Burnaev이 [arXiv]에 게시한 'G-CUT3R: Guided 3D Reconstruction with Camera and Depth Prior Integration' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-19 13:15:01+0900\",\"children\":\"2025년 8월 19일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"3D Reconstruction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D Reconstruction\"]}],[\"$\",\"span\",\"Deep Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Deep Learning\"]}],[\"$\",\"span\",\"Multi-Modal Fusion\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-Modal Fusion\"]}],[\"$\",\"span\",\"Camera Pose Estimation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Camera Pose Estimation\"]}],[\"$\",\"span\",\"Depth Estimation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Depth Estimation\"]}],[\"$\",\"span\",\"Transformer Networks\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Transformer Networks\"]}],[\"$\",\"span\",\"Prior Information\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Prior Information\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-19-ComoRAG_A_Cognitive-Inspired_Memory-Organized_RAG_for_Stateful_Long_Narrative_Reasoning\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-19-ComoRAG_A_Cognitive-Inspired_Memory-Organized_RAG_for_Stateful_Long_Narrative_Reasoning/\",\"children\":\"[논문리뷰] ComoRAG: A Cognitive-Inspired Memory-Organized RAG for Stateful Long Narrative Reasoning\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yufeng Wang이 [arXiv]에 게시한 'ComoRAG: A Cognitive-Inspired Memory-Organized RAG for Stateful Long Narrative Reasoning' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-19 13:15:01+0900\",\"children\":\"2025년 8월 19일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Cognitive-Inspired RAG\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Cognitive-Inspired RAG\"]}],[\"$\",\"span\",\"Stateful Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Stateful Reasoning\"]}],[\"$\",\"span\",\"Long Narrative Comprehension\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Long Narrative Comprehension\"]}],[\"$\",\"span\",\"Dynamic Memory\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dynamic Memory\"]}],[\"$\",\"span\",\"Metacognitive Regulation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Metacognitive Regulation\"]}],[\"$\",\"span\",\"Multi-step Retrieval\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-step Retrieval\"]}],[\"$\",\"span\",\"Hierarchical Knowledge Source\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Hierarchical Knowledge Source\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-19-Beyond_Solving_Math_Quiz_Evaluating_the_Ability_of_Large_Reasoning_Models_to_Ask_for_Information\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-19-Beyond_Solving_Math_Quiz_Evaluating_the_Ability_of_Large_Reasoning_Models_to_Ask_for_Information/\",\"children\":\"[논문리뷰] Beyond Solving Math Quiz: Evaluating the Ability of Large Reasoning Models to Ask for Information\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Xi Yang이 [arXiv]에 게시한 'Beyond Solving Math Quiz: Evaluating the Ability of Large Reasoning Models to Ask for Information' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-19 13:15:01+0900\",\"children\":\"2025년 8월 19일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Large Reasoning Models (LRMs)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Reasoning Models (LRMs)\"]}],[\"$\",\"span\",\"Information Seeking\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Information Seeking\"]}],[\"$\",\"span\",\"Incomplete Problems\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Incomplete Problems\"]}],[\"$\",\"span\",\"Mathematical Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Mathematical Reasoning\"]}],[\"$\",\"span\",\"Supervised Fine-tuning (SFT)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Supervised Fine-tuning (SFT)\"]}],[\"$\",\"span\",\"Overthinking\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Overthinking\"]}],[\"$\",\"span\",\"Hallucination\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Hallucination\"]}],[\"$\",\"span\",\"CRITIC-math\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"CRITIC-math\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-19-4DNeX_Feed-Forward_4D_Generative_Modeling_Made_Easy\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-19-4DNeX_Feed-Forward_4D_Generative_Modeling_Made_Easy/\",\"children\":\"[논문리뷰] 4DNeX: Feed-Forward 4D Generative Modeling Made Easy\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Zeng Tao이 [arXiv]에 게시한 '4DNeX: Feed-Forward 4D Generative Modeling Made Easy' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-19 13:15:01+0900\",\"children\":\"2025년 8월 19일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"4D Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"4D Generation\"]}],[\"$\",\"span\",\"Dynamic 3D\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dynamic 3D\"]}],[\"$\",\"span\",\"Generative Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generative Models\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}],[\"$\",\"span\",\"Single Image Input\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Single Image Input\"]}],[\"$\",\"span\",\"Video Synthesis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video Synthesis\"]}],[\"$\",\"span\",\"Point Clouds\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Point Clouds\"]}],[\"$\",\"span\",\"Dataset\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dataset\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-18-X-Node_Self-Explanation_is_All_We_Need\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-18-X-Node_Self-Explanation_is_All_We_Need/\",\"children\":\"[논문리뷰] X-Node: Self-Explanation is All We Need\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Islem Rekik이 [arXiv]에 게시한 'X-Node: Self-Explanation is All We Need' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-18 13:14:38+0900\",\"children\":\"2025년 8월 18일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Graph Neural Networks\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Graph Neural Networks\"]}],[\"$\",\"span\",\"Explainable AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Explainable AI\"]}],[\"$\",\"span\",\"Self-Explanation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Self-Explanation\"]}],[\"$\",\"span\",\"Node Classification\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Node Classification\"]}],[\"$\",\"span\",\"Medical Imaging\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Medical Imaging\"]}],[\"$\",\"span\",\"Natural Language Processing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Natural Language Processing\"]}],[\"$\",\"span\",\"Interpretability\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Interpretability\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-18-Thyme_Think_Beyond_Images\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-18-Thyme_Think_Beyond_Images/\",\"children\":\"[논문리뷰] Thyme: Think Beyond Images\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Wei Chen이 [arXiv]에 게시한 'Thyme: Think Beyond Images' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-18 13:14:38+0900\",\"children\":\"2025년 8월 18일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Multimodal LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal LLMs\"]}],[\"$\",\"span\",\"Code Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Code Generation\"]}],[\"$\",\"span\",\"Image Processing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image Processing\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Supervised Fine-Tuning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Supervised Fine-Tuning\"]}],[\"$\",\"span\",\"Visual Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Visual Reasoning\"]}],[\"$\",\"span\",\"Sandbox\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Sandbox\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-18-TexVerse_A_Universe_of_3D_Objects_with_High-Resolution_Textures\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-18-TexVerse_A_Universe_of_3D_Objects_with_High-Resolution_Textures/\",\"children\":\"[논문리뷰] TexVerse: A Universe of 3D Objects with High-Resolution Textures\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Nan Cao이 [arXiv]에 게시한 'TexVerse: A Universe of 3D Objects with High-Resolution Textures' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-18 13:14:38+0900\",\"children\":\"2025년 8월 18일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"3D Dataset\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D Dataset\"]}],[\"$\",\"span\",\"High-Resolution Textures\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"High-Resolution Textures\"]}],[\"$\",\"span\",\"Physically Based Rendering (PBR)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Physically Based Rendering (PBR)\"]}],[\"$\",\"span\",\"3D Animation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D Animation\"]}],[\"$\",\"span\",\"Data Curation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Curation\"]}],[\"$\",\"span\",\"GPT-5 Annotations\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"GPT-5 Annotations\"]}],[\"$\",\"span\",\"Sketchfab\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Sketchfab\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-18-StyleMM_Stylized_3D_Morphable_Face_Model_via_Text-Driven_Aligned_Image_Translation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-18-StyleMM_Stylized_3D_Morphable_Face_Model_via_Text-Driven_Aligned_Image_Translation/\",\"children\":\"[논문리뷰] StyleMM: Stylized 3D Morphable Face Model via Text-Driven Aligned Image Translation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Junyong Noh이 [arXiv]에 게시한 'StyleMM: Stylized 3D Morphable Face Model via Text-Driven Aligned Image Translation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-18 13:14:38+0900\",\"children\":\"2025년 8월 18일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"3D Morphable Model\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D Morphable Model\"]}],[\"$\",\"span\",\"Face Stylization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Face Stylization\"]}],[\"$\",\"span\",\"Text-to-Image Translation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Text-to-Image Translation\"]}],[\"$\",\"span\",\"Diffusion Model\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Model\"]}],[\"$\",\"span\",\"Attribute Preservation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Attribute Preservation\"]}],[\"$\",\"span\",\"Generative AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generative AI\"]}],[\"$\",\"span\",\"Computer Graphics\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Computer Graphics\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-18-SSRL_Self-Search_Reinforcement_Learning\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-18-SSRL_Self-Search_Reinforcement_Learning/\",\"children\":\"[논문리뷰] SSRL: Self-Search Reinforcement Learning\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yanxu Chen이 [arXiv]에 게시한 'SSRL: Self-Search Reinforcement Learning' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-18 13:14:38+0900\",\"children\":\"2025년 8월 18일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Self-Search\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Self-Search\"]}],[\"$\",\"span\",\"Sim-to-Real Transfer\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Sim-to-Real Transfer\"]}],[\"$\",\"span\",\"Agentic AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Agentic AI\"]}],[\"$\",\"span\",\"Knowledge Retrieval\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Knowledge Retrieval\"]}],[\"$\",\"span\",\"Reward Modeling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reward Modeling\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-18-SPARSE_Data_Rich_Results_Few-Shot_Semi-Supervised_Learning_via_Class-Conditioned_Image_Translation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-18-SPARSE_Data_Rich_Results_Few-Shot_Semi-Supervised_Learning_via_Class-Conditioned_Image_Translation/\",\"children\":\"[논문리뷰] SPARSE Data, Rich Results: Few-Shot Semi-Supervised Learning via Class-Conditioned Image Translation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Paolo Soda이 [arXiv]에 게시한 'SPARSE Data, Rich Results: Few-Shot Semi-Supervised Learning via Class-Conditioned Image Translation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-18 13:14:38+0900\",\"children\":\"2025년 8월 18일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Semi-supervised Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Semi-supervised Learning\"]}],[\"$\",\"span\",\"Few-shot Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Few-shot Learning\"]}],[\"$\",\"span\",\"Medical Imaging\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Medical Imaging\"]}],[\"$\",\"span\",\"GAN-based Methods\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"GAN-based Methods\"]}],[\"$\",\"span\",\"Image-to-image Translation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image-to-image Translation\"]}],[\"$\",\"span\",\"Pseudo-labeling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Pseudo-labeling\"]}],[\"$\",\"span\",\"Ensemble Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Ensemble Learning\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-18-PaperRegister_Boosting_Flexible-grained_Paper_Search_via_Hierarchical_Register_Indexing\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-18-PaperRegister_Boosting_Flexible-grained_Paper_Search_via_Hierarchical_Register_Indexing/\",\"children\":\"[논문리뷰] PaperRegister: Boosting Flexible-grained Paper Search via Hierarchical Register Indexing\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Xianpei Han이 [arXiv]에 게시한 'PaperRegister: Boosting Flexible-grained Paper Search via Hierarchical Register Indexing' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-18 13:14:38+0900\",\"children\":\"2025년 8월 18일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"논문 검색\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"논문 검색\"]}],[\"$\",\"span\",\"계층적 인덱싱\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"계층적 인덱싱\"]}],[\"$\",\"span\",\"유연한 검색\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"유연한 검색\"]}],[\"$\",\"span\",\"대규모 언어 모델\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"대규모 언어 모델\"]}],[\"$\",\"span\",\"정보 추출\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"정보 추출\"]}],[\"$\",\"span\",\"뷰 인식\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"뷰 인식\"]}],[\"$\",\"span\",\"강화 학습\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"강화 학습\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-18-MAESTRO_Masked_AutoEncoders_for_Multimodal_Multitemporal_and_Multispectral_Earth_Observation_Data\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-18-MAESTRO_Masked_AutoEncoders_for_Multimodal_Multitemporal_and_Multispectral_Earth_Observation_Data/\",\"children\":\"[논문리뷰] MAESTRO: Masked AutoEncoders for Multimodal, Multitemporal, and Multispectral Earth Observation Data\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Nicolas Gonthier이 [arXiv]에 게시한 'MAESTRO: Masked AutoEncoders for Multimodal, Multitemporal, and Multispectral Earth Observation Data' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-18 13:14:38+0900\",\"children\":\"2025년 8월 18일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Self-supervised Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Self-supervised Learning\"]}],[\"$\",\"span\",\"Masked Autoencoder\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Masked Autoencoder\"]}],[\"$\",\"span\",\"Earth Observation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Earth Observation\"]}],[\"$\",\"span\",\"Multimodal\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal\"]}],[\"$\",\"span\",\"Multitemporal\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multitemporal\"]}],[\"$\",\"span\",\"Multispectral\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multispectral\"]}],[\"$\",\"span\",\"Fusion Strategies\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Fusion Strategies\"]}],[\"$\",\"span\",\"Target Normalization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Target Normalization\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-18-FantasyTalking2_Timestep-Layer_Adaptive_Preference_Optimization_for_Audio-Driven_Portrait_Animation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-18-FantasyTalking2_Timestep-Layer_Adaptive_Preference_Optimization_for_Audio-Driven_Portrait_Animation/\",\"children\":\"[논문리뷰] FantasyTalking2: Timestep-Layer Adaptive Preference Optimization for Audio-Driven Portrait Animation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Mu Xu이 [arXiv]에 게시한 'FantasyTalking2: Timestep-Layer Adaptive Preference Optimization for Audio-Driven Portrait Animation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-18 13:14:38+0900\",\"children\":\"2025년 8월 18일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Audio-Driven Animation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Audio-Driven Animation\"]}],[\"$\",\"span\",\"Preference Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Preference Optimization\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}],[\"$\",\"span\",\"Reward Modeling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reward Modeling\"]}],[\"$\",\"span\",\"Human Feedback\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Human Feedback\"]}],[\"$\",\"span\",\"Multi-Objective Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-Objective Optimization\"]}],[\"$\",\"span\",\"Timestep-Layer Adaptive\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Timestep-Layer Adaptive\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-18-DINOv3\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-18-DINOv3/\",\"children\":\"[논문리뷰] DINOv3\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Maxime Oquab이 [arXiv]에 게시한 'DINOv3' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-18 13:14:38+0900\",\"children\":\"2025년 8월 18일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Self-supervised Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Self-supervised Learning\"]}],[\"$\",\"span\",\"Foundation Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Foundation Models\"]}],[\"$\",\"span\",\"Vision Transformer\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision Transformer\"]}],[\"$\",\"span\",\"Dense Feature Maps\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dense Feature Maps\"]}],[\"$\",\"span\",\"Gram Anchoring\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Gram Anchoring\"]}],[\"$\",\"span\",\"Model Distillation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Model Distillation\"]}],[\"$\",\"span\",\"Geospatial AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Geospatial AI\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-18-Controlling_Multimodal_LLMs_via_Reward-guided_Decoding\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-18-Controlling_Multimodal_LLMs_via_Reward-guided_Decoding/\",\"children\":\"[논문리뷰] Controlling Multimodal LLMs via Reward-guided Decoding\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Michal Drozdzal이 [arXiv]에 게시한 'Controlling Multimodal LLMs via Reward-guided Decoding' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-18 13:14:38+0900\",\"children\":\"2025년 8월 18일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Multimodal LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal LLMs\"]}],[\"$\",\"span\",\"Reward Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reward Models\"]}],[\"$\",\"span\",\"Guided Decoding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Guided Decoding\"]}],[\"$\",\"span\",\"Visual Grounding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Visual Grounding\"]}],[\"$\",\"span\",\"Hallucination Mitigation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Hallucination Mitigation\"]}],[\"$\",\"span\",\"Object Precision\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Object Precision\"]}],[\"$\",\"span\",\"Object Recall\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Object Recall\"]}],[\"$\",\"span\",\"Inference-time Control\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Inference-time Control\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-15-We-Math_2.0_A_Versatile_MathBook_System_for_Incentivizing_Visual_Mathematical_Reasoning\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-15-We-Math_2.0_A_Versatile_MathBook_System_for_Incentivizing_Visual_Mathematical_Reasoning/\",\"children\":\"[논문리뷰] We-Math 2.0: A Versatile MathBook System for Incentivizing Visual Mathematical Reasoning\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Xiaowan Wang이 [arXiv]에 게시한 'We-Math 2.0: A Versatile MathBook System for Incentivizing Visual Mathematical Reasoning' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-15 13:09:31+0900\",\"children\":\"2025년 8월 15일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Visual Mathematical Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Visual Mathematical Reasoning\"]}],[\"$\",\"span\",\"MLLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"MLLMs\"]}],[\"$\",\"span\",\"Knowledge System\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Knowledge System\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Curriculum Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Curriculum Learning\"]}],[\"$\",\"span\",\"Dataset Construction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dataset Construction\"]}],[\"$\",\"span\",\"Mathematical Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Mathematical Benchmark\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-15-UI-Venus_Technical_Report_Building_High-performance_UI_Agents_with_RFT\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-15-UI-Venus_Technical_Report_Building_High-performance_UI_Agents_with_RFT/\",\"children\":\"[논문리뷰] UI-Venus Technical Report: Building High-performance UI Agents with RFT\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Shuheng Shen이 [arXiv]에 게시한 'UI-Venus Technical Report: Building High-performance UI Agents with RFT' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-15 13:09:31+0900\",\"children\":\"2025년 8월 15일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"UI Agent\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"UI Agent\"]}],[\"$\",\"span\",\"MLLM\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"MLLM\"]}],[\"$\",\"span\",\"RFT\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"RFT\"]}],[\"$\",\"span\",\"UI Grounding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"UI Grounding\"]}],[\"$\",\"span\",\"UI Navigation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"UI Navigation\"]}],[\"$\",\"span\",\"GRPO\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"GRPO\"]}],[\"$\",\"span\",\"Data Cleaning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Cleaning\"]}],[\"$\",\"span\",\"Self-Evolving Trajectory\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Self-Evolving Trajectory\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-15-ToonComposer_Streamlining_Cartoon_Production_with_Generative_Post-Keyframing\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-15-ToonComposer_Streamlining_Cartoon_Production_with_Generative_Post-Keyframing/\",\"children\":\"[논문리뷰] ToonComposer: Streamlining Cartoon Production with Generative Post-Keyframing\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Xiaoyu Li이 [arXiv]에 게시한 'ToonComposer: Streamlining Cartoon Production with Generative Post-Keyframing' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-15 13:09:31+0900\",\"children\":\"2025년 8월 15일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Cartoon Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Cartoon Generation\"]}],[\"$\",\"span\",\"Video Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video Diffusion Models\"]}],[\"$\",\"span\",\"DiT\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"DiT\"]}],[\"$\",\"span\",\"Post-Keyframing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Post-Keyframing\"]}],[\"$\",\"span\",\"Low-Rank Adaptation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Low-Rank Adaptation\"]}],[\"$\",\"span\",\"Sparse Control\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Sparse Control\"]}],[\"$\",\"span\",\"Generative AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generative AI\"]}],[\"$\",\"span\",\"Animation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Animation\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-15-STream3R_Scalable_Sequential_3D_Reconstruction_with_Causal_Transformer\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-15-STream3R_Scalable_Sequential_3D_Reconstruction_with_Causal_Transformer/\",\"children\":\"[논문리뷰] STream3R: Scalable Sequential 3D Reconstruction with Causal Transformer\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Honghua Chen이 [arXiv]에 게시한 'STream3R: Scalable Sequential 3D Reconstruction with Causal Transformer' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-15 13:09:31+0900\",\"children\":\"2025년 8월 15일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"3D Reconstruction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D Reconstruction\"]}],[\"$\",\"span\",\"Causal Transformer\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Causal Transformer\"]}],[\"$\",\"span\",\"Sequential Modeling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Sequential Modeling\"]}],[\"$\",\"span\",\"Streaming Data\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Streaming Data\"]}],[\"$\",\"span\",\"Pointmap Prediction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Pointmap Prediction\"]}],[\"$\",\"span\",\"Online Perception\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Online Perception\"]}],[\"$\",\"span\",\"KVCache\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"KVCache\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-15-Processing_and_acquisition_traces_in_visual_encoders_What_does_CLIP_know_about_your_camera\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-15-Processing_and_acquisition_traces_in_visual_encoders_What_does_CLIP_know_about_your_camera/\",\"children\":\"[논문리뷰] Processing and acquisition traces in visual encoders: What does CLIP know about your camera?\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Giorgos Tolias이 [arXiv]에 게시한 'Processing and acquisition traces in visual encoders: What does CLIP know about your camera?' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-15 13:09:31+0900\",\"children\":\"2025년 8월 15일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Visual Encoders\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Visual Encoders\"]}],[\"$\",\"span\",\"Metadata\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Metadata\"]}],[\"$\",\"span\",\"Image Processing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image Processing\"]}],[\"$\",\"span\",\"Image Acquisition\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image Acquisition\"]}],[\"$\",\"span\",\"Robustness\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Robustness\"]}],[\"$\",\"span\",\"CLIP\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"CLIP\"]}],[\"$\",\"span\",\"Foundation Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Foundation Models\"]}],[\"$\",\"span\",\"Distribution Shift\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Distribution Shift\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-15-PRELUDE_A_Benchmark_Designed_to_Require_Global_Comprehension_and_Reasoning_over_Long_Contexts\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-15-PRELUDE_A_Benchmark_Designed_to_Require_Global_Comprehension_and_Reasoning_over_Long_Contexts/\",\"children\":\"[논문리뷰] PRELUDE: A Benchmark Designed to Require Global Comprehension and Reasoning over Long Contexts\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Rui Lu이 [arXiv]에 게시한 'PRELUDE: A Benchmark Designed to Require Global Comprehension and Reasoning over Long Contexts' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-15 13:09:31+0900\",\"children\":\"2025년 8월 15일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Long-Context Understanding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Long-Context Understanding\"]}],[\"$\",\"span\",\"Reasoning Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reasoning Benchmark\"]}],[\"$\",\"span\",\"LLMs Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLMs Evaluation\"]}],[\"$\",\"span\",\"Natural Language Processing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Natural Language Processing\"]}],[\"$\",\"span\",\"Global Comprehension\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Global Comprehension\"]}],[\"$\",\"span\",\"Fluid Intelligence\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Fluid Intelligence\"]}],[\"$\",\"span\",\"Prequel Entailment\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Prequel Entailment\"]}],[\"$\",\"span\",\"RAG\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"RAG\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-15-Passk_Training_for_Adaptively_Balancing_Exploration_and_Exploitation_of_Large_Reasoning_Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-15-Passk_Training_for_Adaptively_Balancing_Exploration_and_Exploitation_of_Large_Reasoning_Models/\",\"children\":\"[논문리뷰] Pass@k Training for Adaptively Balancing Exploration and Exploitation of Large Reasoning Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Qinghao Ye이 [arXiv]에 게시한 'Pass@k Training for Adaptively Balancing Exploration and Exploitation of Large Reasoning Models' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-15 13:09:31+0900\",\"children\":\"2025년 8월 15일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Exploration-Exploitation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Exploration-Exploitation\"]}],[\"$\",\"span\",\"Reward Design\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reward Design\"]}],[\"$\",\"span\",\"Reasoning Tasks\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reasoning Tasks\"]}],[\"$\",\"span\",\"Pass@k\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Pass@k\"]}],[\"$\",\"span\",\"Policy Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Policy Optimization\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-15-NextStep-1_Toward_Autoregressive_Image_Generation_with_Continuous_Tokens_at_Scale\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-15-NextStep-1_Toward_Autoregressive_Image_Generation_with_Continuous_Tokens_at_Scale/\",\"children\":\"[논문리뷰] NextStep-1: Toward Autoregressive Image Generation with Continuous Tokens at Scale\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Quan Sun이 [arXiv]에 게시한 'NextStep-1: Toward Autoregressive Image Generation with Continuous Tokens at Scale' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-15 13:09:31+0900\",\"children\":\"2025년 8월 15일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Autoregressive Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Autoregressive Models\"]}],[\"$\",\"span\",\"Text-to-Image Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Text-to-Image Generation\"]}],[\"$\",\"span\",\"Continuous Latent Tokens\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Continuous Latent Tokens\"]}],[\"$\",\"span\",\"Flow Matching\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Flow Matching\"]}],[\"$\",\"span\",\"Image Editing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image Editing\"]}],[\"$\",\"span\",\"Multimodal Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Learning\"]}],[\"$\",\"span\",\"Transformer Architecture\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Transformer Architecture\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-15-HumanSense_From_Multimodal_Perception_to_Empathetic_Context-Aware_Responses_through_Reasoning_MLLMs\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-15-HumanSense_From_Multimodal_Perception_to_Empathetic_Context-Aware_Responses_through_Reasoning_MLLMs/\",\"children\":\"[논문리뷰] HumanSense: From Multimodal Perception to Empathetic Context-Aware Responses through Reasoning MLLMs\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yi Yuan이 [arXiv]에 게시한 'HumanSense: From Multimodal Perception to Empathetic Context-Aware Responses through Reasoning MLLMs' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-15 13:09:31+0900\",\"children\":\"2025년 8월 15일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Multimodal LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal LLMs\"]}],[\"$\",\"span\",\"Human-Centered AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Human-Centered AI\"]}],[\"$\",\"span\",\"Empathy\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Empathy\"]}],[\"$\",\"span\",\"Context-Awareness\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Context-Awareness\"]}],[\"$\",\"span\",\"MLLM Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"MLLM Benchmark\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reasoning\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-15-From_Black_Box_to_Transparency_Enhancing_Automated_Interpreting_Assessment_with_Explainable_AI_in_College_Classrooms\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-15-From_Black_Box_to_Transparency_Enhancing_Automated_Interpreting_Assessment_with_Explainable_AI_in_College_Classrooms/\",\"children\":\"[논문리뷰] From Black Box to Transparency: Enhancing Automated Interpreting Assessment with Explainable AI in College Classrooms\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Ziyin Zhang이 [arXiv]에 게시한 'From Black Box to Transparency: Enhancing Automated Interpreting Assessment with Explainable AI in College Classrooms' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-15 13:09:31+0900\",\"children\":\"2025년 8월 15일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Automated Interpreting Assessment\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Automated Interpreting Assessment\"]}],[\"$\",\"span\",\"Explainable AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Explainable AI\"]}],[\"$\",\"span\",\"Data Augmentation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Augmentation\"]}],[\"$\",\"span\",\"Variational Autoencoder\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Variational Autoencoder\"]}],[\"$\",\"span\",\"SHAP\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"SHAP\"]}],[\"$\",\"span\",\"Interpreting Quality\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Interpreting Quality\"]}],[\"$\",\"span\",\"Natural Language Processing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Natural Language Processing\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-15-A_Survey_on_Diffusion_Language_Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-15-A_Survey_on_Diffusion_Language_Models/\",\"children\":\"[논문리뷰] A Survey on Diffusion Language Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Zhiqiang Shen이 [arXiv]에 게시한 'A Survey on Diffusion Language Models' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-15 13:09:31+0900\",\"children\":\"2025년 8월 15일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Diffusion Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Language Models\"]}],[\"$\",\"span\",\"Generative AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generative AI\"]}],[\"$\",\"span\",\"Parallel Decoding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Parallel Decoding\"]}],[\"$\",\"span\",\"Text Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Text Generation\"]}],[\"$\",\"span\",\"Multimodal AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal AI\"]}],[\"$\",\"span\",\"Model Compression\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Model Compression\"]}],[\"$\",\"span\",\"Reinforcement Learning from Human Feedback\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning from Human Feedback\"]}],[\"$\",\"span\",\"Inference Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Inference Optimization\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-15-2025-8-15-Explainability_and_Privacy_in_NLP\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-15-2025-8-15-Explainability_and_Privacy_in_NLP/\",\"children\":\"[논문리뷰] When Explainability Meets Privacy: An Investigation at the Intersection of Post-hoc Explainability and Differential Privacy in the Context of Natural Language Processing\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Gjergji Kasneci이 [arXiv]에 게시한 'When Explainability Meets Privacy: An Investigation at the Intersection of Post-hoc Explainability and Differential Privacy in the Context of Natural Language Processing' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-15 13:09:31+0900\",\"children\":\"2025년 8월 15일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Natural Language Processing (NLP)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Natural Language Processing (NLP)\"]}],[\"$\",\"span\",\"Explainable AI (XAI)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Explainable AI (XAI)\"]}],[\"$\",\"span\",\"Post-hoc Explainability\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Post-hoc Explainability\"]}],[\"$\",\"span\",\"Differential Privacy (DP)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Differential Privacy (DP)\"]}],[\"$\",\"span\",\"Privacy-Utility Trade-off\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Privacy-Utility Trade-off\"]}],[\"$\",\"span\",\"Model Faithfulness\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Model Faithfulness\"]}],[\"$\",\"span\",\"Text Privatization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Text Privatization\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-14-VisCodex_Unified_Multimodal_Code_Generation_via_Merging_Vision_and_Coding_Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-14-VisCodex_Unified_Multimodal_Code_Generation_via_Merging_Vision_and_Coding_Models/\",\"children\":\"[논문리뷰] VisCodex: Unified Multimodal Code Generation via Merging Vision and Coding Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Dongdong Zhang이 [arXiv]에 게시한 'VisCodex: Unified Multimodal Code Generation via Merging Vision and Coding Models' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-14 13:19:02+0900\",\"children\":\"2025년 8월 14일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Multimodal LLM\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal LLM\"]}],[\"$\",\"span\",\"Code Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Code Generation\"]}],[\"$\",\"span\",\"Model Merging\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Model Merging\"]}],[\"$\",\"span\",\"Task Vectors\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Task Vectors\"]}],[\"$\",\"span\",\"Vision-Language Model\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision-Language Model\"]}],[\"$\",\"span\",\"Coding LLM\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Coding LLM\"]}],[\"$\",\"span\",\"Instruction Tuning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Instruction Tuning\"]}],[\"$\",\"span\",\"Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmark\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-14-Story2Board_A_Training-Free_Approach_for_Expressive_Storyboard_Generation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-14-Story2Board_A_Training-Free_Approach_for_Expressive_Storyboard_Generation/\",\"children\":\"[논문리뷰] Story2Board: A Training-Free Approach for Expressive Storyboard Generation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Dani Lischinski이 [arXiv]에 게시한 'Story2Board: A Training-Free Approach for Expressive Storyboard Generation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-14 13:19:02+0900\",\"children\":\"2025년 8월 14일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Storyboard Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Storyboard Generation\"]}],[\"$\",\"span\",\"Text-to-Image\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Text-to-Image\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}],[\"$\",\"span\",\"Training-Free\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Training-Free\"]}],[\"$\",\"span\",\"Character Consistency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Character Consistency\"]}],[\"$\",\"span\",\"Scene Diversity\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Scene Diversity\"]}],[\"$\",\"span\",\"Visual Storytelling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Visual Storytelling\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-14-Stand-In_A_Lightweight_and_Plug-and-Play_Identity_Control_for_Video_Generation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-14-Stand-In_A_Lightweight_and_Plug-and-Play_Identity_Control_for_Video_Generation/\",\"children\":\"[논문리뷰] Stand-In: A Lightweight and Plug-and-Play Identity Control for Video Generation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Chen Li이 [arXiv]에 게시한 'Stand-In: A Lightweight and Plug-and-Play Identity Control for Video Generation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-14 13:19:02+0900\",\"children\":\"2025년 8월 14일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Video Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video Generation\"]}],[\"$\",\"span\",\"Identity Preservation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Identity Preservation\"]}],[\"$\",\"span\",\"Plug-and-Play\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Plug-and-Play\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}],[\"$\",\"span\",\"Self-Attention\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Self-Attention\"]}],[\"$\",\"span\",\"Lightweight AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Lightweight AI\"]}],[\"$\",\"span\",\"Conditional Image Branch\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Conditional Image Branch\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-14-Seeing_Listening_Remembering_and_Reasoning_A_Multimodal_Agent_with_Long-Term_Memory\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-14-Seeing_Listening_Remembering_and_Reasoning_A_Multimodal_Agent_with_Long-Term_Memory/\",\"children\":\"[논문리뷰] Seeing, Listening, Remembering, and Reasoning: A Multimodal Agent with Long-Term Memory\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yuan Lin이 [arXiv]에 게시한 'Seeing, Listening, Remembering, and Reasoning: A Multimodal Agent with Long-Term Memory' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-14 13:19:02+0900\",\"children\":\"2025년 8월 14일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Multimodal Agent\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Agent\"]}],[\"$\",\"span\",\"Long-Term Memory\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Long-Term Memory\"]}],[\"$\",\"span\",\"Episodic Memory\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Episodic Memory\"]}],[\"$\",\"span\",\"Semantic Memory\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Semantic Memory\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Video Question Answering\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video Question Answering\"]}],[\"$\",\"span\",\"Entity-Centric Memory\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Entity-Centric Memory\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-14-Noise_Hypernetworks_Amortizing_Test-Time_Compute_in_Diffusion_Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-14-Noise_Hypernetworks_Amortizing_Test-Time_Compute_in_Diffusion_Models/\",\"children\":\"[논문리뷰] Noise Hypernetworks: Amortizing Test-Time Compute in Diffusion Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Zeynep Akata이 [arXiv]에 게시한 'Noise Hypernetworks: Amortizing Test-Time Compute in Diffusion Models' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-14 13:19:02+0900\",\"children\":\"2025년 8월 14일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}],[\"$\",\"span\",\"Hypernetworks\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Hypernetworks\"]}],[\"$\",\"span\",\"Test-Time Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Test-Time Optimization\"]}],[\"$\",\"span\",\"Reward-Guided Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reward-Guided Generation\"]}],[\"$\",\"span\",\"Latent Space Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Latent Space Optimization\"]}],[\"$\",\"span\",\"LoRA\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LoRA\"]}],[\"$\",\"span\",\"Generative AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generative AI\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-14-Mol-R1_Towards_Explicit_Long-CoT_Reasoning_in_Molecule_Discovery\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-14-Mol-R1_Towards_Explicit_Long-CoT_Reasoning_in_Molecule_Discovery/\",\"children\":\"[논문리뷰] Mol-R1: Towards Explicit Long-CoT Reasoning in Molecule Discovery\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Di Zhang이 [arXiv]에 게시한 'Mol-R1: Towards Explicit Long-CoT Reasoning in Molecule Discovery' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-14 13:19:02+0900\",\"children\":\"2025년 8월 14일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Molecule Discovery\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Molecule Discovery\"]}],[\"$\",\"span\",\"Chain-of-Thought\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Chain-of-Thought\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Supervised Fine-tuning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Supervised Fine-tuning\"]}],[\"$\",\"span\",\"Molecular Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Molecular Generation\"]}],[\"$\",\"span\",\"Explainable AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Explainable AI\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-14-MathReal_We_Keep_It_Real_A_Real_Scene_Benchmark_for_Evaluating_Math_Reasoning_in_Multimodal_Large_Language_Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-14-MathReal_We_Keep_It_Real_A_Real_Scene_Benchmark_for_Evaluating_Math_Reasoning_in_Multimodal_Large_Language_Models/\",\"children\":\"[논문리뷰] MathReal: We Keep It Real! A Real Scene Benchmark for Evaluating Math Reasoning in Multimodal Large Language Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Zhihan Zhou이 [arXiv]에 게시한 'MathReal: We Keep It Real! A Real Scene Benchmark for Evaluating Math Reasoning in Multimodal Large Language Models' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-14 13:19:02+0900\",\"children\":\"2025년 8월 14일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Multimodal Large Language Models (MLLMs)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Large Language Models (MLLMs)\"]}],[\"$\",\"span\",\"Math Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Math Reasoning\"]}],[\"$\",\"span\",\"Real-World Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Real-World Benchmark\"]}],[\"$\",\"span\",\"Visual Perception\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Visual Perception\"]}],[\"$\",\"span\",\"Robustness\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Robustness\"]}],[\"$\",\"span\",\"K-12 Education\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"K-12 Education\"]}],[\"$\",\"span\",\"Dataset\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dataset\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-14-Learning_to_Align_Aligning_to_Learn_A_Unified_Approach_for_Self-Optimized_Alignment\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-14-Learning_to_Align_Aligning_to_Learn_A_Unified_Approach_for_Self-Optimized_Alignment/\",\"children\":\"[논문리뷰] Learning to Align, Aligning to Learn: A Unified Approach for Self-Optimized Alignment\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Lei Fan이 [arXiv]에 게시한 'Learning to Align, Aligning to Learn: A Unified Approach for Self-Optimized Alignment' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-14 13:19:02+0900\",\"children\":\"2025년 8월 14일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLM Alignment\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Alignment\"]}],[\"$\",\"span\",\"Reinforcement Learning from Human Feedback\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning from Human Feedback\"]}],[\"$\",\"span\",\"Preference Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Preference Learning\"]}],[\"$\",\"span\",\"Group Relative Alignment Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Group Relative Alignment Optimization\"]}],[\"$\",\"span\",\"Self-Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Self-Optimization\"]}],[\"$\",\"span\",\"Mixture-of-Experts\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Mixture-of-Experts\"]}],[\"$\",\"span\",\"Imitation Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Imitation Learning\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-14-IAG_Input-aware_Backdoor_Attack_on_VLMs_for_Visual_Grounding\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-14-IAG_Input-aware_Backdoor_Attack_on_VLMs_for_Visual_Grounding/\",\"children\":\"[논문리뷰] IAG: Input-aware Backdoor Attack on VLMs for Visual Grounding\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Di Zhang이 [arXiv]에 게시한 'IAG: Input-aware Backdoor Attack on VLMs for Visual Grounding' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-14 13:19:02+0900\",\"children\":\"2025년 8월 14일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Backdoor Attack\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Backdoor Attack\"]}],[\"$\",\"span\",\"Vision-Language Models (VLMs)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision-Language Models (VLMs)\"]}],[\"$\",\"span\",\"Visual Grounding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Visual Grounding\"]}],[\"$\",\"span\",\"Input-aware Trigger\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Input-aware Trigger\"]}],[\"$\",\"span\",\"Adversarial Attack\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Adversarial Attack\"]}],[\"$\",\"span\",\"Security\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Security\"]}],[\"$\",\"span\",\"U-Net\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"U-Net\"]}],[\"$\",\"span\",\"Open-vocabulary\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Open-vocabulary\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-14-GSFixer_Improving_3D_Gaussian_Splatting_with_Reference-Guided_Video_Diffusion_Priors\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-14-GSFixer_Improving_3D_Gaussian_Splatting_with_Reference-Guided_Video_Diffusion_Priors/\",\"children\":\"[논문리뷰] GSFixer: Improving 3D Gaussian Splatting with Reference-Guided Video Diffusion Priors\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Qingnan Fan이 [arXiv]에 게시한 'GSFixer: Improving 3D Gaussian Splatting with Reference-Guided Video Diffusion Priors' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-14 13:19:02+0900\",\"children\":\"2025년 8월 14일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"3D Gaussian Splatting\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D Gaussian Splatting\"]}],[\"$\",\"span\",\"Novel View Synthesis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Novel View Synthesis\"]}],[\"$\",\"span\",\"Diffusion Model\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Model\"]}],[\"$\",\"span\",\"Artifact Restoration\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Artifact Restoration\"]}],[\"$\",\"span\",\"Sparse-view 3D Reconstruction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Sparse-view 3D Reconstruction\"]}],[\"$\",\"span\",\"Reference-Guided\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reference-Guided\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-14-Echo-4o_Harnessing_the_Power_of_GPT-4o_Synthetic_Images_for_Improved_Image_Generation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-14-Echo-4o_Harnessing_the_Power_of_GPT-4o_Synthetic_Images_for_Improved_Image_Generation/\",\"children\":\"[논문리뷰] Echo-4o: Harnessing the Power of GPT-4o Synthetic Images for Improved Image Generation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Zhenghao Hu이 [arXiv]에 게시한 'Echo-4o: Harnessing the Power of GPT-4o Synthetic Images for Improved Image Generation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-14 13:19:02+0900\",\"children\":\"2025년 8월 14일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Synthetic Data\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Synthetic Data\"]}],[\"$\",\"span\",\"Image Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image Generation\"]}],[\"$\",\"span\",\"GPT-4o\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"GPT-4o\"]}],[\"$\",\"span\",\"Multimodal Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Models\"]}],[\"$\",\"span\",\"Instruction Following\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Instruction Following\"]}],[\"$\",\"span\",\"Surreal Image Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Surreal Image Generation\"]}],[\"$\",\"span\",\"Dataset\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dataset\"]}],[\"$\",\"span\",\"Benchmarking\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmarking\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-14-Diffusion_LLMs_Can_Do_Faster-Than-AR_Inference_via_Discrete_Diffusion_Forcing\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-14-Diffusion_LLMs_Can_Do_Faster-Than-AR_Inference_via_Discrete_Diffusion_Forcing/\",\"children\":\"[논문리뷰] Diffusion LLMs Can Do Faster-Than-AR Inference via Discrete Diffusion Forcing\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Hao Zhang이 [arXiv]에 게시한 'Diffusion LLMs Can Do Faster-Than-AR Inference via Discrete Diffusion Forcing' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-14 13:19:02+0900\",\"children\":\"2025년 8월 14일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Diffusion LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion LLMs\"]}],[\"$\",\"span\",\"Faster Inference\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Faster Inference\"]}],[\"$\",\"span\",\"Discrete Diffusion Forcing (D2F)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Discrete Diffusion Forcing (D2F)\"]}],[\"$\",\"span\",\"Autoregressive Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Autoregressive Generation\"]}],[\"$\",\"span\",\"KV Cache Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"KV Cache Optimization\"]}],[\"$\",\"span\",\"Parallel Decoding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Parallel Decoding\"]}],[\"$\",\"span\",\"Text Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Text Generation\"]}],[\"$\",\"span\",\"Model Distillation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Model Distillation\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-14-Cooper_Co-Optimizing_Policy_and_Reward_Models_in_Reinforcement_Learning_for_Large_Language_Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-14-Cooper_Co-Optimizing_Policy_and_Reward_Models_in_Reinforcement_Learning_for_Large_Language_Models/\",\"children\":\"[논문리뷰] Cooper: Co-Optimizing Policy and Reward Models in Reinforcement Learning for Large Language Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Guiyang Hou이 [arXiv]에 게시한 'Cooper: Co-Optimizing Policy and Reward Models in Reinforcement Learning for Large Language Models' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-14 13:19:02+0900\",\"children\":\"2025년 8월 14일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Reward Model\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reward Model\"]}],[\"$\",\"span\",\"Policy Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Policy Optimization\"]}],[\"$\",\"span\",\"Reward Hacking\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reward Hacking\"]}],[\"$\",\"span\",\"Hybrid Annotation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Hybrid Annotation\"]}],[\"$\",\"span\",\"Mathematical Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Mathematical Reasoning\"]}],[\"$\",\"span\",\"Verifiable Rewards\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Verifiable Rewards\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-14-Can_LLM-Generated_Textual_Explanations_Enhance_Model_Classification_Performance_An_Empirical_Study\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-14-Can_LLM-Generated_Textual_Explanations_Enhance_Model_Classification_Performance_An_Empirical_Study/\",\"children\":\"[논문리뷰] Can LLM-Generated Textual Explanations Enhance Model Classification Performance? An Empirical Study\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Gjergji Kasneci이 [arXiv]에 게시한 'Can LLM-Generated Textual Explanations Enhance Model Classification Performance? An Empirical Study' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-14 13:19:02+0900\",\"children\":\"2025년 8월 14일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Explainable NLP\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Explainable NLP\"]}],[\"$\",\"span\",\"Natural Language Explanations\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Natural Language Explanations\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Pre-trained Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Pre-trained Language Models\"]}],[\"$\",\"span\",\"Natural Language Inference\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Natural Language Inference\"]}],[\"$\",\"span\",\"Model Performance Enhancement\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Model Performance Enhancement\"]}],[\"$\",\"span\",\"Text Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Text Generation\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-14-AWorld_Dynamic_Multi-Agent_System_with_Stable_Maneuvering_for_Robust_GAIA_Problem_Solving\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-14-AWorld_Dynamic_Multi-Agent_System_with_Stable_Maneuvering_for_Robust_GAIA_Problem_Solving/\",\"children\":\"[논문리뷰] AWorld: Dynamic Multi-Agent System with Stable Maneuvering for Robust GAIA Problem Solving\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Jinjie Gu이 [arXiv]에 게시한 'AWorld: Dynamic Multi-Agent System with Stable Maneuvering for Robust GAIA Problem Solving' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-14 13:19:02+0900\",\"children\":\"2025년 8월 14일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Multi-Agent System\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-Agent System\"]}],[\"$\",\"span\",\"Agent Stability\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Agent Stability\"]}],[\"$\",\"span\",\"LLM\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM\"]}],[\"$\",\"span\",\"Tool Use\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Tool Use\"]}],[\"$\",\"span\",\"GAIA Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"GAIA Benchmark\"]}],[\"$\",\"span\",\"Robustness\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Robustness\"]}],[\"$\",\"span\",\"Dynamic Supervision\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dynamic Supervision\"]}],[\"$\",\"span\",\"Maneuvering\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Maneuvering\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-14-AMFT_Aligning_LLM_Reasoners_by_Meta-Learning_the_Optimal_Imitation-Exploration_Balance\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-14-AMFT_Aligning_LLM_Reasoners_by_Meta-Learning_the_Optimal_Imitation-Exploration_Balance/\",\"children\":\"[논문리뷰] AMFT: Aligning LLM Reasoners by Meta-Learning the Optimal Imitation-Exploration Balance\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yong Li이 [arXiv]에 게시한 'AMFT: Aligning LLM Reasoners by Meta-Learning the Optimal Imitation-Exploration Balance' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-14 13:19:02+0900\",\"children\":\"2025년 8월 14일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Fine-tuning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Fine-tuning\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Meta-learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Meta-learning\"]}],[\"$\",\"span\",\"Adaptive Control\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Adaptive Control\"]}],[\"$\",\"span\",\"Imitation Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Imitation Learning\"]}],[\"$\",\"span\",\"Exploration\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Exploration\"]}],[\"$\",\"span\",\"Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reasoning\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-13-WGAST_Weakly-Supervised_Generative_Network_for_Daily_10_m_Land_Surface_Temperature_Estimation_via_Spatio-Temporal_Fusion\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-13-WGAST_Weakly-Supervised_Generative_Network_for_Daily_10_m_Land_Surface_Temperature_Estimation_via_Spatio-Temporal_Fusion/\",\"children\":\"[논문리뷰] WGAST: Weakly-Supervised Generative Network for Daily 10 m Land Surface Temperature Estimation via Spatio-Temporal Fusion\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Rachid Nedjai이 [arXiv]에 게시한 'WGAST: Weakly-Supervised Generative Network for Daily 10 m Land Surface Temperature Estimation via Spatio-Temporal Fusion' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-13 13:29:23+0900\",\"children\":\"2025년 8월 13일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Spatio-Temporal Fusion\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Spatio-Temporal Fusion\"]}],[\"$\",\"span\",\"Land Surface Temperature\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Land Surface Temperature\"]}],[\"$\",\"span\",\"Generative Adversarial Network\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generative Adversarial Network\"]}],[\"$\",\"span\",\"Weakly-Supervised Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Weakly-Supervised Learning\"]}],[\"$\",\"span\",\"Remote Sensing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Remote Sensing\"]}],[\"$\",\"span\",\"Deep Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Deep Learning\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-13-VertexRegen_Mesh_Generation_with_Continuous_Level_of_Detail\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-13-VertexRegen_Mesh_Generation_with_Continuous_Level_of_Detail/\",\"children\":\"[논문리뷰] VertexRegen: Mesh Generation with Continuous Level of Detail\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Jakob Engel이 [arXiv]에 게시한 'VertexRegen: Mesh Generation with Continuous Level of Detail' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-13 13:29:23+0900\",\"children\":\"2025년 8월 13일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Mesh Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Mesh Generation\"]}],[\"$\",\"span\",\"Level of Detail (LOD)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Level of Detail (LOD)\"]}],[\"$\",\"span\",\"Progressive Meshes\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Progressive Meshes\"]}],[\"$\",\"span\",\"Vertex Split\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vertex Split\"]}],[\"$\",\"span\",\"Autoregressive Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Autoregressive Models\"]}],[\"$\",\"span\",\"Transformer\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Transformer\"]}],[\"$\",\"span\",\"3D Graphics\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D Graphics\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-13-UNCAGE_Contrastive_Attention_Guidance_for_Masked_Generative_Transformers_in_Text-to-Image_Generation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-13-UNCAGE_Contrastive_Attention_Guidance_for_Masked_Generative_Transformers_in_Text-to-Image_Generation/\",\"children\":\"[논문리뷰] UNCAGE: Contrastive Attention Guidance for Masked Generative Transformers in Text-to-Image Generation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Kevin Galim이 [arXiv]에 게시한 'UNCAGE: Contrastive Attention Guidance for Masked Generative Transformers in Text-to-Image Generation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-13 13:29:23+0900\",\"children\":\"2025년 8월 13일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Text-to-Image Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Text-to-Image Generation\"]}],[\"$\",\"span\",\"Masked Generative Transformers\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Masked Generative Transformers\"]}],[\"$\",\"span\",\"Compositional Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Compositional Generation\"]}],[\"$\",\"span\",\"Attention Guidance\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Attention Guidance\"]}],[\"$\",\"span\",\"Unmasking Strategy\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Unmasking Strategy\"]}],[\"$\",\"span\",\"Contrastive Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Contrastive Learning\"]}],[\"$\",\"span\",\"Training-Free\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Training-Free\"]}],[\"$\",\"span\",\"Attribute Binding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Attribute Binding\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-13-Train_Long_Think_Short_Curriculum_Learning_for_Efficient_Reasoning\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-13-Train_Long_Think_Short_Curriculum_Learning_for_Efficient_Reasoning/\",\"children\":\"[논문리뷰] Train Long, Think Short: Curriculum Learning for Efficient Reasoning\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Marzyeh Ghassemi이 [arXiv]에 게시한 'Train Long, Think Short: Curriculum Learning for Efficient Reasoning' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-13 13:29:23+0900\",\"children\":\"2025년 8월 13일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Curriculum Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Curriculum Learning\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Reasoning Efficiency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reasoning Efficiency\"]}],[\"$\",\"span\",\"Token Budget Control\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Token Budget Control\"]}],[\"$\",\"span\",\"Group Relative Policy Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Group Relative Policy Optimization\"]}],[\"$\",\"span\",\"Chain-of-Thought\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Chain-of-Thought\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-13-Towards_Affordance-Aware_Robotic_Dexterous_Grasping_with_Human-like_Priors\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-13-Towards_Affordance-Aware_Robotic_Dexterous_Grasping_with_Human-like_Priors/\",\"children\":\"[논문리뷰] Towards Affordance-Aware Robotic Dexterous Grasping with Human-like Priors\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Haoran Xu이 [arXiv]에 게시한 'Towards Affordance-Aware Robotic Dexterous Grasping with Human-like Priors' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-13 13:29:23+0900\",\"children\":\"2025년 8월 13일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Robotic Dexterous Grasping\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Robotic Dexterous Grasping\"]}],[\"$\",\"span\",\"Affordance-Aware\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Affordance-Aware\"]}],[\"$\",\"span\",\"Human-like Priors\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Human-like Priors\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Vision-Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision-Language Models\"]}],[\"$\",\"span\",\"Two-Stage Training\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Two-Stage Training\"]}],[\"$\",\"span\",\"Manipulation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Manipulation\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-13-TopXGen_Topic-Diverse_Parallel_Data_Generation_for_Low-Resource_Machine_Translation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-13-TopXGen_Topic-Diverse_Parallel_Data_Generation_for_Low-Resource_Machine_Translation/\",\"children\":\"[논문리뷰] TopXGen: Topic-Diverse Parallel Data Generation for Low-Resource Machine Translation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Rachel Bawden이 [arXiv]에 게시한 'TopXGen: Topic-Diverse Parallel Data Generation for Low-Resource Machine Translation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-13 13:29:23+0900\",\"children\":\"2025년 8월 13일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Low-Resource MT\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Low-Resource MT\"]}],[\"$\",\"span\",\"Data Augmentation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Augmentation\"]}],[\"$\",\"span\",\"Large Language Models (LLMs)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models (LLMs)\"]}],[\"$\",\"span\",\"Back-Translation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Back-Translation\"]}],[\"$\",\"span\",\"In-Context Learning (ICL)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"In-Context Learning (ICL)\"]}],[\"$\",\"span\",\"Fine-Tuning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Fine-Tuning\"]}],[\"$\",\"span\",\"Topic-Guided Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Topic-Guided Generation\"]}],[\"$\",\"span\",\"Parallel Data Synthesis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Parallel Data Synthesis\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-13-Time_Is_a_Feature_Exploiting_Temporal_Dynamics_in_Diffusion_Language_Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-13-Time_Is_a_Feature_Exploiting_Temporal_Dynamics_in_Diffusion_Language_Models/\",\"children\":\"[논문리뷰] Time Is a Feature: Exploiting Temporal Dynamics in Diffusion Language Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Chenchen Jing이 [arXiv]에 게시한 'Time Is a Feature: Exploiting Temporal Dynamics in Diffusion Language Models' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-13 13:29:23+0900\",\"children\":\"2025년 8월 13일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Diffusion Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Language Models\"]}],[\"$\",\"span\",\"Temporal Oscillation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Temporal Oscillation\"]}],[\"$\",\"span\",\"Self-Consistency Voting\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Self-Consistency Voting\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Temporal Semantic Entropy\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Temporal Semantic Entropy\"]}],[\"$\",\"span\",\"Text Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Text Generation\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-13-Test-Time_Reinforcement_Learning_for_GUI_Grounding_via_Region_Consistency\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-13-Test-Time_Reinforcement_Learning_for_GUI_Grounding_via_Region_Consistency/\",\"children\":\"[논문리뷰] Test-Time Reinforcement Learning for GUI Grounding via Region Consistency\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Zhengxi Lu이 [arXiv]에 게시한 'Test-Time Reinforcement Learning for GUI Grounding via Region Consistency' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-13 13:29:23+0900\",\"children\":\"2025년 8월 13일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"GUI Grounding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"GUI Grounding\"]}],[\"$\",\"span\",\"Test-Time Scaling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Test-Time Scaling\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Region Consistency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Region Consistency\"]}],[\"$\",\"span\",\"Spatial Voting\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Spatial Voting\"]}],[\"$\",\"span\",\"Self-Supervised Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Self-Supervised Learning\"]}],[\"$\",\"span\",\"Vision-Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision-Language Models\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-13-OpenCUA_Open_Foundations_for_Computer-Use_Agents\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-13-OpenCUA_Open_Foundations_for_Computer-Use_Agents/\",\"children\":\"[논문리뷰] OpenCUA: Open Foundations for Computer-Use Agents\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Tianbao Xie이 [arXiv]에 게시한 'OpenCUA: Open Foundations for Computer-Use Agents' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-13 13:29:23+0900\",\"children\":\"2025년 8월 13일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Computer-Use Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Computer-Use Agents\"]}],[\"$\",\"span\",\"Vision-Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision-Language Models\"]}],[\"$\",\"span\",\"Chain-of-Thought Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Chain-of-Thought Reasoning\"]}],[\"$\",\"span\",\"Large-scale Dataset\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large-scale Dataset\"]}],[\"$\",\"span\",\"Open-source Framework\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Open-source Framework\"]}],[\"$\",\"span\",\"Desktop Automation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Desktop Automation\"]}],[\"$\",\"span\",\"Agent Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Agent Evaluation\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-13-NVSpeech_An_Integrated_and_Scalable_Pipeline_for_Human-Like_Speech_Modeling_with_Paralinguistic_Vocalizations\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-13-NVSpeech_An_Integrated_and_Scalable_Pipeline_for_Human-Like_Speech_Modeling_with_Paralinguistic_Vocalizations/\",\"children\":\"[논문리뷰] NVSpeech: An Integrated and Scalable Pipeline for Human-Like Speech Modeling with Paralinguistic Vocalizations\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Haoyue Zhan이 [arXiv]에 게시한 'NVSpeech: An Integrated and Scalable Pipeline for Human-Like Speech Modeling with Paralinguistic Vocalizations' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-13 13:29:23+0900\",\"children\":\"2025년 8월 13일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Paralinguistic Vocalizations\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Paralinguistic Vocalizations\"]}],[\"$\",\"span\",\"Speech Recognition\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Speech Recognition\"]}],[\"$\",\"span\",\"Text-to-Speech\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Text-to-Speech\"]}],[\"$\",\"span\",\"Speech Synthesis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Speech Synthesis\"]}],[\"$\",\"span\",\"Data Annotation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Annotation\"]}],[\"$\",\"span\",\"Mandarin Speech\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Mandarin Speech\"]}],[\"$\",\"span\",\"Expressive Speech\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Expressive Speech\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-13-Matrix-3D_Omnidirectional_Explorable_3D_World_Generation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-13-Matrix-3D_Omnidirectional_Explorable_3D_World_Generation/\",\"children\":\"[논문리뷰] Matrix-3D: Omnidirectional Explorable 3D World Generation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yuqi Li이 [arXiv]에 게시한 'Matrix-3D: Omnidirectional Explorable 3D World Generation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-13 13:29:23+0900\",\"children\":\"2025년 8월 13일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"3D World Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D World Generation\"]}],[\"$\",\"span\",\"Panoramic Video Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Panoramic Video Generation\"]}],[\"$\",\"span\",\"3D Reconstruction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D Reconstruction\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}],[\"$\",\"span\",\"Gaussian Splatting\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Gaussian Splatting\"]}],[\"$\",\"span\",\"Dataset\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dataset\"]}],[\"$\",\"span\",\"Camera Control\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Camera Control\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-13-HierSearch_A_Hierarchical_Enterprise_Deep_Search_Framework_Integrating_Local_and_Web_Searches\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-13-HierSearch_A_Hierarchical_Enterprise_Deep_Search_Framework_Integrating_Local_and_Web_Searches/\",\"children\":\"[논문리뷰] HierSearch: A Hierarchical Enterprise Deep Search Framework Integrating Local and Web Searches\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Qiang Ju이 [arXiv]에 게시한 'HierSearch: A Hierarchical Enterprise Deep Search Framework Integrating Local and Web Searches' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-13 13:29:23+0900\",\"children\":\"2025년 8월 13일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Hierarchical Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Hierarchical Reinforcement Learning\"]}],[\"$\",\"span\",\"Deep Search\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Deep Search\"]}],[\"$\",\"span\",\"Multi-source RAG\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-source RAG\"]}],[\"$\",\"span\",\"Agentic AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Agentic AI\"]}],[\"$\",\"span\",\"Knowledge Integration\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Knowledge Integration\"]}],[\"$\",\"span\",\"Enterprise Search\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Enterprise Search\"]}],[\"$\",\"span\",\"Large Reasoning Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Reasoning Models\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-13-GeRe_Towards_Efficient_Anti-Forgetting_in_Continual_Learning_of_LLM_via_General_Samples_Replay\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-13-GeRe_Towards_Efficient_Anti-Forgetting_in_Continual_Learning_of_LLM_via_General_Samples_Replay/\",\"children\":\"[논문리뷰] GeRe: Towards Efficient Anti-Forgetting in Continual Learning of LLM via General Samples Replay\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yang Fan이 [arXiv]에 게시한 'GeRe: Towards Efficient Anti-Forgetting in Continual Learning of LLM via General Samples Replay' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-13 13:29:23+0900\",\"children\":\"2025년 8월 13일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Continual Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Continual Learning\"]}],[\"$\",\"span\",\"Large Language Models (LLMs)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models (LLMs)\"]}],[\"$\",\"span\",\"Catastrophic Forgetting\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Catastrophic Forgetting\"]}],[\"$\",\"span\",\"Replay\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Replay\"]}],[\"$\",\"span\",\"Knowledge Distillation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Knowledge Distillation\"]}],[\"$\",\"span\",\"Activation States\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Activation States\"]}],[\"$\",\"span\",\"Anti-forgetting\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Anti-forgetting\"]}],[\"$\",\"span\",\"Threshold-based Margin Loss\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Threshold-based Margin Loss\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-13-Feedback-Driven_Tool-Use_Improvements_in_Large_Language_Models_via_Automated_Build_Environments\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-13-Feedback-Driven_Tool-Use_Improvements_in_Large_Language_Models_via_Automated_Build_Environments/\",\"children\":\"[논문리뷰] Feedback-Driven Tool-Use Improvements in Large Language Models via Automated Build Environments\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Xuesong Yao이 [arXiv]에 게시한 'Feedback-Driven Tool-Use Improvements in Large Language Models via Automated Build Environments' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-13 13:29:23+0900\",\"children\":\"2025년 8월 13일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Large Language Models (LLMs)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models (LLMs)\"]}],[\"$\",\"span\",\"Tool Use\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Tool Use\"]}],[\"$\",\"span\",\"Reinforcement Learning (RL)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning (RL)\"]}],[\"$\",\"span\",\"Automated Environment Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Automated Environment Generation\"]}],[\"$\",\"span\",\"Feedback-Driven Training\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Feedback-Driven Training\"]}],[\"$\",\"span\",\"Reward Mechanism\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reward Mechanism\"]}],[\"$\",\"span\",\"Contextual Understanding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Contextual Understanding\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-13-Democratizing_Diplomacy_A_Harness_for_Evaluating_Any_Large_Language_Model_on_Full-Press_Diplomacy\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-13-Democratizing_Diplomacy_A_Harness_for_Evaluating_Any_Large_Language_Model_on_Full-Press_Diplomacy/\",\"children\":\"[논문리뷰] Democratizing Diplomacy: A Harness for Evaluating Any Large Language Model on Full-Press Diplomacy\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Elizabeth Karpinski이 [arXiv]에 게시한 'Democratizing Diplomacy: A Harness for Evaluating Any Large Language Model on Full-Press Diplomacy' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-13 13:29:23+0900\",\"children\":\"2025년 8월 13일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Diplomacy Game\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diplomacy Game\"]}],[\"$\",\"span\",\"Multi-agent Systems\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-agent Systems\"]}],[\"$\",\"span\",\"Strategic Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Strategic Reasoning\"]}],[\"$\",\"span\",\"LLM Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Evaluation\"]}],[\"$\",\"span\",\"Prompt Engineering\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Prompt Engineering\"]}],[\"$\",\"span\",\"Behavioral Analysis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Behavioral Analysis\"]}],[\"$\",\"span\",\"Game AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Game AI\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-13-DeCRED_Decoder-Centric_Regularization_for_Encoder-Decoder_Based_Speech_Recognition\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-13-DeCRED_Decoder-Centric_Regularization_for_Encoder-Decoder_Based_Speech_Recognition/\",\"children\":\"[논문리뷰] DeCRED: Decoder-Centric Regularization for Encoder-Decoder Based Speech Recognition\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Lukáš Burget이 [arXiv]에 게시한 'DeCRED: Decoder-Centric Regularization for Encoder-Decoder Based Speech Recognition' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-13 13:29:23+0900\",\"children\":\"2025년 8월 13일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Speech Recognition\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Speech Recognition\"]}],[\"$\",\"span\",\"Encoder-Decoder\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Encoder-Decoder\"]}],[\"$\",\"span\",\"Regularization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Regularization\"]}],[\"$\",\"span\",\"Decoder-Centric\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Decoder-Centric\"]}],[\"$\",\"span\",\"Intermediate Supervision\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Intermediate Supervision\"]}],[\"$\",\"span\",\"Out-of-Domain Generalization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Out-of-Domain Generalization\"]}],[\"$\",\"span\",\"Internal Language Model\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Internal Language Model\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-13-Cut2Next_Generating_Next_Shot_via_In-Context_Tuning\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-13-Cut2Next_Generating_Next_Shot_via_In-Context_Tuning/\",\"children\":\"[논문리뷰] Cut2Next: Generating Next Shot via In-Context Tuning\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yu Qiao이 [arXiv]에 게시한 'Cut2Next: Generating Next Shot via In-Context Tuning' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-13 13:29:23+0900\",\"children\":\"2025년 8월 13일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Next Shot Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Next Shot Generation\"]}],[\"$\",\"span\",\"In-Context Tuning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"In-Context Tuning\"]}],[\"$\",\"span\",\"Diffusion Transformer\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Transformer\"]}],[\"$\",\"span\",\"Cinematic Continuity\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Cinematic Continuity\"]}],[\"$\",\"span\",\"Hierarchical Prompting\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Hierarchical Prompting\"]}],[\"$\",\"span\",\"Video Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video Generation\"]}],[\"$\",\"span\",\"Shot Editing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Shot Editing\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-13-CharacterShot_Controllable_and_Consistent_4D_Character_Animation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-13-CharacterShot_Controllable_and_Consistent_4D_Character_Animation/\",\"children\":\"[논문리뷰] CharacterShot: Controllable and Consistent 4D Character Animation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Fei Shen이 [arXiv]에 게시한 'CharacterShot: Controllable and Consistent 4D Character Animation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-13 13:29:23+0900\",\"children\":\"2025년 8월 13일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"4D Character Animation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"4D Character Animation\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}],[\"$\",\"span\",\"Gaussian Splatting\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Gaussian Splatting\"]}],[\"$\",\"span\",\"Pose Control\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Pose Control\"]}],[\"$\",\"span\",\"Multi-view Synthesis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-view Synthesis\"]}],[\"$\",\"span\",\"Temporal Consistency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Temporal Consistency\"]}],[\"$\",\"span\",\"Character Dataset\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Character Dataset\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-13-Bridging_Theory_and_Practice_in_Quantum_Game_Theory_Optimized_Implementation_of_the_Battle_of_the_Sexes_with_Error_Mitigation_on_NISQ_Hardware\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-13-Bridging_Theory_and_Practice_in_Quantum_Game_Theory_Optimized_Implementation_of_the_Battle_of_the_Sexes_with_Error_Mitigation_on_NISQ_Hardware/\",\"children\":\"[논문리뷰] Bridging Theory and Practice in Quantum Game Theory: Optimized Implementation of the Battle of the Sexes with Error Mitigation on NISQ Hardware\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Jhon Alejandro Andrade이 [arXiv]에 게시한 'Bridging Theory and Practice in Quantum Game Theory: Optimized Implementation of the Battle of the Sexes with Error Mitigation on NISQ Hardware' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-13 13:29:23+0900\",\"children\":\"2025년 8월 13일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Quantum Game Theory\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Quantum Game Theory\"]}],[\"$\",\"span\",\"NISQ Hardware\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"NISQ Hardware\"]}],[\"$\",\"span\",\"Error Mitigation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Error Mitigation\"]}],[\"$\",\"span\",\"Battle of the Sexes\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Battle of the Sexes\"]}],[\"$\",\"span\",\"Qiskit\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Qiskit\"]}],[\"$\",\"span\",\"Quantum Computing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Quantum Computing\"]}],[\"$\",\"span\",\"Strategic Coordination\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Strategic Coordination\"]}],[\"$\",\"span\",\"Payoff Maximization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Payoff Maximization\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-13-BiasGym_Fantastic_Biases_and_How_to_Find_and_Remove_Them\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-13-BiasGym_Fantastic_Biases_and_How_to_Find_and_Remove_Them/\",\"children\":\"[논문리뷰] BiasGym: Fantastic Biases and How to Find (and Remove) Them\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Arnav Arora이 [arXiv]에 게시한 'BiasGym: Fantastic Biases and How to Find (and Remove) Them' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-13 13:29:23+0900\",\"children\":\"2025년 8월 13일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Bias Mitigation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Bias Mitigation\"]}],[\"$\",\"span\",\"LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLMs\"]}],[\"$\",\"span\",\"Mechanistic Interpretability\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Mechanistic Interpretability\"]}],[\"$\",\"span\",\"Fine-tuning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Fine-tuning\"]}],[\"$\",\"span\",\"Attention Steering\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Attention Steering\"]}],[\"$\",\"span\",\"Stereotype Analysis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Stereotype Analysis\"]}],[\"$\",\"span\",\"Safety Alignment\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Safety Alignment\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-13-Beyond_Ten_Turns_Unlocking_Long-Horizon_Agentic_Search_with_Large-Scale_Asynchronous_RL\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-13-Beyond_Ten_Turns_Unlocking_Long-Horizon_Agentic_Search_with_Large-Scale_Asynchronous_RL/\",\"children\":\"[논문리뷰] Beyond Ten Turns: Unlocking Long-Horizon Agentic Search with Large-Scale Asynchronous RL\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Chuyi He이 [arXiv]에 게시한 'Beyond Ten Turns: Unlocking Long-Horizon Agentic Search with Large-Scale Asynchronous RL' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-13 13:29:23+0900\",\"children\":\"2025년 8월 13일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"LLM Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Agents\"]}],[\"$\",\"span\",\"Agentic Search\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Agentic Search\"]}],[\"$\",\"span\",\"Asynchronous RL\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Asynchronous RL\"]}],[\"$\",\"span\",\"Long-Horizon Planning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Long-Horizon Planning\"]}],[\"$\",\"span\",\"Tool Use\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Tool Use\"]}],[\"$\",\"span\",\"Data Synthesis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Synthesis\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-13-AutoCodeBench_Large_Language_Models_are_Automatic_Code_Benchmark_Generators\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-13-AutoCodeBench_Large_Language_Models_are_Automatic_Code_Benchmark_Generators/\",\"children\":\"[논문리뷰] AutoCodeBench: Large Language Models are Automatic Code Benchmark Generators\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Tao Zhang이 [arXiv]에 게시한 'AutoCodeBench: Large Language Models are Automatic Code Benchmark Generators' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-13 13:29:23+0900\",\"children\":\"2025년 8월 13일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"코드 생성\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"코드 생성\"]}],[\"$\",\"span\",\"대규모 언어 모델\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"대규모 언어 모델\"]}],[\"$\",\"span\",\"코드 벤치마크\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"코드 벤치마크\"]}],[\"$\",\"span\",\"다국어 프로그래밍\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"다국어 프로그래밍\"]}],[\"$\",\"span\",\"자동화된 데이터 생성\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"자동화된 데이터 생성\"]}],[\"$\",\"span\",\"샌드박스 평가\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"샌드박스 평가\"]}],[\"$\",\"span\",\"멀티모달 AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"멀티모달 AI\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-13-Aryabhata_An_exam-focused_language_model_for_JEE_Math\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-13-Aryabhata_An_exam-focused_language_model_for_JEE_Math/\",\"children\":\"[논문리뷰] Aryabhata: An exam-focused language model for JEE Math\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Sandeep Varma이 [arXiv]에 게시한 'Aryabhata: An exam-focused language model for JEE Math' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-13 13:29:23+0900\",\"children\":\"2025년 8월 13일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Language Model\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Language Model\"]}],[\"$\",\"span\",\"Math Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Math Reasoning\"]}],[\"$\",\"span\",\"JEE\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"JEE\"]}],[\"$\",\"span\",\"Supervised Fine-Tuning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Supervised Fine-Tuning\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Model Merging\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Model Merging\"]}],[\"$\",\"span\",\"Chain-of-Thought\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Chain-of-Thought\"]}],[\"$\",\"span\",\"Curriculum Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Curriculum Learning\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-13-Adversarial_Video_Promotion_Against_Text-to-Video_Retrieval\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-13-Adversarial_Video_Promotion_Against_Text-to-Video_Retrieval/\",\"children\":\"[논문리뷰] Adversarial Video Promotion Against Text-to-Video Retrieval\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Shuai Liu이 [arXiv]에 게시한 'Adversarial Video Promotion Against Text-to-Video Retrieval' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-13 13:29:23+0900\",\"children\":\"2025년 8월 13일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Adversarial Attack\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Adversarial Attack\"]}],[\"$\",\"span\",\"Video Promotion\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video Promotion\"]}],[\"$\",\"span\",\"Text-to-Video Retrieval\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Text-to-Video Retrieval\"]}],[\"$\",\"span\",\"Modality Refinement\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Modality Refinement\"]}],[\"$\",\"span\",\"Black-box Attack\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Black-box Attack\"]}],[\"$\",\"span\",\"Video Manipulation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video Manipulation\"]}],[\"$\",\"span\",\"Transferability\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Transferability\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-12-WideSearch_Benchmarking_Agentic_Broad_Info-Seeking\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-12-WideSearch_Benchmarking_Agentic_Broad_Info-Seeking/\",\"children\":\"[논문리뷰] WideSearch: Benchmarking Agentic Broad Info-Seeking\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yan Gao이 [arXiv]에 게시한 'WideSearch: Benchmarking Agentic Broad Info-Seeking' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-12 13:29:09+0900\",\"children\":\"2025년 8월 12일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Agentic Search\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Agentic Search\"]}],[\"$\",\"span\",\"LLM\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM\"]}],[\"$\",\"span\",\"Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmark\"]}],[\"$\",\"span\",\"Information Seeking\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Information Seeking\"]}],[\"$\",\"span\",\"Structured Output\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Structured Output\"]}],[\"$\",\"span\",\"Evaluation Metrics\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Evaluation Metrics\"]}],[\"$\",\"span\",\"Multi-agent Systems\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-agent Systems\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-12-When_Good_Sounds_Go_Adversarial_Jailbreaking_Audio-Language_Models_with_Benign_Inputs\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-12-When_Good_Sounds_Go_Adversarial_Jailbreaking_Audio-Language_Models_with_Benign_Inputs/\",\"children\":\"[논문리뷰] When Good Sounds Go Adversarial: Jailbreaking Audio-Language Models with Benign Inputs\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Dasol Choi이 [arXiv]에 게시한 'When Good Sounds Go Adversarial: Jailbreaking Audio-Language Models with Benign Inputs' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-12 13:29:09+0900\",\"children\":\"2025년 8월 12일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Audio-Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Audio-Language Models\"]}],[\"$\",\"span\",\"Jailbreak Attack\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Jailbreak Attack\"]}],[\"$\",\"span\",\"Adversarial Audio\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Adversarial Audio\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Projected Gradient Descent\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Projected Gradient Descent\"]}],[\"$\",\"span\",\"Native Payload Discovery\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Native Payload Discovery\"]}],[\"$\",\"span\",\"Multimodal AI Safety\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal AI Safety\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-12-VisR-Bench_An_Empirical_Study_on_Visual_Retrieval-Augmented_Generation_for_Multilingual_Long_Document_Understanding\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-12-VisR-Bench_An_Empirical_Study_on_Visual_Retrieval-Augmented_Generation_for_Multilingual_Long_Document_Understanding/\",\"children\":\"[논문리뷰] VisR-Bench: An Empirical Study on Visual Retrieval-Augmented Generation for Multilingual Long Document Understanding\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Tong Yu이 [arXiv]에 게시한 'VisR-Bench: An Empirical Study on Visual Retrieval-Augmented Generation for Multilingual Long Document Understanding' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-12 13:29:09+0900\",\"children\":\"2025년 8월 12일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Multimodal Retrieval\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Retrieval\"]}],[\"$\",\"span\",\"Retrieval-Augmented Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Retrieval-Augmented Generation\"]}],[\"$\",\"span\",\"Long Document Understanding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Long Document Understanding\"]}],[\"$\",\"span\",\"Multilingual NLP\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multilingual NLP\"]}],[\"$\",\"span\",\"Visual QA\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Visual QA\"]}],[\"$\",\"span\",\"Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmark\"]}],[\"$\",\"span\",\"MLLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"MLLMs\"]}],[\"$\",\"span\",\"Table Understanding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Table Understanding\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-12-UserBench_An_Interactive_Gym_Environment_for_User-Centric_Agents\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-12-UserBench_An_Interactive_Gym_Environment_for_User-Centric_Agents/\",\"children\":\"[논문리뷰] UserBench: An Interactive Gym Environment for User-Centric Agents\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Jianguo Zhang이 [arXiv]에 게시한 'UserBench: An Interactive Gym Environment for User-Centric Agents' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-12 13:29:09+0900\",\"children\":\"2025년 8월 12일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"User-Centric AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"User-Centric AI\"]}],[\"$\",\"span\",\"LLM Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Evaluation\"]}],[\"$\",\"span\",\"Interactive Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Interactive Agents\"]}],[\"$\",\"span\",\"Gym Environment\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Gym Environment\"]}],[\"$\",\"span\",\"Preference Elicitation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Preference Elicitation\"]}],[\"$\",\"span\",\"Multi-turn Dialogue\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-turn Dialogue\"]}],[\"$\",\"span\",\"Tool Use\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Tool Use\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-12-Temporal_Self-Rewarding_Language_Models_Decoupling_Chosen-Rejected_via_Past-Future\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-12-Temporal_Self-Rewarding_Language_Models_Decoupling_Chosen-Rejected_via_Past-Future/\",\"children\":\"[논문리뷰] Temporal Self-Rewarding Language Models: Decoupling Chosen-Rejected via Past-Future\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Qiufeng Wang이 [arXiv]에 게시한 'Temporal Self-Rewarding Language Models: Decoupling Chosen-Rejected via Past-Future' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-12 13:29:09+0900\",\"children\":\"2025년 8월 12일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Self-Rewarding LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Self-Rewarding LLMs\"]}],[\"$\",\"span\",\"Direct Preference Optimization (DPO)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Direct Preference Optimization (DPO)\"]}],[\"$\",\"span\",\"Preference Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Preference Learning\"]}],[\"$\",\"span\",\"Generative AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generative AI\"]}],[\"$\",\"span\",\"Gradient Collapse\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Gradient Collapse\"]}],[\"$\",\"span\",\"LLM Alignment\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Alignment\"]}],[\"$\",\"span\",\"Iterative Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Iterative Optimization\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-12-Speech-to-LaTeX_New_Models_and_Datasets_for_Converting_Spoken_Equations_and_Sentences\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-12-Speech-to-LaTeX_New_Models_and_Datasets_for_Converting_Spoken_Equations_and_Sentences/\",\"children\":\"[논문리뷰] Speech-to-LaTeX: New Models and Datasets for Converting Spoken Equations and Sentences\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Matvey Skripkin이 [arXiv]에 게시한 'Speech-to-LaTeX: New Models and Datasets for Converting Spoken Equations and Sentences' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-12 13:29:09+0900\",\"children\":\"2025년 8월 12일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Speech-to-LaTeX\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Speech-to-LaTeX\"]}],[\"$\",\"span\",\"ASR\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"ASR\"]}],[\"$\",\"span\",\"Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Language Models\"]}],[\"$\",\"span\",\"Multimodal AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal AI\"]}],[\"$\",\"span\",\"Dataset Creation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dataset Creation\"]}],[\"$\",\"span\",\"Mathematical Expression Recognition\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Mathematical Expression Recognition\"]}],[\"$\",\"span\",\"LaTeX Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LaTeX Generation\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-12-Shortcut_Learning_in_Generalist_Robot_Policies_The_Role_of_Dataset_Diversity_and_Fragmentation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-12-Shortcut_Learning_in_Generalist_Robot_Policies_The_Role_of_Dataset_Diversity_and_Fragmentation/\",\"children\":\"[논문리뷰] Shortcut Learning in Generalist Robot Policies: The Role of Dataset Diversity and Fragmentation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Hengtao Shen이 [arXiv]에 게시한 'Shortcut Learning in Generalist Robot Policies: The Role of Dataset Diversity and Fragmentation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-12 13:29:09+0900\",\"children\":\"2025년 8월 12일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Robot Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Robot Learning\"]}],[\"$\",\"span\",\"Generalization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generalization\"]}],[\"$\",\"span\",\"Shortcut Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Shortcut Learning\"]}],[\"$\",\"span\",\"Dataset Diversity\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dataset Diversity\"]}],[\"$\",\"span\",\"Dataset Fragmentation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dataset Fragmentation\"]}],[\"$\",\"span\",\"Data Augmentation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Augmentation\"]}],[\"$\",\"span\",\"Imitation Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Imitation Learning\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-12-Reinforcement_Learning_in_Vision_A_Survey\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-12-Reinforcement_Learning_in_Vision_A_Survey/\",\"children\":\"[논문리뷰] Reinforcement Learning in Vision: A Survey\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Qingwei Meng이 [arXiv]에 게시한 'Reinforcement Learning in Vision: A Survey' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-12 13:29:09+0900\",\"children\":\"2025년 8월 12일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Reinforcement Learning (RL)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning (RL)\"]}],[\"$\",\"span\",\"Computer Vision (CV)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Computer Vision (CV)\"]}],[\"$\",\"span\",\"Multimodal Large Language Models (MLLMs)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Large Language Models (MLLMs)\"]}],[\"$\",\"span\",\"Visual Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Visual Generation\"]}],[\"$\",\"span\",\"Vision-Language-Action (VLA) Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision-Language-Action (VLA) Models\"]}],[\"$\",\"span\",\"Policy Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Policy Optimization\"]}],[\"$\",\"span\",\"Reward Modeling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reward Modeling\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-12-ReasonRank_Empowering_Passage_Ranking_with_Strong_Reasoning_Ability\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-12-ReasonRank_Empowering_Passage_Ranking_with_Strong_Reasoning_Ability/\",\"children\":\"[논문리뷰] ReasonRank: Empowering Passage Ranking with Strong Reasoning Ability\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yuchen Li이 [arXiv]에 게시한 'ReasonRank: Empowering Passage Ranking with Strong Reasoning Ability' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-12 13:29:09+0900\",\"children\":\"2025년 8월 12일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Passage Ranking\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Passage Ranking\"]}],[\"$\",\"span\",\"Reasoning Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reasoning Models\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Data Synthesis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Synthesis\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Listwise Reranking\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Listwise Reranking\"]}],[\"$\",\"span\",\"Information Retrieval\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Information Retrieval\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-12-Part_I_Tricks_or_Traps_A_Deep_Dive_into_RL_for_LLM_Reasoning\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-12-Part_I_Tricks_or_Traps_A_Deep_Dive_into_RL_for_LLM_Reasoning/\",\"children\":\"[논문리뷰] Part I: Tricks or Traps? A Deep Dive into RL for LLM Reasoning\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Jiaheng Liu이 [arXiv]에 게시한 'Part I: Tricks or Traps? A Deep Dive into RL for LLM Reasoning' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-12 13:29:09+0900\",\"children\":\"2025년 8월 12일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"LLM Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Reasoning\"]}],[\"$\",\"span\",\"Policy Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Policy Optimization\"]}],[\"$\",\"span\",\"Normalization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Normalization\"]}],[\"$\",\"span\",\"Clipping\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Clipping\"]}],[\"$\",\"span\",\"Loss Aggregation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Loss Aggregation\"]}],[\"$\",\"span\",\"Overlong Filtering\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Overlong Filtering\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-12-OmniEAR_Benchmarking_Agent_Reasoning_in_Embodied_Tasks\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-12-OmniEAR_Benchmarking_Agent_Reasoning_in_Embodied_Tasks/\",\"children\":\"[논문리뷰] OmniEAR: Benchmarking Agent Reasoning in Embodied Tasks\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Hongxing Li이 [arXiv]에 게시한 'OmniEAR: Benchmarking Agent Reasoning in Embodied Tasks' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-12 13:29:09+0900\",\"children\":\"2025년 8월 12일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Embodied AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Embodied AI\"]}],[\"$\",\"span\",\"Agent Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Agent Reasoning\"]}],[\"$\",\"span\",\"LLM\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM\"]}],[\"$\",\"span\",\"Benchmarking\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmarking\"]}],[\"$\",\"span\",\"Tool Use\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Tool Use\"]}],[\"$\",\"span\",\"Multi-Agent Systems\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-Agent Systems\"]}],[\"$\",\"span\",\"Physical Interaction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Physical Interaction\"]}],[\"$\",\"span\",\"Constraint Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Constraint Reasoning\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-12-Omni-Effects_Unified_and_Spatially-Controllable_Visual_Effects_Generation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-12-Omni-Effects_Unified_and_Spatially-Controllable_Visual_Effects_Generation/\",\"children\":\"[논문리뷰] Omni-Effects: Unified and Spatially-Controllable Visual Effects Generation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Xiaokun Feng이 [arXiv]에 게시한 'Omni-Effects: Unified and Spatially-Controllable Visual Effects Generation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-12 13:29:09+0900\",\"children\":\"2025년 8월 12일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Visual Effects\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Visual Effects\"]}],[\"$\",\"span\",\"Video Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video Generation\"]}],[\"$\",\"span\",\"LoRA\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LoRA\"]}],[\"$\",\"span\",\"Mixture of Experts\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Mixture of Experts\"]}],[\"$\",\"span\",\"Spatial Control\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Spatial Control\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}],[\"$\",\"span\",\"Multi-VFX\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-VFX\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-12-MolmoAct_Action_Reasoning_Models_that_can_Reason_in_Space\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-12-MolmoAct_Action_Reasoning_Models_that_can_Reason_in_Space/\",\"children\":\"[논문리뷰] MolmoAct: Action Reasoning Models that can Reason in Space\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Shuo Liu이 [arXiv]에 게시한 'MolmoAct: Action Reasoning Models that can Reason in Space' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-12 13:29:09+0900\",\"children\":\"2025년 8월 12일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Robotics\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Robotics\"]}],[\"$\",\"span\",\"Action Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Action Reasoning\"]}],[\"$\",\"span\",\"Vision-Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision-Language Models\"]}],[\"$\",\"span\",\"Spatial Planning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Spatial Planning\"]}],[\"$\",\"span\",\"Depth Perception\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Depth Perception\"]}],[\"$\",\"span\",\"Trajectory Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Trajectory Generation\"]}],[\"$\",\"span\",\"Explainable AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Explainable AI\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-12-MoBE_Mixture-of-Basis-Experts_for_Compressing_MoE-based_LLMs\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-12-MoBE_Mixture-of-Basis-Experts_for_Compressing_MoE-based_LLMs/\",\"children\":\"[논문리뷰] MoBE: Mixture-of-Basis-Experts for Compressing MoE-based LLMs\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Jianguo Li이 [arXiv]에 게시한 'MoBE: Mixture-of-Basis-Experts for Compressing MoE-based LLMs' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-12 13:29:09+0900\",\"children\":\"2025년 8월 12일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Mixture-of-Experts (MoE)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Mixture-of-Experts (MoE)\"]}],[\"$\",\"span\",\"LLM Compression\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Compression\"]}],[\"$\",\"span\",\"Matrix Decomposition\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Matrix Decomposition\"]}],[\"$\",\"span\",\"Parameter Efficiency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Parameter Efficiency\"]}],[\"$\",\"span\",\"Deep Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Deep Learning\"]}],[\"$\",\"span\",\"Memory Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Memory Optimization\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-12-Less_Is_More_Training-Free_Sparse_Attention_with_Global_Locality_for_Efficient_Reasoning\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-12-Less_Is_More_Training-Free_Sparse_Attention_with_Global_Locality_for_Efficient_Reasoning/\",\"children\":\"[논문리뷰] Less Is More: Training-Free Sparse Attention with Global Locality for Efficient Reasoning\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Baihong Yuan이 [arXiv]에 게시한 'Less Is More: Training-Free Sparse Attention with Global Locality for Efficient Reasoning' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-12 13:29:09+0900\",\"children\":\"2025년 8월 12일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Sparse Attention\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Sparse Attention\"]}],[\"$\",\"span\",\"LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLMs\"]}],[\"$\",\"span\",\"Reasoning Tasks\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reasoning Tasks\"]}],[\"$\",\"span\",\"Efficiency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Efficiency\"]}],[\"$\",\"span\",\"Training-Free\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Training-Free\"]}],[\"$\",\"span\",\"Global Locality\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Global Locality\"]}],[\"$\",\"span\",\"KV Cache Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"KV Cache Optimization\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-12-Klear-Reasoner_Advancing_Reasoning_Capability_via_Gradient-Preserving_Clipping_Policy_Optimization\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-12-Klear-Reasoner_Advancing_Reasoning_Capability_via_Gradient-Preserving_Clipping_Policy_Optimization/\",\"children\":\"[논문리뷰] Klear-Reasoner: Advancing Reasoning Capability via Gradient-Preserving Clipping Policy Optimization\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Guanting Dong이 [arXiv]에 게시한 'Klear-Reasoner: Advancing Reasoning Capability via Gradient-Preserving Clipping Policy Optimization' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-12 13:29:09+0900\",\"children\":\"2025년 8월 12일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Reasoning LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reasoning LLMs\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"PPO\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"PPO\"]}],[\"$\",\"span\",\"Gradient Clipping\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Gradient Clipping\"]}],[\"$\",\"span\",\"Supervised Fine-tuning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Supervised Fine-tuning\"]}],[\"$\",\"span\",\"Math Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Math Reasoning\"]}],[\"$\",\"span\",\"Code Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Code Generation\"]}],[\"$\",\"span\",\"Policy Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Policy Optimization\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-12-Grove_MoE_Towards_Efficient_and_Superior_MoE_LLMs_with_Adjugate_Experts\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-12-Grove_MoE_Towards_Efficient_and_Superior_MoE_LLMs_with_Adjugate_Experts/\",\"children\":\"[논문리뷰] Grove MoE: Towards Efficient and Superior MoE LLMs with Adjugate Experts\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Tieyuan Chen이 [arXiv]에 게시한 'Grove MoE: Towards Efficient and Superior MoE LLMs with Adjugate Experts' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-12 13:29:09+0900\",\"children\":\"2025년 8월 12일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Mixture of Experts\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Mixture of Experts\"]}],[\"$\",\"span\",\"LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLMs\"]}],[\"$\",\"span\",\"MoE Architecture\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"MoE Architecture\"]}],[\"$\",\"span\",\"Dynamic Activation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dynamic Activation\"]}],[\"$\",\"span\",\"Adjugate Experts\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Adjugate Experts\"]}],[\"$\",\"span\",\"Upcycling Strategy\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Upcycling Strategy\"]}],[\"$\",\"span\",\"Load Balancing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Load Balancing\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-12-GLiClass_Generalist_Lightweight_Model_for_Sequence_Classification_Tasks\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-12-GLiClass_Generalist_Lightweight_Model_for_Sequence_Classification_Tasks/\",\"children\":\"[논문리뷰] GLiClass: Generalist Lightweight Model for Sequence Classification Tasks\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Alexander Yavorskyi이 [arXiv]에 게시한 'GLiClass: Generalist Lightweight Model for Sequence Classification Tasks' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-12 13:29:09+0900\",\"children\":\"2025년 8월 12일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Sequence Classification\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Sequence Classification\"]}],[\"$\",\"span\",\"Zero-shot Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Zero-shot Learning\"]}],[\"$\",\"span\",\"Few-shot Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Few-shot Learning\"]}],[\"$\",\"span\",\"Transformer\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Transformer\"]}],[\"$\",\"span\",\"Multi-label Classification\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-label Classification\"]}],[\"$\",\"span\",\"PPO\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"PPO\"]}],[\"$\",\"span\",\"GLiNER\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"GLiNER\"]}],[\"$\",\"span\",\"Computational Efficiency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Computational Efficiency\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-12-Follow-Your-Shape_Shape-Aware_Image_Editing_via_Trajectory-Guided_Region_Control\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-12-Follow-Your-Shape_Shape-Aware_Image_Editing_via_Trajectory-Guided_Region_Control/\",\"children\":\"[논문리뷰] Follow-Your-Shape: Shape-Aware Image Editing via Trajectory-Guided Region Control\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Hongyu Liu이 [arXiv]에 게시한 'Follow-Your-Shape: Shape-Aware Image Editing via Trajectory-Guided Region Control' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-12 13:29:09+0900\",\"children\":\"2025년 8월 12일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Image Editing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image Editing\"]}],[\"$\",\"span\",\"Shape Transformation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Shape Transformation\"]}],[\"$\",\"span\",\"Rectified Flow\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Rectified Flow\"]}],[\"$\",\"span\",\"Trajectory Divergence Map\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Trajectory Divergence Map\"]}],[\"$\",\"span\",\"Region Control\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Region Control\"]}],[\"$\",\"span\",\"Generative Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generative Models\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-12-Fact2Fiction_Targeted_Poisoning_Attack_to_Agentic_Fact-checking_System\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-12-Fact2Fiction_Targeted_Poisoning_Attack_to_Agentic_Fact-checking_System/\",\"children\":\"[논문리뷰] Fact2Fiction: Targeted Poisoning Attack to Agentic Fact-checking System\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Reynold Cheng이 [arXiv]에 게시한 'Fact2Fiction: Targeted Poisoning Attack to Agentic Fact-checking System' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-12 13:29:09+0900\",\"children\":\"2025년 8월 12일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Adversarial Attack\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Adversarial Attack\"]}],[\"$\",\"span\",\"Poisoning Attack\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Poisoning Attack\"]}],[\"$\",\"span\",\"Fact-checking\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Fact-checking\"]}],[\"$\",\"span\",\"LLM Agent\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Agent\"]}],[\"$\",\"span\",\"Retrieval Augmented Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Retrieval Augmented Generation\"]}],[\"$\",\"span\",\"Misinformation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Misinformation\"]}],[\"$\",\"span\",\"System Security\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"System Security\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-12-Deep_Ignorance_Filtering_Pretraining_Data_Builds_Tamper-Resistant_Safeguards_into_Open-Weight_LLMs\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-12-Deep_Ignorance_Filtering_Pretraining_Data_Builds_Tamper-Resistant_Safeguards_into_Open-Weight_LLMs/\",\"children\":\"[논문리뷰] Deep Ignorance: Filtering Pretraining Data Builds Tamper-Resistant Safeguards into Open-Weight LLMs\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Robert Kirk이 [arXiv]에 게시한 'Deep Ignorance: Filtering Pretraining Data Builds Tamper-Resistant Safeguards into Open-Weight LLMs' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-12 13:29:09+0900\",\"children\":\"2025년 8월 12일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLMs\"]}],[\"$\",\"span\",\"데이터 필터링\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"데이터 필터링\"]}],[\"$\",\"span\",\"사전 학습\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"사전 학습\"]}],[\"$\",\"span\",\"변조 저항성\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"변조 저항성\"]}],[\"$\",\"span\",\"바이오위협\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"바이오위협\"]}],[\"$\",\"span\",\"AI 안전\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"AI 안전\"]}],[\"$\",\"span\",\"서킷 브레이킹\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"서킷 브레이킹\"]}],[\"$\",\"span\",\"머신 언러닝\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"머신 언러닝\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-12-Compressing_Chain-of-Thought_in_LLMs_via_Step_Entropy\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-12-Compressing_Chain-of-Thought_in_LLMs_via_Step_Entropy/\",\"children\":\"[논문리뷰] Compressing Chain-of-Thought in LLMs via Step Entropy\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Zhijian Xu이 [arXiv]에 게시한 'Compressing Chain-of-Thought in LLMs via Step Entropy' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-12 13:29:09+0900\",\"children\":\"2025년 8월 12일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLM\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM\"]}],[\"$\",\"span\",\"Chain-of-Thought\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Chain-of-Thought\"]}],[\"$\",\"span\",\"CoT Compression\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"CoT Compression\"]}],[\"$\",\"span\",\"Step Entropy\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Step Entropy\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"SFT\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"SFT\"]}],[\"$\",\"span\",\"GRPO\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"GRPO\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-12-BrowseComp-Plus_A_More_Fair_and_Transparent_Evaluation_Benchmark_of_Deep-Research_Agent\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-12-BrowseComp-Plus_A_More_Fair_and_Transparent_Evaluation_Benchmark_of_Deep-Research_Agent/\",\"children\":\"[논문리뷰] BrowseComp-Plus: A More Fair and Transparent Evaluation Benchmark of Deep-Research Agent\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Kai Zou이 [arXiv]에 게시한 'BrowseComp-Plus: A More Fair and Transparent Evaluation Benchmark of Deep-Research Agent' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-12 13:29:09+0900\",\"children\":\"2025년 8월 12일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Benchmarking\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmarking\"]}],[\"$\",\"span\",\"Deep-Research Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Deep-Research Agents\"]}],[\"$\",\"span\",\"LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLMs\"]}],[\"$\",\"span\",\"Retrieval\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Retrieval\"]}],[\"$\",\"span\",\"Curated Corpus\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Curated Corpus\"]}],[\"$\",\"span\",\"Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Evaluation\"]}],[\"$\",\"span\",\"Fairness\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Fairness\"]}],[\"$\",\"span\",\"Transparency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Transparency\"]}],[\"$\",\"span\",\"Reproducibility\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reproducibility\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-12-Bifrost-1_Bridging_Multimodal_LLMs_and_Diffusion_Models_with_Patch-level_CLIP_Latents\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-12-Bifrost-1_Bridging_Multimodal_LLMs_and_Diffusion_Models_with_Patch-level_CLIP_Latents/\",\"children\":\"[논문리뷰] Bifrost-1: Bridging Multimodal LLMs and Diffusion Models with Patch-level CLIP Latents\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Mohit Bansal이 [arXiv]에 게시한 'Bifrost-1: Bridging Multimodal LLMs and Diffusion Models with Patch-level CLIP Latents' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-12 13:29:09+0900\",\"children\":\"2025년 8월 12일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Multimodal LLM\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal LLM\"]}],[\"$\",\"span\",\"Diffusion Model\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Model\"]}],[\"$\",\"span\",\"CLIP Latent\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"CLIP Latent\"]}],[\"$\",\"span\",\"Image Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image Generation\"]}],[\"$\",\"span\",\"Multimodal Understanding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Understanding\"]}],[\"$\",\"span\",\"ControlNet\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"ControlNet\"]}],[\"$\",\"span\",\"Training Efficiency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Training Efficiency\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-12-A_Comprehensive_Survey_of_Self-Evolving_AI_Agents_A_New_Paradigm_Bridging_Foundation_Models_and_Lifelong_Agentic_Systems\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-12-A_Comprehensive_Survey_of_Self-Evolving_AI_Agents_A_New_Paradigm_Bridging_Foundation_Models_and_Lifelong_Agentic_Systems/\",\"children\":\"[논문리뷰] A Comprehensive Survey of Self-Evolving AI Agents: A New Paradigm Bridging Foundation Models and Lifelong Agentic Systems\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Xinhao Yi이 [arXiv]에 게시한 'A Comprehensive Survey of Self-Evolving AI Agents: A New Paradigm Bridging Foundation Models and Lifelong Agentic Systems' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-12 13:29:09+0900\",\"children\":\"2025년 8월 12일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Self-Evolving AI Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Self-Evolving AI Agents\"]}],[\"$\",\"span\",\"Lifelong Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Lifelong Learning\"]}],[\"$\",\"span\",\"Foundation Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Foundation Models\"]}],[\"$\",\"span\",\"Multi-Agent Systems\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-Agent Systems\"]}],[\"$\",\"span\",\"Agent Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Agent Optimization\"]}],[\"$\",\"span\",\"Prompt Engineering\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Prompt Engineering\"]}],[\"$\",\"span\",\"Tool Use\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Tool Use\"]}],[\"$\",\"span\",\"AI Safety\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"AI Safety\"]}],[\"$\",\"span\",\"Survey\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Survey\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-11-Voost_A_Unified_and_Scalable_Diffusion_Transformer_for_Bidirectional_Virtual_Try-On_and_Try-Off\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-11-Voost_A_Unified_and_Scalable_Diffusion_Transformer_for_Bidirectional_Virtual_Try-On_and_Try-Off/\",\"children\":\"[논문리뷰] Voost: A Unified and Scalable Diffusion Transformer for Bidirectional Virtual Try-On and Try-Off\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"jgkwak이 [arXiv]에 게시한 'Voost: A Unified and Scalable Diffusion Transformer for Bidirectional Virtual Try-On and Try-Off' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-11 13:13:28+0900\",\"children\":\"2025년 8월 11일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Virtual Try-On\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Virtual Try-On\"]}],[\"$\",\"span\",\"Virtual Try-Off\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Virtual Try-Off\"]}],[\"$\",\"span\",\"Diffusion Transformer\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Transformer\"]}],[\"$\",\"span\",\"Bidirectional Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Bidirectional Learning\"]}],[\"$\",\"span\",\"Generative AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generative AI\"]}],[\"$\",\"span\",\"Fashion Synthesis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Fashion Synthesis\"]}],[\"$\",\"span\",\"Attention Mechanism\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Attention Mechanism\"]}],[\"$\",\"span\",\"Self-Correction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Self-Correction\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-11-UI-AGILE_Advancing_GUI_Agents_with_Effective_Reinforcement_Learning_and_Precise_Inference-Time_Grounding\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-11-UI-AGILE_Advancing_GUI_Agents_with_Effective_Reinforcement_Learning_and_Precise_Inference-Time_Grounding/\",\"children\":\"[논문리뷰] UI-AGILE: Advancing GUI Agents with Effective Reinforcement Learning and Precise Inference-Time Grounding\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Bingqi Chen이 [arXiv]에 게시한 'UI-AGILE: Advancing GUI Agents with Effective Reinforcement Learning and Precise Inference-Time Grounding' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-11 13:13:28+0900\",\"children\":\"2025년 8월 11일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"GUI Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"GUI Agents\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Grounding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Grounding\"]}],[\"$\",\"span\",\"MLLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"MLLMs\"]}],[\"$\",\"span\",\"Reward Function\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reward Function\"]}],[\"$\",\"span\",\"Resampling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Resampling\"]}],[\"$\",\"span\",\"Visual Noise Reduction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Visual Noise Reduction\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-11-Pruning_the_Unsurprising_Efficient_Code_Reasoning_via_First-Token_Surprisal\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-11-Pruning_the_Unsurprising_Efficient_Code_Reasoning_via_First-Token_Surprisal/\",\"children\":\"[논문리뷰] Pruning the Unsurprising: Efficient Code Reasoning via First-Token Surprisal\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Chengcheng Wan이 [arXiv]에 게시한 'Pruning the Unsurprising: Efficient Code Reasoning via First-Token Surprisal' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-11 13:13:28+0900\",\"children\":\"2025년 8월 11일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Code Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Code Reasoning\"]}],[\"$\",\"span\",\"CoT Compression\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"CoT Compression\"]}],[\"$\",\"span\",\"LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLMs\"]}],[\"$\",\"span\",\"Efficiency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Efficiency\"]}],[\"$\",\"span\",\"Surprisal\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Surprisal\"]}],[\"$\",\"span\",\"Pruning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Pruning\"]}],[\"$\",\"span\",\"Fine-tuning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Fine-tuning\"]}],[\"$\",\"span\",\"Large Reasoning Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Reasoning Models\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-11-MeshLLM_Empowering_Large_Language_Models_to_Progressively_Understand_and_Generate_3D_Mesh\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-11-MeshLLM_Empowering_Large_Language_Models_to_Progressively_Understand_and_Generate_3D_Mesh/\",\"children\":\"[논문리뷰] MeshLLM: Empowering Large Language Models to Progressively Understand and Generate 3D Mesh\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yi Yang이 [arXiv]에 게시한 'MeshLLM: Empowering Large Language Models to Progressively Understand and Generate 3D Mesh' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-11 13:13:28+0900\",\"children\":\"2025년 8월 11일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"3D Mesh Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D Mesh Generation\"]}],[\"$\",\"span\",\"LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLMs\"]}],[\"$\",\"span\",\"Mesh Understanding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Mesh Understanding\"]}],[\"$\",\"span\",\"Text-to-3D\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Text-to-3D\"]}],[\"$\",\"span\",\"Primitive-Mesh Decomposition\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Primitive-Mesh Decomposition\"]}],[\"$\",\"span\",\"Progressive Training\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Progressive Training\"]}],[\"$\",\"span\",\"Multimodal AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal AI\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-11-Memp_Exploring_Agent_Procedural_Memory\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-11-Memp_Exploring_Agent_Procedural_Memory/\",\"children\":\"[논문리뷰] Memp: Exploring Agent Procedural Memory\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Shuofei Qiao이 [arXiv]에 게시한 'Memp: Exploring Agent Procedural Memory' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-11 13:13:28+0900\",\"children\":\"2025년 8월 11일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Procedural Memory\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Procedural Memory\"]}],[\"$\",\"span\",\"LLM Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Agents\"]}],[\"$\",\"span\",\"Memory Management\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Memory Management\"]}],[\"$\",\"span\",\"Task Automation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Task Automation\"]}],[\"$\",\"span\",\"Lifelong Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Lifelong Learning\"]}],[\"$\",\"span\",\"Experience Replay\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Experience Replay\"]}],[\"$\",\"span\",\"Agent Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Agent Learning\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-11-MELLA_Bridging_Linguistic_Capability_and_Cultural_Groundedness_for_Low-Resource_Language_MLLMs\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-11-MELLA_Bridging_Linguistic_Capability_and_Cultural_Groundedness_for_Low-Resource_Language_MLLMs/\",\"children\":\"[논문리뷰] MELLA: Bridging Linguistic Capability and Cultural Groundedness for Low-Resource Language MLLMs\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Guohang Yan이 [arXiv]에 게시한 'MELLA: Bridging Linguistic Capability and Cultural Groundedness for Low-Resource Language MLLMs' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-11 13:13:28+0900\",\"children\":\"2025년 8월 11일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Multimodal Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Large Language Models\"]}],[\"$\",\"span\",\"Low-Resource Languages\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Low-Resource Languages\"]}],[\"$\",\"span\",\"Cultural Groundedness\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Cultural Groundedness\"]}],[\"$\",\"span\",\"Linguistic Capability\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Linguistic Capability\"]}],[\"$\",\"span\",\"Dataset Creation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dataset Creation\"]}],[\"$\",\"span\",\"Multilingual AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multilingual AI\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-11-LightSwitch_Multi-view_Relighting_with_Material-guided_Diffusion\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-11-LightSwitch_Multi-view_Relighting_with_Material-guided_Diffusion/\",\"children\":\"[논문리뷰] LightSwitch: Multi-view Relighting with Material-guided Diffusion\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Shubham Tulsiani이 [arXiv]에 게시한 'LightSwitch: Multi-view Relighting with Material-guided Diffusion' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-11 13:13:28+0900\",\"children\":\"2025년 8월 11일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Multi-view Relighting\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-view Relighting\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}],[\"$\",\"span\",\"Material-guided\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Material-guided\"]}],[\"$\",\"span\",\"Inverse Rendering\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Inverse Rendering\"]}],[\"$\",\"span\",\"3D Scene Reconstruction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D Scene Reconstruction\"]}],[\"$\",\"span\",\"Image Synthesis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image Synthesis\"]}],[\"$\",\"span\",\"Consistent Relighting\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Consistent Relighting\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-11-InfiGUI-G1_Advancing_GUI_Grounding_with_Adaptive_Exploration_Policy_Optimization\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-11-InfiGUI-G1_Advancing_GUI_Grounding_with_Adaptive_Exploration_Policy_Optimization/\",\"children\":\"[논문리뷰] InfiGUI-G1: Advancing GUI Grounding with Adaptive Exploration Policy Optimization\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Pengxiang Li이 [arXiv]에 게시한 'InfiGUI-G1: Advancing GUI Grounding with Adaptive Exploration Policy Optimization' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-11 13:13:28+0900\",\"children\":\"2025년 8월 11일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"GUI Grounding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"GUI Grounding\"]}],[\"$\",\"span\",\"MLLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"MLLMs\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Policy Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Policy Optimization\"]}],[\"$\",\"span\",\"Exploration Strategy\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Exploration Strategy\"]}],[\"$\",\"span\",\"Semantic Alignment\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Semantic Alignment\"]}],[\"$\",\"span\",\"Adaptive Exploration Reward\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Adaptive Exploration Reward\"]}],[\"$\",\"span\",\"Human-Computer Interaction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Human-Computer Interaction\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-11-GLM-4.5_Agentic_Reasoning_and_Coding_ARC_Foundation_Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-11-GLM-4.5_Agentic_Reasoning_and_Coding_ARC_Foundation_Models/\",\"children\":\"[논문리뷰] GLM-4.5: Agentic, Reasoning, and Coding (ARC) Foundation Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"GLM-4. 5 Team이 [arXiv]에 게시한 'GLM-4.5: Agentic, Reasoning, and Coding (ARC) Foundation Models' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-11 13:13:28+0900\",\"children\":\"2025년 8월 11일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Large Language Model\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Model\"]}],[\"$\",\"span\",\"Mixture-of-Experts\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Mixture-of-Experts\"]}],[\"$\",\"span\",\"Agentic AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Agentic AI\"]}],[\"$\",\"span\",\"Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reasoning\"]}],[\"$\",\"span\",\"Code Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Code Generation\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Foundation Model\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Foundation Model\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-11-GENIE_Gaussian_Encoding_for_Neural_Radiance_Fields_Interactive_Editing\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-11-GENIE_Gaussian_Encoding_for_Neural_Radiance_Fields_Interactive_Editing/\",\"children\":\"[논문리뷰] GENIE: Gaussian Encoding for Neural Radiance Fields Interactive Editing\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Przemysław Spurek이 [arXiv]에 게시한 'GENIE: Gaussian Encoding for Neural Radiance Fields Interactive Editing' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-11 13:13:28+0900\",\"children\":\"2025년 8월 11일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Neural Radiance Fields (NeRF)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Neural Radiance Fields (NeRF)\"]}],[\"$\",\"span\",\"Gaussian Splatting (GS)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Gaussian Splatting (GS)\"]}],[\"$\",\"span\",\"Interactive Editing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Interactive Editing\"]}],[\"$\",\"span\",\"3D Scene Representation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D Scene Representation\"]}],[\"$\",\"span\",\"Physics Simulation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Physics Simulation\"]}],[\"$\",\"span\",\"Hybrid Model\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Hybrid Model\"]}],[\"$\",\"span\",\"Real-time Rendering\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Real-time Rendering\"]}],[\"$\",\"span\",\"Ray Tracing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Ray Tracing\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-11-Adapting_Vision-Language_Models_Without_Labels_A_Comprehensive_Survey\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-11-Adapting_Vision-Language_Models_Without_Labels_A_Comprehensive_Survey/\",\"children\":\"[논문리뷰] Adapting Vision-Language Models Without Labels: A Comprehensive Survey\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Eleni Chatzi이 [arXiv]에 게시한 'Adapting Vision-Language Models Without Labels: A Comprehensive Survey' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-11 13:13:28+0900\",\"children\":\"2025년 8월 11일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Vision-Language Models (VLMs)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision-Language Models (VLMs)\"]}],[\"$\",\"span\",\"Unsupervised Adaptation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Unsupervised Adaptation\"]}],[\"$\",\"span\",\"Test-Time Adaptation (TTA)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Test-Time Adaptation (TTA)\"]}],[\"$\",\"span\",\"Domain Transfer\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Domain Transfer\"]}],[\"$\",\"span\",\"Multimodal Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Learning\"]}],[\"$\",\"span\",\"Label-Free Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Label-Free Learning\"]}],[\"$\",\"span\",\"Zero-Shot Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Zero-Shot Learning\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-8-Visual_Document_Understanding_and_Question_Answering_A_Multi-Agent_Collaboration_Framework_with_Test-Time_Scaling\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-8-Visual_Document_Understanding_and_Question_Answering_A_Multi-Agent_Collaboration_Framework_with_Test-Time_Scaling/\",\"children\":\"[논문리뷰] Visual Document Understanding and Question Answering: A Multi-Agent Collaboration Framework with Test-Time Scaling\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Ruolin Shen이 [arXiv]에 게시한 'Visual Document Understanding and Question Answering: A Multi-Agent Collaboration Framework with Test-Time Scaling' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-08 13:32:22+0900\",\"children\":\"2025년 8월 8일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Visual Document Understanding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Visual Document Understanding\"]}],[\"$\",\"span\",\"Visual Question Answering\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Visual Question Answering\"]}],[\"$\",\"span\",\"Multi-Agent System\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-Agent System\"]}],[\"$\",\"span\",\"Test-Time Scaling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Test-Time Scaling\"]}],[\"$\",\"span\",\"Self-Correction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Self-Correction\"]}],[\"$\",\"span\",\"Mixed Reward Modeling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Mixed Reward Modeling\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-8-StrandDesigner_Towards_Practical_Strand_Generation_with_Sketch_Guidance\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-8-StrandDesigner_Towards_Practical_Strand_Generation_with_Sketch_Guidance/\",\"children\":\"[논문리뷰] StrandDesigner: Towards Practical Strand Generation with Sketch Guidance\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Xiaobin Hu이 [arXiv]에 게시한 'StrandDesigner: Towards Practical Strand Generation with Sketch Guidance' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-08 13:32:22+0900\",\"children\":\"2025년 8월 8일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Strand Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Strand Generation\"]}],[\"$\",\"span\",\"Sketch Guidance\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Sketch Guidance\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}],[\"$\",\"span\",\"Multi-scale Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-scale Learning\"]}],[\"$\",\"span\",\"Adaptive Conditioning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Adaptive Conditioning\"]}],[\"$\",\"span\",\"3D Hair Modeling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D Hair Modeling\"]}],[\"$\",\"span\",\"Computer Graphics\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Computer Graphics\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-8-Steering_One-Step_Diffusion_Model_with_Fidelity-Rich_Decoder_for_Fast_Image_Compression\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-8-Steering_One-Step_Diffusion_Model_with_Fidelity-Rich_Decoder_for_Fast_Image_Compression/\",\"children\":\"[논문리뷰] Steering One-Step Diffusion Model with Fidelity-Rich Decoder for Fast Image Compression\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yifei Ji이 [arXiv]에 게시한 'Steering One-Step Diffusion Model with Fidelity-Rich Decoder for Fast Image Compression' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-08 13:32:22+0900\",\"children\":\"2025년 8월 8일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Image Compression\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image Compression\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}],[\"$\",\"span\",\"One-Step Decoding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"One-Step Decoding\"]}],[\"$\",\"span\",\"Fidelity Guidance\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Fidelity Guidance\"]}],[\"$\",\"span\",\"Rate Annealing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Rate Annealing\"]}],[\"$\",\"span\",\"VAE\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"VAE\"]}],[\"$\",\"span\",\"Perceptual Quality\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Perceptual Quality\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-8-RPCANet_Deep_Interpretable_Robust_PCA_for_Sparse_Object_Segmentation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-8-RPCANet_Deep_Interpretable_Robust_PCA_for_Sparse_Object_Segmentation/\",\"children\":\"[논문리뷰] RPCANet++: Deep Interpretable Robust PCA for Sparse Object Segmentation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Jian Yang이 [arXiv]에 게시한 'RPCANet++: Deep Interpretable Robust PCA for Sparse Object Segmentation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-08 13:32:22+0900\",\"children\":\"2025년 8월 8일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Robust PCA\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Robust PCA\"]}],[\"$\",\"span\",\"Deep Unfolding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Deep Unfolding\"]}],[\"$\",\"span\",\"Sparse Segmentation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Sparse Segmentation\"]}],[\"$\",\"span\",\"Interpretability\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Interpretability\"]}],[\"$\",\"span\",\"Image Decomposition\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image Decomposition\"]}],[\"$\",\"span\",\"Computer Vision\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Computer Vision\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-8-REINA_Regularized_Entropy_Information-Based_Loss_for_Efficient_Simultaneous_Speech_Translation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-8-REINA_Regularized_Entropy_Information-Based_Loss_for_Efficient_Simultaneous_Speech_Translation/\",\"children\":\"[논문리뷰] REINA: Regularized Entropy Information-Based Loss for Efficient Simultaneous Speech Translation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Xiao Yu이 [arXiv]에 게시한 'REINA: Regularized Entropy Information-Based Loss for Efficient Simultaneous Speech Translation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-08 13:32:22+0900\",\"children\":\"2025년 8월 8일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Simultaneous Speech Translation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Simultaneous Speech Translation\"]}],[\"$\",\"span\",\"Adaptive Policy\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Adaptive Policy\"]}],[\"$\",\"span\",\"Entropy-based Loss\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Entropy-based Loss\"]}],[\"$\",\"span\",\"Mutual Information\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Mutual Information\"]}],[\"$\",\"span\",\"Latency-Quality Trade-off\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Latency-Quality Trade-off\"]}],[\"$\",\"span\",\"Speech-to-Text Translation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Speech-to-Text Translation\"]}],[\"$\",\"span\",\"REINA\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"REINA\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-8-R-Zero_Self-Evolving_Reasoning_LLM_from_Zero_Data\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-8-R-Zero_Self-Evolving_Reasoning_LLM_from_Zero_Data/\",\"children\":\"[논문리뷰] R-Zero: Self-Evolving Reasoning LLM from Zero Data\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Zongxia Li이 [arXiv]에 게시한 'R-Zero: Self-Evolving Reasoning LLM from Zero Data' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-08 13:32:22+0900\",\"children\":\"2025년 8월 8일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Self-Evolving LLM\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Self-Evolving LLM\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Curriculum Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Curriculum Learning\"]}],[\"$\",\"span\",\"Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reasoning\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Self-Play\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Self-Play\"]}],[\"$\",\"span\",\"Zero-Data Training\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Zero-Data Training\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-8-PRvL_Quantifying_the_Capabilities_and_Risks_of_Large_Language_Models_for_PII_Redaction\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-8-PRvL_Quantifying_the_Capabilities_and_Risks_of_Large_Language_Models_for_PII_Redaction/\",\"children\":\"[논문리뷰] PRvL: Quantifying the Capabilities and Risks of Large Language Models for PII Redaction\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Prajit Das이 [arXiv]에 게시한 'PRvL: Quantifying the Capabilities and Risks of Large Language Models for PII Redaction' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-08 13:32:22+0900\",\"children\":\"2025년 8월 8일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"PII Redaction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"PII Redaction\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Instruction Tuning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Instruction Tuning\"]}],[\"$\",\"span\",\"Retrieval-Augmented Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Retrieval-Augmented Generation\"]}],[\"$\",\"span\",\"Privacy Preservation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Privacy Preservation\"]}],[\"$\",\"span\",\"Model Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Model Evaluation\"]}],[\"$\",\"span\",\"Cross-Domain Generalization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Cross-Domain Generalization\"]}],[\"$\",\"span\",\"Open-Source LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Open-Source LLMs\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-8-On_the_Generalization_of_SFT_A_Reinforcement_Learning_Perspective_with_Reward_Rectification\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-8-On_the_Generalization_of_SFT_A_Reinforcement_Learning_Perspective_with_Reward_Rectification/\",\"children\":\"[논문리뷰] On the Generalization of SFT: A Reinforcement Learning Perspective with Reward Rectification\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Xinyu Ye이 [arXiv]에 게시한 'On the Generalization of SFT: A Reinforcement Learning Perspective with Reward Rectification' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-08 13:32:22+0900\",\"children\":\"2025년 8월 8일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Supervised Fine-Tuning (SFT)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Supervised Fine-Tuning (SFT)\"]}],[\"$\",\"span\",\"Reinforcement Learning (RL)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning (RL)\"]}],[\"$\",\"span\",\"Generalization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generalization\"]}],[\"$\",\"span\",\"Reward Rectification\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reward Rectification\"]}],[\"$\",\"span\",\"Dynamic Fine-Tuning (DFT)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dynamic Fine-Tuning (DFT)\"]}],[\"$\",\"span\",\"LLM\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM\"]}],[\"$\",\"span\",\"Policy Gradient\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Policy Gradient\"]}],[\"$\",\"span\",\"Mathematical Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Mathematical Reasoning\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-8-MOSEv2_A_More_Challenging_Dataset_for_Video_Object_Segmentation_in_Complex_Scenes\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-8-MOSEv2_A_More_Challenging_Dataset_for_Video_Object_Segmentation_in_Complex_Scenes/\",\"children\":\"[논문리뷰] MOSEv2: A More Challenging Dataset for Video Object Segmentation in Complex Scenes\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Xudong Jiang이 [arXiv]에 게시한 'MOSEv2: A More Challenging Dataset for Video Object Segmentation in Complex Scenes' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-08 13:32:22+0900\",\"children\":\"2025년 8월 8일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Video Object Segmentation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video Object Segmentation\"]}],[\"$\",\"span\",\"Dataset\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dataset\"]}],[\"$\",\"span\",\"Complex Scenes\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Complex Scenes\"]}],[\"$\",\"span\",\"Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmark\"]}],[\"$\",\"span\",\"Object Tracking\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Object Tracking\"]}],[\"$\",\"span\",\"Computer Vision\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Computer Vision\"]}],[\"$\",\"span\",\"Dataset Challenges\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dataset Challenges\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-8-Marco-Voice_Technical_Report\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-8-Marco-Voice_Technical_Report/\",\"children\":\"[논문리뷰] Marco-Voice Technical Report\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Qingjuan Li이 [arXiv]에 게시한 'Marco-Voice Technical Report' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-08 13:32:22+0900\",\"children\":\"2025년 8월 8일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Speech Synthesis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Speech Synthesis\"]}],[\"$\",\"span\",\"Voice Cloning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Voice Cloning\"]}],[\"$\",\"span\",\"Emotion Control\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Emotion Control\"]}],[\"$\",\"span\",\"Text-to-Speech\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Text-to-Speech\"]}],[\"$\",\"span\",\"Disentanglement\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Disentanglement\"]}],[\"$\",\"span\",\"Contrastive Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Contrastive Learning\"]}],[\"$\",\"span\",\"Flow Matching\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Flow Matching\"]}],[\"$\",\"span\",\"Emotional Speech Dataset\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Emotional Speech Dataset\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-8-I_Think_Therefore_I_Am_Under-Qualified_A_Benchmark_for_Evaluating_Linguistic_Shibboleth_Detection_in_LLM_Hiring_Evaluations\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-8-I_Think_Therefore_I_Am_Under-Qualified_A_Benchmark_for_Evaluating_Linguistic_Shibboleth_Detection_in_LLM_Hiring_Evaluations/\",\"children\":\"[논문리뷰] I Think, Therefore I Am Under-Qualified? A Benchmark for Evaluating Linguistic Shibboleth Detection in LLM Hiring Evaluations\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Chirag Shah이 [arXiv]에 게시한 'I Think, Therefore I Am Under-Qualified? A Benchmark for Evaluating Linguistic Shibboleth Detection in LLM Hiring Evaluations' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-08 13:32:22+0900\",\"children\":\"2025년 8월 8일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLM Bias\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Bias\"]}],[\"$\",\"span\",\"Hiring Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Hiring Evaluation\"]}],[\"$\",\"span\",\"Linguistic Shibboleth\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Linguistic Shibboleth\"]}],[\"$\",\"span\",\"Hedging Language\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Hedging Language\"]}],[\"$\",\"span\",\"Fairness\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Fairness\"]}],[\"$\",\"span\",\"Benchmarking\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmarking\"]}],[\"$\",\"span\",\"Sociolinguistics\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Sociolinguistics\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-8-InfiAlign_A_Scalable_and_Sample-Efficient_Framework_for_Aligning_LLMs_to_Enhance_Reasoning_Capabilities\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-8-InfiAlign_A_Scalable_and_Sample-Efficient_Framework_for_Aligning_LLMs_to_Enhance_Reasoning_Capabilities/\",\"children\":\"[논문리뷰] InfiAlign: A Scalable and Sample-Efficient Framework for Aligning LLMs to Enhance Reasoning Capabilities\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Zhijie Sang이 [arXiv]에 게시한 'InfiAlign: A Scalable and Sample-Efficient Framework for Aligning LLMs to Enhance Reasoning Capabilities' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-08 13:32:22+0900\",\"children\":\"2025년 8월 8일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLM Alignment\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Alignment\"]}],[\"$\",\"span\",\"Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reasoning\"]}],[\"$\",\"span\",\"Data Curation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Curation\"]}],[\"$\",\"span\",\"Supervised Fine-tuning (SFT)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Supervised Fine-tuning (SFT)\"]}],[\"$\",\"span\",\"Direct Preference Optimization (DPO)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Direct Preference Optimization (DPO)\"]}],[\"$\",\"span\",\"Sample Efficiency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Sample Efficiency\"]}],[\"$\",\"span\",\"Scalability\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Scalability\"]}],[\"$\",\"span\",\"Multi-dimensional Filtering\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-dimensional Filtering\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-8-I2CR_Intra-_and_Inter-modal_Collaborative_Reflections_for_Multimodal_Entity_Linking\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-8-I2CR_Intra-_and_Inter-modal_Collaborative_Reflections_for_Multimodal_Entity_Linking/\",\"children\":\"[논문리뷰] I2CR: Intra- and Inter-modal Collaborative Reflections for Multimodal Entity Linking\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Chao Wang이 [arXiv]에 게시한 'I2CR: Intra- and Inter-modal Collaborative Reflections for Multimodal Entity Linking' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-08 13:32:22+0900\",\"children\":\"2025년 8월 8일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Multimodal Entity Linking\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Entity Linking\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Collaborative Reflection\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Collaborative Reflection\"]}],[\"$\",\"span\",\"Iterative Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Iterative Reasoning\"]}],[\"$\",\"span\",\"Visual Information\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Visual Information\"]}],[\"$\",\"span\",\"Text-centric\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Text-centric\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-8-Hop_Skip_and_Overthink_Diagnosing_Why_Reasoning_Models_Fumble_during_Multi-Hop_Analysis\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-8-Hop_Skip_and_Overthink_Diagnosing_Why_Reasoning_Models_Fumble_during_Multi-Hop_Analysis/\",\"children\":\"[논문리뷰] Hop, Skip, and Overthink: Diagnosing Why Reasoning Models Fumble during Multi-Hop Analysis\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Reshmi Ghosh이 [arXiv]에 게시한 'Hop, Skip, and Overthink: Diagnosing Why Reasoning Models Fumble during Multi-Hop Analysis' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-08 13:32:22+0900\",\"children\":\"2025년 8월 8일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Multi-hop Question Answering\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-hop Question Answering\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Reasoning Errors\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reasoning Errors\"]}],[\"$\",\"span\",\"Error Taxonomy\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Error Taxonomy\"]}],[\"$\",\"span\",\"Human Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Human Evaluation\"]}],[\"$\",\"span\",\"Automated Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Automated Evaluation\"]}],[\"$\",\"span\",\"Overthinking\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Overthinking\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-8-Hi3DEval_Advancing_3D_Generation_Evaluation_with_Hierarchical_Validity\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-8-Hi3DEval_Advancing_3D_Generation_Evaluation_with_Hierarchical_Validity/\",\"children\":\"[논문리뷰] Hi3DEval: Advancing 3D Generation Evaluation with Hierarchical Validity\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Zhibing Li이 [arXiv]에 게시한 'Hi3DEval: Advancing 3D Generation Evaluation with Hierarchical Validity' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-08 13:32:22+0900\",\"children\":\"2025년 8월 8일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"3D Generation Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D Generation Evaluation\"]}],[\"$\",\"span\",\"Hierarchical Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Hierarchical Evaluation\"]}],[\"$\",\"span\",\"Material Properties\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Material Properties\"]}],[\"$\",\"span\",\"Multi-Agent Annotation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-Agent Annotation\"]}],[\"$\",\"span\",\"Hybrid Scoring System\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Hybrid Scoring System\"]}],[\"$\",\"span\",\"Video-based Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video-based Evaluation\"]}],[\"$\",\"span\",\"Part-level Analysis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Part-level Analysis\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-8-Genie_Envisioner_A_Unified_World_Foundation_Platform_for_Robotic_Manipulation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-8-Genie_Envisioner_A_Unified_World_Foundation_Platform_for_Robotic_Manipulation/\",\"children\":\"[논문리뷰] Genie Envisioner: A Unified World Foundation Platform for Robotic Manipulation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Shengcong Chen이 [arXiv]에 게시한 'Genie Envisioner: A Unified World Foundation Platform for Robotic Manipulation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-08 13:32:22+0900\",\"children\":\"2025년 8월 8일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Robotic Manipulation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Robotic Manipulation\"]}],[\"$\",\"span\",\"World Model\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"World Model\"]}],[\"$\",\"span\",\"Video Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video Generation\"]}],[\"$\",\"span\",\"Diffusion Model\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Model\"]}],[\"$\",\"span\",\"Embodied AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Embodied AI\"]}],[\"$\",\"span\",\"Foundation Model\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Foundation Model\"]}],[\"$\",\"span\",\"Robotics Simulation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Robotics Simulation\"]}],[\"$\",\"span\",\"Policy Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Policy Learning\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-8-Evaluating_Synthesizing_and_Enhancing_for_Customer_Support_Conversation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-8-Evaluating_Synthesizing_and_Enhancing_for_Customer_Support_Conversation/\",\"children\":\"[논문리뷰] Evaluating, Synthesizing, and Enhancing for Customer Support Conversation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Feng Chen이 [arXiv]에 게시한 'Evaluating, Synthesizing, and Enhancing for Customer Support Conversation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-08 13:32:22+0900\",\"children\":\"2025년 8월 8일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Customer Support\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Customer Support\"]}],[\"$\",\"span\",\"Dialogue Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dialogue Generation\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Role-Playing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Role-Playing\"]}],[\"$\",\"span\",\"COPC Framework\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"COPC Framework\"]}],[\"$\",\"span\",\"Synthetic Data\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Synthetic Data\"]}],[\"$\",\"span\",\"Strategy Prediction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Strategy Prediction\"]}],[\"$\",\"span\",\"Empathetic AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Empathetic AI\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-8-Dont_Overthink_It_A_Survey_of_Efficient_R1-style_Large_Reasoning_Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-8-Dont_Overthink_It_A_Survey_of_Efficient_R1-style_Large_Reasoning_Models/\",\"children\":\"[논문리뷰] Don't Overthink It: A Survey of Efficient R1-style Large Reasoning Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Fangzhou Yao이 [arXiv]에 게시한 'Don't Overthink It: A Survey of Efficient R1-style Large Reasoning Models' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-08 13:32:22+0900\",\"children\":\"2025년 8월 8일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Large Reasoning Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Reasoning Models\"]}],[\"$\",\"span\",\"Efficient Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Efficient Reasoning\"]}],[\"$\",\"span\",\"Chain-of-Thought\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Chain-of-Thought\"]}],[\"$\",\"span\",\"Model Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Model Optimization\"]}],[\"$\",\"span\",\"Model Collaboration\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Model Collaboration\"]}],[\"$\",\"span\",\"Overthinking Problem\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Overthinking Problem\"]}],[\"$\",\"span\",\"LLM Efficiency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Efficiency\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-8-DeepPHY_Benchmarking_Agentic_VLMs_on_Physical_Reasoning\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-8-DeepPHY_Benchmarking_Agentic_VLMs_on_Physical_Reasoning/\",\"children\":\"[논문리뷰] DeepPHY: Benchmarking Agentic VLMs on Physical Reasoning\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Ziming Wang이 [arXiv]에 게시한 'DeepPHY: Benchmarking Agentic VLMs on Physical Reasoning' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-08 13:32:22+0900\",\"children\":\"2025년 8월 8일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Vision Language Models (VLMs)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision Language Models (VLMs)\"]}],[\"$\",\"span\",\"Agentic AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Agentic AI\"]}],[\"$\",\"span\",\"Physical Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Physical Reasoning\"]}],[\"$\",\"span\",\"Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmark\"]}],[\"$\",\"span\",\"Simulation Environments\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Simulation Environments\"]}],[\"$\",\"span\",\"Action Planning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Action Planning\"]}],[\"$\",\"span\",\"Interactive AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Interactive AI\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-8-CoAct-1_Computer-using_Agents_with_Coding_as_Actions\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-8-CoAct-1_Computer-using_Agents_with_Coding_as_Actions/\",\"children\":\"[논문리뷰] CoAct-1: Computer-using Agents with Coding as Actions\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Taiwei Shi이 [arXiv]에 게시한 'CoAct-1: Computer-using Agents with Coding as Actions' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-08 13:32:22+0900\",\"children\":\"2025년 8월 8일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"AI Agent\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"AI Agent\"]}],[\"$\",\"span\",\"Multi-agent System\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-agent System\"]}],[\"$\",\"span\",\"GUI Automation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"GUI Automation\"]}],[\"$\",\"span\",\"Programmatic Control\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Programmatic Control\"]}],[\"$\",\"span\",\"Code Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Code Generation\"]}],[\"$\",\"span\",\"OSWorld Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"OSWorld Benchmark\"]}],[\"$\",\"span\",\"Hybrid AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Hybrid AI\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-8-Can_Large_Multimodal_Models_Actively_Recognize_Faulty_Inputs_A_Systematic_Evaluation_Framework_of_Their_Input_Scrutiny_Ability\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-8-Can_Large_Multimodal_Models_Actively_Recognize_Faulty_Inputs_A_Systematic_Evaluation_Framework_of_Their_Input_Scrutiny_Ability/\",\"children\":\"[논문리뷰] Can Large Multimodal Models Actively Recognize Faulty Inputs? A Systematic Evaluation Framework of Their Input Scrutiny Ability\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yuan Wu이 [arXiv]에 게시한 'Can Large Multimodal Models Actively Recognize Faulty Inputs? A Systematic Evaluation Framework of Their Input Scrutiny Ability' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-08 13:32:22+0900\",\"children\":\"2025년 8월 8일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Large Multimodal Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Multimodal Models\"]}],[\"$\",\"span\",\"Input Scrutiny\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Input Scrutiny\"]}],[\"$\",\"span\",\"Error Detection\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Error Detection\"]}],[\"$\",\"span\",\"Faulty Inputs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Faulty Inputs\"]}],[\"$\",\"span\",\"Evaluation Framework\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Evaluation Framework\"]}],[\"$\",\"span\",\"Modality Preference\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Modality Preference\"]}],[\"$\",\"span\",\"Cross-Modal Inconsistency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Cross-Modal Inconsistency\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-8-Are_We_on_the_Right_Way_for_Assessing_Document_Retrieval-Augmented_Generation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-8-Are_We_on_the_Right_Way_for_Assessing_Document_Retrieval-Augmented_Generation/\",\"children\":\"[논문리뷰] Are We on the Right Way for Assessing Document Retrieval-Augmented Generation?\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Junjie Yang이 [arXiv]에 게시한 'Are We on the Right Way for Assessing Document Retrieval-Augmented Generation?' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-08 13:32:22+0900\",\"children\":\"2025년 8월 8일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Retrieval-Augmented Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Retrieval-Augmented Generation\"]}],[\"$\",\"span\",\"Multimodal LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal LLMs\"]}],[\"$\",\"span\",\"Benchmark Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmark Evaluation\"]}],[\"$\",\"span\",\"Document Understanding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Document Understanding\"]}],[\"$\",\"span\",\"Multi-hop Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-hop Reasoning\"]}],[\"$\",\"span\",\"Information Retrieval\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Information Retrieval\"]}],[\"$\",\"span\",\"Evaluation Dataset\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Evaluation Dataset\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-8-Are_Todays_LLMs_Ready_to_Explain_Well-Being_Concepts\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-8-Are_Todays_LLMs_Ready_to_Explain_Well-Being_Concepts/\",\"children\":\"[논문리뷰] Are Today's LLMs Ready to Explain Well-Being Concepts?\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Huan Liu이 [arXiv]에 게시한 'Are Today's LLMs Ready to Explain Well-Being Concepts?' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-08 13:32:22+0900\",\"children\":\"2025년 8월 8일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Well-being Concepts\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Well-being Concepts\"]}],[\"$\",\"span\",\"LLM Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Evaluation\"]}],[\"$\",\"span\",\"Principle-Guided Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Principle-Guided Evaluation\"]}],[\"$\",\"span\",\"LLM-as-a-Judge\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM-as-a-Judge\"]}],[\"$\",\"span\",\"Supervised Fine-Tuning (SFT)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Supervised Fine-Tuning (SFT)\"]}],[\"$\",\"span\",\"Direct Preference Optimization (DPO)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Direct Preference Optimization (DPO)\"]}],[\"$\",\"span\",\"Explanation Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Explanation Generation\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-7-Web-CogReasoner_Towards_Knowledge-Induced_Cognitive_Reasoning_for_Web_Agents\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-7-Web-CogReasoner_Towards_Knowledge-Induced_Cognitive_Reasoning_for_Web_Agents/\",\"children\":\"[논문리뷰] Web-CogReasoner: Towards Knowledge-Induced Cognitive Reasoning for Web Agents\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Xinyu Yang이 [arXiv]에 게시한 'Web-CogReasoner: Towards Knowledge-Induced Cognitive Reasoning for Web Agents' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-07 13:38:21+0900\",\"children\":\"2025년 8월 7일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Web Agent\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Web Agent\"]}],[\"$\",\"span\",\"Cognitive Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Cognitive Reasoning\"]}],[\"$\",\"span\",\"Knowledge-Induced\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Knowledge-Induced\"]}],[\"$\",\"span\",\"Large Multimodal Models (LMMs)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Multimodal Models (LMMs)\"]}],[\"$\",\"span\",\"Bloom's Taxonomy\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Bloom's Taxonomy\"]}],[\"$\",\"span\",\"Chain-of-Thought (CoT)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Chain-of-Thought (CoT)\"]}],[\"$\",\"span\",\"Web-CogDataset\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Web-CogDataset\"]}],[\"$\",\"span\",\"Web-CogBench\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Web-CogBench\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-7-Training_Long-Context_Multi-Turn_Software_Engineering_Agents_with_Reinforcement_Learning\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-7-Training_Long-Context_Multi-Turn_Software_Engineering_Agents_with_Reinforcement_Learning/\",\"children\":\"[논문리뷰] Training Long-Context, Multi-Turn Software Engineering Agents with Reinforcement Learning\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Maksim Nekrashevich이 [arXiv]에 게시한 'Training Long-Context, Multi-Turn Software Engineering Agents with Reinforcement Learning' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-07 13:38:21+0900\",\"children\":\"2025년 8월 7일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Software Engineering\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Software Engineering\"]}],[\"$\",\"span\",\"Multi-Turn Interaction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-Turn Interaction\"]}],[\"$\",\"span\",\"Long Context\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Long Context\"]}],[\"$\",\"span\",\"DAPO\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"DAPO\"]}],[\"$\",\"span\",\"Autonomous Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Autonomous Agents\"]}],[\"$\",\"span\",\"SWE-BENCH\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"SWE-BENCH\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-7-The_Cow_of_Rembrandt_-_Analyzing_Artistic_Prompt_Interpretation_in_Text-to-Image_Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-7-The_Cow_of_Rembrandt_-_Analyzing_Artistic_Prompt_Interpretation_in_Text-to-Image_Models/\",\"children\":\"[논문리뷰] The Cow of Rembrandt - Analyzing Artistic Prompt Interpretation in Text-to-Image Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Elisabetta Rocchetti이 [arXiv]에 게시한 'The Cow of Rembrandt - Analyzing Artistic Prompt Interpretation in Text-to-Image Models' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-07 13:38:21+0900\",\"children\":\"2025년 8월 7일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Text-to-Image Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Text-to-Image Generation\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}],[\"$\",\"span\",\"Cross-Attention Analysis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Cross-Attention Analysis\"]}],[\"$\",\"span\",\"Content-Style Disentanglement\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Content-Style Disentanglement\"]}],[\"$\",\"span\",\"Artistic Style Transfer\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Artistic Style Transfer\"]}],[\"$\",\"span\",\"Explainable AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Explainable AI\"]}],[\"$\",\"span\",\"SDXL\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"SDXL\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-7-Sotopia-RL_Reward_Design_for_Social_Intelligence\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-7-Sotopia-RL_Reward_Design_for_Social_Intelligence/\",\"children\":\"[논문리뷰] Sotopia-RL: Reward Design for Social Intelligence\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Keyang Xuan이 [arXiv]에 게시한 'Sotopia-RL: Reward Design for Social Intelligence' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-07 13:38:21+0900\",\"children\":\"2025년 8월 7일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Social Intelligence\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Social Intelligence\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Reward Design\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reward Design\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Utterance-level Rewards\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Utterance-level Rewards\"]}],[\"$\",\"span\",\"Multi-dimensional Rewards\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-dimensional Rewards\"]}],[\"$\",\"span\",\"Partial Observability\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Partial Observability\"]}],[\"$\",\"span\",\"SOTOPIA\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"SOTOPIA\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-7-SonicMaster_Towards_Controllable_All-in-One_Music_Restoration_and_Mastering\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-7-SonicMaster_Towards_Controllable_All-in-One_Music_Restoration_and_Mastering/\",\"children\":\"[논문리뷰] SonicMaster: Towards Controllable All-in-One Music Restoration and Mastering\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Ambuj Mehrish이 [arXiv]에 게시한 'SonicMaster: Towards Controllable All-in-One Music Restoration and Mastering' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-07 13:38:21+0900\",\"children\":\"2025년 8월 7일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Music Restoration\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Music Restoration\"]}],[\"$\",\"span\",\"Audio Mastering\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Audio Mastering\"]}],[\"$\",\"span\",\"Generative Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generative Models\"]}],[\"$\",\"span\",\"Flow Matching\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Flow Matching\"]}],[\"$\",\"span\",\"Text-to-Audio\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Text-to-Audio\"]}],[\"$\",\"span\",\"Audio Quality Enhancement\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Audio Quality Enhancement\"]}],[\"$\",\"span\",\"Multi-task Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-task Learning\"]}],[\"$\",\"span\",\"Dataset Creation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dataset Creation\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-7-Sel3DCraft_Interactive_Visual_Prompts_for_User-Friendly_Text-to-3D_Generation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-7-Sel3DCraft_Interactive_Visual_Prompts_for_User-Friendly_Text-to-3D_Generation/\",\"children\":\"[논문리뷰] Sel3DCraft: Interactive Visual Prompts for User-Friendly Text-to-3D Generation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Hao Huang이 [arXiv]에 게시한 'Sel3DCraft: Interactive Visual Prompts for User-Friendly Text-to-3D Generation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-07 13:38:21+0900\",\"children\":\"2025년 8월 7일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Text-to-3D Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Text-to-3D Generation\"]}],[\"$\",\"span\",\"Prompt Engineering\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Prompt Engineering\"]}],[\"$\",\"span\",\"Visual Analytics\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Visual Analytics\"]}],[\"$\",\"span\",\"Human-Computer Interaction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Human-Computer Interaction\"]}],[\"$\",\"span\",\"Multi-modal Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-modal Large Language Models\"]}],[\"$\",\"span\",\"3D Model Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D Model Evaluation\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-7-SEAgent_Self-Evolving_Computer_Use_Agent_with_Autonomous_Learning_from_Experience\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-7-SEAgent_Self-Evolving_Computer_Use_Agent_with_Autonomous_Learning_from_Experience/\",\"children\":\"[논문리뷰] SEAgent: Self-Evolving Computer Use Agent with Autonomous Learning from Experience\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Xiaoyi Dong이 [arXiv]에 게시한 'SEAgent: Self-Evolving Computer Use Agent with Autonomous Learning from Experience' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-07 13:38:21+0900\",\"children\":\"2025년 8월 7일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Computer Use Agent\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Computer Use Agent\"]}],[\"$\",\"span\",\"Self-Evolving\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Self-Evolving\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Curriculum Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Curriculum Learning\"]}],[\"$\",\"span\",\"Vision-Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision-Language Models\"]}],[\"$\",\"span\",\"Experiential Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Experiential Learning\"]}],[\"$\",\"span\",\"Specialist-to-Generalist\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Specialist-to-Generalist\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-7-Sculptor_Empowering_LLMs_with_Cognitive_Agency_via_Active_Context_Management\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-7-Sculptor_Empowering_LLMs_with_Cognitive_Agency_via_Active_Context_Management/\",\"children\":\"[논문리뷰] Sculptor: Empowering LLMs with Cognitive Agency via Active Context Management\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yunxin Liu이 [arXiv]에 게시한 'Sculptor: Empowering LLMs with Cognitive Agency via Active Context Management' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-07 13:38:21+0900\",\"children\":\"2025년 8월 7일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Active Context Management\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Active Context Management\"]}],[\"$\",\"span\",\"Proactive Interference\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Proactive Interference\"]}],[\"$\",\"span\",\"Tool Augmentation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Tool Augmentation\"]}],[\"$\",\"span\",\"Working Memory\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Working Memory\"]}],[\"$\",\"span\",\"Context Curation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Context Curation\"]}],[\"$\",\"span\",\"Long Context\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Long Context\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-7-RL-PLUS_Countering_Capability_Boundary_Collapse_of_LLMs_in_Reinforcement_Learning_with_Hybrid-policy_Optimization\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-7-RL-PLUS_Countering_Capability_Boundary_Collapse_of_LLMs_in_Reinforcement_Learning_with_Hybrid-policy_Optimization/\",\"children\":\"[논문리뷰] RL-PLUS: Countering Capability Boundary Collapse of LLMs in Reinforcement Learning with Hybrid-policy Optimization\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Kechi Zhang이 [arXiv]에 게시한 'RL-PLUS: Countering Capability Boundary Collapse of LLMs in Reinforcement Learning with Hybrid-policy Optimization' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-07 13:38:21+0900\",\"children\":\"2025년 8월 7일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Capability Collapse\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Capability Collapse\"]}],[\"$\",\"span\",\"Hybrid Policy Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Hybrid Policy Optimization\"]}],[\"$\",\"span\",\"Multiple Importance Sampling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multiple Importance Sampling\"]}],[\"$\",\"span\",\"Exploration\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Exploration\"]}],[\"$\",\"span\",\"Math Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Math Reasoning\"]}],[\"$\",\"span\",\"Out-of-Distribution\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Out-of-Distribution\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-7-Reasoning_Language_Models_for_Root_Cause_Analysis_in_5G_Wireless_Networks\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-7-Reasoning_Language_Models_for_Root_Cause_Analysis_in_5G_Wireless_Networks/\",\"children\":\"[논문리뷰] Reasoning Language Models for Root Cause Analysis in 5G Wireless Networks\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Haozhe Zhang이 [arXiv]에 게시한 'Reasoning Language Models for Root Cause Analysis in 5G Wireless Networks' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-07 13:38:21+0900\",\"children\":\"2025년 8월 7일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Root Cause Analysis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Root Cause Analysis\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"5G Wireless Networks\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"5G Wireless Networks\"]}],[\"$\",\"span\",\"Supervised Fine-Tuning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Supervised Fine-Tuning\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Chain-of-Thought\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Chain-of-Thought\"]}],[\"$\",\"span\",\"TeleLogs Dataset\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"TeleLogs Dataset\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-7-Position_The_Current_AI_Conference_Model_is_Unsustainable_Diagnosing_the_Crisis_of_Centralized_AI_Conference\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-7-Position_The_Current_AI_Conference_Model_is_Unsustainable_Diagnosing_the_Crisis_of_Centralized_AI_Conference/\",\"children\":\"[논문리뷰] Position: The Current AI Conference Model is Unsustainable! Diagnosing the Crisis of Centralized AI Conference\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Jiaying Wu이 [arXiv]에 게시한 'Position: The Current AI Conference Model is Unsustainable! Diagnosing the Crisis of Centralized AI Conference' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-07 13:38:21+0900\",\"children\":\"2025년 8월 7일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"AI Conferences\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"AI Conferences\"]}],[\"$\",\"span\",\"Sustainability\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Sustainability\"]}],[\"$\",\"span\",\"Peer Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Peer Review\"]}],[\"$\",\"span\",\"Community Building\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Community Building\"]}],[\"$\",\"span\",\"Environmental Impact\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Environmental Impact\"]}],[\"$\",\"span\",\"Mental Health\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Mental Health\"]}],[\"$\",\"span\",\"Centralized Model\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Centralized Model\"]}],[\"$\",\"span\",\"Decentralized Model\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Decentralized Model\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-7-OpenMed_NER_Open-Source_Domain-Adapted_State-of-the-Art_Transformers_for_Biomedical_NER_Across_12_Public_Datasets\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-7-OpenMed_NER_Open-Source_Domain-Adapted_State-of-the-Art_Transformers_for_Biomedical_NER_Across_12_Public_Datasets/\",\"children\":\"[논문리뷰] OpenMed NER: Open-Source, Domain-Adapted State-of-the-Art Transformers for Biomedical NER Across 12 Public Datasets\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"MaziyarPanahi이 [arXiv]에 게시한 'OpenMed NER: Open-Source, Domain-Adapted State-of-the-Art Transformers for Biomedical NER Across 12 Public Datasets' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-07 13:38:21+0900\",\"children\":\"2025년 8월 7일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Biomedical NER\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Biomedical NER\"]}],[\"$\",\"span\",\"Transformer\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Transformer\"]}],[\"$\",\"span\",\"Domain Adaptation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Domain Adaptation\"]}],[\"$\",\"span\",\"LoRA\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LoRA\"]}],[\"$\",\"span\",\"Open-Source\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Open-Source\"]}],[\"$\",\"span\",\"Named Entity Recognition\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Named Entity Recognition\"]}],[\"$\",\"span\",\"Healthcare AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Healthcare AI\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-7-MiDashengLM_Efficient_Audio_Understanding_with_General_Audio_Captions\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-7-MiDashengLM_Efficient_Audio_Understanding_with_General_Audio_Captions/\",\"children\":\"[논문리뷰] MiDashengLM: Efficient Audio Understanding with General Audio Captions\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yadong Niu이 [arXiv]에 게시한 'MiDashengLM: Efficient Audio Understanding with General Audio Captions' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-07 13:38:21+0900\",\"children\":\"2025년 8월 7일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Audio-Language Model\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Audio-Language Model\"]}],[\"$\",\"span\",\"General Audio Captions\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"General Audio Captions\"]}],[\"$\",\"span\",\"Audio Understanding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Audio Understanding\"]}],[\"$\",\"span\",\"Speech Recognition\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Speech Recognition\"]}],[\"$\",\"span\",\"Efficient Inference\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Efficient Inference\"]}],[\"$\",\"span\",\"Public Datasets\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Public Datasets\"]}],[\"$\",\"span\",\"Multimodality\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodality\"]}],[\"$\",\"span\",\"Data Curation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Curation\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-7-Light-IF_Endowing_LLMs_with_Generalizable_Reasoning_via_Preview_and_Self-Checking_for_Complex_Instruction_Following\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-7-Light-IF_Endowing_LLMs_with_Generalizable_Reasoning_via_Preview_and_Self-Checking_for_Complex_Instruction_Following/\",\"children\":\"[논문리뷰] Light-IF: Endowing LLMs with Generalizable Reasoning via Preview and Self-Checking for Complex Instruction Following\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Liang Xu이 [arXiv]에 게시한 'Light-IF: Endowing LLMs with Generalizable Reasoning via Preview and Self-Checking for Complex Instruction Following' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-07 13:38:21+0900\",\"children\":\"2025년 8월 7일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLMs\"]}],[\"$\",\"span\",\"Instruction Following\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Instruction Following\"]}],[\"$\",\"span\",\"Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reasoning\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Supervised Fine-tuning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Supervised Fine-tuning\"]}],[\"$\",\"span\",\"Entropy Regularization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Entropy Regularization\"]}],[\"$\",\"span\",\"Self-Checking\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Self-Checking\"]}],[\"$\",\"span\",\"Previewing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Previewing\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-7-LeanK_Learnable_K_Cache_Channel_Pruning_for_Efficient_Decoding\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-7-LeanK_Learnable_K_Cache_Channel_Pruning_for_Efficient_Decoding/\",\"children\":\"[논문리뷰] LeanK: Learnable K Cache Channel Pruning for Efficient Decoding\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yuqing Yang이 [arXiv]에 게시한 'LeanK: Learnable K Cache Channel Pruning for Efficient Decoding' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-07 13:38:21+0900\",\"children\":\"2025년 8월 7일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLM\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM\"]}],[\"$\",\"span\",\"KV Cache Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"KV Cache Optimization\"]}],[\"$\",\"span\",\"Model Pruning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Model Pruning\"]}],[\"$\",\"span\",\"Efficient Decoding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Efficient Decoding\"]}],[\"$\",\"span\",\"Memory Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Memory Optimization\"]}],[\"$\",\"span\",\"Static Sparsity\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Static Sparsity\"]}],[\"$\",\"span\",\"Transformer\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Transformer\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-7-LaTCoder_Converting_Webpage_Design_to_Code_with_Layout-as-Thought\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-7-LaTCoder_Converting_Webpage_Design_to_Code_with_Layout-as-Thought/\",\"children\":\"[논문리뷰] LaTCoder: Converting Webpage Design to Code with Layout-as-Thought\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Tianpeng Lv이 [arXiv]에 게시한 'LaTCoder: Converting Webpage Design to Code with Layout-as-Thought' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-07 13:38:21+0900\",\"children\":\"2025년 8월 7일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Design-to-Code\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Design-to-Code\"]}],[\"$\",\"span\",\"Webpage Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Webpage Generation\"]}],[\"$\",\"span\",\"Multimodal Large Language Models (MLLMs)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Large Language Models (MLLMs)\"]}],[\"$\",\"span\",\"Layout Preservation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Layout Preservation\"]}],[\"$\",\"span\",\"Chain-of-Thought (CoT)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Chain-of-Thought (CoT)\"]}],[\"$\",\"span\",\"UI Automation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"UI Automation\"]}],[\"$\",\"span\",\"Code Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Code Generation\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-7-Is_Chain-of-Thought_Reasoning_of_LLMs_a_Mirage_A_Data_Distribution_Lens\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-7-Is_Chain-of-Thought_Reasoning_of_LLMs_a_Mirage_A_Data_Distribution_Lens/\",\"children\":\"[논문리뷰] Is Chain-of-Thought Reasoning of LLMs a Mirage? A Data Distribution Lens\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Zhen Tan이 [arXiv]에 게시한 'Is Chain-of-Thought Reasoning of LLMs a Mirage? A Data Distribution Lens' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-07 13:38:21+0900\",\"children\":\"2025년 8월 7일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Chain-of-Thought\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Chain-of-Thought\"]}],[\"$\",\"span\",\"LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLMs\"]}],[\"$\",\"span\",\"OOD Generalization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"OOD Generalization\"]}],[\"$\",\"span\",\"Data Distribution Shift\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Distribution Shift\"]}],[\"$\",\"span\",\"Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reasoning\"]}],[\"$\",\"span\",\"Pattern Matching\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Pattern Matching\"]}],[\"$\",\"span\",\"DataAlchemy\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"DataAlchemy\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-7-IFDECORATOR_Wrapping_Instruction_Following_Reinforcement_Learning_with_Verifiable_Rewards\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-7-IFDECORATOR_Wrapping_Instruction_Following_Reinforcement_Learning_with_Verifiable_Rewards/\",\"children\":\"[논문리뷰] IFDECORATOR: Wrapping Instruction Following Reinforcement Learning with Verifiable Rewards\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Ling-I Wu이 [arXiv]에 게시한 'IFDECORATOR: Wrapping Instruction Following Reinforcement Learning with Verifiable Rewards' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-07 13:38:21+0900\",\"children\":\"2025년 8월 7일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Instruction Following\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Instruction Following\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Reward Hacking\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reward Hacking\"]}],[\"$\",\"span\",\"LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLMs\"]}],[\"$\",\"span\",\"Curriculum Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Curriculum Learning\"]}],[\"$\",\"span\",\"Data Flywheel\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Flywheel\"]}],[\"$\",\"span\",\"Verifiable Rewards\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Verifiable Rewards\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-7-IAUNet_Instance-Aware_U-Net\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-7-IAUNet_Instance-Aware_U-Net/\",\"children\":\"[논문리뷰] IAUNet: Instance-Aware U-Net\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Dmytro Fishman이 [arXiv]에 게시한 'IAUNet: Instance-Aware U-Net' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-07 13:38:21+0900\",\"children\":\"2025년 8월 7일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Instance Segmentation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Instance Segmentation\"]}],[\"$\",\"span\",\"U-Net\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"U-Net\"]}],[\"$\",\"span\",\"Query-based Model\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Query-based Model\"]}],[\"$\",\"span\",\"Transformer Decoder\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Transformer Decoder\"]}],[\"$\",\"span\",\"Biomedical Imaging\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Biomedical Imaging\"]}],[\"$\",\"span\",\"Cell Segmentation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Cell Segmentation\"]}],[\"$\",\"span\",\"Deep Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Deep Learning\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-7-HPSv3_Towards_Wide-Spectrum_Human_Preference_Score\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-7-HPSv3_Towards_Wide-Spectrum_Human_Preference_Score/\",\"children\":\"[논문리뷰] HPSv3: Towards Wide-Spectrum Human Preference Score\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Hongsheng Li이 [arXiv]에 게시한 'HPSv3: Towards Wide-Spectrum Human Preference Score' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-07 13:38:21+0900\",\"children\":\"2025년 8월 7일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Human Preference Score\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Human Preference Score\"]}],[\"$\",\"span\",\"Text-to-Image Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Text-to-Image Generation\"]}],[\"$\",\"span\",\"Image Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image Evaluation\"]}],[\"$\",\"span\",\"Vision-Language Models (VLMs)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision-Language Models (VLMs)\"]}],[\"$\",\"span\",\"Uncertainty-Aware Ranking Loss\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Uncertainty-Aware Ranking Loss\"]}],[\"$\",\"span\",\"Dataset\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dataset\"]}],[\"$\",\"span\",\"Iterative Refinement\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Iterative Refinement\"]}],[\"$\",\"span\",\"Chain-of-Thought\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Chain-of-Thought\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-7-Gaussian_Variation_Field_Diffusion_for_High-fidelity_Video-to-4D_Synthesis\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-7-Gaussian_Variation_Field_Diffusion_for_High-fidelity_Video-to-4D_Synthesis/\",\"children\":\"[논문리뷰] Gaussian Variation Field Diffusion for High-fidelity Video-to-4D Synthesis\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Feng Zhao이 [arXiv]에 게시한 'Gaussian Variation Field Diffusion for High-fidelity Video-to-4D Synthesis' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-07 13:38:21+0900\",\"children\":\"2025년 8월 7일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"4D Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"4D Generation\"]}],[\"$\",\"span\",\"Video-to-3D Synthesis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video-to-3D Synthesis\"]}],[\"$\",\"span\",\"Gaussian Splatting\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Gaussian Splatting\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}],[\"$\",\"span\",\"Latent Space Modeling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Latent Space Modeling\"]}],[\"$\",\"span\",\"Variational Autoencoder\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Variational Autoencoder\"]}],[\"$\",\"span\",\"Temporal Coherence\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Temporal Coherence\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-7-EVOC2RUST_A_Skeleton-guided_Framework_for_Project-Level_C-to-Rust_Translation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-7-EVOC2RUST_A_Skeleton-guided_Framework_for_Project-Level_C-to-Rust_Translation/\",\"children\":\"[논문리뷰] EVOC2RUST: A Skeleton-guided Framework for Project-Level C-to-Rust Translation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Dong Chen이 [arXiv]에 게시한 'EVOC2RUST: A Skeleton-guided Framework for Project-Level C-to-Rust Translation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-07 13:38:21+0900\",\"children\":\"2025년 8월 7일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"C-to-Rust Conversion\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"C-to-Rust Conversion\"]}],[\"$\",\"span\",\"Project-Level Translation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Project-Level Translation\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Code Synthesis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Code Synthesis\"]}],[\"$\",\"span\",\"Memory Safety\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Memory Safety\"]}],[\"$\",\"span\",\"Software Migration\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Software Migration\"]}],[\"$\",\"span\",\"Hybrid Translation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Hybrid Translation\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-7-Enhancing_Vision-Language_Model_Training_with_Reinforcement_Learning_in_Synthetic_Worlds_for_Real-World_Success\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-7-Enhancing_Vision-Language_Model_Training_with_Reinforcement_Learning_in_Synthetic_Worlds_for_Real-World_Success/\",\"children\":\"[논문리뷰] Enhancing Vision-Language Model Training with Reinforcement Learning in Synthetic Worlds for Real-World Success\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Ruslan Rakhimov이 [arXiv]에 게시한 'Enhancing Vision-Language Model Training with Reinforcement Learning in Synthetic Worlds for Real-World Success' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-07 13:38:21+0900\",\"children\":\"2025년 8월 7일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Vision-Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision-Language Models\"]}],[\"$\",\"span\",\"Synthetic Worlds\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Synthetic Worlds\"]}],[\"$\",\"span\",\"Transfer Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Transfer Learning\"]}],[\"$\",\"span\",\"PPO\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"PPO\"]}],[\"$\",\"span\",\"Actor-Critic\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Actor-Critic\"]}],[\"$\",\"span\",\"Embodied AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Embodied AI\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-7-Efficient_Agents_Building_Effective_Agents_While_Reducing_Cost\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-7-Efficient_Agents_Building_Effective_Agents_While_Reducing_Cost/\",\"children\":\"[논문리뷰] Efficient Agents: Building Effective Agents While Reducing Cost\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yue Hou이 [arXiv]에 게시한 'Efficient Agents: Building Effective Agents While Reducing Cost' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-07 13:38:21+0900\",\"children\":\"2025년 8월 7일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLM Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Agents\"]}],[\"$\",\"span\",\"Cost Efficiency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Cost Efficiency\"]}],[\"$\",\"span\",\"Performance-Cost Trade-off\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Performance-Cost Trade-off\"]}],[\"$\",\"span\",\"Agent Frameworks\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Agent Frameworks\"]}],[\"$\",\"span\",\"GAIA Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"GAIA Benchmark\"]}],[\"$\",\"span\",\"Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Optimization\"]}],[\"$\",\"span\",\"Resource Management\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Resource Management\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-7-DreamVVT_Mastering_Realistic_Video_Virtual_Try-On_in_the_Wild_via_a_Stage-Wise_Diffusion_Transformer_Framework\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-7-DreamVVT_Mastering_Realistic_Video_Virtual_Try-On_in_the_Wild_via_a_Stage-Wise_Diffusion_Transformer_Framework/\",\"children\":\"[논문리뷰] DreamVVT: Mastering Realistic Video Virtual Try-On in the Wild via a Stage-Wise Diffusion Transformer Framework\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Chao Liang이 [arXiv]에 게시한 'DreamVVT: Mastering Realistic Video Virtual Try-On in the Wild via a Stage-Wise Diffusion Transformer Framework' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-07 13:38:21+0900\",\"children\":\"2025년 8월 7일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Video Virtual Try-On\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video Virtual Try-On\"]}],[\"$\",\"span\",\"Diffusion Transformers\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Transformers\"]}],[\"$\",\"span\",\"Stage-Wise Framework\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Stage-Wise Framework\"]}],[\"$\",\"span\",\"Vision-Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision-Language Models\"]}],[\"$\",\"span\",\"LoRA\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LoRA\"]}],[\"$\",\"span\",\"Temporal Consistency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Temporal Consistency\"]}],[\"$\",\"span\",\"Garment Preservation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Garment Preservation\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-7-CoTox_Chain-of-Thought-Based_Molecular_Toxicity_Reasoning_and_Prediction\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-7-CoTox_Chain-of-Thought-Based_Molecular_Toxicity_Reasoning_and_Prediction/\",\"children\":\"[논문리뷰] CoTox: Chain-of-Thought-Based Molecular Toxicity Reasoning and Prediction\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Donghyeon Lee이 [arXiv]에 게시한 'CoTox: Chain-of-Thought-Based Molecular Toxicity Reasoning and Prediction' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-07 13:38:21+0900\",\"children\":\"2025년 8월 7일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Toxicity Prediction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Toxicity Prediction\"]}],[\"$\",\"span\",\"Large Language Model\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Model\"]}],[\"$\",\"span\",\"Chain-of-Thought\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Chain-of-Thought\"]}],[\"$\",\"span\",\"Drug Development\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Drug Development\"]}],[\"$\",\"span\",\"Cheminformatics\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Cheminformatics\"]}],[\"$\",\"span\",\"Interpretable AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Interpretable AI\"]}],[\"$\",\"span\",\"IUPAC Nomenclature\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"IUPAC Nomenclature\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-7-C3D-AD_Toward_Continual_3D_Anomaly_Detection_via_Kernel_Attention_with_Learnable_Advisor\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-7-C3D-AD_Toward_Continual_3D_Anomaly_Detection_via_Kernel_Attention_with_Learnable_Advisor/\",\"children\":\"[논문리뷰] C3D-AD: Toward Continual 3D Anomaly Detection via Kernel Attention with Learnable Advisor\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Jinbao Wang이 [arXiv]에 게시한 'C3D-AD: Toward Continual 3D Anomaly Detection via Kernel Attention with Learnable Advisor' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-07 13:38:21+0900\",\"children\":\"2025년 8월 7일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"3D Anomaly Detection\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D Anomaly Detection\"]}],[\"$\",\"span\",\"Continual Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Continual Learning\"]}],[\"$\",\"span\",\"Kernel Attention\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Kernel Attention\"]}],[\"$\",\"span\",\"Learnable Advisor\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Learnable Advisor\"]}],[\"$\",\"span\",\"Parameter Perturbation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Parameter Perturbation\"]}],[\"$\",\"span\",\"Point Cloud\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Point Cloud\"]}],[\"$\",\"span\",\"Industrial AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Industrial AI\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-7-A_Coarse-to-Fine_Approach_to_Multi-Modality_3D_Occupancy_Grounding\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-7-A_Coarse-to-Fine_Approach_to_Multi-Modality_3D_Occupancy_Grounding/\",\"children\":\"[논문리뷰] A Coarse-to-Fine Approach to Multi-Modality 3D Occupancy Grounding\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Jianke Zhu이 [arXiv]에 게시한 'A Coarse-to-Fine Approach to Multi-Modality 3D Occupancy Grounding' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-07 13:38:21+0900\",\"children\":\"2025년 8월 7일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"3D Occupancy Grounding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D Occupancy Grounding\"]}],[\"$\",\"span\",\"Multi-modal Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-modal Learning\"]}],[\"$\",\"span\",\"Natural Language Understanding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Natural Language Understanding\"]}],[\"$\",\"span\",\"Autonomous Driving\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Autonomous Driving\"]}],[\"$\",\"span\",\"Voxel-based Prediction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Voxel-based Prediction\"]}],[\"$\",\"span\",\"Benchmark Dataset\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmark Dataset\"]}],[\"$\",\"span\",\"Coarse-to-Fine\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Coarse-to-Fine\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-7-Agent_Lightning_Train_ANY_AI_Agents_with_Reinforcement_Learning\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-7-Agent_Lightning_Train_ANY_AI_Agents_with_Reinforcement_Learning/\",\"children\":\"[논문리뷰] Agent Lightning: Train ANY AI Agents with Reinforcement Learning\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Zilong Wang이 [arXiv]에 게시한 'Agent Lightning: Train ANY AI Agents with Reinforcement Learning' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-07 13:38:21+0900\",\"children\":\"2025년 8월 7일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"AI Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"AI Agents\"]}],[\"$\",\"span\",\"Framework\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Framework\"]}],[\"$\",\"span\",\"Markov Decision Process\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Markov Decision Process\"]}],[\"$\",\"span\",\"Hierarchical RL\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Hierarchical RL\"]}],[\"$\",\"span\",\"Training-Agent Disaggregation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Training-Agent Disaggregation\"]}],[\"$\",\"span\",\"Observability\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Observability\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-6-TRACEALIGN_--_Tracing_the_Drift_Attributing_Alignment_Failures_to_Training-Time_Belief_Sources_in_LLMs\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-6-TRACEALIGN_--_Tracing_the_Drift_Attributing_Alignment_Failures_to_Training-Time_Belief_Sources_in_LLMs/\",\"children\":\"[논문리뷰] TRACEALIGN -- Tracing the Drift: Attributing Alignment Failures to Training-Time Belief Sources in LLMs\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Aman Chadha이 [arXiv]에 게시한 'TRACEALIGN -- Tracing the Drift: Attributing Alignment Failures to Training-Time Belief Sources in LLMs' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-06 13:46:36+0900\",\"children\":\"2025년 8월 6일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLM Alignment\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Alignment\"]}],[\"$\",\"span\",\"Alignment Drift\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Alignment Drift\"]}],[\"$\",\"span\",\"Training Data Provenance\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Training Data Provenance\"]}],[\"$\",\"span\",\"Belief Conflict Index (BCI)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Belief Conflict Index (BCI)\"]}],[\"$\",\"span\",\"Suffix Array\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Suffix Array\"]}],[\"$\",\"span\",\"Safety Interventions\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Safety Interventions\"]}],[\"$\",\"span\",\"Reinforcement Learning from Human Feedback\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning from Human Feedback\"]}],[\"$\",\"span\",\"Explainable AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Explainable AI\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-6-Tool-integrated_Reinforcement_Learning_for_Repo_Deep_Search\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-6-Tool-integrated_Reinforcement_Learning_for_Repo_Deep_Search/\",\"children\":\"[논문리뷰] Tool-integrated Reinforcement Learning for Repo Deep Search\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yanzhen Zou이 [arXiv]에 게시한 'Tool-integrated Reinforcement Learning for Repo Deep Search' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-06 13:46:36+0900\",\"children\":\"2025년 8월 6일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Issue Localization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Issue Localization\"]}],[\"$\",\"span\",\"Large Language Models (LLMs)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models (LLMs)\"]}],[\"$\",\"span\",\"Reinforcement Learning (RL)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning (RL)\"]}],[\"$\",\"span\",\"Supervised Fine-tuning (SFT)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Supervised Fine-tuning (SFT)\"]}],[\"$\",\"span\",\"Tool-integrated Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Tool-integrated Agents\"]}],[\"$\",\"span\",\"Software Engineering\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Software Engineering\"]}],[\"$\",\"span\",\"Code Search\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Code Search\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-6-Skywork_UniPic_Unified_Autoregressive_Modeling_for_Visual_Understanding_and_Generation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-6-Skywork_UniPic_Unified_Autoregressive_Modeling_for_Visual_Understanding_and_Generation/\",\"children\":\"[논문리뷰] Skywork UniPic: Unified Autoregressive Modeling for Visual Understanding and Generation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Tianyidan Xie이 [arXiv]에 게시한 'Skywork UniPic: Unified Autoregressive Modeling for Visual Understanding and Generation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-06 13:46:36+0900\",\"children\":\"2025년 8월 6일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Autoregressive Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Autoregressive Models\"]}],[\"$\",\"span\",\"Multimodal AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal AI\"]}],[\"$\",\"span\",\"Image Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image Generation\"]}],[\"$\",\"span\",\"Image Editing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image Editing\"]}],[\"$\",\"span\",\"Visual Understanding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Visual Understanding\"]}],[\"$\",\"span\",\"Unified Architecture\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Unified Architecture\"]}],[\"$\",\"span\",\"Parameter Efficiency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Parameter Efficiency\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-6-Seed_Diffusion_A_Large-Scale_Diffusion_Language_Model_with_High-Speed_Inference\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-6-Seed_Diffusion_A_Large-Scale_Diffusion_Language_Model_with_High-Speed_Inference/\",\"children\":\"[논문리뷰] Seed Diffusion: A Large-Scale Diffusion Language Model with High-Speed Inference\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Fan Xia이 [arXiv]에 게시한 'Seed Diffusion: A Large-Scale Diffusion Language Model with High-Speed Inference' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-06 13:46:36+0900\",\"children\":\"2025년 8월 6일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}],[\"$\",\"span\",\"Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Language Models\"]}],[\"$\",\"span\",\"Code Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Code Generation\"]}],[\"$\",\"span\",\"Non-Autoregressive Inference\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Non-Autoregressive Inference\"]}],[\"$\",\"span\",\"High-Speed Inference\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"High-Speed Inference\"]}],[\"$\",\"span\",\"Discrete Diffusion\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Discrete Diffusion\"]}],[\"$\",\"span\",\"LLM Inference\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Inference\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-6-Multi-human_Interactive_Talking_Dataset\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-6-Multi-human_Interactive_Talking_Dataset/\",\"children\":\"[논문리뷰] Multi-human Interactive Talking Dataset\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Mike Zheng Shou이 [arXiv]에 게시한 'Multi-human Interactive Talking Dataset' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-06 13:46:36+0900\",\"children\":\"2025년 8월 6일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Multi-human Video Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-human Video Generation\"]}],[\"$\",\"span\",\"Interactive Talking\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Interactive Talking\"]}],[\"$\",\"span\",\"Dataset\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dataset\"]}],[\"$\",\"span\",\"Audio-driven Animation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Audio-driven Animation\"]}],[\"$\",\"span\",\"Pose Control\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Pose Control\"]}],[\"$\",\"span\",\"Speech Interaction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Speech Interaction\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-6-LongVie_Multimodal-Guided_Controllable_Ultra-Long_Video_Generation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-6-LongVie_Multimodal-Guided_Controllable_Ultra-Long_Video_Generation/\",\"children\":\"[논문리뷰] LongVie: Multimodal-Guided Controllable Ultra-Long Video Generation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Chenyang Si이 [arXiv]에 게시한 'LongVie: Multimodal-Guided Controllable Ultra-Long Video Generation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-06 13:46:36+0900\",\"children\":\"2025년 8월 6일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Ultra-long Video Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Ultra-long Video Generation\"]}],[\"$\",\"span\",\"Multimodal Guidance\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Guidance\"]}],[\"$\",\"span\",\"Controllable Video Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Controllable Video Generation\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}],[\"$\",\"span\",\"Temporal Consistency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Temporal Consistency\"]}],[\"$\",\"span\",\"Visual Quality\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Visual Quality\"]}],[\"$\",\"span\",\"Autoregressive Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Autoregressive Generation\"]}],[\"$\",\"span\",\"Degradation-aware Training\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Degradation-aware Training\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-6-LiveMCPBench_Can_Agents_Navigate_an_Ocean_of_MCP_Tools\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-6-LiveMCPBench_Can_Agents_Navigate_an_Ocean_of_MCP_Tools/\",\"children\":\"[논문리뷰] LiveMCPBench: Can Agents Navigate an Ocean of MCP Tools?\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yaojie Lu이 [arXiv]에 게시한 'LiveMCPBench: Can Agents Navigate an Ocean of MCP Tools?' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-06 13:46:36+0900\",\"children\":\"2025년 8월 6일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLM Agent\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Agent\"]}],[\"$\",\"span\",\"Tool-use\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Tool-use\"]}],[\"$\",\"span\",\"MCP\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"MCP\"]}],[\"$\",\"span\",\"Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmark\"]}],[\"$\",\"span\",\"Large-scale\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large-scale\"]}],[\"$\",\"span\",\"Real-world tasks\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Real-world tasks\"]}],[\"$\",\"span\",\"Automated Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Automated Evaluation\"]}],[\"$\",\"span\",\"Meta-tool-learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Meta-tool-learning\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-6-LAMIC_Layout-Aware_Multi-Image_Composition_via_Scalability_of_Multimodal_Diffusion_Transformer\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-6-LAMIC_Layout-Aware_Multi-Image_Composition_via_Scalability_of_Multimodal_Diffusion_Transformer/\",\"children\":\"[논문리뷰] LAMIC: Layout-Aware Multi-Image Composition via Scalability of Multimodal Diffusion Transformer\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Shunyu Yao이 [arXiv]에 게시한 'LAMIC: Layout-Aware Multi-Image Composition via Scalability of Multimodal Diffusion Transformer' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-06 13:46:36+0900\",\"children\":\"2025년 8월 6일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Multi-Image Composition\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-Image Composition\"]}],[\"$\",\"span\",\"Layout Control\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Layout Control\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}],[\"$\",\"span\",\"Transformer\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Transformer\"]}],[\"$\",\"span\",\"Attention Mechanisms\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Attention Mechanisms\"]}],[\"$\",\"span\",\"Training-Free\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Training-Free\"]}],[\"$\",\"span\",\"Zero-Shot Generalization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Zero-Shot Generalization\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-6-Goedel-Prover-V2_Scaling_Formal_Theorem_Proving_with_Scaffolded_Data_Synthesis_and_Self-Correction\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-6-Goedel-Prover-V2_Scaling_Formal_Theorem_Proving_with_Scaffolded_Data_Synthesis_and_Self-Correction/\",\"children\":\"[논문리뷰] Goedel-Prover-V2: Scaling Formal Theorem Proving with Scaffolded Data Synthesis and Self-Correction\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Jui-Hui Chung이 [arXiv]에 게시한 'Goedel-Prover-V2: Scaling Formal Theorem Proving with Scaffolded Data Synthesis and Self-Correction' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-06 13:46:36+0900\",\"children\":\"2025년 8월 6일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Automated Theorem Proving\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Automated Theorem Proving\"]}],[\"$\",\"span\",\"Formal Verification\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Formal Verification\"]}],[\"$\",\"span\",\"Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Language Models\"]}],[\"$\",\"span\",\"Self-Correction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Self-Correction\"]}],[\"$\",\"span\",\"Data Synthesis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Synthesis\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Model Averaging\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Model Averaging\"]}],[\"$\",\"span\",\"Lean\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Lean\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-6-CRINN_Contrastive_Reinforcement_Learning_for_Approximate_Nearest_Neighbor_Search\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-6-CRINN_Contrastive_Reinforcement_Learning_for_Approximate_Nearest_Neighbor_Search/\",\"children\":\"[논문리뷰] CRINN: Contrastive Reinforcement Learning for Approximate Nearest Neighbor Search\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Jiwei Li이 [arXiv]에 게시한 'CRINN: Contrastive Reinforcement Learning for Approximate Nearest Neighbor Search' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-06 13:46:36+0900\",\"children\":\"2025년 8월 6일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Approximate Nearest Neighbor Search\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Approximate Nearest Neighbor Search\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Code Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Code Optimization\"]}],[\"$\",\"span\",\"HNSW\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"HNSW\"]}],[\"$\",\"span\",\"Retrieval-Augmented Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Retrieval-Augmented Generation\"]}],[\"$\",\"span\",\"Contrastive Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Contrastive Learning\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-6-CompassVerifier_A_Unified_and_Robust_Verifier_for_LLMs_Evaluation_and_Outcome_Reward\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-6-CompassVerifier_A_Unified_and_Robust_Verifier_for_LLMs_Evaluation_and_Outcome_Reward/\",\"children\":\"[논문리뷰] CompassVerifier: A Unified and Robust Verifier for LLMs Evaluation and Outcome Reward\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Songyang Gao이 [arXiv]에 게시한 'CompassVerifier: A Unified and Robust Verifier for LLMs Evaluation and Outcome Reward' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-06 13:46:36+0900\",\"children\":\"2025년 8월 6일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLM Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Evaluation\"]}],[\"$\",\"span\",\"Answer Verification\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Answer Verification\"]}],[\"$\",\"span\",\"Reward Model\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reward Model\"]}],[\"$\",\"span\",\"Benchmarking\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmarking\"]}],[\"$\",\"span\",\"Data Augmentation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Augmentation\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Formula Verification\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Formula Verification\"]}],[\"$\",\"span\",\"Hallucination Detection\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Hallucination Detection\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-6-ChartCap_Mitigating_Hallucination_of_Dense_Chart_Captioning\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-6-ChartCap_Mitigating_Hallucination_of_Dense_Chart_Captioning/\",\"children\":\"[논문리뷰] ChartCap: Mitigating Hallucination of Dense Chart Captioning\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Gunhee Kim이 [arXiv]에 게시한 'ChartCap: Mitigating Hallucination of Dense Chart Captioning' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-06 13:46:36+0900\",\"children\":\"2025년 8월 6일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Chart Captioning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Chart Captioning\"]}],[\"$\",\"span\",\"Hallucination Mitigation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Hallucination Mitigation\"]}],[\"$\",\"span\",\"Dataset Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dataset Generation\"]}],[\"$\",\"span\",\"Visual Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Visual Language Models\"]}],[\"$\",\"span\",\"Cycle Consistency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Cycle Consistency\"]}],[\"$\",\"span\",\"Reference-Free Metric\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reference-Free Metric\"]}],[\"$\",\"span\",\"Data Visualization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Visualization\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-6-AlignGuard-LoRA_Alignment-Preserving_Fine-Tuning_via_Fisher-Guided_Decomposition_and_Riemannian-Geodesic_Collision_Regularization\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-6-AlignGuard-LoRA_Alignment-Preserving_Fine-Tuning_via_Fisher-Guided_Decomposition_and_Riemannian-Geodesic_Collision_Regularization/\",\"children\":\"[논문리뷰] AlignGuard-LoRA: Alignment-Preserving Fine-Tuning via Fisher-Guided Decomposition and Riemannian-Geodesic Collision Regularization\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Aman Chadha이 [arXiv]에 게시한 'AlignGuard-LoRA: Alignment-Preserving Fine-Tuning via Fisher-Guided Decomposition and Riemannian-Geodesic Collision Regularization' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-06 13:46:36+0900\",\"children\":\"2025년 8월 6일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Alignment Preservation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Alignment Preservation\"]}],[\"$\",\"span\",\"Fine-Tuning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Fine-Tuning\"]}],[\"$\",\"span\",\"LoRA\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LoRA\"]}],[\"$\",\"span\",\"Fisher Information Matrix\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Fisher Information Matrix\"]}],[\"$\",\"span\",\"Catastrophic Forgetting\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Catastrophic Forgetting\"]}],[\"$\",\"span\",\"LLM Safety\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Safety\"]}],[\"$\",\"span\",\"Riemannian Geometry\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Riemannian Geometry\"]}],[\"$\",\"span\",\"Parameter-Efficient Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Parameter-Efficient Learning\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-5-VeOmni__Scaling_Any_Modality_Model_Training_with_Model-Centric __Distributed_Recipe_Zoo\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-5-VeOmni__Scaling_Any_Modality_Model_Training_with_Model-Centric __Distributed_Recipe_Zoo/\",\"children\":\"[논문리뷰] VeOmni: Scaling Any Modality Model Training with Model-Centric Distributed Recipe Zoo\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Bin Jia이 [arXiv]에 게시한 'VeOmni: Scaling Any Modality Model Training with Model-Centric Distributed Recipe Zoo' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-05 11:40:52+0900\",\"children\":\"2025년 8월 5일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Omni-modal LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Omni-modal LLMs\"]}],[\"$\",\"span\",\"Distributed Training\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Distributed Training\"]}],[\"$\",\"span\",\"Model-centric\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Model-centric\"]}],[\"$\",\"span\",\"Parallelism\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Parallelism\"]}],[\"$\",\"span\",\"FSDP\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"FSDP\"]}],[\"$\",\"span\",\"Sequence Parallelism\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Sequence Parallelism\"]}],[\"$\",\"span\",\"Expert Parallelism\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Expert Parallelism\"]}],[\"$\",\"span\",\"Mixture-of-Experts\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Mixture-of-Experts\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-5-SitEmb-v1.5__Improved_Context-Aware_Dense_Retrieval_for_Semantic __Association_and_Long_Story_Comprehension\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-5-SitEmb-v1.5__Improved_Context-Aware_Dense_Retrieval_for_Semantic __Association_and_Long_Story_Comprehension/\",\"children\":\"[논문리뷰] SitEmb-v1.5: Improved Context-Aware Dense Retrieval for Semantic Association and Long Story Comprehension\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Liyan Xu이 [arXiv]에 게시한 'SitEmb-v1.5: Improved Context-Aware Dense Retrieval for Semantic Association and Long Story Comprehension' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-05 11:40:52+0900\",\"children\":\"2025년 8월 5일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Dense Retrieval\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dense Retrieval\"]}],[\"$\",\"span\",\"Context-Aware Embedding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Context-Aware Embedding\"]}],[\"$\",\"span\",\"RAG\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"RAG\"]}],[\"$\",\"span\",\"Long Document Comprehension\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Long Document Comprehension\"]}],[\"$\",\"span\",\"Residual Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Residual Learning\"]}],[\"$\",\"span\",\"Semantic Association\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Semantic Association\"]}],[\"$\",\"span\",\"Text Embedding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Text Embedding\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-5-RoboMemory__A_Brain-inspired_Multi-memory_Agentic_Framework_for_Lifelong __Learning_in_Physical_Embodied_Systems\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-5-RoboMemory__A_Brain-inspired_Multi-memory_Agentic_Framework_for_Lifelong __Learning_in_Physical_Embodied_Systems/\",\"children\":\"[논문리뷰] RoboMemory: A Brain-inspired Multi-memory Agentic Framework for Lifelong Learning in Physical Embodied Systems\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Junkun Hong이 [arXiv]에 게시한 'RoboMemory: A Brain-inspired Multi-memory Agentic Framework for Lifelong Learning in Physical Embodied Systems' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-05 11:40:52+0900\",\"children\":\"2025년 8월 5일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Brain-inspired AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Brain-inspired AI\"]}],[\"$\",\"span\",\"Lifelong Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Lifelong Learning\"]}],[\"$\",\"span\",\"Embodied AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Embodied AI\"]}],[\"$\",\"span\",\"Multi-memory Systems\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-memory Systems\"]}],[\"$\",\"span\",\"Knowledge Graph\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Knowledge Graph\"]}],[\"$\",\"span\",\"Robotics\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Robotics\"]}],[\"$\",\"span\",\"Closed-Loop Planning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Closed-Loop Planning\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-5-Qwen-Image_Technical_Report\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-5-Qwen-Image_Technical_Report/\",\"children\":\"[논문리뷰] Qwen-Image Technical Report\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Kaiyuan Gao이 [arXiv]에 게시한 'Qwen-Image Technical Report' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-05 11:40:52+0900\",\"children\":\"2025년 8월 5일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Image Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image Generation\"]}],[\"$\",\"span\",\"Text-to-Image\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Text-to-Image\"]}],[\"$\",\"span\",\"Image Editing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image Editing\"]}],[\"$\",\"span\",\"Text Rendering\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Text Rendering\"]}],[\"$\",\"span\",\"Multimodal Diffusion Transformer\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Diffusion Transformer\"]}],[\"$\",\"span\",\"Curriculum Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Curriculum Learning\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Foundation Model\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Foundation Model\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-5-Personalized_Safety_Alignment_for_Text-to-Image_Diffusion_Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-5-Personalized_Safety_Alignment_for_Text-to-Image_Diffusion_Models/\",\"children\":\"[논문리뷰] Personalized Safety Alignment for Text-to-Image Diffusion Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Kaidong Yu이 [arXiv]에 게시한 'Personalized Safety Alignment for Text-to-Image Diffusion Models' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-05 11:40:52+0900\",\"children\":\"2025년 8월 5일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Personalized Safety Alignment\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Personalized Safety Alignment\"]}],[\"$\",\"span\",\"Text-to-Image Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Text-to-Image Diffusion Models\"]}],[\"$\",\"span\",\"DPO\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"DPO\"]}],[\"$\",\"span\",\"User Preferences\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"User Preferences\"]}],[\"$\",\"span\",\"Content Moderation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Content Moderation\"]}],[\"$\",\"span\",\"Generative AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generative AI\"]}],[\"$\",\"span\",\"Cross-Attention\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Cross-Attention\"]}],[\"$\",\"span\",\"Safety Alignment\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Safety Alignment\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-5-Llama-3.1-FoundationAI-SecurityLLM-8B-Instruct_Technical_Report\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-5-Llama-3.1-FoundationAI-SecurityLLM-8B-Instruct_Technical_Report/\",\"children\":\"[논문리뷰] Llama-3.1-FoundationAI-SecurityLLM-8B-Instruct Technical Report\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Anu Vellore이 [arXiv]에 게시한 'Llama-3.1-FoundationAI-SecurityLLM-8B-Instruct Technical Report' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-05 11:40:52+0900\",\"children\":\"2025년 8월 5일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Large Language Model\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Model\"]}],[\"$\",\"span\",\"Cybersecurity\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Cybersecurity\"]}],[\"$\",\"span\",\"Instruction Tuning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Instruction Tuning\"]}],[\"$\",\"span\",\"Direct Preference Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Direct Preference Optimization\"]}],[\"$\",\"span\",\"Cyber Threat Intelligence\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Cyber Threat Intelligence\"]}],[\"$\",\"span\",\"Foundation Model\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Foundation Model\"]}],[\"$\",\"span\",\"Chatbot\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Chatbot\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-5-InstructVLA__Vision-Language-Action_Instruction_Tuning_from __Understanding_to_Manipulation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-5-InstructVLA__Vision-Language-Action_Instruction_Tuning_from __Understanding_to_Manipulation/\",\"children\":\"[논문리뷰] InstructVLA: Vision-Language-Action Instruction Tuning from Understanding to Manipulation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yang Tian이 [arXiv]에 게시한 'InstructVLA: Vision-Language-Action Instruction Tuning from Understanding to Manipulation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-05 11:40:52+0900\",\"children\":\"2025년 8월 5일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Vision-Language-Action (VLA)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision-Language-Action (VLA)\"]}],[\"$\",\"span\",\"Instruction Tuning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Instruction Tuning\"]}],[\"$\",\"span\",\"Multimodal Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Reasoning\"]}],[\"$\",\"span\",\"Robotic Manipulation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Robotic Manipulation\"]}],[\"$\",\"span\",\"Catastrophic Forgetting\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Catastrophic Forgetting\"]}],[\"$\",\"span\",\"Mixture-of-Experts (MoE)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Mixture-of-Experts (MoE)\"]}],[\"$\",\"span\",\"Flow Matching\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Flow Matching\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-5-Exploitation_Is_All_You_Need..._for_Exploration\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-5-Exploitation_Is_All_You_Need..._for_Exploration/\",\"children\":\"[논문리뷰] Exploitation Is All You Need... for Exploration\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Jesse Roberts이 [arXiv]에 게시한 'Exploitation Is All You Need... for Exploration' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-05 11:40:52+0900\",\"children\":\"2025년 8월 5일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Exploration-Exploitation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Exploration-Exploitation\"]}],[\"$\",\"span\",\"Meta-RL\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Meta-RL\"]}],[\"$\",\"span\",\"Transformer Architecture\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Transformer Architecture\"]}],[\"$\",\"span\",\"Emergent Behavior\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Emergent Behavior\"]}],[\"$\",\"span\",\"Multi-Armed Bandits\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-Armed Bandits\"]}],[\"$\",\"span\",\"Gridworlds\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Gridworlds\"]}],[\"$\",\"span\",\"Pseudo-Thompson Sampling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Pseudo-Thompson Sampling\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-5-Cyber-Zero__Training_Cybersecurity_Agents_without_Runtime\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-5-Cyber-Zero__Training_Cybersecurity_Agents_without_Runtime/\",\"children\":\"[논문리뷰] Cyber-Zero: Training Cybersecurity Agents without Runtime\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Zijian Wang이 [arXiv]에 게시한 'Cyber-Zero: Training Cybersecurity Agents without Runtime' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-05 11:40:52+0900\",\"children\":\"2025년 8월 5일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Cybersecurity Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Cybersecurity Agents\"]}],[\"$\",\"span\",\"LLM Training\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Training\"]}],[\"$\",\"span\",\"Trajectory Synthesis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Trajectory Synthesis\"]}],[\"$\",\"span\",\"Runtime-Free Training\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Runtime-Free Training\"]}],[\"$\",\"span\",\"CTF Challenges\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"CTF Challenges\"]}],[\"$\",\"span\",\"LLM Simulation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Simulation\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-5-CellForge__Agentic_Design_of_Virtual_Cell_Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-5-CellForge__Agentic_Design_of_Virtual_Cell_Models/\",\"children\":\"[논문리뷰] CellForge: Agentic Design of Virtual Cell Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Daniel Shao이 [arXiv]에 게시한 'CellForge: Agentic Design of Virtual Cell Models' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-05 11:40:52+0900\",\"children\":\"2025년 8월 5일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"AI Scientist\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"AI Scientist\"]}],[\"$\",\"span\",\"Multi-Agent System\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-Agent System\"]}],[\"$\",\"span\",\"Virtual Cell Modeling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Virtual Cell Modeling\"]}],[\"$\",\"span\",\"Single-Cell Perturbation Prediction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Single-Cell Perturbation Prediction\"]}],[\"$\",\"span\",\"Deep Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Deep Learning\"]}],[\"$\",\"span\",\"Automated Model Design\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Automated Model Design\"]}],[\"$\",\"span\",\"Code Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Code Generation\"]}],[\"$\",\"span\",\"Retrieval-Augmented Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Retrieval-Augmented Generation\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-5-Beyond_the_Trade-off__Self-Supervised_Reinforcement_Learning_for __Reasoning_Models'_Instruction_Following\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-5-Beyond_the_Trade-off__Self-Supervised_Reinforcement_Learning_for __Reasoning_Models'_Instruction_Following/\",\"children\":\"[논문리뷰] Beyond the Trade-off: Self-Supervised Reinforcement Learning for Reasoning Models' Instruction Following\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Jiaqing Liang이 [arXiv]에 게시한 'Beyond the Trade-off: Self-Supervised Reinforcement Learning for Reasoning Models' Instruction Following' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-05 11:40:52+0900\",\"children\":\"2025년 8월 5일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Self-Supervised RL\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Self-Supervised RL\"]}],[\"$\",\"span\",\"Instruction Following\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Instruction Following\"]}],[\"$\",\"span\",\"Reasoning Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reasoning Models\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Reward Modeling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reward Modeling\"]}],[\"$\",\"span\",\"Curriculum Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Curriculum Learning\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-5-A_Glimpse_to_Compress__Dynamic_Visual_Token_Pruning_for_Large __Vision-Language_Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-5-A_Glimpse_to_Compress__Dynamic_Visual_Token_Pruning_for_Large __Vision-Language_Models/\",\"children\":\"[논문리뷰] A Glimpse to Compress: Dynamic Visual Token Pruning for Large Vision-Language Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Zuxuan Wu이 [arXiv]에 게시한 'A Glimpse to Compress: Dynamic Visual Token Pruning for Large Vision-Language Models' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-05 11:40:52+0900\",\"children\":\"2025년 8월 5일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Large Vision-Language Models (LVLMs)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Vision-Language Models (LVLMs)\"]}],[\"$\",\"span\",\"Visual Token Pruning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Visual Token Pruning\"]}],[\"$\",\"span\",\"Dynamic Compression\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dynamic Compression\"]}],[\"$\",\"span\",\"GlimpsePrune\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"GlimpsePrune\"]}],[\"$\",\"span\",\"Computational Efficiency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Computational Efficiency\"]}],[\"$\",\"span\",\"VQA\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"VQA\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-5-AgentTTS__Large_Language_Model_Agent_for_Test-time_Compute-optimal __Scaling_Strategy_in_Complex_Tasks\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-5-AgentTTS__Large_Language_Model_Agent_for_Test-time_Compute-optimal __Scaling_Strategy_in_Complex_Tasks/\",\"children\":\"[논문리뷰] AgentTTS: Large Language Model Agent for Test-time Compute-optimal Scaling Strategy in Complex Tasks\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Zhiwei Zhang이 [arXiv]에 게시한 'AgentTTS: Large Language Model Agent for Test-time Compute-optimal Scaling Strategy in Complex Tasks' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-05 11:40:52+0900\",\"children\":\"2025년 8월 5일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"LLM Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Agents\"]}],[\"$\",\"span\",\"Test-time Scaling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Test-time Scaling\"]}],[\"$\",\"span\",\"Compute Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Compute Optimization\"]}],[\"$\",\"span\",\"Multi-stage Tasks\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-stage Tasks\"]}],[\"$\",\"span\",\"Resource Allocation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Resource Allocation\"]}],[\"$\",\"span\",\"Search Efficiency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Search Efficiency\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-4-SWE-Exp__Experience-Driven_Software_Issue_Resolution\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-4-SWE-Exp__Experience-Driven_Software_Issue_Resolution/\",\"children\":\"[논문리뷰] SWE-Exp: Experience-Driven Software Issue Resolution\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Heng Lian이 [arXiv]에 게시한 'SWE-Exp: Experience-Driven Software Issue Resolution' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-04 12:17:01+0900\",\"children\":\"2025년 8월 4일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Software Issue Resolution\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Software Issue Resolution\"]}],[\"$\",\"span\",\"LLM Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Agents\"]}],[\"$\",\"span\",\"Experience-Driven Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Experience-Driven Learning\"]}],[\"$\",\"span\",\"Automated Program Repair\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Automated Program Repair\"]}],[\"$\",\"span\",\"Multi-Agent Systems\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-Agent Systems\"]}],[\"$\",\"span\",\"Knowledge Management\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Knowledge Management\"]}],[\"$\",\"span\",\"Continuous Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Continuous Learning\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-4-SWE-Debate__Competitive_Multi-Agent_Debate_for_Software_Issue_Resolution\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-4-SWE-Debate__Competitive_Multi-Agent_Debate_for_Software_Issue_Resolution/\",\"children\":\"[논문리뷰] SWE-Debate: Competitive Multi-Agent Debate for Software Issue Resolution\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Heng Lian이 [arXiv]에 게시한 'SWE-Debate: Competitive Multi-Agent Debate for Software Issue Resolution' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-04 12:17:01+0900\",\"children\":\"2025년 8월 4일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Multi-Agent System\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-Agent System\"]}],[\"$\",\"span\",\"Software Engineering\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Software Engineering\"]}],[\"$\",\"span\",\"Fault Localization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Fault Localization\"]}],[\"$\",\"span\",\"Issue Resolution\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Issue Resolution\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Competitive Debate\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Competitive Debate\"]}],[\"$\",\"span\",\"Graph Traversal\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Graph Traversal\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-4-SpA2V__Harnessing_Spatial_Auditory_Cues_for_Audio-driven_Spatially-aware __Video_Generation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-4-SpA2V__Harnessing_Spatial_Auditory_Cues_for_Audio-driven_Spatially-aware __Video_Generation/\",\"children\":\"[논문리뷰] SpA2V: Harnessing Spatial Auditory Cues for Audio-driven Spatially-aware Video Generation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Long Chen이 [arXiv]에 게시한 'SpA2V: Harnessing Spatial Auditory Cues for Audio-driven Spatially-aware Video Generation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-04 12:17:01+0900\",\"children\":\"2025년 8월 4일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Audio-driven Video Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Audio-driven Video Generation\"]}],[\"$\",\"span\",\"Spatial Auditory Cues\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Spatial Auditory Cues\"]}],[\"$\",\"span\",\"Video Scene Layout\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video Scene Layout\"]}],[\"$\",\"span\",\"MLLM\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"MLLM\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}],[\"$\",\"span\",\"Training-free\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Training-free\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-4-PixNerd__Pixel_Neural_Field_Diffusion\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-4-PixNerd__Pixel_Neural_Field_Diffusion/\",\"children\":\"[논문리뷰] PixNerd: Pixel Neural Field Diffusion\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Limin Wang이 [arXiv]에 게시한 'PixNerd: Pixel Neural Field Diffusion' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-04 12:17:01+0900\",\"children\":\"2025년 8월 4일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}],[\"$\",\"span\",\"Neural Fields\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Neural Fields\"]}],[\"$\",\"span\",\"Pixel Space\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Pixel Space\"]}],[\"$\",\"span\",\"Generative Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generative Models\"]}],[\"$\",\"span\",\"Image Synthesis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image Synthesis\"]}],[\"$\",\"span\",\"Transformer Architecture\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Transformer Architecture\"]}],[\"$\",\"span\",\"End-to-End Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"End-to-End Learning\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-4-Multimodal_Referring_Segmentation__A_Survey\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-4-Multimodal_Referring_Segmentation__A_Survey/\",\"children\":\"[논문리뷰] Multimodal Referring Segmentation: A Survey\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Zuxuan Wu이 [arXiv]에 게시한 'Multimodal Referring Segmentation: A Survey' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-04 12:17:01+0900\",\"children\":\"2025년 8월 4일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Multimodal Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multimodal Learning\"]}],[\"$\",\"span\",\"Referring Segmentation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Referring Segmentation\"]}],[\"$\",\"span\",\"Vision-Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision-Language Models\"]}],[\"$\",\"span\",\"Image Segmentation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image Segmentation\"]}],[\"$\",\"span\",\"Video Segmentation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Video Segmentation\"]}],[\"$\",\"span\",\"3D Vision\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D Vision\"]}],[\"$\",\"span\",\"Survey\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Survey\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-4-Learning_an_Efficient_Multi-Turn_Dialogue_Evaluator_from_Multiple_Judges\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-4-Learning_an_Efficient_Multi-Turn_Dialogue_Evaluator_from_Multiple_Judges/\",\"children\":\"[논문리뷰] Learning an Efficient Multi-Turn Dialogue Evaluator from Multiple Judges\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Chengfei Lv이 [arXiv]에 게시한 'Learning an Efficient Multi-Turn Dialogue Evaluator from Multiple Judges' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-04 12:17:01+0900\",\"children\":\"2025년 8월 4일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Multi-Turn Dialogue Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-Turn Dialogue Evaluation\"]}],[\"$\",\"span\",\"LLM-as-a-Judge\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM-as-a-Judge\"]}],[\"$\",\"span\",\"Multi-Judge Aggregation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-Judge Aggregation\"]}],[\"$\",\"span\",\"Preference Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Preference Learning\"]}],[\"$\",\"span\",\"Dialogue Quality Assessment\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dialogue Quality Assessment\"]}],[\"$\",\"span\",\"Maximum Likelihood Estimation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Maximum Likelihood Estimation\"]}],[\"$\",\"span\",\"Computational Efficiency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Computational Efficiency\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-4-Investigating_Hallucination_in_Conversations_for_Low_Resource_Languages\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-4-Investigating_Hallucination_in_Conversations_for_Low_Resource_Languages/\",\"children\":\"[논문리뷰] Investigating Hallucination in Conversations for Low Resource Languages\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Fatemeh Jamshidi이 [arXiv]에 게시한 'Investigating Hallucination in Conversations for Low Resource Languages' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-04 12:17:01+0900\",\"children\":\"2025년 8월 4일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"LLM Hallucination\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Hallucination\"]}],[\"$\",\"span\",\"Low-resource Languages\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Low-resource Languages\"]}],[\"$\",\"span\",\"Conversational AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Conversational AI\"]}],[\"$\",\"span\",\"ROUGE Score\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"ROUGE Score\"]}],[\"$\",\"span\",\"Cross-lingual Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Cross-lingual Evaluation\"]}],[\"$\",\"span\",\"Factual Consistency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Factual Consistency\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-4-IGL-Nav__Incremental_3D_Gaussian_Localization_for_Image-goal_Navigation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-4-IGL-Nav__Incremental_3D_Gaussian_Localization_for_Image-goal_Navigation/\",\"children\":\"[논문리뷰] IGL-Nav: Incremental 3D Gaussian Localization for Image-goal Navigation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Jianjiang Feng이 [arXiv]에 게시한 'IGL-Nav: Incremental 3D Gaussian Localization for Image-goal Navigation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-04 12:17:01+0900\",\"children\":\"2025년 8월 4일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Image-goal Navigation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image-goal Navigation\"]}],[\"$\",\"span\",\"3D Gaussian Splatting (3DGS)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D Gaussian Splatting (3DGS)\"]}],[\"$\",\"span\",\"Incremental Scene Representation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Incremental Scene Representation\"]}],[\"$\",\"span\",\"Coarse-to-fine Localization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Coarse-to-fine Localization\"]}],[\"$\",\"span\",\"Embodied AI\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Embodied AI\"]}],[\"$\",\"span\",\"Robotics\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Robotics\"]}],[\"$\",\"span\",\"Differentiable Rendering\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Differentiable Rendering\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-4-Beyond_Fixed__Variable-Length_Denoising_for_Diffusion_Large_Language __Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-4-Beyond_Fixed__Variable-Length_Denoising_for_Diffusion_Large_Language __Models/\",\"children\":\"[논문리뷰] Beyond Fixed: Variable-Length Denoising for Diffusion Large Language Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Jiaqi Wang이 [arXiv]에 게시한 'Beyond Fixed: Variable-Length Denoising for Diffusion Large Language Models' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-04 12:17:01+0900\",\"children\":\"2025년 8월 4일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Diffusion Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Large Language Models\"]}],[\"$\",\"span\",\"Variable-Length Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Variable-Length Generation\"]}],[\"$\",\"span\",\"Dynamic Length Adaptation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dynamic Length Adaptation\"]}],[\"$\",\"span\",\"Denoising Strategy\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Denoising Strategy\"]}],[\"$\",\"span\",\"Inference Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Inference Optimization\"]}],[\"$\",\"span\",\"Computational Efficiency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Computational Efficiency\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-4-3D-R1__Enhancing_Reasoning_in_3D_VLMs_for_Unified_Scene_Understanding\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-4-3D-R1__Enhancing_Reasoning_in_3D_VLMs_for_Unified_Scene_Understanding/\",\"children\":\"[논문리뷰] 3D-R1: Enhancing Reasoning in 3D VLMs for Unified Scene Understanding\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Hao Tang이 [arXiv]에 게시한 '3D-R1: Enhancing Reasoning in 3D VLMs for Unified Scene Understanding' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-04 12:17:01+0900\",\"children\":\"2025년 8월 4일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"3D Vision-Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D Vision-Language Models\"]}],[\"$\",\"span\",\"Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reasoning\"]}],[\"$\",\"span\",\"Scene Understanding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Scene Understanding\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Chain-of-Thought\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Chain-of-Thought\"]}],[\"$\",\"span\",\"Dynamic View Selection\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dynamic View Selection\"]}],[\"$\",\"span\",\"Multi-task Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-task Learning\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-3-villa-X__Enhancing_Latent_Action_Modeling_in_Vision-Language-Action __Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-3-villa-X__Enhancing_Latent_Action_Modeling_in_Vision-Language-Action__Models/\",\"children\":\"[논문리뷰] villa-X: Enhancing Latent Action Modeling in Vision-Language-Action Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Kaixin Wang이 [arXiv]에 게시한 'villa-X: Enhancing Latent Action Modeling in Vision-Language-Action Models' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-03 07:35:17+0900\",\"children\":\"2025년 8월 3일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Vision-Language-Action Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision-Language-Action Models\"]}],[\"$\",\"span\",\"Latent Actions\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Latent Actions\"]}],[\"$\",\"span\",\"Robot Manipulation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Robot Manipulation\"]}],[\"$\",\"span\",\"Pre-training\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Pre-training\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}],[\"$\",\"span\",\"Proprioceptive Feedback\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Proprioceptive Feedback\"]}],[\"$\",\"span\",\"Foundation Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Foundation Models\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-3-TARS__MinMax_Token-Adaptive_Preference_Strategy_for_Hallucination __Reduction_in_MLLMs\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-3-TARS__MinMax_Token-Adaptive_Preference_Strategy_for_Hallucination__Reduction_in_MLLMs/\",\"children\":\"[논문리뷰] TARS: MinMax Token-Adaptive Preference Strategy for Hallucination Reduction in MLLMs\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Jiasheng Tang이 [arXiv]에 게시한 'TARS: MinMax Token-Adaptive Preference Strategy for Hallucination Reduction in MLLMs' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-03 07:35:17+0900\",\"children\":\"2025년 8월 3일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"MLLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"MLLMs\"]}],[\"$\",\"span\",\"Hallucination Reduction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Hallucination Reduction\"]}],[\"$\",\"span\",\"Preference Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Preference Optimization\"]}],[\"$\",\"span\",\"Min-Max Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Min-Max Optimization\"]}],[\"$\",\"span\",\"Token-Adaptive Strategy\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Token-Adaptive Strategy\"]}],[\"$\",\"span\",\"Spectral Regularization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Spectral Regularization\"]}],[\"$\",\"span\",\"Visual Grounding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Visual Grounding\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-3-Seed-Prover__Deep_and_Broad_Reasoning_for_Automated_Theorem_Proving\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-3-Seed-Prover__Deep_and_Broad_Reasoning_for_Automated_Theorem_Proving/\",\"children\":\"[논문리뷰] Seed-Prover: Deep and Broad Reasoning for Automated Theorem Proving\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Zhicheng Jiang이 [arXiv]에 게시한 'Seed-Prover: Deep and Broad Reasoning for Automated Theorem Proving' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-03 07:35:17+0900\",\"children\":\"2025년 8월 3일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Automated Theorem Proving\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Automated Theorem Proving\"]}],[\"$\",\"span\",\"Large Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models\"]}],[\"$\",\"span\",\"Formal Verification\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Formal Verification\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Lean\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Lean\"]}],[\"$\",\"span\",\"Geometry Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Geometry Reasoning\"]}],[\"$\",\"span\",\"Chain-of-Thought\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Chain-of-Thought\"]}],[\"$\",\"span\",\"Lemma-Style Proving\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Lemma-Style Proving\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-3-Scalable_Multi-Task_Reinforcement_Learning_for_Generalizable_Spatial __Intelligence_in_Visuomotor_Agents\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-3-Scalable_Multi-Task_Reinforcement_Learning_for_Generalizable_Spatial__Intelligence_in_Visuomotor_Agents/\",\"children\":\"[논문리뷰] Scalable Multi-Task Reinforcement Learning for Generalizable Spatial Intelligence in Visuomotor Agents\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Anji Liu이 [arXiv]에 게시한 'Scalable Multi-Task Reinforcement Learning for Generalizable Spatial Intelligence in Visuomotor Agents' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-03 07:35:17+0900\",\"children\":\"2025년 8월 3일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Reinforcement Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Reinforcement Learning\"]}],[\"$\",\"span\",\"Multi-Task Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-Task Learning\"]}],[\"$\",\"span\",\"Visuomotor Agents\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Visuomotor Agents\"]}],[\"$\",\"span\",\"Spatial Reasoning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Spatial Reasoning\"]}],[\"$\",\"span\",\"Generalization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generalization\"]}],[\"$\",\"span\",\"Minecraft\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Minecraft\"]}],[\"$\",\"span\",\"Cross-View Goal Specification\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Cross-View Goal Specification\"]}],[\"$\",\"span\",\"Automated Task Synthesis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Automated Task Synthesis\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-3-RecGPT_Technical_Report\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-3-RecGPT_Technical_Report/\",\"children\":\"[논문리뷰] RecGPT Technical Report\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Jian Wu이 [arXiv]에 게시한 'RecGPT Technical Report' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-03 07:35:17+0900\",\"children\":\"2025년 8월 3일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Recommender Systems\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Recommender Systems\"]}],[\"$\",\"span\",\"Large Language Models (LLMs)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models (LLMs)\"]}],[\"$\",\"span\",\"User Intent Modeling\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"User Intent Modeling\"]}],[\"$\",\"span\",\"Multi-Stage Training\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-Stage Training\"]}],[\"$\",\"span\",\"Human-in-the-Loop\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Human-in-the-Loop\"]}],[\"$\",\"span\",\"E-commerce\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"E-commerce\"]}],[\"$\",\"span\",\"Filter Bubble Mitigation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Filter Bubble Mitigation\"]}],[\"$\",\"span\",\"Matthew Effect\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Matthew Effect\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-3-Phi-Ground_Tech_Report__Advancing_Perception_in_GUI_Grounding\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-3-Phi-Ground_Tech_Report__Advancing_Perception_in_GUI_Grounding/\",\"children\":\"[논문리뷰] Phi-Ground Tech Report: Advancing Perception in GUI Grounding\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Kai Qiu이 [arXiv]에 게시한 'Phi-Ground Tech Report: Advancing Perception in GUI Grounding' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-03 07:35:17+0900\",\"children\":\"2025년 8월 3일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"GUI grounding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"GUI grounding\"]}],[\"$\",\"span\",\"AI agent\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"AI agent\"]}],[\"$\",\"span\",\"Large Multi-modal Model\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Multi-modal Model\"]}],[\"$\",\"span\",\"Perception\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Perception\"]}],[\"$\",\"span\",\"Data Augmentation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Augmentation\"]}],[\"$\",\"span\",\"Direct Preference Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Direct Preference Optimization\"]}],[\"$\",\"span\",\"Computational Efficiency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Computational Efficiency\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-3-Persona_Vectors__Monitoring_and_Controlling_Character_Traits_in_Language __Models\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-3-Persona_Vectors__Monitoring_and_Controlling_Character_Traits_in_Language__Models/\",\"children\":\"[논문리뷰] Persona Vectors: Monitoring and Controlling Character Traits in Language Models\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Jack Lindsey이 [arXiv]에 게시한 'Persona Vectors: Monitoring and Controlling Character Traits in Language Models' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-03 07:35:17+0900\",\"children\":\"2025년 8월 3일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Large Language Models (LLMs)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Large Language Models (LLMs)\"]}],[\"$\",\"span\",\"Persona Control\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Persona Control\"]}],[\"$\",\"span\",\"Activation Steering\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Activation Steering\"]}],[\"$\",\"span\",\"Finetuning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Finetuning\"]}],[\"$\",\"span\",\"Behavioral Shift Detection\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Behavioral Shift Detection\"]}],[\"$\",\"span\",\"Interpretability\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Interpretability\"]}],[\"$\",\"span\",\"Data Filtering\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Filtering\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-3-On_the_Expressiveness_of_Softmax_Attention__A_Recurrent_Neural_Network __Perspective\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-3-On_the_Expressiveness_of_Softmax_Attention__A_Recurrent_Neural_Network__Perspective/\",\"children\":\"[논문리뷰] On the Expressiveness of Softmax Attention: A Recurrent Neural Network Perspective\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Eric C. Larson이 [arXiv]에 게시한 'On the Expressiveness of Softmax Attention: A Recurrent Neural Network Perspective' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-03 07:35:17+0900\",\"children\":\"2025년 8월 3일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Softmax Attention\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Softmax Attention\"]}],[\"$\",\"span\",\"Linear Attention\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Linear Attention\"]}],[\"$\",\"span\",\"Recurrent Neural Networks (RNNs)\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Recurrent Neural Networks (RNNs)\"]}],[\"$\",\"span\",\"Taylor Series Expansion\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Taylor Series Expansion\"]}],[\"$\",\"span\",\"Attention Mechanisms\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Attention Mechanisms\"]}],[\"$\",\"span\",\"Expressiveness\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Expressiveness\"]}],[\"$\",\"span\",\"Transformer Architectures\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Transformer Architectures\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-3-NeRF_Is_a_Valuable_Assistant_for_3D_Gaussian_Splatting\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-3-NeRF_Is_a_Valuable_Assistant_for_3D_Gaussian_Splatting/\",\"children\":\"[논문리뷰] NeRF Is a Valuable Assistant for 3D Gaussian Splatting\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"ZeSheng Wang이 [arXiv]에 게시한 'NeRF Is a Valuable Assistant for 3D Gaussian Splatting' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-03 07:35:17+0900\",\"children\":\"2025년 8월 3일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"NeRF\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"NeRF\"]}],[\"$\",\"span\",\"3D Gaussian Splatting\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D Gaussian Splatting\"]}],[\"$\",\"span\",\"Hybrid Model\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Hybrid Model\"]}],[\"$\",\"span\",\"Joint Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Joint Optimization\"]}],[\"$\",\"span\",\"Scene Representation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Scene Representation\"]}],[\"$\",\"span\",\"Neural Rendering\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Neural Rendering\"]}],[\"$\",\"span\",\"Residual Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Residual Learning\"]}],[\"$\",\"span\",\"Sparse View\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Sparse View\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-3-iLRM__An_Iterative_Large_3D_Reconstruction_Model\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-3-iLRM__An_Iterative_Large_3D_Reconstruction_Model/\",\"children\":\"[논문리뷰] iLRM: An Iterative Large 3D Reconstruction Model\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Abdelrahman Mohamed이 [arXiv]에 게시한 'iLRM: An Iterative Large 3D Reconstruction Model' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-03 07:35:17+0900\",\"children\":\"2025년 8월 3일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"3D Reconstruction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"3D Reconstruction\"]}],[\"$\",\"span\",\"Gaussian Splatting\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Gaussian Splatting\"]}],[\"$\",\"span\",\"Iterative Refinement\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Iterative Refinement\"]}],[\"$\",\"span\",\"Transformer Architecture\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Transformer Architecture\"]}],[\"$\",\"span\",\"Multi-view Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-view Learning\"]}],[\"$\",\"span\",\"Scalability\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Scalability\"]}],[\"$\",\"span\",\"Feed-forward Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Feed-forward Models\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-3-Flow_Equivariant_Recurrent_Neural_Networks\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-3-Flow_Equivariant_Recurrent_Neural_Networks/\",\"children\":\"[논문리뷰] Flow Equivariant Recurrent Neural Networks\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"T. Anderson Keller이 [arXiv]에 게시한 'Flow Equivariant Recurrent Neural Networks' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-03 07:35:17+0900\",\"children\":\"2025년 8월 3일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Flow Equivariance\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Flow Equivariance\"]}],[\"$\",\"span\",\"Recurrent Neural Networks\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Recurrent Neural Networks\"]}],[\"$\",\"span\",\"Sequence Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Sequence Models\"]}],[\"$\",\"span\",\"Group Equivariance\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Group Equivariance\"]}],[\"$\",\"span\",\"Lie Subgroups\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Lie Subgroups\"]}],[\"$\",\"span\",\"Generalization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Generalization\"]}],[\"$\",\"span\",\"Time-Parameterized Symmetries\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Time-Parameterized Symmetries\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-3-Enhanced_Arabic_Text_Retrieval_with_Attentive_Relevance_Scoring\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-3-Enhanced_Arabic_Text_Retrieval_with_Attentive_Relevance_Scoring/\",\"children\":\"[논문리뷰] Enhanced Arabic Text Retrieval with Attentive Relevance Scoring\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Abdenour Hadid이 [arXiv]에 게시한 'Enhanced Arabic Text Retrieval with Attentive Relevance Scoring' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-03 07:35:17+0900\",\"children\":\"2025년 8월 3일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Arabic NLP\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Arabic NLP\"]}],[\"$\",\"span\",\"Dense Passage Retrieval\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dense Passage Retrieval\"]}],[\"$\",\"span\",\"Attentive Relevance Scoring\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Attentive Relevance Scoring\"]}],[\"$\",\"span\",\"Information Retrieval\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Information Retrieval\"]}],[\"$\",\"span\",\"Question Answering\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Question Answering\"]}],[\"$\",\"span\",\"Transformer Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Transformer Models\"]}],[\"$\",\"span\",\"Semantic Matching\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Semantic Matching\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-3-Efficient_Machine_Unlearning_via_Influence_Approximation\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-3-Efficient_Machine_Unlearning_via_Influence_Approximation/\",\"children\":\"[논문리뷰] Efficient Machine Unlearning via Influence Approximation\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Enhong Chen이 [arXiv]에 게시한 'Efficient Machine Unlearning via Influence Approximation' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-03 07:35:17+0900\",\"children\":\"2025년 8월 3일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Machine Unlearning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Machine Unlearning\"]}],[\"$\",\"span\",\"Influence Function\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Influence Function\"]}],[\"$\",\"span\",\"Incremental Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Incremental Learning\"]}],[\"$\",\"span\",\"Privacy Protection\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Privacy Protection\"]}],[\"$\",\"span\",\"Gradient Optimization\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Gradient Optimization\"]}],[\"$\",\"span\",\"Model Editing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Model Editing\"]}],[\"$\",\"span\",\"Computational Efficiency\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Computational Efficiency\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-3-C3__A_Bilingual_Benchmark_for_Spoken_Dialogue_Models_Exploring __Challenges_in_Complex_Conversations\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-3-C3__A_Bilingual_Benchmark_for_Spoken_Dialogue_Models_Exploring__Challenges_in_Complex_Conversations/\",\"children\":\"[논문리뷰] C3: A Bilingual Benchmark for Spoken Dialogue Models Exploring Challenges in Complex Conversations\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yiwen Guo이 [arXiv]에 게시한 'C3: A Bilingual Benchmark for Spoken Dialogue Models Exploring Challenges in Complex Conversations' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-03 07:35:17+0900\",\"children\":\"2025년 8월 3일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Spoken Dialogue Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Spoken Dialogue Models\"]}],[\"$\",\"span\",\"Bilingual Benchmark\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Bilingual Benchmark\"]}],[\"$\",\"span\",\"Complex Conversations\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Complex Conversations\"]}],[\"$\",\"span\",\"Ambiguity Resolution\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Ambiguity Resolution\"]}],[\"$\",\"span\",\"Context Understanding\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Context Understanding\"]}],[\"$\",\"span\",\"LLM Evaluation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLM Evaluation\"]}],[\"$\",\"span\",\"Human-Computer Interaction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Human-Computer Interaction\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-3-Beyond_Linear_Bottlenecks__Spline-Based_Knowledge_Distillation_for __Culturally_Diverse_Art_Style_Classification\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-3-Beyond_Linear_Bottlenecks__Spline-Based_Knowledge_Distillation_for__Culturally_Diverse_Art_Style_Classification/\",\"children\":\"[논문리뷰] Beyond Linear Bottlenecks: Spline-Based Knowledge Distillation for Culturally Diverse Art Style Classification\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Abdelmalik Taleb-Ahmed이 [arXiv]에 게시한 'Beyond Linear Bottlenecks: Spline-Based Knowledge Distillation for Culturally Diverse Art Style Classification' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-03 07:35:17+0900\",\"children\":\"2025년 8월 3일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Kolmogorov-Arnold Networks\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Kolmogorov-Arnold Networks\"]}],[\"$\",\"span\",\"Knowledge Distillation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Knowledge Distillation\"]}],[\"$\",\"span\",\"Art Style Classification\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Art Style Classification\"]}],[\"$\",\"span\",\"Self-Supervised Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Self-Supervised Learning\"]}],[\"$\",\"span\",\"Spline-Based Activation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Spline-Based Activation\"]}],[\"$\",\"span\",\"Dual-Teacher\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dual-Teacher\"]}],[\"$\",\"span\",\"Gram Matrix\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Gram Matrix\"]}]]}]]}]]}],[\"$\",\"article\",\"2025-8-3-AgroBench__Vision-Language_Model_Benchmark_in_Agriculture\",{\"className\":\"archive__item\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"archive__item-title\",\"children\":[\"$\",\"$L5\",null,{\"href\":\"/ai/review/2025-8-3-AgroBench__Vision-Language_Model_Benchmark_in_Agriculture/\",\"children\":\"[논문리뷰] AgroBench: Vision-Language Model Benchmark in Agriculture\"}]}],[\"$\",\"div\",null,{\"className\":\"archive__item-excerpt\",\"children\":\"Yoshitaka Ushiku이 [arXiv]에 게시한 'AgroBench: Vision-Language Model Benchmark in Agriculture' 논문에 대한 자세한 리뷰입니다.\"}],[\"$\",\"div\",null,{\"className\":\"archive__item-meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-03 07:35:17+0900\",\"children\":\"2025년 8월 3일\"}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy mt-2\",\"children\":[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Vision-Language Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Vision-Language Models\"]}],[\"$\",\"span\",\"Agriculture\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Agriculture\"]}],[\"$\",\"span\",\"Benchmarking\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Benchmarking\"]}],[\"$\",\"span\",\"Disease Identification\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Disease Identification\"]}],[\"$\",\"span\",\"Pest Management\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Pest Management\"]}],[\"$\",\"span\",\"Crop Management\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Crop Management\"]}],[\"$\",\"span\",\"Agronomy\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Agronomy\"]}]]}]]}]]}]]}]]}],[\"$\",\"aside\",null,{\"className\":\"lg:w-80\",\"children\":[\"$\",\"$L6\",null,{}]}]]}]}],[\"$\",\"div\",null,{\"id\":\"footer\",\"className\":\"page__footer\",\"children\":[\"$\",\"footer\",null,{\"className\":\"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8\",\"children\":[\"$\",\"div\",null,{\"className\":\"text-center text-gray-500 text-sm\",\"children\":[\"$\",\"p\",null,{\"children\":\"© 2025 secrett2633. All rights reserved.\"}]}]}]}]]],null],null]},[\"$\",\"$L7\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"categories\",\"children\",\"$8\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L9\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"styles\":null}],null]},[\"$\",\"$L7\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"categories\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L9\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"styles\":null}],null]},[[\"$\",\"html\",null,{\"lang\":\"ko\",\"className\":\"no-js\",\"children\":[[\"$\",\"head\",null,{\"children\":[[\"$\",\"link\",null,{\"rel\":\"icon\",\"type\":\"image/png\",\"sizes\":\"32x32\",\"href\":\"/favicon-32x32.png\"}],[\"$\",\"link\",null,{\"rel\":\"icon\",\"type\":\"image/png\",\"sizes\":\"16x16\",\"href\":\"/favicon-16x16.png\"}],[\"$\",\"meta\",null,{\"name\":\"msapplication-TileColor\",\"content\":\"#ffc40d\"}],[\"$\",\"meta\",null,{\"name\":\"theme-color\",\"content\":\"#ffffff\"}],[\"$\",\"script\",null,{\"async\":true,\"src\":\"https://www.googletagmanager.com/gtag/js?id=G-NE2W3CFPNY\"}],[\"$\",\"script\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"\\n              window.dataLayer = window.dataLayer || [];\\n              function gtag(){dataLayer.push(arguments);}\\n              gtag('js', new Date());\\n              gtag('config', 'G-NE2W3CFPNY');\\n            \"}}]]}],[\"$\",\"body\",null,{\"className\":\"__className_9012cf layout--default\",\"children\":[\"$\",\"div\",null,{\"className\":\"min-h-screen bg-gray-50\",\"children\":[[\"$\",\"$L4\",null,{}],[\"$\",\"main\",null,{\"className\":\"initial-content\",\"children\":[\"$\",\"$L7\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L9\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[\"$\",\"div\",null,{\"className\":\"min-h-screen flex items-center justify-center bg-gray-50\",\"children\":[\"$\",\"div\",null,{\"className\":\"max-w-md w-full bg-white rounded-lg shadow-md p-8 text-center\",\"children\":[[\"$\",\"h1\",null,{\"className\":\"text-6xl font-bold text-primary-600 mb-4\",\"children\":\"404\"}],[\"$\",\"h2\",null,{\"className\":\"text-2xl font-semibold text-gray-900 mb-4\",\"children\":\"페이지를 찾을 수 없습니다\"}],[\"$\",\"p\",null,{\"className\":\"text-gray-600 mb-8\",\"children\":\"요청하신 페이지가 존재하지 않거나 이동되었을 수 있습니다.\"}],[\"$\",\"$L5\",null,{\"href\":\"/\",\"className\":\"inline-flex items-center px-4 py-2 bg-primary-600 text-white rounded-md hover:bg-primary-700 transition-colors\",\"children\":\"홈으로 돌아가기\"}]]}]}],\"notFoundStyles\":[],\"styles\":null}]}],[\"$\",\"div\",null,{\"id\":\"footer\",\"className\":\"page__footer\",\"children\":[\"$\",\"footer\",null,{\"className\":\"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8\",\"children\":[\"$\",\"div\",null,{\"className\":\"text-center text-gray-500 text-sm\",\"children\":[\"$\",\"p\",null,{\"children\":\"© 2025 secrett2633. All rights reserved.\"}]}]}]}]]}]}]]}],null],[[\"$\",\"div\",null,{\"className\":\"flex items-center justify-center min-h-screen\",\"children\":[\"$\",\"div\",null,{\"className\":\"animate-spin rounded-full h-32 w-32 border-b-2 border-primary-600\"}]}],[],[]]],\"couldBeIntercepted\":false,\"initialHead\":[null,\"$La\"],\"globalErrorComponent\":\"$b\",\"missingSlots\":\"$Wc\"}]]\n"])</script><script>self.__next_f.push([1,"a:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}],[\"$\",\"meta\",\"1\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"2\",{\"children\":\"secrett2633's blog\"}],[\"$\",\"meta\",\"3\",{\"name\":\"description\",\"content\":\"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트\"}],[\"$\",\"meta\",\"4\",{\"name\":\"author\",\"content\":\"secrett2633\"}],[\"$\",\"meta\",\"5\",{\"name\":\"keywords\",\"content\":\"Django, Python, DevOps, AI, ML, 블로그, 기술\"}],[\"$\",\"meta\",\"6\",{\"name\":\"creator\",\"content\":\"secrett2633\"}],[\"$\",\"meta\",\"7\",{\"name\":\"publisher\",\"content\":\"secrett2633\"}],[\"$\",\"meta\",\"8\",{\"name\":\"robots\",\"content\":\"index, follow\"}],[\"$\",\"meta\",\"9\",{\"name\":\"googlebot\",\"content\":\"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1\"}],[\"$\",\"link\",\"10\",{\"rel\":\"canonical\",\"href\":\"https://secrett2633.github.io/\"}],[\"$\",\"meta\",\"11\",{\"name\":\"format-detection\",\"content\":\"telephone=no, address=no, email=no\"}],[\"$\",\"meta\",\"12\",{\"property\":\"og:title\",\"content\":\"secrett2633's blog\"}],[\"$\",\"meta\",\"13\",{\"property\":\"og:description\",\"content\":\"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트\"}],[\"$\",\"meta\",\"14\",{\"property\":\"og:url\",\"content\":\"https://secrett2633.github.io/\"}],[\"$\",\"meta\",\"15\",{\"property\":\"og:site_name\",\"content\":\"secrett2633's blog\"}],[\"$\",\"meta\",\"16\",{\"property\":\"og:locale\",\"content\":\"ko_KR\"}],[\"$\",\"meta\",\"17\",{\"property\":\"og:type\",\"content\":\"website\"}],[\"$\",\"meta\",\"18\",{\"name\":\"twitter:card\",\"content\":\"summary_large_image\"}],[\"$\",\"meta\",\"19\",{\"name\":\"twitter:title\",\"content\":\"secrett2633's blog\"}],[\"$\",\"meta\",\"20\",{\"name\":\"twitter:description\",\"content\":\"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트\"}]]\n3:null\n"])</script></body></html>