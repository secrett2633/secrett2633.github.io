<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.22.0 by Michael Rose
  Copyright 2013-2020 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="ko" class="no-js">
  <head>
    <style> 
      ::-webkit-scrollbar{ 
        width: 10px;
        height: 10px;
      }

      ::-webkit-scrollbar-track {
        width: 0px;
        background-color: #626262;
        /* border-radius: 5px; */
      }

      ::-webkit-scrollbar-thumb {
        width: 0px;
        background-color: #E2E2E2;
        border-radius: 5px;
      }

      ::-webkit-scrollbar-thumb:hover {
        width: 10px;
        height: 20px;
        /* background-color: rgba(190, 190, 190, 0.2); */
        background-color: #A2A2A2;
        border-radius: 5px;
      }

      ::-webkit-scrollbar-track:hover {
        width: 10px;
        /* background-color: rgba(150, 150, 150, 0.1); */
        background-color: #626262;
        border-radius: 5px;
        /* background: transparent; */
        /* border-radius: 10px; */
      }

      ::-webkit-scrollbar-button:start:decrement,::-webkit-scrollbar-button:end:increment {
          width:0px;
          height: 0px;
          /* background-color: rgb(14, 221, 24); */
          /* border-radius: 50%; */
      }
    </style>
    
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>[논문리뷰] TPLA: Tensor Parallel Latent Attention for Efficient Disaggregated Prefill &amp; Decode Inference | secrett2633</title>
<meta name="description" content="Di Yin이 [arXiv]에 게시한 ‘TPLA: Tensor Parallel Latent Attention for Efficient Disaggregated Prefill &amp; Decode Inference’ 논문에 대한 자세한 리뷰입니다.">


  <meta name="author" content="secrett2633">
  
  <meta property="article:author" content="secrett2633">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="ko_KR">
<meta property="og:site_name" content="secrett2633's blog">
<meta property="og:title" content="[논문리뷰] TPLA: Tensor Parallel Latent Attention for Efficient Disaggregated Prefill &amp; Decode Inference">
<meta property="og:url" content="http://localhost:4000/ai/review/2025-8-25-TPLA_Tensor_Parallel_Latent_Attention_for_Efficient_Disaggregated_Prefill_Decode_Inference/">


  <meta property="og:description" content="Di Yin이 [arXiv]에 게시한 ‘TPLA: Tensor Parallel Latent Attention for Efficient Disaggregated Prefill &amp; Decode Inference’ 논문에 대한 자세한 리뷰입니다.">







  <meta property="article:published_time" content="2025-08-25T13:13:07+09:00">



  <meta property="article:modified_time" content="2025-08-25T13:13:07+09:00">



  

  


<link rel="canonical" href="http://localhost:4000/ai/review/2025-8-25-TPLA_Tensor_Parallel_Latent_Attention_for_Efficient_Disaggregated_Prefill_Decode_Inference/">




<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "Person",
      "name": "secrett2633",
      "url": "http://localhost:4000/"
    
  }
</script>






<!-- end _includes/seo.html -->



  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="secrett2633's blog Feed">


<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css">

<!--[if IE]>
  <style>
    /* old IE unsupported flexbox fixes */
    .greedy-nav .site-title {
      padding-right: 3em;
    }
    .greedy-nav button {
      position: absolute;
      top: 0;
      right: 0;
      height: 100%;
    }
  </style>
<![endif]-->


    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->


    <link rel="icon" type="image/png" sizes="32x32" href="https://secrett2633.github.io/assets/images/favicon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="https://secrett2633.github.io/assets/images/favicon/favicon-16x16.png">
    <meta name="msapplication-TileColor" content="#ffc40d">
    <meta name="theme-color" content="#ffffff">
  </head>

  <body class="layout--single">
    <nav class="skip-links">
  <h2 class="screen-reader-text">Skip links</h2>
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
          secrett2633's blog
          
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="https://github.com/secrett2633">GitHub</a>
            </li></ul>
        
        <button class="search__toggle" type="button">
          <span class="visually-hidden">Toggle search</span>
          <svg class="icon" width="16" height="16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 15.99 16">
            <path d="M15.5,13.12L13.19,10.8a1.69,1.69,0,0,0-1.28-.55l-0.06-.06A6.5,6.5,0,0,0,5.77,0,6.5,6.5,0,0,0,2.46,11.59a6.47,6.47,0,0,0,7.74.26l0.05,0.05a1.65,1.65,0,0,0,.5,1.24l2.38,2.38A1.68,1.68,0,0,0,15.5,13.12ZM6.4,2A4.41,4.41,0,1,1,2,6.4,4.43,4.43,0,0,1,6.4,2Z" transform="translate(-.01)"></path>
          </svg>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      



<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="https://schema.org/Person">

  

  <!-- 2022.02.17 author content hidden -->
  <!-- <div class="author__content">
    
      <h3 class="author__name" itemprop="name">secrett2633</h3>
    
    
  </div> -->

  <div class="author__urls-wrapper">
    <!-- <button class="btn btn--inverse">Follow</button> -->
    <ul class="author__urls social-icons">
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs" rel="nofollow noopener noreferrer">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>

  
    
      
      
      
      
    
    
      

<nav class="nav__list">
  
  <input id="ac-toc" name="accordion-toc" type="checkbox" />
  <label for="ac-toc">Toggle Menu</label>
  <ul class="nav__items">
    
      <li>
        
          <!-- title -->
              <span class="nav__sub-title">Backend</span>
              <hr>
        

        
        <ul>
          
            <li><a href="/backend/django/">Django</a></li>
          
            <li><a href="/backend/logging/">Logging</a></li>
          
        </ul>
        
      </li>
    
      <li>
        
          <!-- title -->
              <span class="nav__sub-title">Python</span>
              <hr>
        

        
        <ul>
          
            <li><a href="/python/pep/">PEP</a></li>
          
        </ul>
        
      </li>
    
      <li>
        
          <!-- title -->
              <span class="nav__sub-title">AI/ML</span>
              <hr>
        

        
        <ul>
          
            <li><a href="/ai/llm/">LLM</a></li>
          
            <li><a href="/ai/review/">Review</a></li>
          
        </ul>
        
      </li>
    
      <li>
        
          <!-- title -->
              <span class="nav__sub-title">DevOps</span>
              <hr>
        

        
        <ul>
          
            <li><a href="/devops/nginx/">Nginx</a></li>
          
            <li><a href="/devops/docker/">Docker</a></li>
          
            <li><a href="/devops/safeline/">SafeLine</a></li>
          
            <li><a href="/devops/jenkins/">Jenkins</a></li>
          
            <li><a href="/devops/github-actions/">GitHub Actions</a></li>
          
            <li><a href="/devops/aws/">AWS</a></li>
          
        </ul>
        
      </li>
    
      <li>
        
          <!-- title -->
              <span class="nav__sub-title">etc</span>
              <hr>
        

        
        <ul>
          
            <li><a href="/etc/me/">Me</a></li>
          
            <li><a href="/etc/chrome-extension/">Chrome Extension</a></li>
          
        </ul>
        
      </li>
    
  </ul>
</nav>

    
  
  </div>



  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="[논문리뷰] TPLA: Tensor Parallel Latent Attention for Efficient Disaggregated Prefill &amp; Decode Inference">
    <meta itemprop="description" content="Di Yin이 [arXiv]에 게시한 ‘TPLA: Tensor Parallel Latent Attention for Efficient Disaggregated Prefill &amp; Decode Inference’ 논문에 대한 자세한 리뷰입니다.">
    <meta itemprop="datePublished" content="2025-08-25T13:13:07+09:00">
    <meta itemprop="dateModified" content="2025-08-25T13:13:07+09:00">

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">[논문리뷰] TPLA: Tensor Parallel Latent Attention for Efficient Disaggregated Prefill &amp; Decode Inference
</h1>
          

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <i class="far fa-calendar-alt" aria-hidden="true"></i>
        <time datetime="2025-08-25T13:13:07+09:00">August 25, 2025</time>
      </span>
    

    

    
  </p>


        </header>
      

      <section class="page__content" itemprop="text">
        
          <aside class="sidebar__right sticky">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> On this page</h4></header>
              <ul class="toc__menu"><li><a href="#핵심-연구-목표">핵심 연구 목표</a></li><li><a href="#핵심-방법론">핵심 방법론</a></li><li><a href="#주요-결과">주요 결과</a></li><li><a href="#ai-실무자를-위한-시사점">AI 실무자를 위한 시사점</a></li></ul>

            </nav>
          </aside>
        
        <blockquote>
  <p><strong>링크:</strong> <a href="https://arxiv.org/abs/2508.15881">논문 PDF로 바로 열기</a></p>
</blockquote>

<p><strong>저자:</strong> Xiaojuan Tang, Fanxu Meng, Pingzhi Tang, Yuxuan Wang, Di Yin, Xing Sun, Muhan Zhang</p>

<h2 id="핵심-연구-목표">핵심 연구 목표</h2>
<p>본 논문은 <strong>DeepSeek-V2</strong>에서 도입된 <strong>Multi-Head Latent Attention (MLA)</strong>이 <strong>Tensor Parallelism (TP)</strong> 환경에서 KV 캐시 메모리 절감 효과를 잃는 문제를 해결하고자 합니다. 특히, TP 환경에서 각 디바이스가 <strong>전체 latent vector (cKV)</strong>를 로드해야 하는 비효율성을 개선하여, MLA의 압축 이점과 TP 효율성을 동시에 달성하면서도 <strong>표현 능력(representational capacity)</strong>을 유지하는 것을 목표로 합니다.</p>

<h2 id="핵심-방법론">핵심 방법론</h2>
<p>제안하는 <strong>Tensor-Parallel Latent Attention (TPLA)</strong>은 <strong>latent representation</strong>과 각 헤드의 입력 차원을 디바이스 간에 분할하고, 각 샤드에서 독립적으로 어텐션을 수행한 후 <strong>all-reduce</strong>로 결과를 결합합니다. <strong>TPLA</strong>는 각 어텐션 헤드가 <strong>전체 latent representation</strong>을 활용하게 하여 표현 능력을 유지하며, 디바이스는 <strong>KV 캐시의 파티션만 로드</strong>합니다. 또한, <strong>Hadamard transform</strong> 또는 <strong>PCA</strong>와 같은 <strong>직교 변환</strong>을 <strong>RMSNorm</strong> 및 <strong>softmax</strong> 연산에 적용하여 크로스-샤드 간섭을 완화하고 정확도 저하를 최소화합니다. <strong>Prefill 단계</strong>에서는 <strong>MLA</strong> 방식을 사용하고 <strong>디코딩 단계</strong>에서는 <strong>TPLA</strong>를 사용하는 <strong>Prefill/Decode Separation</strong> 전략을 채택하여 각 단계의 효율성을 최적화합니다.</p>

<h2 id="주요-결과">주요 결과</h2>
<p><strong>DeepSeek-V3</strong> 및 <strong>Kimi-K2</strong> 모델에서 <strong>32K 토큰 컨텍스트 길이</strong> 기준으로 디바이스당 KV 캐시를 감소시켜 각각 <strong>1.79배</strong> 및 <strong>1.93배의 속도 향상</strong>을 달성했습니다. 이러한 성능 향상은 <strong>LongBench</strong> 및 <strong>commonsense benchmarks</strong>에서 성능 저하 없이 이루어졌으며, <strong>FlashAttention-3</strong>와 호환되어 실용적인 구현이 가능함을 보였습니다. 특히, <strong>PCA 기반 재매개변수화(reparameterization)</strong>는 RMSNorm과 softmax를 동시에 병렬화할 때 <strong>최상의 성능</strong>을 일관되게 제공했습니다.</p>

<h2 id="ai-실무자를-위한-시사점">AI 실무자를 위한 시사점</h2>
<p><strong>TPLA</strong>는 <strong>MLA 기반 LLM</strong>의 <strong>Tensor Parallelism</strong> 추론 효율성을 크게 향상시켜 <strong>장문 컨텍스트 추론 비용</strong>을 절감할 수 있는 실용적인 솔루션을 제공합니다. 기존 <strong>사전 훈련된 MLA 모델</strong>에 <strong>재훈련 없이</strong> 적용 가능하여 도입 장벽이 낮으며, <strong>FlashAttention-3</strong>와 같은 최적화 라이브러리와의 호환성으로 <strong>end-to-end 성능 향상</strong>을 기대할 수 있습니다. <strong>Prefill/Decode 단계 분리</strong> 전략은 각 단계의 컴퓨팅 및 메모리 특성을 고려한 최적화를 가능하게 하여 전체 추론 파이프라인의 효율성을 높입니다.</p>

<blockquote>
  <p>⚠️ <strong>알림:</strong> 이 리뷰는 AI로 작성되었습니다.</p>
</blockquote>

        
      </section>

      <footer class="page__meta">
        
        
  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      <a href="/tags/#decoding-speedup" class="page__taxonomy-item" rel="tag">Decoding Speedup</a><span class="sep">, </span>
    
      <a href="/tags/#kv-cache-optimization" class="page__taxonomy-item" rel="tag">KV Cache Optimization</a><span class="sep">, </span>
    
      <a href="/tags/#latent-attention" class="page__taxonomy-item" rel="tag">Latent Attention</a><span class="sep">, </span>
    
      <a href="/tags/#llm-inference" class="page__taxonomy-item" rel="tag">LLM Inference</a><span class="sep">, </span>
    
      <a href="/tags/#memory-efficiency" class="page__taxonomy-item" rel="tag">Memory Efficiency</a><span class="sep">, </span>
    
      <a href="/tags/#prefill-decode-separation" class="page__taxonomy-item" rel="tag">Prefill/Decode Separation</a><span class="sep">, </span>
    
      <a href="/tags/#reparameterization" class="page__taxonomy-item" rel="tag">Reparameterization</a><span class="sep">, </span>
    
      <a href="/tags/#review" class="page__taxonomy-item" rel="tag">Review</a><span class="sep">, </span>
    
      <a href="/tags/#tensor-parallelism" class="page__taxonomy-item" rel="tag">Tensor Parallelism</a>
    
    </span>
  </p>




  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> Categories: </strong>
    <span itemprop="keywords">
    
      <a href="/categories/#review" class="page__taxonomy-item" rel="tag">Review</a>
    
    </span>
  </p>


        
  <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Updated:</strong> <time datetime="2025-08-25">August 25, 2025</time></p>


      </footer>

      

      
  <nav class="pagination">
    
      <a href="/ai/review/2025-8-25-Selective_Contrastive_Learning_for_Weakly_Supervised_Affordance_Grounding/" class="pagination--pager" title="[논문리뷰] Selective Contrastive Learning for Weakly Supervised Affordance Grounding
">Previous</a>
    
    
      <a href="/ai/review/2025-8-26-Beyond_Memorization_Extending_Reasoning_Depth_with_Recurrence_Memory_and_Test-Time_Compute_Scaling/" class="pagination--pager" title="[논문리뷰] Beyond Memorization: Extending Reasoning Depth with Recurrence, Memory and Test-Time Compute Scaling
">Next</a>
    
  </nav>


    </div>

    
  </article>

</div>

    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><form class="search-content__form" onkeydown="return event.key != 'Enter';">
    <label class="sr-only" for="search">
      Enter your search term...
    </label>
    <input type="search" id="search" class="search-input" tabindex="-1" placeholder="Enter your search term..." />
  </form>
  <div id="results" class="results"></div></div>

      </div>
    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    

    
      
        
      
        
      
        
      
        
      
        
      
        
      
    

    
      <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2025 secrett2633. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>




<script src="/assets/js/lunr/lunr.min.js"></script>
<script src="/assets/js/lunr/lunr-store.js"></script>
<script src="/assets/js/lunr/lunr-en.js"></script>




    <script>
  'use strict';

  (function() {
    var commentContainer = document.querySelector('#utterances-comments');

    if (!commentContainer) {
      return;
    }

    var script = document.createElement('script');
    script.setAttribute('src', 'https://utteranc.es/client.js');
    script.setAttribute('repo', 'secrett2633/secrett2633.github.io');
    script.setAttribute('issue-term', 'pathname');
    script.setAttribute('theme', 'github-light');
    script.setAttribute('crossorigin', 'anonymous');

    commentContainer.appendChild(script);
  })();
</script>

  





  </body>
</html>
