<!DOCTYPE html><html lang="ko" class="no-js"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/secrett2633.github.io/_next/static/media/e4af272ccee01ff0-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/secrett2633.github.io/_next/static/css/b9d6ec750ad82add.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/secrett2633.github.io/_next/static/chunks/webpack-a04af954a21fa650.js"/><script src="/secrett2633.github.io/_next/static/chunks/fd9d1056-62aaf4b921c84028.js" async=""></script><script src="/secrett2633.github.io/_next/static/chunks/23-ca4408d024135d8d.js" async=""></script><script src="/secrett2633.github.io/_next/static/chunks/main-app-fa660020ba1e0b6e.js" async=""></script><script src="/secrett2633.github.io/_next/static/chunks/231-c4b666723e6aae68.js" async=""></script><script src="/secrett2633.github.io/_next/static/chunks/app/layout-8808afda01b7a1b7.js" async=""></script><script src="/secrett2633.github.io/_next/static/chunks/app/%5B...slug%5D/page-01b66e77b48ed573.js" async=""></script><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-NE2W3CFPNY"></script><title>secrett2633&#x27;s blog</title><meta name="description" content="기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트"/><meta name="author" content="secrett2633"/><meta name="keywords" content="Django, Python, DevOps, AI, ML, 블로그, 기술"/><meta name="creator" content="secrett2633"/><meta name="publisher" content="secrett2633"/><meta name="robots" content="index, follow"/><meta name="googlebot" content="index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1"/><link rel="canonical" href="https://secrett2633.github.io/"/><meta name="format-detection" content="telephone=no, address=no, email=no"/><meta property="og:title" content="secrett2633&#x27;s blog"/><meta property="og:description" content="기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트"/><meta property="og:url" content="https://secrett2633.github.io/"/><meta property="og:site_name" content="secrett2633&#x27;s blog"/><meta property="og:locale" content="ko_KR"/><meta property="og:type" content="website"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:title" content="secrett2633&#x27;s blog"/><meta name="twitter:description" content="기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트"/><meta name="next-size-adjust"/><link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"/><meta name="msapplication-TileColor" content="#ffc40d"/><meta name="theme-color" content="#ffffff"/><script>
              window.dataLayer = window.dataLayer || [];
              function gtag(){dataLayer.push(arguments);}
              gtag('js', new Date());
              gtag('config', 'G-NE2W3CFPNY');
            </script><script src="/secrett2633.github.io/_next/static/chunks/polyfills-78c92fac7aa8fdd8.js" noModule=""></script></head><body class="__className_9012cf layout--default"><div class="min-h-screen bg-gray-50"><div class="masthead"><div class="masthead__inner-wrap"><div class="masthead__menu"><nav id="site-nav" class="greedy-nav"><a class="site-title" href="/secrett2633.github.io">secrett2633&#x27;s blog</a><div class="flex items-center space-x-4"><ul class="visible-links"><li class="masthead__menu-item"><a href="https://github.com/secrett2633" target="_blank" rel="noopener noreferrer">GitHub</a></li></ul><button class="search__toggle" type="button"><svg class="icon" width="16" height="16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 15.99 16"><path d="M15.5,13.12L13.19,10.8a1.69,1.69,0,0,0-1.28-.55l-0.06-.06A6.5,6.5,0,0,0,5.77,0,6.5,6.5,0,0,0,2.46,11.59a6.47,6.47,0,0,0,7.74.26l0.05,0.05a1.65,1.65,0,0,0,.5,1.24l2.38,2.38A1.68,1.68,0,0,0,15.5,13.12ZM6.4,2A4.41,4.41,0,1,1,2,6.4,4.43,4.43,0,0,1,6.4,2Z" transform="translate(-.01)"></path></svg></button><button class="greedy-nav__toggle" type="button"><div class="navicon"></div></button></div><ul class="hidden-links hidden md:hidden"><li><a href="https://github.com/secrett2633" target="_blank" rel="noopener noreferrer" class="block py-2">GitHub</a></li></ul></nav></div></div></div><main class="initial-content"><!--$--><div class="flex flex-col lg:flex-row gap-8"><main class="flex-1"><article class="page"><header class="mb-8"><h1 class="page__title">[논문리뷰] NVSpeech: An Integrated and Scalable Pipeline for Human-Like Speech Modeling with Paralinguistic Vocalizations</h1><div class="page__meta"><time dateTime="2025-08-13 13:29:23+0900">2025년 8월 13일</time><span class="ml-4">수정: <!-- -->2025년 8월 13일</span></div></header><div class="page__content"><div><blockquote>
<p><strong>링크:</strong> <a href="https://arxiv.org/abs/2508.04195">논문 PDF로 바로 열기</a></p>
</blockquote>
<p><strong>저자:</strong> Huan Liao, Qinke Ni, Yuancheng Wang, Yiheng Lu, Haoyue Zhan</p>
<h2>핵심 연구 목표</h2>
<p>본 연구는 자연스러운 음성 의사소통에 필수적인 웃음, 호흡, 감탄사 등의 **비언어적 발성(paralinguistic vocalizations)**이 기존 ASR 및 TTS 시스템에서 간과되는 문제를 해결하고자 합니다. 궁극적으로 중국어 음성에서 비언어적 발성의 인식과 합성을 아우르는 통합적이고 확장 가능한 파이프라인을 구축하여 인간과 유사한 표현적인 음성 모델링을 목표로 합니다.</p>
<h2>핵심 방법론</h2>
<p>연구팀은 <strong>18가지 단어 수준의 비언어적 범주</strong>로 수동으로 주석 처리된 <strong>48,430개</strong>의 발화 데이터셋(<strong>NVSpeech_human</strong>)을 구축했습니다. 이 데이터를 활용하여 비언어적 단서를 인라인 디코딩 가능한 토큰으로 처리하는 <strong>비언어적 인지 ASR 모델</strong>을 개발했으며, 이를 통해 <strong>174,179개</strong>의 발화(총 <strong>573시간</strong>)로 구성된 대규모 코퍼스를 자동으로 주석 처리했습니다. 마지막으로, 자동 및 수동 주석 데이터를 모두 사용하여 <strong>CosyVoice</strong> 및 <strong>CosyVoice2</strong>와 같은 제로샷 TTS 모델을 미세 조정하여 단어 수준에서 비언어적 발성을 제어할 수 있도록 했습니다.</p>
<h2>주요 결과</h2>
<p>비언어적 인지 ASR 모델은 <strong>SenseVoice</strong>가 인(in-domain) 테스트셋에서 <strong>0.83</strong>, 오픈(open-domain) 테스트셋에서 <strong>0.85</strong>의 가장 높은 <strong>F1 점수</strong>를 달성하며 탁월한 성능을 보였습니다. TTS 실험에서는 대규모 자동 주석 데이터셋으로 미세 조정된 모델이 가장 우수했으며, 청취자들이 기존 음성 대비 <strong>78.7%</strong>(CosyVoice) 및 <strong>75.4%</strong>(CosyVoice2)의 높은 선호도를 보였습니다. 또한, 합성된 음성은 높은 자연성(NMOS: <strong>3.9-4.0</strong>)과 음질(QMOS: <strong>4.04-3.96</strong>)을 유지했습니다.</p>
<h2>AI 실무자를 위한 시사점</h2>
<p>본 연구는 대규모, 단어 수준으로 주석 처리된 비언어적 음성 데이터셋(<strong>NVSpeech</strong>)의 중요성을 강조하며, 이는 인간과 유사한 음성 AI 개발의 핵심 기반이 됩니다. 제안된 통합 파이프라인은 복잡한 비언어적 단서를 인식하고 합성하는 실용적이고 확장 가능한 방법을 제공하여, 대화형 AI, 표현적 챗봇, 가상 비서 등의 개발에 직접 적용될 수 있습니다. 또한, 이 연구는 만다린어와 같은 성조 언어의 표현적 음성 모델링에 대한 향후 연구 방향을 제시합니다.</p>
<blockquote>
<p>⚠️ <strong>알림:</strong> 이 리뷰는 AI로 작성되었습니다.</p>
</blockquote>
</div></div><footer class="page__meta mt-8"><div class="page__taxonomy mb-4"><h4 class="text-sm font-medium text-gray-900 mb-2">카테고리</h4><span class="page__taxonomy-item">Review</span></div><div class="page__taxonomy"><h4 class="text-sm font-medium text-gray-900 mb-2">태그</h4><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Paralinguistic Vocalizations</span><span class="page__taxonomy-item">#<!-- -->Speech Recognition</span><span class="page__taxonomy-item">#<!-- -->Text-to-Speech</span><span class="page__taxonomy-item">#<!-- -->Speech Synthesis</span><span class="page__taxonomy-item">#<!-- -->Data Annotation</span><span class="page__taxonomy-item">#<!-- -->Mandarin Speech</span><span class="page__taxonomy-item">#<!-- -->Expressive Speech</span></div></footer></article></main></div><!--/$--></main><div id="footer" class="page__footer"><footer class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8"><div class="text-center text-gray-500 text-sm"><p>© 2025 secrett2633. All rights reserved.</p></div></footer></div></div><script src="/secrett2633.github.io/_next/static/chunks/webpack-a04af954a21fa650.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0]);self.__next_f.push([2,null])</script><script>self.__next_f.push([1,"1:HL[\"/secrett2633.github.io/_next/static/media/e4af272ccee01ff0-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n2:HL[\"/secrett2633.github.io/_next/static/css/b9d6ec750ad82add.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"3:I[5751,[],\"\"]\n6:I[9275,[],\"\"]\n8:I[1343,[],\"\"]\n9:I[4281,[\"231\",\"static/chunks/231-c4b666723e6aae68.js\",\"185\",\"static/chunks/app/layout-8808afda01b7a1b7.js\"],\"default\"]\na:I[231,[\"231\",\"static/chunks/231-c4b666723e6aae68.js\",\"877\",\"static/chunks/app/%5B...slug%5D/page-01b66e77b48ed573.js\"],\"\"]\nc:I[6130,[],\"\"]\n7:[\"slug\",\"ai/review/2025-8-13-NVSpeech_An_Integrated_and_Scalable_Pipeline_for_Human-Like_Speech_Modeling_with_Paralinguistic_Vocalizations\",\"c\"]\nd:[]\n"])</script><script>self.__next_f.push([1,"0:[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/secrett2633.github.io/_next/static/css/b9d6ec750ad82add.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]],[\"$\",\"$L3\",null,{\"buildId\":\"iV6XySbMHIJ3imQdvgy3I\",\"assetPrefix\":\"/secrett2633.github.io\",\"initialCanonicalUrl\":\"/ai/review/2025-8-13-NVSpeech_An_Integrated_and_Scalable_Pipeline_for_Human-Like_Speech_Modeling_with_Paralinguistic_Vocalizations/\",\"initialTree\":[\"\",{\"children\":[[\"slug\",\"ai/review/2025-8-13-NVSpeech_An_Integrated_and_Scalable_Pipeline_for_Human-Like_Speech_Modeling_with_Paralinguistic_Vocalizations\",\"c\"],{\"children\":[\"__PAGE__?{\\\"slug\\\":[\\\"ai\\\",\\\"review\\\",\\\"2025-8-13-NVSpeech_An_Integrated_and_Scalable_Pipeline_for_Human-Like_Speech_Modeling_with_Paralinguistic_Vocalizations\\\"]}\",{}]}]},\"$undefined\",\"$undefined\",true],\"initialSeedData\":[\"\",{\"children\":[[\"slug\",\"ai/review/2025-8-13-NVSpeech_An_Integrated_and_Scalable_Pipeline_for_Human-Like_Speech_Modeling_with_Paralinguistic_Vocalizations\",\"c\"],{\"children\":[\"__PAGE__\",{},[[\"$L4\",\"$L5\"],null],null]},[\"$\",\"$L6\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"$7\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L8\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"styles\":null}],null]},[[\"$\",\"html\",null,{\"lang\":\"ko\",\"className\":\"no-js\",\"children\":[[\"$\",\"head\",null,{\"children\":[[\"$\",\"link\",null,{\"rel\":\"icon\",\"type\":\"image/png\",\"sizes\":\"32x32\",\"href\":\"/favicon-32x32.png\"}],[\"$\",\"link\",null,{\"rel\":\"icon\",\"type\":\"image/png\",\"sizes\":\"16x16\",\"href\":\"/favicon-16x16.png\"}],[\"$\",\"meta\",null,{\"name\":\"msapplication-TileColor\",\"content\":\"#ffc40d\"}],[\"$\",\"meta\",null,{\"name\":\"theme-color\",\"content\":\"#ffffff\"}],[\"$\",\"script\",null,{\"async\":true,\"src\":\"https://www.googletagmanager.com/gtag/js?id=G-NE2W3CFPNY\"}],[\"$\",\"script\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"\\n              window.dataLayer = window.dataLayer || [];\\n              function gtag(){dataLayer.push(arguments);}\\n              gtag('js', new Date());\\n              gtag('config', 'G-NE2W3CFPNY');\\n            \"}}]]}],[\"$\",\"body\",null,{\"className\":\"__className_9012cf layout--default\",\"children\":[\"$\",\"div\",null,{\"className\":\"min-h-screen bg-gray-50\",\"children\":[[\"$\",\"$L9\",null,{}],[\"$\",\"main\",null,{\"className\":\"initial-content\",\"children\":[\"$\",\"$L6\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L8\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[\"$\",\"div\",null,{\"className\":\"min-h-screen flex items-center justify-center bg-gray-50\",\"children\":[\"$\",\"div\",null,{\"className\":\"max-w-md w-full bg-white rounded-lg shadow-md p-8 text-center\",\"children\":[[\"$\",\"h1\",null,{\"className\":\"text-6xl font-bold text-primary-600 mb-4\",\"children\":\"404\"}],[\"$\",\"h2\",null,{\"className\":\"text-2xl font-semibold text-gray-900 mb-4\",\"children\":\"페이지를 찾을 수 없습니다\"}],[\"$\",\"p\",null,{\"className\":\"text-gray-600 mb-8\",\"children\":\"요청하신 페이지가 존재하지 않거나 이동되었을 수 있습니다.\"}],[\"$\",\"$La\",null,{\"href\":\"/\",\"className\":\"inline-flex items-center px-4 py-2 bg-primary-600 text-white rounded-md hover:bg-primary-700 transition-colors\",\"children\":\"홈으로 돌아가기\"}]]}]}],\"notFoundStyles\":[],\"styles\":null}]}],[\"$\",\"div\",null,{\"id\":\"footer\",\"className\":\"page__footer\",\"children\":[\"$\",\"footer\",null,{\"className\":\"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8\",\"children\":[\"$\",\"div\",null,{\"className\":\"text-center text-gray-500 text-sm\",\"children\":[\"$\",\"p\",null,{\"children\":\"© 2025 secrett2633. All rights reserved.\"}]}]}]}]]}]}]]}],null],[[\"$\",\"div\",null,{\"className\":\"flex items-center justify-center min-h-screen\",\"children\":[\"$\",\"div\",null,{\"className\":\"animate-spin rounded-full h-32 w-32 border-b-2 border-primary-600\"}]}],[],[]]],\"couldBeIntercepted\":false,\"initialHead\":[null,\"$Lb\"],\"globalErrorComponent\":\"$c\",\"missingSlots\":\"$Wd\"}]]\n"])</script><script>self.__next_f.push([1,"e:Tc0d,"])</script><script>self.__next_f.push([1,"\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003e링크:\u003c/strong\u003e \u003ca href=\"https://arxiv.org/abs/2508.04195\"\u003e논문 PDF로 바로 열기\u003c/a\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e\u003cstrong\u003e저자:\u003c/strong\u003e Huan Liao, Qinke Ni, Yuancheng Wang, Yiheng Lu, Haoyue Zhan\u003c/p\u003e\n\u003ch2\u003e핵심 연구 목표\u003c/h2\u003e\n\u003cp\u003e본 연구는 자연스러운 음성 의사소통에 필수적인 웃음, 호흡, 감탄사 등의 **비언어적 발성(paralinguistic vocalizations)**이 기존 ASR 및 TTS 시스템에서 간과되는 문제를 해결하고자 합니다. 궁극적으로 중국어 음성에서 비언어적 발성의 인식과 합성을 아우르는 통합적이고 확장 가능한 파이프라인을 구축하여 인간과 유사한 표현적인 음성 모델링을 목표로 합니다.\u003c/p\u003e\n\u003ch2\u003e핵심 방법론\u003c/h2\u003e\n\u003cp\u003e연구팀은 \u003cstrong\u003e18가지 단어 수준의 비언어적 범주\u003c/strong\u003e로 수동으로 주석 처리된 \u003cstrong\u003e48,430개\u003c/strong\u003e의 발화 데이터셋(\u003cstrong\u003eNVSpeech_human\u003c/strong\u003e)을 구축했습니다. 이 데이터를 활용하여 비언어적 단서를 인라인 디코딩 가능한 토큰으로 처리하는 \u003cstrong\u003e비언어적 인지 ASR 모델\u003c/strong\u003e을 개발했으며, 이를 통해 \u003cstrong\u003e174,179개\u003c/strong\u003e의 발화(총 \u003cstrong\u003e573시간\u003c/strong\u003e)로 구성된 대규모 코퍼스를 자동으로 주석 처리했습니다. 마지막으로, 자동 및 수동 주석 데이터를 모두 사용하여 \u003cstrong\u003eCosyVoice\u003c/strong\u003e 및 \u003cstrong\u003eCosyVoice2\u003c/strong\u003e와 같은 제로샷 TTS 모델을 미세 조정하여 단어 수준에서 비언어적 발성을 제어할 수 있도록 했습니다.\u003c/p\u003e\n\u003ch2\u003e주요 결과\u003c/h2\u003e\n\u003cp\u003e비언어적 인지 ASR 모델은 \u003cstrong\u003eSenseVoice\u003c/strong\u003e가 인(in-domain) 테스트셋에서 \u003cstrong\u003e0.83\u003c/strong\u003e, 오픈(open-domain) 테스트셋에서 \u003cstrong\u003e0.85\u003c/strong\u003e의 가장 높은 \u003cstrong\u003eF1 점수\u003c/strong\u003e를 달성하며 탁월한 성능을 보였습니다. TTS 실험에서는 대규모 자동 주석 데이터셋으로 미세 조정된 모델이 가장 우수했으며, 청취자들이 기존 음성 대비 \u003cstrong\u003e78.7%\u003c/strong\u003e(CosyVoice) 및 \u003cstrong\u003e75.4%\u003c/strong\u003e(CosyVoice2)의 높은 선호도를 보였습니다. 또한, 합성된 음성은 높은 자연성(NMOS: \u003cstrong\u003e3.9-4.0\u003c/strong\u003e)과 음질(QMOS: \u003cstrong\u003e4.04-3.96\u003c/strong\u003e)을 유지했습니다.\u003c/p\u003e\n\u003ch2\u003eAI 실무자를 위한 시사점\u003c/h2\u003e\n\u003cp\u003e본 연구는 대규모, 단어 수준으로 주석 처리된 비언어적 음성 데이터셋(\u003cstrong\u003eNVSpeech\u003c/strong\u003e)의 중요성을 강조하며, 이는 인간과 유사한 음성 AI 개발의 핵심 기반이 됩니다. 제안된 통합 파이프라인은 복잡한 비언어적 단서를 인식하고 합성하는 실용적이고 확장 가능한 방법을 제공하여, 대화형 AI, 표현적 챗봇, 가상 비서 등의 개발에 직접 적용될 수 있습니다. 또한, 이 연구는 만다린어와 같은 성조 언어의 표현적 음성 모델링에 대한 향후 연구 방향을 제시합니다.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e⚠️ \u003cstrong\u003e알림:\u003c/strong\u003e 이 리뷰는 AI로 작성되었습니다.\u003c/p\u003e\n\u003c/blockquote\u003e\n"])</script><script>self.__next_f.push([1,"5:[\"$\",\"div\",null,{\"className\":\"flex flex-col lg:flex-row gap-8\",\"children\":[\"$\",\"main\",null,{\"className\":\"flex-1\",\"children\":[\"$\",\"article\",null,{\"className\":\"page\",\"children\":[[\"$\",\"header\",null,{\"className\":\"mb-8\",\"children\":[[\"$\",\"h1\",null,{\"className\":\"page__title\",\"children\":\"[논문리뷰] NVSpeech: An Integrated and Scalable Pipeline for Human-Like Speech Modeling with Paralinguistic Vocalizations\"}],[\"$\",\"div\",null,{\"className\":\"page__meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-13 13:29:23+0900\",\"children\":\"2025년 8월 13일\"}],[\"$\",\"span\",null,{\"className\":\"ml-4\",\"children\":[\"수정: \",\"2025년 8월 13일\"]}]]}]]}],[\"$\",\"div\",null,{\"className\":\"page__content\",\"children\":[\"$\",\"div\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"$e\"}}]}],[\"$\",\"footer\",null,{\"className\":\"page__meta mt-8\",\"children\":[[\"$\",\"div\",null,{\"className\":\"page__taxonomy mb-4\",\"children\":[[\"$\",\"h4\",null,{\"className\":\"text-sm font-medium text-gray-900 mb-2\",\"children\":\"카테고리\"}],[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":\"Review\"}]]]}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy\",\"children\":[[\"$\",\"h4\",null,{\"className\":\"text-sm font-medium text-gray-900 mb-2\",\"children\":\"태그\"}],[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Paralinguistic Vocalizations\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Paralinguistic Vocalizations\"]}],[\"$\",\"span\",\"Speech Recognition\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Speech Recognition\"]}],[\"$\",\"span\",\"Text-to-Speech\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Text-to-Speech\"]}],[\"$\",\"span\",\"Speech Synthesis\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Speech Synthesis\"]}],[\"$\",\"span\",\"Data Annotation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Data Annotation\"]}],[\"$\",\"span\",\"Mandarin Speech\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Mandarin Speech\"]}],[\"$\",\"span\",\"Expressive Speech\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Expressive Speech\"]}]]]}]]}]]}]}]}]\n"])</script><script>self.__next_f.push([1,"b:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}],[\"$\",\"meta\",\"1\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"2\",{\"children\":\"secrett2633's blog\"}],[\"$\",\"meta\",\"3\",{\"name\":\"description\",\"content\":\"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트\"}],[\"$\",\"meta\",\"4\",{\"name\":\"author\",\"content\":\"secrett2633\"}],[\"$\",\"meta\",\"5\",{\"name\":\"keywords\",\"content\":\"Django, Python, DevOps, AI, ML, 블로그, 기술\"}],[\"$\",\"meta\",\"6\",{\"name\":\"creator\",\"content\":\"secrett2633\"}],[\"$\",\"meta\",\"7\",{\"name\":\"publisher\",\"content\":\"secrett2633\"}],[\"$\",\"meta\",\"8\",{\"name\":\"robots\",\"content\":\"index, follow\"}],[\"$\",\"meta\",\"9\",{\"name\":\"googlebot\",\"content\":\"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1\"}],[\"$\",\"link\",\"10\",{\"rel\":\"canonical\",\"href\":\"https://secrett2633.github.io/\"}],[\"$\",\"meta\",\"11\",{\"name\":\"format-detection\",\"content\":\"telephone=no, address=no, email=no\"}],[\"$\",\"meta\",\"12\",{\"property\":\"og:title\",\"content\":\"secrett2633's blog\"}],[\"$\",\"meta\",\"13\",{\"property\":\"og:description\",\"content\":\"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트\"}],[\"$\",\"meta\",\"14\",{\"property\":\"og:url\",\"content\":\"https://secrett2633.github.io/\"}],[\"$\",\"meta\",\"15\",{\"property\":\"og:site_name\",\"content\":\"secrett2633's blog\"}],[\"$\",\"meta\",\"16\",{\"property\":\"og:locale\",\"content\":\"ko_KR\"}],[\"$\",\"meta\",\"17\",{\"property\":\"og:type\",\"content\":\"website\"}],[\"$\",\"meta\",\"18\",{\"name\":\"twitter:card\",\"content\":\"summary_large_image\"}],[\"$\",\"meta\",\"19\",{\"name\":\"twitter:title\",\"content\":\"secrett2633's blog\"}],[\"$\",\"meta\",\"20\",{\"name\":\"twitter:description\",\"content\":\"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트\"}],[\"$\",\"meta\",\"21\",{\"name\":\"next-size-adjust\"}]]\n4:null\n"])</script></body></html>