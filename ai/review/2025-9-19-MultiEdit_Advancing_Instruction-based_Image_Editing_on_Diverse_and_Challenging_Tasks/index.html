<!DOCTYPE html><html lang="ko" class="no-js"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/secrett2633.github.io/_next/static/media/e4af272ccee01ff0-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/secrett2633.github.io/_next/static/css/b9d6ec750ad82add.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/secrett2633.github.io/_next/static/chunks/webpack-a04af954a21fa650.js"/><script src="/secrett2633.github.io/_next/static/chunks/fd9d1056-62aaf4b921c84028.js" async=""></script><script src="/secrett2633.github.io/_next/static/chunks/23-ca4408d024135d8d.js" async=""></script><script src="/secrett2633.github.io/_next/static/chunks/main-app-fa660020ba1e0b6e.js" async=""></script><script src="/secrett2633.github.io/_next/static/chunks/231-c4b666723e6aae68.js" async=""></script><script src="/secrett2633.github.io/_next/static/chunks/app/layout-8808afda01b7a1b7.js" async=""></script><script src="/secrett2633.github.io/_next/static/chunks/app/%5B...slug%5D/page-01b66e77b48ed573.js" async=""></script><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-NE2W3CFPNY"></script><title>secrett2633&#x27;s blog</title><meta name="description" content="기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트"/><meta name="author" content="secrett2633"/><meta name="keywords" content="Django, Python, DevOps, AI, ML, 블로그, 기술"/><meta name="creator" content="secrett2633"/><meta name="publisher" content="secrett2633"/><meta name="robots" content="index, follow"/><meta name="googlebot" content="index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1"/><link rel="canonical" href="https://secrett2633.github.io/"/><meta name="format-detection" content="telephone=no, address=no, email=no"/><meta property="og:title" content="secrett2633&#x27;s blog"/><meta property="og:description" content="기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트"/><meta property="og:url" content="https://secrett2633.github.io/"/><meta property="og:site_name" content="secrett2633&#x27;s blog"/><meta property="og:locale" content="ko_KR"/><meta property="og:type" content="website"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:title" content="secrett2633&#x27;s blog"/><meta name="twitter:description" content="기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트"/><meta name="next-size-adjust"/><link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"/><meta name="msapplication-TileColor" content="#ffc40d"/><meta name="theme-color" content="#ffffff"/><script>
              window.dataLayer = window.dataLayer || [];
              function gtag(){dataLayer.push(arguments);}
              gtag('js', new Date());
              gtag('config', 'G-NE2W3CFPNY');
            </script><script src="/secrett2633.github.io/_next/static/chunks/polyfills-78c92fac7aa8fdd8.js" noModule=""></script></head><body class="__className_9012cf layout--default"><div class="min-h-screen bg-gray-50"><div class="masthead"><div class="masthead__inner-wrap"><div class="masthead__menu"><nav id="site-nav" class="greedy-nav"><a class="site-title" href="/secrett2633.github.io">secrett2633&#x27;s blog</a><div class="flex items-center space-x-4"><ul class="visible-links"><li class="masthead__menu-item"><a href="https://github.com/secrett2633" target="_blank" rel="noopener noreferrer">GitHub</a></li></ul><button class="search__toggle" type="button"><svg class="icon" width="16" height="16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 15.99 16"><path d="M15.5,13.12L13.19,10.8a1.69,1.69,0,0,0-1.28-.55l-0.06-.06A6.5,6.5,0,0,0,5.77,0,6.5,6.5,0,0,0,2.46,11.59a6.47,6.47,0,0,0,7.74.26l0.05,0.05a1.65,1.65,0,0,0,.5,1.24l2.38,2.38A1.68,1.68,0,0,0,15.5,13.12ZM6.4,2A4.41,4.41,0,1,1,2,6.4,4.43,4.43,0,0,1,6.4,2Z" transform="translate(-.01)"></path></svg></button><button class="greedy-nav__toggle" type="button"><div class="navicon"></div></button></div><ul class="hidden-links hidden md:hidden"><li><a href="https://github.com/secrett2633" target="_blank" rel="noopener noreferrer" class="block py-2">GitHub</a></li></ul></nav></div></div></div><main class="initial-content"><!--$--><div class="flex flex-col lg:flex-row gap-8"><main class="flex-1"><article class="page"><header class="mb-8"><h1 class="page__title">[논문리뷰] MultiEdit: Advancing Instruction-based Image Editing on Diverse and Challenging Tasks</h1><div class="page__meta"><time dateTime="2025-09-19 13:12:21+0900">2025년 9월 19일</time><span class="ml-4">수정: <!-- -->2025년 9월 19일</span></div></header><div class="page__content"><div><blockquote>
<p><strong>링크:</strong> <a href="https://arxiv.org/abs/2509.14638">논문 PDF로 바로 열기</a></p>
</blockquote>
<p><strong>저자:</strong> Mingsong Li, Lin Liu, Hongjun Wang, Haoxing Chen, Xijun Gu, Shizhan Liu, Dong Gong, Junbo Zhao, Zhenzhong Lan, Jianguo Li</p>
<h2>핵심 연구 목표</h2>
<p>본 연구는 기존 지시 기반 이미지 편집(IBIE) 방법론의 한계, 특히 제한된 데이터셋 다양성과 품질로 인한 복잡한 편집 태스크에서의 성능 저하 문제를 해결하고자 합니다. 노이즈 많고 편향된 캡션 기반 데이터 구축 방식의 문제점을 극복하고, 다양한 고품질 편집 시나리오를 포괄하는 새로운 대규모 데이터셋인 <strong>MultiEdit</strong>를 구축하는 것을 목표로 합니다. 이를 통해 파운데이션 모델의 발전과 복잡한 IBIE 역량의 확장을 촉진하고자 합니다.</p>
<h2>핵심 방법론</h2>
<p>새로운 <strong>MLLM-driven 데이터 구축 파이프라인</strong>을 도입하여 원본 이미지로부터 시각 적응형 편집 지시를 직접 생성하고, **SOTA ImageGen 모델 (GPT-Image-1)**을 활용하여 고품질의 편집된 이미지를 생성합니다. <strong>MultiEdit</strong>는 6가지 도전적인 편집 태스크에 걸쳐 107K개 이상의 샘플을 포함하며, 18가지 비스타일 전송 편집 유형과 38가지 스타일 전송 작업을 포괄합니다. 모델 성능 평가를 위해 1,100개의 고품질 샘플로 구성된 <strong>MultiEdit-Test</strong> 벤치마크를 구축했으며, <strong>데이터 기반 멀티태스크 학습 (DMTL)</strong> 및 <strong>손실 기반 멀티태스크 학습 (LMTL)</strong> 전략을 탐색하여 효과적인 미세 조정 방안을 제시합니다.</p>
<h2>주요 결과</h2>
<p><strong>MultiEdit-Train</strong> 데이터셋으로 파운데이션 모델(예: <strong>SD3</strong>, <strong>UltraEdit</strong>)을 미세 조정했을 때 복잡한 편집 태스크에서 성능이 크게 향상되었습니다. <strong>SD3</strong>의 경우 <strong>MultiEdit-Test</strong>에서 <strong>CLIPimg</strong> 점수가 약 <strong>9.4%</strong>, <strong>DINO</strong> 점수가 약 <strong>16.1%</strong> 증가했습니다. <strong>ME-UEdit-DMTL</strong> 모델은 <strong>MultiEdit-Test</strong>에서 <strong>CLIPimg 0.8174</strong>, <strong>DINO 0.8071</strong>를 달성하여 기존 SOTA 모델인 <strong>Step1X-Edit</strong>의 <strong>DINO</strong> 점수를 <strong>5% 이상</strong> 능가했습니다. 또한, <strong>MultiEdit</strong>와 외부 데이터를 혼합한 훈련은 <strong>EmuEdit-Test</strong>에서 <strong>0.8409 CLIPimg</strong>, <strong>0.7668 DINO</strong>의 최고 점수를 기록하며 강력한 시너지를 입증했습니다.</p>
<h2>AI 실무자를 위한 시사점</h2>
<p><strong>MultiEdit</strong>는 기존 데이터셋의 한계를 넘어선 <strong>다양하고 도전적인 이미지 편집 시나리오</strong>를 위한 귀중한 자원을 제공합니다. 제시된 <strong>MLLM-driven 데이터 생성 파이프라인</strong>은 고품질의 학습 데이터를 효율적으로 구축하는 새로운 패러다임을 제시하며, 이는 <strong>AI 이미지 생성 모델</strong>의 <strong>지시 이해 능력</strong>과 <strong>정밀한 편집 성능</strong> 향상에 기여할 수 있습니다. AI 실무자들은 <strong>MultiEdit</strong>를 활용하여 <strong>객체 참조 편집, GUI 편집, 텍스트 편집, 뷰 편집, 스타일 전송</strong> 등 복잡한 태스크에서 더욱 강력하고 정교한 <strong>지시 기반 이미지 편집 시스템</strong>을 개발하고, <strong>멀티태스크 학습 전략</strong>을 통해 모델의 범용성과 효율성을 극대화할 수 있습니다.</p>
<blockquote>
<p>⚠️ <strong>알림:</strong> 이 리뷰는 AI로 작성되었습니다.</p>
</blockquote>
</div></div><footer class="page__meta mt-8"><div class="page__taxonomy mb-4"><h4 class="text-sm font-medium text-gray-900 mb-2">카테고리</h4><span class="page__taxonomy-item">Review</span></div><div class="page__taxonomy"><h4 class="text-sm font-medium text-gray-900 mb-2">태그</h4><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Instruction-based Image Editing</span><span class="page__taxonomy-item">#<!-- -->Dataset</span><span class="page__taxonomy-item">#<!-- -->Multi-modal LLM</span><span class="page__taxonomy-item">#<!-- -->Image Generation</span><span class="page__taxonomy-item">#<!-- -->Style Transfer</span><span class="page__taxonomy-item">#<!-- -->Multi-task Learning</span><span class="page__taxonomy-item">#<!-- -->Fine-tuning</span></div></footer></article></main></div><!--/$--></main><div id="footer" class="page__footer"><footer class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8"><div class="text-center text-gray-500 text-sm"><p>© 2025 secrett2633. All rights reserved.</p></div></footer></div></div><script src="/secrett2633.github.io/_next/static/chunks/webpack-a04af954a21fa650.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0]);self.__next_f.push([2,null])</script><script>self.__next_f.push([1,"1:HL[\"/secrett2633.github.io/_next/static/media/e4af272ccee01ff0-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n2:HL[\"/secrett2633.github.io/_next/static/css/b9d6ec750ad82add.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"3:I[5751,[],\"\"]\n6:I[9275,[],\"\"]\n8:I[1343,[],\"\"]\n9:I[4281,[\"231\",\"static/chunks/231-c4b666723e6aae68.js\",\"185\",\"static/chunks/app/layout-8808afda01b7a1b7.js\"],\"default\"]\na:I[231,[\"231\",\"static/chunks/231-c4b666723e6aae68.js\",\"877\",\"static/chunks/app/%5B...slug%5D/page-01b66e77b48ed573.js\"],\"\"]\nc:I[6130,[],\"\"]\n7:[\"slug\",\"ai/review/2025-9-19-MultiEdit_Advancing_Instruction-based_Image_Editing_on_Diverse_and_Challenging_Tasks\",\"c\"]\nd:[]\n"])</script><script>self.__next_f.push([1,"0:[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/secrett2633.github.io/_next/static/css/b9d6ec750ad82add.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]],[\"$\",\"$L3\",null,{\"buildId\":\"iV6XySbMHIJ3imQdvgy3I\",\"assetPrefix\":\"/secrett2633.github.io\",\"initialCanonicalUrl\":\"/ai/review/2025-9-19-MultiEdit_Advancing_Instruction-based_Image_Editing_on_Diverse_and_Challenging_Tasks/\",\"initialTree\":[\"\",{\"children\":[[\"slug\",\"ai/review/2025-9-19-MultiEdit_Advancing_Instruction-based_Image_Editing_on_Diverse_and_Challenging_Tasks\",\"c\"],{\"children\":[\"__PAGE__?{\\\"slug\\\":[\\\"ai\\\",\\\"review\\\",\\\"2025-9-19-MultiEdit_Advancing_Instruction-based_Image_Editing_on_Diverse_and_Challenging_Tasks\\\"]}\",{}]}]},\"$undefined\",\"$undefined\",true],\"initialSeedData\":[\"\",{\"children\":[[\"slug\",\"ai/review/2025-9-19-MultiEdit_Advancing_Instruction-based_Image_Editing_on_Diverse_and_Challenging_Tasks\",\"c\"],{\"children\":[\"__PAGE__\",{},[[\"$L4\",\"$L5\"],null],null]},[\"$\",\"$L6\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"$7\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L8\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"styles\":null}],null]},[[\"$\",\"html\",null,{\"lang\":\"ko\",\"className\":\"no-js\",\"children\":[[\"$\",\"head\",null,{\"children\":[[\"$\",\"link\",null,{\"rel\":\"icon\",\"type\":\"image/png\",\"sizes\":\"32x32\",\"href\":\"/favicon-32x32.png\"}],[\"$\",\"link\",null,{\"rel\":\"icon\",\"type\":\"image/png\",\"sizes\":\"16x16\",\"href\":\"/favicon-16x16.png\"}],[\"$\",\"meta\",null,{\"name\":\"msapplication-TileColor\",\"content\":\"#ffc40d\"}],[\"$\",\"meta\",null,{\"name\":\"theme-color\",\"content\":\"#ffffff\"}],[\"$\",\"script\",null,{\"async\":true,\"src\":\"https://www.googletagmanager.com/gtag/js?id=G-NE2W3CFPNY\"}],[\"$\",\"script\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"\\n              window.dataLayer = window.dataLayer || [];\\n              function gtag(){dataLayer.push(arguments);}\\n              gtag('js', new Date());\\n              gtag('config', 'G-NE2W3CFPNY');\\n            \"}}]]}],[\"$\",\"body\",null,{\"className\":\"__className_9012cf layout--default\",\"children\":[\"$\",\"div\",null,{\"className\":\"min-h-screen bg-gray-50\",\"children\":[[\"$\",\"$L9\",null,{}],[\"$\",\"main\",null,{\"className\":\"initial-content\",\"children\":[\"$\",\"$L6\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L8\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[\"$\",\"div\",null,{\"className\":\"min-h-screen flex items-center justify-center bg-gray-50\",\"children\":[\"$\",\"div\",null,{\"className\":\"max-w-md w-full bg-white rounded-lg shadow-md p-8 text-center\",\"children\":[[\"$\",\"h1\",null,{\"className\":\"text-6xl font-bold text-primary-600 mb-4\",\"children\":\"404\"}],[\"$\",\"h2\",null,{\"className\":\"text-2xl font-semibold text-gray-900 mb-4\",\"children\":\"페이지를 찾을 수 없습니다\"}],[\"$\",\"p\",null,{\"className\":\"text-gray-600 mb-8\",\"children\":\"요청하신 페이지가 존재하지 않거나 이동되었을 수 있습니다.\"}],[\"$\",\"$La\",null,{\"href\":\"/\",\"className\":\"inline-flex items-center px-4 py-2 bg-primary-600 text-white rounded-md hover:bg-primary-700 transition-colors\",\"children\":\"홈으로 돌아가기\"}]]}]}],\"notFoundStyles\":[],\"styles\":null}]}],[\"$\",\"div\",null,{\"id\":\"footer\",\"className\":\"page__footer\",\"children\":[\"$\",\"footer\",null,{\"className\":\"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8\",\"children\":[\"$\",\"div\",null,{\"className\":\"text-center text-gray-500 text-sm\",\"children\":[\"$\",\"p\",null,{\"children\":\"© 2025 secrett2633. All rights reserved.\"}]}]}]}]]}]}]]}],null],[[\"$\",\"div\",null,{\"className\":\"flex items-center justify-center min-h-screen\",\"children\":[\"$\",\"div\",null,{\"className\":\"animate-spin rounded-full h-32 w-32 border-b-2 border-primary-600\"}]}],[],[]]],\"couldBeIntercepted\":false,\"initialHead\":[null,\"$Lb\"],\"globalErrorComponent\":\"$c\",\"missingSlots\":\"$Wd\"}]]\n"])</script><script>self.__next_f.push([1,"e:Tf57,"])</script><script>self.__next_f.push([1,"\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003e링크:\u003c/strong\u003e \u003ca href=\"https://arxiv.org/abs/2509.14638\"\u003e논문 PDF로 바로 열기\u003c/a\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e\u003cstrong\u003e저자:\u003c/strong\u003e Mingsong Li, Lin Liu, Hongjun Wang, Haoxing Chen, Xijun Gu, Shizhan Liu, Dong Gong, Junbo Zhao, Zhenzhong Lan, Jianguo Li\u003c/p\u003e\n\u003ch2\u003e핵심 연구 목표\u003c/h2\u003e\n\u003cp\u003e본 연구는 기존 지시 기반 이미지 편집(IBIE) 방법론의 한계, 특히 제한된 데이터셋 다양성과 품질로 인한 복잡한 편집 태스크에서의 성능 저하 문제를 해결하고자 합니다. 노이즈 많고 편향된 캡션 기반 데이터 구축 방식의 문제점을 극복하고, 다양한 고품질 편집 시나리오를 포괄하는 새로운 대규모 데이터셋인 \u003cstrong\u003eMultiEdit\u003c/strong\u003e를 구축하는 것을 목표로 합니다. 이를 통해 파운데이션 모델의 발전과 복잡한 IBIE 역량의 확장을 촉진하고자 합니다.\u003c/p\u003e\n\u003ch2\u003e핵심 방법론\u003c/h2\u003e\n\u003cp\u003e새로운 \u003cstrong\u003eMLLM-driven 데이터 구축 파이프라인\u003c/strong\u003e을 도입하여 원본 이미지로부터 시각 적응형 편집 지시를 직접 생성하고, **SOTA ImageGen 모델 (GPT-Image-1)**을 활용하여 고품질의 편집된 이미지를 생성합니다. \u003cstrong\u003eMultiEdit\u003c/strong\u003e는 6가지 도전적인 편집 태스크에 걸쳐 107K개 이상의 샘플을 포함하며, 18가지 비스타일 전송 편집 유형과 38가지 스타일 전송 작업을 포괄합니다. 모델 성능 평가를 위해 1,100개의 고품질 샘플로 구성된 \u003cstrong\u003eMultiEdit-Test\u003c/strong\u003e 벤치마크를 구축했으며, \u003cstrong\u003e데이터 기반 멀티태스크 학습 (DMTL)\u003c/strong\u003e 및 \u003cstrong\u003e손실 기반 멀티태스크 학습 (LMTL)\u003c/strong\u003e 전략을 탐색하여 효과적인 미세 조정 방안을 제시합니다.\u003c/p\u003e\n\u003ch2\u003e주요 결과\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eMultiEdit-Train\u003c/strong\u003e 데이터셋으로 파운데이션 모델(예: \u003cstrong\u003eSD3\u003c/strong\u003e, \u003cstrong\u003eUltraEdit\u003c/strong\u003e)을 미세 조정했을 때 복잡한 편집 태스크에서 성능이 크게 향상되었습니다. \u003cstrong\u003eSD3\u003c/strong\u003e의 경우 \u003cstrong\u003eMultiEdit-Test\u003c/strong\u003e에서 \u003cstrong\u003eCLIPimg\u003c/strong\u003e 점수가 약 \u003cstrong\u003e9.4%\u003c/strong\u003e, \u003cstrong\u003eDINO\u003c/strong\u003e 점수가 약 \u003cstrong\u003e16.1%\u003c/strong\u003e 증가했습니다. \u003cstrong\u003eME-UEdit-DMTL\u003c/strong\u003e 모델은 \u003cstrong\u003eMultiEdit-Test\u003c/strong\u003e에서 \u003cstrong\u003eCLIPimg 0.8174\u003c/strong\u003e, \u003cstrong\u003eDINO 0.8071\u003c/strong\u003e를 달성하여 기존 SOTA 모델인 \u003cstrong\u003eStep1X-Edit\u003c/strong\u003e의 \u003cstrong\u003eDINO\u003c/strong\u003e 점수를 \u003cstrong\u003e5% 이상\u003c/strong\u003e 능가했습니다. 또한, \u003cstrong\u003eMultiEdit\u003c/strong\u003e와 외부 데이터를 혼합한 훈련은 \u003cstrong\u003eEmuEdit-Test\u003c/strong\u003e에서 \u003cstrong\u003e0.8409 CLIPimg\u003c/strong\u003e, \u003cstrong\u003e0.7668 DINO\u003c/strong\u003e의 최고 점수를 기록하며 강력한 시너지를 입증했습니다.\u003c/p\u003e\n\u003ch2\u003eAI 실무자를 위한 시사점\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eMultiEdit\u003c/strong\u003e는 기존 데이터셋의 한계를 넘어선 \u003cstrong\u003e다양하고 도전적인 이미지 편집 시나리오\u003c/strong\u003e를 위한 귀중한 자원을 제공합니다. 제시된 \u003cstrong\u003eMLLM-driven 데이터 생성 파이프라인\u003c/strong\u003e은 고품질의 학습 데이터를 효율적으로 구축하는 새로운 패러다임을 제시하며, 이는 \u003cstrong\u003eAI 이미지 생성 모델\u003c/strong\u003e의 \u003cstrong\u003e지시 이해 능력\u003c/strong\u003e과 \u003cstrong\u003e정밀한 편집 성능\u003c/strong\u003e 향상에 기여할 수 있습니다. AI 실무자들은 \u003cstrong\u003eMultiEdit\u003c/strong\u003e를 활용하여 \u003cstrong\u003e객체 참조 편집, GUI 편집, 텍스트 편집, 뷰 편집, 스타일 전송\u003c/strong\u003e 등 복잡한 태스크에서 더욱 강력하고 정교한 \u003cstrong\u003e지시 기반 이미지 편집 시스템\u003c/strong\u003e을 개발하고, \u003cstrong\u003e멀티태스크 학습 전략\u003c/strong\u003e을 통해 모델의 범용성과 효율성을 극대화할 수 있습니다.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e⚠️ \u003cstrong\u003e알림:\u003c/strong\u003e 이 리뷰는 AI로 작성되었습니다.\u003c/p\u003e\n\u003c/blockquote\u003e\n"])</script><script>self.__next_f.push([1,"5:[\"$\",\"div\",null,{\"className\":\"flex flex-col lg:flex-row gap-8\",\"children\":[\"$\",\"main\",null,{\"className\":\"flex-1\",\"children\":[\"$\",\"article\",null,{\"className\":\"page\",\"children\":[[\"$\",\"header\",null,{\"className\":\"mb-8\",\"children\":[[\"$\",\"h1\",null,{\"className\":\"page__title\",\"children\":\"[논문리뷰] MultiEdit: Advancing Instruction-based Image Editing on Diverse and Challenging Tasks\"}],[\"$\",\"div\",null,{\"className\":\"page__meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-09-19 13:12:21+0900\",\"children\":\"2025년 9월 19일\"}],[\"$\",\"span\",null,{\"className\":\"ml-4\",\"children\":[\"수정: \",\"2025년 9월 19일\"]}]]}]]}],[\"$\",\"div\",null,{\"className\":\"page__content\",\"children\":[\"$\",\"div\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"$e\"}}]}],[\"$\",\"footer\",null,{\"className\":\"page__meta mt-8\",\"children\":[[\"$\",\"div\",null,{\"className\":\"page__taxonomy mb-4\",\"children\":[[\"$\",\"h4\",null,{\"className\":\"text-sm font-medium text-gray-900 mb-2\",\"children\":\"카테고리\"}],[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":\"Review\"}]]]}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy\",\"children\":[[\"$\",\"h4\",null,{\"className\":\"text-sm font-medium text-gray-900 mb-2\",\"children\":\"태그\"}],[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Instruction-based Image Editing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Instruction-based Image Editing\"]}],[\"$\",\"span\",\"Dataset\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dataset\"]}],[\"$\",\"span\",\"Multi-modal LLM\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-modal LLM\"]}],[\"$\",\"span\",\"Image Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Image Generation\"]}],[\"$\",\"span\",\"Style Transfer\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Style Transfer\"]}],[\"$\",\"span\",\"Multi-task Learning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Multi-task Learning\"]}],[\"$\",\"span\",\"Fine-tuning\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Fine-tuning\"]}]]]}]]}]]}]}]}]\nb:[[\"$\",\"meta\",\"0\",{\"name"])</script><script>self.__next_f.push([1,"\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}],[\"$\",\"meta\",\"1\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"2\",{\"children\":\"secrett2633's blog\"}],[\"$\",\"meta\",\"3\",{\"name\":\"description\",\"content\":\"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트\"}],[\"$\",\"meta\",\"4\",{\"name\":\"author\",\"content\":\"secrett2633\"}],[\"$\",\"meta\",\"5\",{\"name\":\"keywords\",\"content\":\"Django, Python, DevOps, AI, ML, 블로그, 기술\"}],[\"$\",\"meta\",\"6\",{\"name\":\"creator\",\"content\":\"secrett2633\"}],[\"$\",\"meta\",\"7\",{\"name\":\"publisher\",\"content\":\"secrett2633\"}],[\"$\",\"meta\",\"8\",{\"name\":\"robots\",\"content\":\"index, follow\"}],[\"$\",\"meta\",\"9\",{\"name\":\"googlebot\",\"content\":\"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1\"}],[\"$\",\"link\",\"10\",{\"rel\":\"canonical\",\"href\":\"https://secrett2633.github.io/\"}],[\"$\",\"meta\",\"11\",{\"name\":\"format-detection\",\"content\":\"telephone=no, address=no, email=no\"}],[\"$\",\"meta\",\"12\",{\"property\":\"og:title\",\"content\":\"secrett2633's blog\"}],[\"$\",\"meta\",\"13\",{\"property\":\"og:description\",\"content\":\"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트\"}],[\"$\",\"meta\",\"14\",{\"property\":\"og:url\",\"content\":\"https://secrett2633.github.io/\"}],[\"$\",\"meta\",\"15\",{\"property\":\"og:site_name\",\"content\":\"secrett2633's blog\"}],[\"$\",\"meta\",\"16\",{\"property\":\"og:locale\",\"content\":\"ko_KR\"}],[\"$\",\"meta\",\"17\",{\"property\":\"og:type\",\"content\":\"website\"}],[\"$\",\"meta\",\"18\",{\"name\":\"twitter:card\",\"content\":\"summary_large_image\"}],[\"$\",\"meta\",\"19\",{\"name\":\"twitter:title\",\"content\":\"secrett2633's blog\"}],[\"$\",\"meta\",\"20\",{\"name\":\"twitter:description\",\"content\":\"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트\"}],[\"$\",\"meta\",\"21\",{\"name\":\"next-size-adjust\"}]]\n4:null\n"])</script></body></html>