<!DOCTYPE html><html lang="ko" class="no-js"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/secrett2633.github.io/_next/static/media/e4af272ccee01ff0-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/secrett2633.github.io/_next/static/css/b9d6ec750ad82add.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/secrett2633.github.io/_next/static/chunks/webpack-a04af954a21fa650.js"/><script src="/secrett2633.github.io/_next/static/chunks/fd9d1056-62aaf4b921c84028.js" async=""></script><script src="/secrett2633.github.io/_next/static/chunks/23-ca4408d024135d8d.js" async=""></script><script src="/secrett2633.github.io/_next/static/chunks/main-app-fa660020ba1e0b6e.js" async=""></script><script src="/secrett2633.github.io/_next/static/chunks/231-c4b666723e6aae68.js" async=""></script><script src="/secrett2633.github.io/_next/static/chunks/app/layout-8808afda01b7a1b7.js" async=""></script><script src="/secrett2633.github.io/_next/static/chunks/app/%5B...slug%5D/page-01b66e77b48ed573.js" async=""></script><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-NE2W3CFPNY"></script><title>secrett2633&#x27;s blog</title><meta name="description" content="기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트"/><meta name="author" content="secrett2633"/><meta name="keywords" content="Django, Python, DevOps, AI, ML, 블로그, 기술"/><meta name="creator" content="secrett2633"/><meta name="publisher" content="secrett2633"/><meta name="robots" content="index, follow"/><meta name="googlebot" content="index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1"/><link rel="canonical" href="https://secrett2633.github.io/"/><meta name="format-detection" content="telephone=no, address=no, email=no"/><meta property="og:title" content="secrett2633&#x27;s blog"/><meta property="og:description" content="기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트"/><meta property="og:url" content="https://secrett2633.github.io/"/><meta property="og:site_name" content="secrett2633&#x27;s blog"/><meta property="og:locale" content="ko_KR"/><meta property="og:type" content="website"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:title" content="secrett2633&#x27;s blog"/><meta name="twitter:description" content="기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트"/><meta name="next-size-adjust"/><link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"/><meta name="msapplication-TileColor" content="#ffc40d"/><meta name="theme-color" content="#ffffff"/><script>
              window.dataLayer = window.dataLayer || [];
              function gtag(){dataLayer.push(arguments);}
              gtag('js', new Date());
              gtag('config', 'G-NE2W3CFPNY');
            </script><script src="/secrett2633.github.io/_next/static/chunks/polyfills-78c92fac7aa8fdd8.js" noModule=""></script></head><body class="__className_9012cf layout--default"><div class="min-h-screen bg-gray-50"><div class="masthead"><div class="masthead__inner-wrap"><div class="masthead__menu"><nav id="site-nav" class="greedy-nav"><a class="site-title" href="/secrett2633.github.io">secrett2633&#x27;s blog</a><div class="flex items-center space-x-4"><ul class="visible-links"><li class="masthead__menu-item"><a href="https://github.com/secrett2633" target="_blank" rel="noopener noreferrer">GitHub</a></li></ul><button class="search__toggle" type="button"><svg class="icon" width="16" height="16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 15.99 16"><path d="M15.5,13.12L13.19,10.8a1.69,1.69,0,0,0-1.28-.55l-0.06-.06A6.5,6.5,0,0,0,5.77,0,6.5,6.5,0,0,0,2.46,11.59a6.47,6.47,0,0,0,7.74.26l0.05,0.05a1.65,1.65,0,0,0,.5,1.24l2.38,2.38A1.68,1.68,0,0,0,15.5,13.12ZM6.4,2A4.41,4.41,0,1,1,2,6.4,4.43,4.43,0,0,1,6.4,2Z" transform="translate(-.01)"></path></svg></button><button class="greedy-nav__toggle" type="button"><div class="navicon"></div></button></div><ul class="hidden-links hidden md:hidden"><li><a href="https://github.com/secrett2633" target="_blank" rel="noopener noreferrer" class="block py-2">GitHub</a></li></ul></nav></div></div></div><main class="initial-content"><!--$--><div class="flex flex-col lg:flex-row gap-8"><main class="flex-1"><article class="page"><header class="mb-8"><h1 class="page__title">[논문리뷰] Grove MoE: Towards Efficient and Superior MoE LLMs with Adjugate Experts</h1><div class="page__meta"><time dateTime="2025-08-12 13:29:09+0900">2025년 8월 12일</time><span class="ml-4">수정: <!-- -->2025년 8월 12일</span></div></header><div class="page__content"><div><blockquote>
<p><strong>링크:</strong> <a href="https://arxiv.org/abs/2508.07785">논문 PDF로 바로 열기</a></p>
</blockquote>
<p><strong>저자:</strong> Tieyuan Chen, Zhanchao Zhou, Xiaodong Chen, Haoxing Chen, Haoyuan Wu</p>
<h2>핵심 연구 목표</h2>
<p>본 논문은 기존 <strong>MoE (Mixture of Experts)</strong> LLM의 한계인 고정된 파라미터 활성화와 이로 인한 비효율적인 계산 문제를 해결하는 것을 목표로 합니다. 특히, 입력 복잡도에 관계없이 균일한 크기의 전문가를 활성화하는 방식의 비효율성을 개선하여, 모델 용량을 확장하면서도 연산 오버헤드를 관리 가능한 수준으로 유지하는 새로운 <strong>MoE 아키텍처</strong>를 제안합니다.</p>
<h2>핵심 방법론</h2>
<p>본 연구는 <strong>big.LITTLE CPU 아키텍처</strong>에서 영감을 받아, 크기가 다른 전문가들을 통합하는 <strong>Grove MoE 아키텍처</strong>를 제안합니다. 이 아키텍처는 전문가들을 그룹으로 나누고, 각 그룹에 <strong>adjugate expert</strong>를 도입하여, 여러 활성화된 전문가가 동일 그룹에 속할 경우 공유되는 adjugate expert는 한 번만 계산되도록 <strong>동적 활성화 메커니즘</strong>을 구현합니다. 또한, <strong>Qwen3-30B-A3B-Base 모델</strong>을 기반으로 <strong>업사이클링 전략</strong>을 통해 <strong>GroveMoE-Base</strong> 및 <strong>GroveMoE-Inst</strong> 모델을 개발했으며, <strong>무손실 부하 균형 전략</strong>을 적용하여 전문가 활용의 효율성을 높였습니다.</p>
<h2>주요 결과</h2>
<p><strong>GroveMoE</strong> 모델은 토큰 복잡도에 따라 동적으로 <strong>3.14–3.28B</strong> 파라미터를 활성화하여, 유사하거나 더 큰 규모의 <strong>SOTA 오픈소스 LLM</strong>에 필적하는 성능을 달성했습니다 (Figure 1). 특히 <strong>GroveMoE-Inst</strong>는 다양한 벤치마크에서 기존 모델들을 능가하는 성능을 보였으며 (Table 4), <strong>GroveMoE-Base</strong>는 <strong>Qwen3-30B-A3B-Base</strong>보다 우수한 성능을 입증했습니다 (Figure 4). <strong>g=64</strong> 그룹 구성 시 약 **5%**의 계산 절감 효과를 보였으며, <strong>g=16</strong> 구성에서는 최대 **20%**까지 절감되었습니다.</p>
<h2>AI 실무자를 위한 시사점</h2>
<p><strong>Grove MoE 아키텍처</strong>는 효율적인 <strong>LLM</strong> 구축을 위한 새로운 패러다임을 제시하며, 제한된 연산 자원 내에서 모델 용량을 확장하려는 <strong>AI 엔지니어</strong>에게 유용합니다. 특히, <strong>업사이클링 전략</strong>의 효과를 재확인하여 기존 모델을 활용한 효율적인 성능 향상 가능성을 보여줍니다. 다만, 현재 구현에서는 이론적 이점 대비 <strong>추론 속도 오버헤드</strong>가 존재하므로, 최적화된 커널 개발이 실제 배포를 위한 핵심 과제로 남아 있습니다.</p>
<blockquote>
<p>⚠️ <strong>알림:</strong> 이 리뷰는 AI로 작성되었습니다.</p>
</blockquote>
</div></div><footer class="page__meta mt-8"><div class="page__taxonomy mb-4"><h4 class="text-sm font-medium text-gray-900 mb-2">카테고리</h4><span class="page__taxonomy-item">Review</span></div><div class="page__taxonomy"><h4 class="text-sm font-medium text-gray-900 mb-2">태그</h4><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Mixture of Experts</span><span class="page__taxonomy-item">#<!-- -->LLMs</span><span class="page__taxonomy-item">#<!-- -->MoE Architecture</span><span class="page__taxonomy-item">#<!-- -->Dynamic Activation</span><span class="page__taxonomy-item">#<!-- -->Adjugate Experts</span><span class="page__taxonomy-item">#<!-- -->Upcycling Strategy</span><span class="page__taxonomy-item">#<!-- -->Load Balancing</span></div></footer></article></main></div><!--/$--></main><div id="footer" class="page__footer"><footer class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8"><div class="text-center text-gray-500 text-sm"><p>© 2025 secrett2633. All rights reserved.</p></div></footer></div></div><script src="/secrett2633.github.io/_next/static/chunks/webpack-a04af954a21fa650.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0]);self.__next_f.push([2,null])</script><script>self.__next_f.push([1,"1:HL[\"/secrett2633.github.io/_next/static/media/e4af272ccee01ff0-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n2:HL[\"/secrett2633.github.io/_next/static/css/b9d6ec750ad82add.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"3:I[5751,[],\"\"]\n6:I[9275,[],\"\"]\n8:I[1343,[],\"\"]\n9:I[4281,[\"231\",\"static/chunks/231-c4b666723e6aae68.js\",\"185\",\"static/chunks/app/layout-8808afda01b7a1b7.js\"],\"default\"]\na:I[231,[\"231\",\"static/chunks/231-c4b666723e6aae68.js\",\"877\",\"static/chunks/app/%5B...slug%5D/page-01b66e77b48ed573.js\"],\"\"]\nc:I[6130,[],\"\"]\n7:[\"slug\",\"ai/review/2025-8-12-Grove_MoE_Towards_Efficient_and_Superior_MoE_LLMs_with_Adjugate_Experts\",\"c\"]\nd:[]\n"])</script><script>self.__next_f.push([1,"0:[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/secrett2633.github.io/_next/static/css/b9d6ec750ad82add.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]],[\"$\",\"$L3\",null,{\"buildId\":\"iV6XySbMHIJ3imQdvgy3I\",\"assetPrefix\":\"/secrett2633.github.io\",\"initialCanonicalUrl\":\"/ai/review/2025-8-12-Grove_MoE_Towards_Efficient_and_Superior_MoE_LLMs_with_Adjugate_Experts/\",\"initialTree\":[\"\",{\"children\":[[\"slug\",\"ai/review/2025-8-12-Grove_MoE_Towards_Efficient_and_Superior_MoE_LLMs_with_Adjugate_Experts\",\"c\"],{\"children\":[\"__PAGE__?{\\\"slug\\\":[\\\"ai\\\",\\\"review\\\",\\\"2025-8-12-Grove_MoE_Towards_Efficient_and_Superior_MoE_LLMs_with_Adjugate_Experts\\\"]}\",{}]}]},\"$undefined\",\"$undefined\",true],\"initialSeedData\":[\"\",{\"children\":[[\"slug\",\"ai/review/2025-8-12-Grove_MoE_Towards_Efficient_and_Superior_MoE_LLMs_with_Adjugate_Experts\",\"c\"],{\"children\":[\"__PAGE__\",{},[[\"$L4\",\"$L5\"],null],null]},[\"$\",\"$L6\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"$7\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L8\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"styles\":null}],null]},[[\"$\",\"html\",null,{\"lang\":\"ko\",\"className\":\"no-js\",\"children\":[[\"$\",\"head\",null,{\"children\":[[\"$\",\"link\",null,{\"rel\":\"icon\",\"type\":\"image/png\",\"sizes\":\"32x32\",\"href\":\"/favicon-32x32.png\"}],[\"$\",\"link\",null,{\"rel\":\"icon\",\"type\":\"image/png\",\"sizes\":\"16x16\",\"href\":\"/favicon-16x16.png\"}],[\"$\",\"meta\",null,{\"name\":\"msapplication-TileColor\",\"content\":\"#ffc40d\"}],[\"$\",\"meta\",null,{\"name\":\"theme-color\",\"content\":\"#ffffff\"}],[\"$\",\"script\",null,{\"async\":true,\"src\":\"https://www.googletagmanager.com/gtag/js?id=G-NE2W3CFPNY\"}],[\"$\",\"script\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"\\n              window.dataLayer = window.dataLayer || [];\\n              function gtag(){dataLayer.push(arguments);}\\n              gtag('js', new Date());\\n              gtag('config', 'G-NE2W3CFPNY');\\n            \"}}]]}],[\"$\",\"body\",null,{\"className\":\"__className_9012cf layout--default\",\"children\":[\"$\",\"div\",null,{\"className\":\"min-h-screen bg-gray-50\",\"children\":[[\"$\",\"$L9\",null,{}],[\"$\",\"main\",null,{\"className\":\"initial-content\",\"children\":[\"$\",\"$L6\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L8\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[\"$\",\"div\",null,{\"className\":\"min-h-screen flex items-center justify-center bg-gray-50\",\"children\":[\"$\",\"div\",null,{\"className\":\"max-w-md w-full bg-white rounded-lg shadow-md p-8 text-center\",\"children\":[[\"$\",\"h1\",null,{\"className\":\"text-6xl font-bold text-primary-600 mb-4\",\"children\":\"404\"}],[\"$\",\"h2\",null,{\"className\":\"text-2xl font-semibold text-gray-900 mb-4\",\"children\":\"페이지를 찾을 수 없습니다\"}],[\"$\",\"p\",null,{\"className\":\"text-gray-600 mb-8\",\"children\":\"요청하신 페이지가 존재하지 않거나 이동되었을 수 있습니다.\"}],[\"$\",\"$La\",null,{\"href\":\"/\",\"className\":\"inline-flex items-center px-4 py-2 bg-primary-600 text-white rounded-md hover:bg-primary-700 transition-colors\",\"children\":\"홈으로 돌아가기\"}]]}]}],\"notFoundStyles\":[],\"styles\":null}]}],[\"$\",\"div\",null,{\"id\":\"footer\",\"className\":\"page__footer\",\"children\":[\"$\",\"footer\",null,{\"className\":\"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8\",\"children\":[\"$\",\"div\",null,{\"className\":\"text-center text-gray-500 text-sm\",\"children\":[\"$\",\"p\",null,{\"children\":\"© 2025 secrett2633. All rights reserved.\"}]}]}]}]]}]}]]}],null],[[\"$\",\"div\",null,{\"className\":\"flex items-center justify-center min-h-screen\",\"children\":[\"$\",\"div\",null,{\"className\":\"animate-spin rounded-full h-32 w-32 border-b-2 border-primary-600\"}]}],[],[]]],\"couldBeIntercepted\":false,\"initialHead\":[null,\"$Lb\"],\"globalErrorComponent\":\"$c\",\"missingSlots\":\"$Wd\"}]]\n"])</script><script>self.__next_f.push([1,"e:Tc54,"])</script><script>self.__next_f.push([1,"\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003e링크:\u003c/strong\u003e \u003ca href=\"https://arxiv.org/abs/2508.07785\"\u003e논문 PDF로 바로 열기\u003c/a\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e\u003cstrong\u003e저자:\u003c/strong\u003e Tieyuan Chen, Zhanchao Zhou, Xiaodong Chen, Haoxing Chen, Haoyuan Wu\u003c/p\u003e\n\u003ch2\u003e핵심 연구 목표\u003c/h2\u003e\n\u003cp\u003e본 논문은 기존 \u003cstrong\u003eMoE (Mixture of Experts)\u003c/strong\u003e LLM의 한계인 고정된 파라미터 활성화와 이로 인한 비효율적인 계산 문제를 해결하는 것을 목표로 합니다. 특히, 입력 복잡도에 관계없이 균일한 크기의 전문가를 활성화하는 방식의 비효율성을 개선하여, 모델 용량을 확장하면서도 연산 오버헤드를 관리 가능한 수준으로 유지하는 새로운 \u003cstrong\u003eMoE 아키텍처\u003c/strong\u003e를 제안합니다.\u003c/p\u003e\n\u003ch2\u003e핵심 방법론\u003c/h2\u003e\n\u003cp\u003e본 연구는 \u003cstrong\u003ebig.LITTLE CPU 아키텍처\u003c/strong\u003e에서 영감을 받아, 크기가 다른 전문가들을 통합하는 \u003cstrong\u003eGrove MoE 아키텍처\u003c/strong\u003e를 제안합니다. 이 아키텍처는 전문가들을 그룹으로 나누고, 각 그룹에 \u003cstrong\u003eadjugate expert\u003c/strong\u003e를 도입하여, 여러 활성화된 전문가가 동일 그룹에 속할 경우 공유되는 adjugate expert는 한 번만 계산되도록 \u003cstrong\u003e동적 활성화 메커니즘\u003c/strong\u003e을 구현합니다. 또한, \u003cstrong\u003eQwen3-30B-A3B-Base 모델\u003c/strong\u003e을 기반으로 \u003cstrong\u003e업사이클링 전략\u003c/strong\u003e을 통해 \u003cstrong\u003eGroveMoE-Base\u003c/strong\u003e 및 \u003cstrong\u003eGroveMoE-Inst\u003c/strong\u003e 모델을 개발했으며, \u003cstrong\u003e무손실 부하 균형 전략\u003c/strong\u003e을 적용하여 전문가 활용의 효율성을 높였습니다.\u003c/p\u003e\n\u003ch2\u003e주요 결과\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eGroveMoE\u003c/strong\u003e 모델은 토큰 복잡도에 따라 동적으로 \u003cstrong\u003e3.14–3.28B\u003c/strong\u003e 파라미터를 활성화하여, 유사하거나 더 큰 규모의 \u003cstrong\u003eSOTA 오픈소스 LLM\u003c/strong\u003e에 필적하는 성능을 달성했습니다 (Figure 1). 특히 \u003cstrong\u003eGroveMoE-Inst\u003c/strong\u003e는 다양한 벤치마크에서 기존 모델들을 능가하는 성능을 보였으며 (Table 4), \u003cstrong\u003eGroveMoE-Base\u003c/strong\u003e는 \u003cstrong\u003eQwen3-30B-A3B-Base\u003c/strong\u003e보다 우수한 성능을 입증했습니다 (Figure 4). \u003cstrong\u003eg=64\u003c/strong\u003e 그룹 구성 시 약 **5%**의 계산 절감 효과를 보였으며, \u003cstrong\u003eg=16\u003c/strong\u003e 구성에서는 최대 **20%**까지 절감되었습니다.\u003c/p\u003e\n\u003ch2\u003eAI 실무자를 위한 시사점\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eGrove MoE 아키텍처\u003c/strong\u003e는 효율적인 \u003cstrong\u003eLLM\u003c/strong\u003e 구축을 위한 새로운 패러다임을 제시하며, 제한된 연산 자원 내에서 모델 용량을 확장하려는 \u003cstrong\u003eAI 엔지니어\u003c/strong\u003e에게 유용합니다. 특히, \u003cstrong\u003e업사이클링 전략\u003c/strong\u003e의 효과를 재확인하여 기존 모델을 활용한 효율적인 성능 향상 가능성을 보여줍니다. 다만, 현재 구현에서는 이론적 이점 대비 \u003cstrong\u003e추론 속도 오버헤드\u003c/strong\u003e가 존재하므로, 최적화된 커널 개발이 실제 배포를 위한 핵심 과제로 남아 있습니다.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e⚠️ \u003cstrong\u003e알림:\u003c/strong\u003e 이 리뷰는 AI로 작성되었습니다.\u003c/p\u003e\n\u003c/blockquote\u003e\n"])</script><script>self.__next_f.push([1,"5:[\"$\",\"div\",null,{\"className\":\"flex flex-col lg:flex-row gap-8\",\"children\":[\"$\",\"main\",null,{\"className\":\"flex-1\",\"children\":[\"$\",\"article\",null,{\"className\":\"page\",\"children\":[[\"$\",\"header\",null,{\"className\":\"mb-8\",\"children\":[[\"$\",\"h1\",null,{\"className\":\"page__title\",\"children\":\"[논문리뷰] Grove MoE: Towards Efficient and Superior MoE LLMs with Adjugate Experts\"}],[\"$\",\"div\",null,{\"className\":\"page__meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-12 13:29:09+0900\",\"children\":\"2025년 8월 12일\"}],[\"$\",\"span\",null,{\"className\":\"ml-4\",\"children\":[\"수정: \",\"2025년 8월 12일\"]}]]}]]}],[\"$\",\"div\",null,{\"className\":\"page__content\",\"children\":[\"$\",\"div\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"$e\"}}]}],[\"$\",\"footer\",null,{\"className\":\"page__meta mt-8\",\"children\":[[\"$\",\"div\",null,{\"className\":\"page__taxonomy mb-4\",\"children\":[[\"$\",\"h4\",null,{\"className\":\"text-sm font-medium text-gray-900 mb-2\",\"children\":\"카테고리\"}],[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":\"Review\"}]]]}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy\",\"children\":[[\"$\",\"h4\",null,{\"className\":\"text-sm font-medium text-gray-900 mb-2\",\"children\":\"태그\"}],[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Mixture of Experts\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Mixture of Experts\"]}],[\"$\",\"span\",\"LLMs\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"LLMs\"]}],[\"$\",\"span\",\"MoE Architecture\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"MoE Architecture\"]}],[\"$\",\"span\",\"Dynamic Activation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Dynamic Activation\"]}],[\"$\",\"span\",\"Adjugate Experts\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Adjugate Experts\"]}],[\"$\",\"span\",\"Upcycling Strategy\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Upcycling Strategy\"]}],[\"$\",\"span\",\"Load Balancing\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Load Balancing\"]}]]]}]]}]]}]}]}]\nb:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=d"])</script><script>self.__next_f.push([1,"evice-width, initial-scale=1\"}],[\"$\",\"meta\",\"1\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"2\",{\"children\":\"secrett2633's blog\"}],[\"$\",\"meta\",\"3\",{\"name\":\"description\",\"content\":\"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트\"}],[\"$\",\"meta\",\"4\",{\"name\":\"author\",\"content\":\"secrett2633\"}],[\"$\",\"meta\",\"5\",{\"name\":\"keywords\",\"content\":\"Django, Python, DevOps, AI, ML, 블로그, 기술\"}],[\"$\",\"meta\",\"6\",{\"name\":\"creator\",\"content\":\"secrett2633\"}],[\"$\",\"meta\",\"7\",{\"name\":\"publisher\",\"content\":\"secrett2633\"}],[\"$\",\"meta\",\"8\",{\"name\":\"robots\",\"content\":\"index, follow\"}],[\"$\",\"meta\",\"9\",{\"name\":\"googlebot\",\"content\":\"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1\"}],[\"$\",\"link\",\"10\",{\"rel\":\"canonical\",\"href\":\"https://secrett2633.github.io/\"}],[\"$\",\"meta\",\"11\",{\"name\":\"format-detection\",\"content\":\"telephone=no, address=no, email=no\"}],[\"$\",\"meta\",\"12\",{\"property\":\"og:title\",\"content\":\"secrett2633's blog\"}],[\"$\",\"meta\",\"13\",{\"property\":\"og:description\",\"content\":\"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트\"}],[\"$\",\"meta\",\"14\",{\"property\":\"og:url\",\"content\":\"https://secrett2633.github.io/\"}],[\"$\",\"meta\",\"15\",{\"property\":\"og:site_name\",\"content\":\"secrett2633's blog\"}],[\"$\",\"meta\",\"16\",{\"property\":\"og:locale\",\"content\":\"ko_KR\"}],[\"$\",\"meta\",\"17\",{\"property\":\"og:type\",\"content\":\"website\"}],[\"$\",\"meta\",\"18\",{\"name\":\"twitter:card\",\"content\":\"summary_large_image\"}],[\"$\",\"meta\",\"19\",{\"name\":\"twitter:title\",\"content\":\"secrett2633's blog\"}],[\"$\",\"meta\",\"20\",{\"name\":\"twitter:description\",\"content\":\"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트\"}],[\"$\",\"meta\",\"21\",{\"name\":\"next-size-adjust\"}]]\n4:null\n"])</script></body></html>