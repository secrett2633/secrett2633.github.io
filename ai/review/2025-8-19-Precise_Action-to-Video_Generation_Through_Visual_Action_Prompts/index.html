<!DOCTYPE html><html lang="ko" class="no-js"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/secrett2633.github.io/_next/static/media/e4af272ccee01ff0-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/secrett2633.github.io/_next/static/css/b9d6ec750ad82add.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/secrett2633.github.io/_next/static/chunks/webpack-a04af954a21fa650.js"/><script src="/secrett2633.github.io/_next/static/chunks/fd9d1056-62aaf4b921c84028.js" async=""></script><script src="/secrett2633.github.io/_next/static/chunks/23-ca4408d024135d8d.js" async=""></script><script src="/secrett2633.github.io/_next/static/chunks/main-app-fa660020ba1e0b6e.js" async=""></script><script src="/secrett2633.github.io/_next/static/chunks/231-c4b666723e6aae68.js" async=""></script><script src="/secrett2633.github.io/_next/static/chunks/app/layout-8808afda01b7a1b7.js" async=""></script><script src="/secrett2633.github.io/_next/static/chunks/app/%5B...slug%5D/page-01b66e77b48ed573.js" async=""></script><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-NE2W3CFPNY"></script><title>secrett2633&#x27;s blog</title><meta name="description" content="기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트"/><meta name="author" content="secrett2633"/><meta name="keywords" content="Django, Python, DevOps, AI, ML, 블로그, 기술"/><meta name="creator" content="secrett2633"/><meta name="publisher" content="secrett2633"/><meta name="robots" content="index, follow"/><meta name="googlebot" content="index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1"/><link rel="canonical" href="https://secrett2633.github.io/"/><meta name="format-detection" content="telephone=no, address=no, email=no"/><meta property="og:title" content="secrett2633&#x27;s blog"/><meta property="og:description" content="기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트"/><meta property="og:url" content="https://secrett2633.github.io/"/><meta property="og:site_name" content="secrett2633&#x27;s blog"/><meta property="og:locale" content="ko_KR"/><meta property="og:type" content="website"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:title" content="secrett2633&#x27;s blog"/><meta name="twitter:description" content="기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트"/><meta name="next-size-adjust"/><link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"/><meta name="msapplication-TileColor" content="#ffc40d"/><meta name="theme-color" content="#ffffff"/><script>
              window.dataLayer = window.dataLayer || [];
              function gtag(){dataLayer.push(arguments);}
              gtag('js', new Date());
              gtag('config', 'G-NE2W3CFPNY');
            </script><script src="/secrett2633.github.io/_next/static/chunks/polyfills-78c92fac7aa8fdd8.js" noModule=""></script></head><body class="__className_9012cf layout--default"><div class="min-h-screen bg-gray-50"><div class="masthead"><div class="masthead__inner-wrap"><div class="masthead__menu"><nav id="site-nav" class="greedy-nav"><a class="site-title" href="/secrett2633.github.io">secrett2633&#x27;s blog</a><div class="flex items-center space-x-4"><ul class="visible-links"><li class="masthead__menu-item"><a href="https://github.com/secrett2633" target="_blank" rel="noopener noreferrer">GitHub</a></li></ul><button class="search__toggle" type="button"><svg class="icon" width="16" height="16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 15.99 16"><path d="M15.5,13.12L13.19,10.8a1.69,1.69,0,0,0-1.28-.55l-0.06-.06A6.5,6.5,0,0,0,5.77,0,6.5,6.5,0,0,0,2.46,11.59a6.47,6.47,0,0,0,7.74.26l0.05,0.05a1.65,1.65,0,0,0,.5,1.24l2.38,2.38A1.68,1.68,0,0,0,15.5,13.12ZM6.4,2A4.41,4.41,0,1,1,2,6.4,4.43,4.43,0,0,1,6.4,2Z" transform="translate(-.01)"></path></svg></button><button class="greedy-nav__toggle" type="button"><div class="navicon"></div></button></div><ul class="hidden-links hidden md:hidden"><li><a href="https://github.com/secrett2633" target="_blank" rel="noopener noreferrer" class="block py-2">GitHub</a></li></ul></nav></div></div></div><main class="initial-content"><!--$--><div class="flex flex-col lg:flex-row gap-8"><main class="flex-1"><article class="page"><header class="mb-8"><h1 class="page__title">[논문리뷰] Precise Action-to-Video Generation Through Visual Action Prompts</h1><div class="page__meta"><time dateTime="2025-08-19 13:15:01+0900">2025년 8월 19일</time><span class="ml-4">수정: <!-- -->2025년 8월 19일</span></div></header><div class="page__content"><div><blockquote>
<p><strong>링크:</strong> <a href="https://arxiv.org/abs/2508.13104">논문 PDF로 바로 열기</a></p>
</blockquote>
<p><strong>저자:</strong> Yuang Wang, Chao Wen, Haoyu Guo, Sida Peng, Minghan Qin, Hujun Bao, Xiaowei Zhou, Ruizhen Hu</p>
<h2>핵심 연구 목표</h2>
<p>본 논문은 복잡하고 고자유도(high-DoF)의 상호작용(예: 인간의 손 또는 로봇 그리퍼 동작)을 위한 비디오 생성에서 정밀성과 범용성 간의 트레이드오프 문제를 해결하고자 합니다. 기존 텍스트나 원시 행동, 에이전트 중심의 행동 표현이 지닌 한계를 극복하고, 다양한 도메인에 걸쳐 동적 지식 전이를 가능하게 하는 <strong>통합적이고 정밀한 시각적 행동 표현</strong>을 제안하는 것이 목표입니다.</p>
<h2>핵심 방법론</h2>
<p>저자들은 행동을 <strong>2D 스켈레톤</strong>과 같은 **"시각적 행동 프롬프트"**로 렌더링하여 도메인 불가지론적(domain-agnostic) 표현으로 활용합니다. 인간-객체 상호작용(HOI) 비디오에서는 <strong>Wilor</strong> 및 <strong>SAMURAI</strong> 기반의 다단계 파이프라인을 통해 3D 손 메시 궤적을 추출하고 2D 스켈레톤으로 변환하며, 로봇 조작 데이터에서는 상태 로그로부터 렌더링된 스켈레톤을 <strong>MatchAnything</strong> 및 호모그래피 워핑으로 보정합니다. 이렇게 구축된 (스켈레톤, 비디오) 쌍을 활용하여 사전 훈련된 비디오 생성 모델인 **CogVideoX [72]**에 **ControlNet [76]**을 통합하고 **LoRA [30]**를 사용하여 경량 파인튜닝을 수행합니다.</p>
<h2>주요 결과</h2>
<p>제안된 시각적 행동 프롬프트는 텍스트 및 에이전트 중심의 원시 행동 표현보다 <strong>일관되게 우수한 성능</strong>을 보였습니다. RT-1 데이터셋에서 <strong>ST-IoU 0.604</strong>, DROID 데이터셋에서 <strong>ST-IoU 0.450</strong>를 달성하여 기존 방법 대비 동적 정확도 및 생성 품질이 향상되었습니다. 특히, <strong>이종 데이터셋에 대한 공동 훈련</strong>을 통해 DROID에서 객체 일관성이 개선되고 RT-1의 미학습 스킬(예: 서랍 닫기)에 대한 일반화 능력이 입증되었습니다.</p>
<h2>AI 실무자를 위한 시사점</h2>
<p>본 연구는 복잡한 상호작용을 포함하는 비디오 생성에서 <strong>시각적 스켈레톤 프롬프트</strong>가 기존 텍스트나 로봇 제어 신호보다 <strong>더욱 정밀하고 범용적인 제어</strong>를 제공함을 보여줍니다. 이는 <strong>로봇 시뮬레이션, 게임 및 행동 정책 학습</strong>과 같이 정교한 상호작용 구현이 필요한 AI 애플리케이션에 매우 유용할 수 있습니다. 또한, 사전 훈련된 대규모 비디오 모델을 <strong>ControlNet</strong>과 <strong>LoRA</strong>를 통해 효과적으로 파인튜닝함으로써, <strong>다양한 데이터셋의 지식을 통합</strong>하고 <strong>모델 학습 효율성</strong>을 높일 수 있는 실용적인 방안을 제시합니다.</p>
<blockquote>
<p>⚠️ <strong>알림:</strong> 이 리뷰는 AI로 작성되었습니다.</p>
</blockquote>
</div></div><footer class="page__meta mt-8"><div class="page__taxonomy mb-4"><h4 class="text-sm font-medium text-gray-900 mb-2">카테고리</h4><span class="page__taxonomy-item">Review</span></div><div class="page__taxonomy"><h4 class="text-sm font-medium text-gray-900 mb-2">태그</h4><span class="page__taxonomy-item">#<!-- -->Review</span><span class="page__taxonomy-item">#<!-- -->Action-to-Video Generation</span><span class="page__taxonomy-item">#<!-- -->Visual Action Prompts</span><span class="page__taxonomy-item">#<!-- -->Skeleton Representation</span><span class="page__taxonomy-item">#<!-- -->Human-Object Interaction</span><span class="page__taxonomy-item">#<!-- -->Robotic Manipulation</span><span class="page__taxonomy-item">#<!-- -->Cross-Domain Transfer</span><span class="page__taxonomy-item">#<!-- -->Diffusion Models</span></div></footer></article></main></div><!--/$--></main><div id="footer" class="page__footer"><footer class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8"><div class="text-center text-gray-500 text-sm"><p>© 2025 secrett2633. All rights reserved.</p></div></footer></div></div><script src="/secrett2633.github.io/_next/static/chunks/webpack-a04af954a21fa650.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0]);self.__next_f.push([2,null])</script><script>self.__next_f.push([1,"1:HL[\"/secrett2633.github.io/_next/static/media/e4af272ccee01ff0-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n2:HL[\"/secrett2633.github.io/_next/static/css/b9d6ec750ad82add.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"3:I[5751,[],\"\"]\n6:I[9275,[],\"\"]\n8:I[1343,[],\"\"]\n9:I[4281,[\"231\",\"static/chunks/231-c4b666723e6aae68.js\",\"185\",\"static/chunks/app/layout-8808afda01b7a1b7.js\"],\"default\"]\na:I[231,[\"231\",\"static/chunks/231-c4b666723e6aae68.js\",\"877\",\"static/chunks/app/%5B...slug%5D/page-01b66e77b48ed573.js\"],\"\"]\nc:I[6130,[],\"\"]\n7:[\"slug\",\"ai/review/2025-8-19-Precise_Action-to-Video_Generation_Through_Visual_Action_Prompts\",\"c\"]\nd:[]\n"])</script><script>self.__next_f.push([1,"0:[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/secrett2633.github.io/_next/static/css/b9d6ec750ad82add.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]],[\"$\",\"$L3\",null,{\"buildId\":\"iV6XySbMHIJ3imQdvgy3I\",\"assetPrefix\":\"/secrett2633.github.io\",\"initialCanonicalUrl\":\"/ai/review/2025-8-19-Precise_Action-to-Video_Generation_Through_Visual_Action_Prompts/\",\"initialTree\":[\"\",{\"children\":[[\"slug\",\"ai/review/2025-8-19-Precise_Action-to-Video_Generation_Through_Visual_Action_Prompts\",\"c\"],{\"children\":[\"__PAGE__?{\\\"slug\\\":[\\\"ai\\\",\\\"review\\\",\\\"2025-8-19-Precise_Action-to-Video_Generation_Through_Visual_Action_Prompts\\\"]}\",{}]}]},\"$undefined\",\"$undefined\",true],\"initialSeedData\":[\"\",{\"children\":[[\"slug\",\"ai/review/2025-8-19-Precise_Action-to-Video_Generation_Through_Visual_Action_Prompts\",\"c\"],{\"children\":[\"__PAGE__\",{},[[\"$L4\",\"$L5\"],null],null]},[\"$\",\"$L6\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"$7\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L8\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"styles\":null}],null]},[[\"$\",\"html\",null,{\"lang\":\"ko\",\"className\":\"no-js\",\"children\":[[\"$\",\"head\",null,{\"children\":[[\"$\",\"link\",null,{\"rel\":\"icon\",\"type\":\"image/png\",\"sizes\":\"32x32\",\"href\":\"/favicon-32x32.png\"}],[\"$\",\"link\",null,{\"rel\":\"icon\",\"type\":\"image/png\",\"sizes\":\"16x16\",\"href\":\"/favicon-16x16.png\"}],[\"$\",\"meta\",null,{\"name\":\"msapplication-TileColor\",\"content\":\"#ffc40d\"}],[\"$\",\"meta\",null,{\"name\":\"theme-color\",\"content\":\"#ffffff\"}],[\"$\",\"script\",null,{\"async\":true,\"src\":\"https://www.googletagmanager.com/gtag/js?id=G-NE2W3CFPNY\"}],[\"$\",\"script\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"\\n              window.dataLayer = window.dataLayer || [];\\n              function gtag(){dataLayer.push(arguments);}\\n              gtag('js', new Date());\\n              gtag('config', 'G-NE2W3CFPNY');\\n            \"}}]]}],[\"$\",\"body\",null,{\"className\":\"__className_9012cf layout--default\",\"children\":[\"$\",\"div\",null,{\"className\":\"min-h-screen bg-gray-50\",\"children\":[[\"$\",\"$L9\",null,{}],[\"$\",\"main\",null,{\"className\":\"initial-content\",\"children\":[\"$\",\"$L6\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L8\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[\"$\",\"div\",null,{\"className\":\"min-h-screen flex items-center justify-center bg-gray-50\",\"children\":[\"$\",\"div\",null,{\"className\":\"max-w-md w-full bg-white rounded-lg shadow-md p-8 text-center\",\"children\":[[\"$\",\"h1\",null,{\"className\":\"text-6xl font-bold text-primary-600 mb-4\",\"children\":\"404\"}],[\"$\",\"h2\",null,{\"className\":\"text-2xl font-semibold text-gray-900 mb-4\",\"children\":\"페이지를 찾을 수 없습니다\"}],[\"$\",\"p\",null,{\"className\":\"text-gray-600 mb-8\",\"children\":\"요청하신 페이지가 존재하지 않거나 이동되었을 수 있습니다.\"}],[\"$\",\"$La\",null,{\"href\":\"/\",\"className\":\"inline-flex items-center px-4 py-2 bg-primary-600 text-white rounded-md hover:bg-primary-700 transition-colors\",\"children\":\"홈으로 돌아가기\"}]]}]}],\"notFoundStyles\":[],\"styles\":null}]}],[\"$\",\"div\",null,{\"id\":\"footer\",\"className\":\"page__footer\",\"children\":[\"$\",\"footer\",null,{\"className\":\"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8\",\"children\":[\"$\",\"div\",null,{\"className\":\"text-center text-gray-500 text-sm\",\"children\":[\"$\",\"p\",null,{\"children\":\"© 2025 secrett2633. All rights reserved.\"}]}]}]}]]}]}]]}],null],[[\"$\",\"div\",null,{\"className\":\"flex items-center justify-center min-h-screen\",\"children\":[\"$\",\"div\",null,{\"className\":\"animate-spin rounded-full h-32 w-32 border-b-2 border-primary-600\"}]}],[],[]]],\"couldBeIntercepted\":false,\"initialHead\":[null,\"$Lb\"],\"globalErrorComponent\":\"$c\",\"missingSlots\":\"$Wd\"}]]\n"])</script><script>self.__next_f.push([1,"e:Tcb6,"])</script><script>self.__next_f.push([1,"\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003e링크:\u003c/strong\u003e \u003ca href=\"https://arxiv.org/abs/2508.13104\"\u003e논문 PDF로 바로 열기\u003c/a\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e\u003cstrong\u003e저자:\u003c/strong\u003e Yuang Wang, Chao Wen, Haoyu Guo, Sida Peng, Minghan Qin, Hujun Bao, Xiaowei Zhou, Ruizhen Hu\u003c/p\u003e\n\u003ch2\u003e핵심 연구 목표\u003c/h2\u003e\n\u003cp\u003e본 논문은 복잡하고 고자유도(high-DoF)의 상호작용(예: 인간의 손 또는 로봇 그리퍼 동작)을 위한 비디오 생성에서 정밀성과 범용성 간의 트레이드오프 문제를 해결하고자 합니다. 기존 텍스트나 원시 행동, 에이전트 중심의 행동 표현이 지닌 한계를 극복하고, 다양한 도메인에 걸쳐 동적 지식 전이를 가능하게 하는 \u003cstrong\u003e통합적이고 정밀한 시각적 행동 표현\u003c/strong\u003e을 제안하는 것이 목표입니다.\u003c/p\u003e\n\u003ch2\u003e핵심 방법론\u003c/h2\u003e\n\u003cp\u003e저자들은 행동을 \u003cstrong\u003e2D 스켈레톤\u003c/strong\u003e과 같은 **\"시각적 행동 프롬프트\"**로 렌더링하여 도메인 불가지론적(domain-agnostic) 표현으로 활용합니다. 인간-객체 상호작용(HOI) 비디오에서는 \u003cstrong\u003eWilor\u003c/strong\u003e 및 \u003cstrong\u003eSAMURAI\u003c/strong\u003e 기반의 다단계 파이프라인을 통해 3D 손 메시 궤적을 추출하고 2D 스켈레톤으로 변환하며, 로봇 조작 데이터에서는 상태 로그로부터 렌더링된 스켈레톤을 \u003cstrong\u003eMatchAnything\u003c/strong\u003e 및 호모그래피 워핑으로 보정합니다. 이렇게 구축된 (스켈레톤, 비디오) 쌍을 활용하여 사전 훈련된 비디오 생성 모델인 **CogVideoX [72]**에 **ControlNet [76]**을 통합하고 **LoRA [30]**를 사용하여 경량 파인튜닝을 수행합니다.\u003c/p\u003e\n\u003ch2\u003e주요 결과\u003c/h2\u003e\n\u003cp\u003e제안된 시각적 행동 프롬프트는 텍스트 및 에이전트 중심의 원시 행동 표현보다 \u003cstrong\u003e일관되게 우수한 성능\u003c/strong\u003e을 보였습니다. RT-1 데이터셋에서 \u003cstrong\u003eST-IoU 0.604\u003c/strong\u003e, DROID 데이터셋에서 \u003cstrong\u003eST-IoU 0.450\u003c/strong\u003e를 달성하여 기존 방법 대비 동적 정확도 및 생성 품질이 향상되었습니다. 특히, \u003cstrong\u003e이종 데이터셋에 대한 공동 훈련\u003c/strong\u003e을 통해 DROID에서 객체 일관성이 개선되고 RT-1의 미학습 스킬(예: 서랍 닫기)에 대한 일반화 능력이 입증되었습니다.\u003c/p\u003e\n\u003ch2\u003eAI 실무자를 위한 시사점\u003c/h2\u003e\n\u003cp\u003e본 연구는 복잡한 상호작용을 포함하는 비디오 생성에서 \u003cstrong\u003e시각적 스켈레톤 프롬프트\u003c/strong\u003e가 기존 텍스트나 로봇 제어 신호보다 \u003cstrong\u003e더욱 정밀하고 범용적인 제어\u003c/strong\u003e를 제공함을 보여줍니다. 이는 \u003cstrong\u003e로봇 시뮬레이션, 게임 및 행동 정책 학습\u003c/strong\u003e과 같이 정교한 상호작용 구현이 필요한 AI 애플리케이션에 매우 유용할 수 있습니다. 또한, 사전 훈련된 대규모 비디오 모델을 \u003cstrong\u003eControlNet\u003c/strong\u003e과 \u003cstrong\u003eLoRA\u003c/strong\u003e를 통해 효과적으로 파인튜닝함으로써, \u003cstrong\u003e다양한 데이터셋의 지식을 통합\u003c/strong\u003e하고 \u003cstrong\u003e모델 학습 효율성\u003c/strong\u003e을 높일 수 있는 실용적인 방안을 제시합니다.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e⚠️ \u003cstrong\u003e알림:\u003c/strong\u003e 이 리뷰는 AI로 작성되었습니다.\u003c/p\u003e\n\u003c/blockquote\u003e\n"])</script><script>self.__next_f.push([1,"5:[\"$\",\"div\",null,{\"className\":\"flex flex-col lg:flex-row gap-8\",\"children\":[\"$\",\"main\",null,{\"className\":\"flex-1\",\"children\":[\"$\",\"article\",null,{\"className\":\"page\",\"children\":[[\"$\",\"header\",null,{\"className\":\"mb-8\",\"children\":[[\"$\",\"h1\",null,{\"className\":\"page__title\",\"children\":\"[논문리뷰] Precise Action-to-Video Generation Through Visual Action Prompts\"}],[\"$\",\"div\",null,{\"className\":\"page__meta\",\"children\":[[\"$\",\"time\",null,{\"dateTime\":\"2025-08-19 13:15:01+0900\",\"children\":\"2025년 8월 19일\"}],[\"$\",\"span\",null,{\"className\":\"ml-4\",\"children\":[\"수정: \",\"2025년 8월 19일\"]}]]}]]}],[\"$\",\"div\",null,{\"className\":\"page__content\",\"children\":[\"$\",\"div\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"$e\"}}]}],[\"$\",\"footer\",null,{\"className\":\"page__meta mt-8\",\"children\":[[\"$\",\"div\",null,{\"className\":\"page__taxonomy mb-4\",\"children\":[[\"$\",\"h4\",null,{\"className\":\"text-sm font-medium text-gray-900 mb-2\",\"children\":\"카테고리\"}],[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":\"Review\"}]]]}],[\"$\",\"div\",null,{\"className\":\"page__taxonomy\",\"children\":[[\"$\",\"h4\",null,{\"className\":\"text-sm font-medium text-gray-900 mb-2\",\"children\":\"태그\"}],[[\"$\",\"span\",\"Review\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Review\"]}],[\"$\",\"span\",\"Action-to-Video Generation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Action-to-Video Generation\"]}],[\"$\",\"span\",\"Visual Action Prompts\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Visual Action Prompts\"]}],[\"$\",\"span\",\"Skeleton Representation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Skeleton Representation\"]}],[\"$\",\"span\",\"Human-Object Interaction\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Human-Object Interaction\"]}],[\"$\",\"span\",\"Robotic Manipulation\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Robotic Manipulation\"]}],[\"$\",\"span\",\"Cross-Domain Transfer\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Cross-Domain Transfer\"]}],[\"$\",\"span\",\"Diffusion Models\",{\"className\":\"page__taxonomy-item\",\"children\":[\"#\",\"Diffusion Models\"]}]]]}]]}]]}]}]}]\n"])</script><script>self.__next_f.push([1,"b:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}],[\"$\",\"meta\",\"1\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"2\",{\"children\":\"secrett2633's blog\"}],[\"$\",\"meta\",\"3\",{\"name\":\"description\",\"content\":\"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트\"}],[\"$\",\"meta\",\"4\",{\"name\":\"author\",\"content\":\"secrett2633\"}],[\"$\",\"meta\",\"5\",{\"name\":\"keywords\",\"content\":\"Django, Python, DevOps, AI, ML, 블로그, 기술\"}],[\"$\",\"meta\",\"6\",{\"name\":\"creator\",\"content\":\"secrett2633\"}],[\"$\",\"meta\",\"7\",{\"name\":\"publisher\",\"content\":\"secrett2633\"}],[\"$\",\"meta\",\"8\",{\"name\":\"robots\",\"content\":\"index, follow\"}],[\"$\",\"meta\",\"9\",{\"name\":\"googlebot\",\"content\":\"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1\"}],[\"$\",\"link\",\"10\",{\"rel\":\"canonical\",\"href\":\"https://secrett2633.github.io/\"}],[\"$\",\"meta\",\"11\",{\"name\":\"format-detection\",\"content\":\"telephone=no, address=no, email=no\"}],[\"$\",\"meta\",\"12\",{\"property\":\"og:title\",\"content\":\"secrett2633's blog\"}],[\"$\",\"meta\",\"13\",{\"property\":\"og:description\",\"content\":\"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트\"}],[\"$\",\"meta\",\"14\",{\"property\":\"og:url\",\"content\":\"https://secrett2633.github.io/\"}],[\"$\",\"meta\",\"15\",{\"property\":\"og:site_name\",\"content\":\"secrett2633's blog\"}],[\"$\",\"meta\",\"16\",{\"property\":\"og:locale\",\"content\":\"ko_KR\"}],[\"$\",\"meta\",\"17\",{\"property\":\"og:type\",\"content\":\"website\"}],[\"$\",\"meta\",\"18\",{\"name\":\"twitter:card\",\"content\":\"summary_large_image\"}],[\"$\",\"meta\",\"19\",{\"name\":\"twitter:title\",\"content\":\"secrett2633's blog\"}],[\"$\",\"meta\",\"20\",{\"name\":\"twitter:description\",\"content\":\"기술 블로그 - Django, Python, DevOps, AI/ML 관련 포스트\"}],[\"$\",\"meta\",\"21\",{\"name\":\"next-size-adjust\"}]]\n4:null\n"])</script></body></html>