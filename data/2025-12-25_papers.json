[
  {
    "title": "Learning to Reason in 4D: Dynamic Spatial Understanding for Vision Language Models",
    "authors": "",
    "link": "https://arxiv.org/abs/2512.20557",
    "pdf_path": "temp_pdfs/2512.20557.pdf"
  },
  {
    "title": "TurboDiffusion: Accelerating Video Diffusion Models by 100-200 Times",
    "authors": "",
    "link": "https://arxiv.org/abs/2512.16093",
    "pdf_path": "temp_pdfs/2512.16093.pdf"
  },
  {
    "title": "T2AV-Compass: Towards Unified Evaluation for Text-to-Audio-Video Generation",
    "authors": "",
    "link": "https://arxiv.org/abs/2512.21094",
    "pdf_path": "temp_pdfs/2512.21094.pdf"
  },
  {
    "title": "DreaMontage: Arbitrary Frame-Guided One-Shot Video Generation",
    "authors": "",
    "link": "https://arxiv.org/abs/2512.21252",
    "pdf_path": "temp_pdfs/2512.21252.pdf"
  },
  {
    "title": "Beyond Memorization: A Multi-Modal Ordinal Regression Benchmark to Expose Popularity Bias in Vision-Language Models",
    "authors": "Yu-Lun Liu, He Syu, Chia-Jui Chang, Ting-Lin Wu, Li-Zhong Szu-Tu",
    "link": "https://arxiv.org/abs/2512.21337",
    "pdf_path": "temp_pdfs/2512.21337.pdf"
  },
  {
    "title": "Nemotron 3 Nano: Open, Efficient Mixture-of-Experts Hybrid Mamba-Transformer Model for Agentic Reasoning",
    "authors": "",
    "link": "https://arxiv.org/abs/2512.20848",
    "pdf_path": "temp_pdfs/2512.20848.pdf"
  },
  {
    "title": "HiStream: Efficient High-Resolution Video Generation via Redundancy-Eliminated Streaming",
    "authors": "",
    "link": "https://arxiv.org/abs/2512.21338",
    "pdf_path": "temp_pdfs/2512.21338.pdf"
  },
  {
    "title": "TokSuite: Measuring the Impact of Tokenizer Choice on Language Model Behavior",
    "authors": "",
    "link": "https://arxiv.org/abs/2512.20757",
    "pdf_path": "temp_pdfs/2512.20757.pdf"
  },
  {
    "title": "NVIDIA Nemotron 3: Efficient and Open Intelligence",
    "authors": "",
    "link": "https://arxiv.org/abs/2512.20856",
    "pdf_path": "temp_pdfs/2512.20856.pdf"
  },
  {
    "title": "Learning from Next-Frame Prediction: Autoregressive Video Modeling Encodes Effective Representations",
    "authors": "",
    "link": "https://arxiv.org/abs/2512.21004",
    "pdf_path": "temp_pdfs/2512.21004.pdf"
  },
  {
    "title": "Multi-hop Reasoning via Early Knowledge Alignment",
    "authors": "Xuanjing Huang, Qi Luo, Bo Wang, Shicheng Fang, Yuxin Wang",
    "link": "https://arxiv.org/abs/2512.20144",
    "pdf_path": "temp_pdfs/2512.20144.pdf"
  },
  {
    "title": "Streaming Video Instruction Tuning",
    "authors": "Kaiyang Zhou, Xing Sun, Mengdan Zhang, Peixian Chen, Jiaer Xia",
    "link": "https://arxiv.org/abs/2512.21334",
    "pdf_path": "temp_pdfs/2512.21334.pdf"
  },
  {
    "title": "SWE-EVO: Benchmarking Coding Agents in Long-Horizon Software Evolution Scenarios",
    "authors": "Nghi D. Q. Bui, Huy Phan Nhat, Dung Nguyen Manh, Tue Le, Minh V. T. Thai",
    "link": "https://arxiv.org/abs/2512.18470",
    "pdf_path": "temp_pdfs/2512.18470.pdf"
  },
  {
    "title": "LLM Swiss Round: Aggregating Multi-Benchmark Performance via Competitive Swiss-System Dynamics",
    "authors": "",
    "link": "https://arxiv.org/abs/2512.21010",
    "pdf_path": "temp_pdfs/2512.21010.pdf"
  }
]