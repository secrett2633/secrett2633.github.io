[
  {
    "title": "VCode: a Multimodal Coding Benchmark with SVG as Symbolic Visual\n  Representation",
    "authors": "",
    "link": "https://arxiv.org/abs/2511.02778",
    "pdf_path": "temp_pdfs\\2511.02778.pdf"
  },
  {
    "title": "Don't Blind Your VLA: Aligning Visual Representations for OOD\n  Generalization",
    "authors": "Aleksandr I. Panov, Alexey K. Kovalev, Mikhail Kolosov, zelezetsky, tttonyalpha",
    "link": "https://arxiv.org/abs/2510.25616",
    "pdf_path": "temp_pdfs\\2510.25616.pdf"
  },
  {
    "title": "When Visualizing is the First Step to Reasoning: MIRA, a Benchmark for\n  Visual Chain-of-Thought",
    "authors": "",
    "link": "https://arxiv.org/abs/2511.02779",
    "pdf_path": "temp_pdfs\\2511.02779.pdf"
  },
  {
    "title": "Step-Audio-EditX Technical Report",
    "authors": "",
    "link": "https://arxiv.org/abs/2511.03601",
    "pdf_path": "temp_pdfs\\2511.03601.pdf"
  },
  {
    "title": "When Modalities Conflict: How Unimodal Reasoning Uncertainty Governs\n  Preference Dynamics in MLLMs",
    "authors": "Haotian Wang, Xilin Gong, Tengyue Wang, Zhuoran Zhang, DogNeverSleep",
    "link": "https://arxiv.org/abs/2511.02243",
    "pdf_path": "temp_pdfs\\2511.02243.pdf"
  },
  {
    "title": "The Collaboration Gap",
    "authors": "",
    "link": "https://arxiv.org/abs/2511.02687",
    "pdf_path": "temp_pdfs\\2511.02687.pdf"
  },
  {
    "title": "Shorter but not Worse: Frugal Reasoning via Easy Samples as Length\n  Regularizers in Math RLVR",
    "authors": "",
    "link": "https://arxiv.org/abs/2511.01937",
    "pdf_path": "temp_pdfs\\2511.01937.pdf"
  },
  {
    "title": "Brain-IT: Image Reconstruction from fMRI via Brain-Interaction\n  Transformer",
    "authors": "",
    "link": "https://arxiv.org/abs/2510.25976",
    "pdf_path": "temp_pdfs\\2510.25976.pdf"
  },
  {
    "title": "TWIST2: Scalable, Portable, and Holistic Humanoid Data Collection System",
    "authors": "Rocky Duan, Angjoo Kanazawa, Weizhuo Wang, Siheng Zhao, yjze",
    "link": "https://arxiv.org/abs/2511.02832",
    "pdf_path": "temp_pdfs\\2511.02832.pdf"
  },
  {
    "title": "Can Visual Input Be Compressed? A Visual Token Compression Benchmark for\n  Large Multimodal Models",
    "authors": "Shijie Dong, Pengzhou Ji, Yuntao Du, Tianfan Peng, kailinjiang",
    "link": "https://arxiv.org/abs/2511.02650",
    "pdf_path": "temp_pdfs\\2511.02650.pdf"
  },
  {
    "title": "LTD-Bench: Evaluating Large Language Models by Letting Them Draw",
    "authors": "",
    "link": "https://arxiv.org/abs/2511.02347",
    "pdf_path": "temp_pdfs\\2511.02347.pdf"
  },
  {
    "title": "CodeClash: Benchmarking Goal-Oriented Software Engineering",
    "authors": "",
    "link": "https://arxiv.org/abs/2511.00839",
    "pdf_path": "temp_pdfs\\2511.00839.pdf"
  },
  {
    "title": "iFlyBot-VLA Technical Report",
    "authors": "Jiajia wu, Chao Ji, Wenjie Xu, Chenyu Xue, Yuan Zhang",
    "link": "https://arxiv.org/abs/2511.01914",
    "pdf_path": "temp_pdfs\\2511.01914.pdf"
  },
  {
    "title": "RoboChallenge: Large-scale Real-robot Evaluation of Embodied Policies",
    "authors": "",
    "link": "https://arxiv.org/abs/2510.17950",
    "pdf_path": "temp_pdfs\\2510.17950.pdf"
  },
  {
    "title": "Forget BIT, It is All about TOKEN: Towards Semantic Information Theory\n  for LLMs",
    "authors": "Bo Bai",
    "link": "https://arxiv.org/abs/2511.01202",
    "pdf_path": "temp_pdfs\\2511.01202.pdf"
  },
  {
    "title": "BRAINS: A Retrieval-Augmented System for Alzheimer's Detection and\n  Monitoring",
    "authors": "",
    "link": "https://arxiv.org/abs/2511.02490",
    "pdf_path": "temp_pdfs\\2511.02490.pdf"
  },
  {
    "title": "ChartM^3: A Multi-Stage Code-Driven Pipeline for Constructing\n  Multi-Dimensional and Multi-Step Visual Reasoning Data in Chart Comprehension",
    "authors": "Hao Wang, Zhen Xie, Xin Lin, Hao Cheng, Duo Xu",
    "link": "https://arxiv.org/abs/2511.02415",
    "pdf_path": "temp_pdfs\\2511.02415.pdf"
  },
  {
    "title": "RiddleBench: A New Generative Reasoning Benchmark for LLMs",
    "authors": "",
    "link": "https://arxiv.org/abs/2510.24932",
    "pdf_path": "temp_pdfs\\2510.24932.pdf"
  },
  {
    "title": "VidEmo: Affective-Tree Reasoning for Emotion-Centric Video Foundation\n  Models",
    "authors": "Pengfei Wan, Wenyu Qin, Yongjie Zhu, Weicheng Wang, Zhicheng Zhang",
    "link": "https://arxiv.org/abs/2511.02712",
    "pdf_path": "temp_pdfs\\2511.02712.pdf"
  },
  {
    "title": "AyurParam: A State-of-the-Art Bilingual Language Model for Ayurveda",
    "authors": "",
    "link": "https://arxiv.org/abs/2511.02374",
    "pdf_path": "temp_pdfs\\2511.02374.pdf"
  },
  {
    "title": "LiveSecBench: A Dynamic and Culturally-Relevant AI Safety Benchmark for\n  LLMs in Chinese Context",
    "authors": "Tianxin Zhang, Wenxuan Wang, Kejiang Chen, Zhongliang Yang, Yudong Li",
    "link": "https://arxiv.org/abs/2511.02366",
    "pdf_path": "temp_pdfs\\2511.02366.pdf"
  },
  {
    "title": "TabDSR: Decompose, Sanitize, and Reason for Complex Numerical Reasoning\n  in Tabular Data",
    "authors": "Jin Zeng, Wei Lu, Haihua Chen, Fengchang Yu, arnodjiang",
    "link": "https://arxiv.org/abs/2511.02219",
    "pdf_path": "temp_pdfs\\2511.02219.pdf"
  },
  {
    "title": "Discriminately Treating Motion Components Evolves Joint Depth and\n  Ego-Motion Learning",
    "authors": "Zuyi Xiong, Yi Feng, Hongbo Zhao, Zizhan Guo, Mengtan Zhang",
    "link": "https://arxiv.org/abs/2511.01502",
    "pdf_path": "temp_pdfs\\2511.01502.pdf"
  },
  {
    "title": "Reg-DPO: SFT-Regularized Direct Preference Optimization with GT-Pair for\n  Improving Video Generation",
    "authors": "",
    "link": "https://arxiv.org/abs/2511.01450",
    "pdf_path": "temp_pdfs\\2511.01450.pdf"
  },
  {
    "title": "D2D: Detector-to-Differentiable Critic for Improved Numeracy in\n  Text-to-Image Generation",
    "authors": "Ye Zhu, Olga Russakovsky, n-yoo",
    "link": "https://arxiv.org/abs/2510.19278",
    "pdf_path": "temp_pdfs\\2510.19278.pdf"
  }
]