[
  {
    "title": "Thinking with Video: Video Generation as a Promising Multimodal\n  Reasoning Paradigm",
    "authors": "",
    "link": "https://arxiv.org/abs/2511.04570",
    "pdf_path": "temp_pdfs\\2511.04570.pdf"
  },
  {
    "title": "V-Thinker: Interactive Thinking with Images",
    "authors": "Peiqing Yang, Guanting Dong, Minghan Yang, Qiuna Tan, Runqi Qiao",
    "link": "https://arxiv.org/abs/2511.04460",
    "pdf_path": "temp_pdfs\\2511.04460.pdf"
  },
  {
    "title": "Scaling Agent Learning via Experience Synthesis",
    "authors": "",
    "link": "https://arxiv.org/abs/2511.03773",
    "pdf_path": "temp_pdfs\\2511.03773.pdf"
  },
  {
    "title": "Cambrian-S: Towards Spatial Supersensing in Video",
    "authors": "Zihao Yang, Ellis Brown, Pinzhi Huang, Jihan Yang, ShushengYang",
    "link": "https://arxiv.org/abs/2511.04670",
    "pdf_path": "temp_pdfs\\2511.04670.pdf"
  },
  {
    "title": "NVIDIA Nemotron Nano V2 VL",
    "authors": "",
    "link": "https://arxiv.org/abs/2511.03929",
    "pdf_path": "temp_pdfs\\2511.03929.pdf"
  },
  {
    "title": "GUI-360: A Comprehensive Dataset and Benchmark for Computer-Using Agents",
    "authors": "",
    "link": "https://arxiv.org/abs/2511.04307",
    "pdf_path": "temp_pdfs\\2511.04307.pdf"
  },
  {
    "title": "Contamination Detection for VLMs using Multi-Modal Semantic Perturbation",
    "authors": "",
    "link": "https://arxiv.org/abs/2511.03774",
    "pdf_path": "temp_pdfs\\2511.03774.pdf"
  },
  {
    "title": "The Strong Lottery Ticket Hypothesis for Multi-Head Attention Mechanisms",
    "authors": "Susumu Takeuchi, Daichi Fujiki, Yasuyuki Okoshi, Daiki Chijiwa, h-otsuka",
    "link": "https://arxiv.org/abs/2511.04217",
    "pdf_path": "temp_pdfs\\2511.04217.pdf"
  },
  {
    "title": "Benchmark Designers Should \"Train on the Test Set\" to Expose Exploitable\n  Non-Visual Shortcuts",
    "authors": "",
    "link": "https://arxiv.org/abs/2511.04655",
    "pdf_path": "temp_pdfs\\2511.04655.pdf"
  },
  {
    "title": "SIMS-V: Simulated Instruction-Tuning for Spatial Video Understanding",
    "authors": "",
    "link": "https://arxiv.org/abs/2511.04668",
    "pdf_path": "temp_pdfs\\2511.04668.pdf"
  },
  {
    "title": "Learning Vision-Driven Reactive Soccer Skills for Humanoid Robots",
    "authors": "",
    "link": "https://arxiv.org/abs/2511.03996",
    "pdf_path": "temp_pdfs\\2511.03996.pdf"
  },
  {
    "title": "How to Evaluate Speech Translation with Source-Aware Neural MT Metrics",
    "authors": "Luisa Bentivogli, Matteo Negri, Marco Gaido, Mauro Cettolo, spapi",
    "link": "https://arxiv.org/abs/2511.03295",
    "pdf_path": "temp_pdfs\\2511.03295.pdf"
  },
  {
    "title": "RDMA Point-to-Point Communication for LLM Systems",
    "authors": "",
    "link": "https://arxiv.org/abs/2510.27656",
    "pdf_path": "temp_pdfs\\2510.27656.pdf"
  },
  {
    "title": "SAIL-RL: Guiding MLLMs in When and How to Think via Dual-Reward RL\n  Tuning",
    "authors": "",
    "link": "https://arxiv.org/abs/2511.02280",
    "pdf_path": "temp_pdfs\\2511.02280.pdf"
  },
  {
    "title": "EVTAR: End-to-End Try on with Additional Unpaired Visual Reference",
    "authors": "",
    "link": "https://arxiv.org/abs/2511.00956",
    "pdf_path": "temp_pdfs\\2511.00956.pdf"
  }
]