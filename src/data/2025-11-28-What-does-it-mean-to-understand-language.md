---
title: "[논문리뷰] What does it mean to understand language?"
excerpt: "arXiv에 게시된 'What does it mean to understand language?' 논문에 대한 자세한 리뷰입니다."

categories:
  - Review
tags:
  - Review
  - Language Understanding
  - Cognitive Neuroscience
  - Situation Models
  - World Knowledge
  - Embodiment
  - fMRI
  - Large Language Models
  - Brain Networks

permalink: /ai/review/2025-11-28-What-does-it-mean-to-understand-language/

toc: true
toc_sticky: true

date: 2025-11-28 00:00:00+0900+0900
last_modified_at: 2025-11-28 00:00:00+0900+0900
published: true
---
> **링크:** [논문 PDF로 바로 열기](https://arxiv.org/abs/2511.19757)

**저자:** Colton Casto, Anna Ivanova, Evelina Fedorenko, Nancy Kanwisher



## 핵심 연구 목표
본 논문은 인간의 **심층적인 언어 이해** 가 뇌의 핵심 언어 시스템 내에서만 이루어지는 것이 아니라, 해당 시스템에서 얻은 정보가 다른 전문화된 뇌 영역으로 **내보내져(exportation) 처리** 되어야 한다는 가설을 제안합니다. 언어 이해의 인지적, 신경적, 그리고 계산적 의미를 밝히기 위한 새로운 연구 전략을 제시하며, 표면적 의미 추출을 넘어선 상황 모델 구축의 중요성을 강조합니다.

## 핵심 방법론
이 논문은 **인지 신경과학 연구 결과** 를 바탕으로 한 가설적 프레임워크를 제시합니다. 핵심 언어 시스템과 **마음 이론 네트워크** , **직관적 물리 추론 네트워크** , **내비게이션 및 장면 이해 영역** , **지각/운동 영역** 등 다양한 기능적으로 특화된 뇌 영역 간의 정보 흐름을 검토합니다. 특히, **기능적 특이성** , **개별 참여자 내에서의 영역 식별** , **수동적 언어 이해 과제 사용** 을 강력한 증거 평가 기준으로 제안하며, **대규모 언어 모델(LLM)** 을 얕은 이해의 컴퓨테이셔널 모델로 활용하여 뇌의 작동 방식을 탐구합니다.

## 주요 결과
핵심 언어 시스템은 주로 언어의 통계적 패턴을 기반으로 하는 **얕은 언어 이해** 를 담당하며, 이는 초기 **GPT-2 같은 LLM** 의 작동 방식과 유사합니다. 실제로 **상대적으로 작은 LLM** 도 핵심 언어 시스템 반응의 **대부분의 분산(variance)** 을 설명할 수 있음이 제시되었습니다. **심층적 이해** 는 언어 시스템의 정보가 **마음 이론, 직관적 물리, 내비게이션, 지각/운동 시뮬레이션** 등과 관련된 외부 뇌 영역으로 내보내질 때 발생하며, 이러한 내보내기는 언어 입력의 복잡성, 이해자의 목표, 기존 지식 등 여러 요인에 의해 조절됩니다.

## AI 실무자를 위한 시사점
본 연구는 현재의 **LLM** 이 주로 **얕은 언어 이해** 에 머무르고 있음을 시사하며, 인간과 같은 **심층적 언어 이해** 를 구현하기 위해 AI 시스템도 **모듈화된 아키텍처** 를 채택할 필요성을 제안합니다. 이는 LLM이 **외부 지식 베이스** , **지각 모듈** , **물리 엔진** 등과 같은 특화된 "전문가" 모듈과 상호작용하도록 설계하는 **멀티모달 및 접지(grounded) AI 시스템** 개발에 중요한 영감을 제공합니다. 또한, 인간 뇌의 정보 내보내기 메커니즘을 이해하는 것이 **보다 강력하고 유연한 AI 모델** 을 구축하는 데 기여할 수 있습니다.

> ⚠️ **알림:** 이 리뷰는 AI로 작성되었습니다.