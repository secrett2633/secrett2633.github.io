---
title: "[논문리뷰] VITA-E: Natural Embodied Interaction with Concurrent Seeing, Hearing,
  Speaking, and Acting"
excerpt: "Haihan Gao이 [arXiv]에 게시한 'VITA-E: Natural Embodied Interaction with Concurrent Seeing, Hearing,
  Speaking, and Acting' 논문에 대한 자세한 리뷰입니다."

categories:
  - Review
tags:
  - Review
  - Embodied AI
  - Human-Robot Interaction
  - Vision-Language Models
  - Concurrency
  - Interruption
  - Robotics Control
  - Dual-Model Architecture
  - Special Tokens

permalink: /ai/review/2025-10-28-VITA-E_Natural_Embodied_Interaction_with_Concurrent_Seeing_Hearing_Speaking_and_Acting/

toc: true
toc_sticky: true

date: 2025-10-28 13:07:54+0900
last_modified_at: 2025-10-28 13:07:54+0900
published: true
---
> **링크:** [논문 PDF로 바로 열기](https://arxiv.org/abs/2510.21817)

**저자:** Xiaoyu Liu, Chaoyou Fu, Chi Yan, Chu Wu, Haihan Gao, Yi-Fan Zhang, Shaoqi Dong, Cheng Qian, Bin Luo, Xiuyong Yang, Guanwu Li, Yusheng Cai, Yunhang Shen, Deqiang Jiang, Haoyu Cao, Xing Sun, Caifeng Shan, Ran He



## 핵심 연구 목표
기존 VLM 기반 로봇 시스템의 고정적이고 비동시적인 상호작용 패러다임이 유연한 인간-로봇 협력을 저해하는 문제를 해결하는 것을 목표로 합니다. 로봇이 인간처럼 **동시에 보고, 듣고, 말하고, 행동하며** 실시간 사용자 개입에 동적으로 반응할 수 있는 프레임워크를 구축하고자 합니다.

## 핵심 방법론
본 연구는 **"Active Model"**과 **"Standby Model"**로 구성된 **듀얼 모델 아키텍처**를 제안하여 행동 동시성 및 실시간 중단을 가능하게 합니다. **VLM**은 **[ACT], [HALT], [RES], [INST], [END]**와 같은 **특수 토큰**을 직접 생성하여 시스템 상태 전환을 제어하는 **"모델-컨트롤러"** 패러다임을 따릅니다. **ActionNet**, **Libero**, 그리고 자체 수집된 데이터를 활용하여 VLM이 이러한 제어 토큰을 생성하도록 **데이터 큐레이션 및 미세 조정** 과정을 거칩니다.

## 주요 결과
VITA-E는 복잡한 상호작용 시나리오에서 높은 신뢰성을 보였습니다. 음성 중단 및 비상 정지에서 **100%의 성공률**을 달성했으며, 동시에 음성 응답과 행동을 수행하는 **동시성** 작업을 성공적으로 처리했습니다. 작업 전환 시나리오에서는 **93.3%의 성공률**을 기록했고, **VITA-1.5** 기반 모델과의 비교 연구에서 **미세 조정된 VLM**은 비상 정지 명령 처리에서 **0%에서 100%로** 정확도가 크게 향상되었습니다.

## AI 실무자를 위한 시사점
이 연구는 **동시성 멀티태스킹**과 **동적 개입**이 가능한 차세대 AI 로봇 시스템 개발에 중요한 발걸음을 내디뎠습니다. **듀얼 모델 아키텍처**와 **특수 토큰 기반 제어 흐름**은 AI/ML 엔지니어가 보다 자연스럽고 반응성 높은 인간-로봇 상호작용 시스템을 설계하는 데 실용적인 가이드라인을 제공합니다. 다만, 단일 모델 시스템 대비 **더 높은 컴퓨팅 자원 소모**는 고려해야 할 부분입니다.

> ⚠️ **알림:** 이 리뷰는 AI로 작성되었습니다.