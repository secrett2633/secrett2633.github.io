---
title: "[논문리뷰] Deep Ignorance: Filtering Pretraining Data Builds Tamper-Resistant
  Safeguards into Open-Weight LLMs"
excerpt: "Robert Kirk이 [arXiv]에 게시한 'Deep Ignorance: Filtering Pretraining Data Builds Tamper-Resistant
  Safeguards into Open-Weight LLMs' 논문에 대한 자세한 리뷰입니다."

categories:
  - Review
tags:
  - Review
  - LLMs
  - 데이터 필터링
  - 사전 학습
  - 변조 저항성
  - 바이오위협
  - AI 안전
  - 서킷 브레이킹
  - 머신 언러닝

permalink: /ai/review/2025-8-12-Deep_Ignorance_Filtering_Pretraining_Data_Builds_Tamper-Resistant_Safeguards_into_Open-Weight_LLMs/

toc: true
toc_sticky: true

date: 2025-08-12 13:29:09+0900
last_modified_at: 2025-08-12 13:29:09+0900
published: true
---
> **링크:** [논문 PDF로 바로 열기](https://arxiv.org/abs/2508.06601)

**저자:** Kyle O'Brien, Stephen Casper, Quentin Anthony, Tomek Korbak, Robert Kirk, Xander Davies, Ishan Mishra, Geoffrey Irving, Yarin Gal, Stella Biderman



## 핵심 연구 목표
본 논문은 오픈-웨이트 대규모 언어 모델(LLMs)이 이중 용도(dual-use) 지식(예: 바이오위협 프록시 지식)을 학습하는 것을 효과적으로 방지하고, adversarial fine-tuning 공격에 대한 변조 저항성을 높이는 새로운 방법을 제안합니다. 이는 모델의 안전성을 향상시키면서 일반적인 능력의 저하를 최소화하는 것을 목표로 합니다.

## 핵심 방법론
연구팀은 효율적인 **다단계 데이터 필터링 파이프라인**을 도입했습니다. 이 파이프라인은 사전 학습 데이터에서 이중 용도 생물학 관련 텍스트를 식별하고 제거하며, 전체 훈련 **FLOPS**의 **1%** 미만을 차지합니다. 또한, **6.9B-파라미터 모델**을 처음부터 학습시키고, 기존의 사후 훈련 안전 장치인 **Circuit Breaking (CB)** 및 **Latent Adversarial Training (LAT)**과 데이터 필터링의 시너지를 평가했습니다.

## 주요 결과
데이터 필터링은 **10,000 스텝** 및 **300M 토큰**의 adversarial fine-tuning 공격에 대해 기존 사후 훈련 방법보다 **10배 이상** 뛰어난 변조 저항성을 보였습니다. 이는 일반적인 능력(예: **MMLU** 벤치마크)에 대한 저하 없이 달성되었습니다. 그러나 필터링된 모델도 컨텍스트(예: 검색 도구 증강)에서 유해한 정보가 제공될 경우 이를 활용할 수 있음이 확인되어 방어 심층 접근 방식의 필요성을 시사합니다.

## AI 실무자를 위한 시사점
사전 학습 데이터 필터링은 오픈-웨이트 LLMs의 특정 유해 지식 습득을 예방하고 변조 저항성을 구축하는 매우 유망하고 효율적인 방어 계층임을 보여줍니다. AI 실무자들은 **Circuit Breaking**과 같은 사후 훈련 기술과 데이터 필터링을 결합하여 **방어 심층(defense-in-depth)** 전략을 구현함으로써 모델의 안전성을 더욱 강화할 수 있습니다. 그러나 모델이 외부 컨텍스트에서 유해 정보를 활용하는 것을 완전히 막을 수는 없으므로, 추가적인 안전 장치와 지속적인 모니터링이 중요합니다.

> ⚠️ **알림:** 이 리뷰는 AI로 작성되었습니다.