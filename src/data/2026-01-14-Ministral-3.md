---
title: "[논문리뷰] Ministral 3"
excerpt: "arXiv에 게시된 'Ministral 3' 논문에 대한 자세한 리뷰입니다."

categories:
  - Review
tags:
  - Review
  - Large Language Models
  - Model Distillation
  - Pruning
  - Parameter-Efficient AI
  - Multimodal LLMs
  - Instruction Tuning
  - Reinforcement Learning from Human Feedback
  - Open-Source AI

permalink: /ai/review/2026-01-14-Ministral-3/

toc: true
toc_sticky: true

date: 2026-01-14 00:00:00+0900+0900
last_modified_at: 2026-01-14 00:00:00+0900+0900
published: true
---
> **링크:** [논문 PDF로 바로 열기](https://arxiv.org/abs/2601.08584)

**저자:** Alexander H. Liu, Kartik Khandelwal, Sandeep Subramanian, Victor Jouault



## 핵심 연구 목표
본 연구는 **컴퓨팅 및 메모리 제약이 있는 환경** 을 위한 효율적인 **매개변수 효율적(parameter-efficient) 밀집 언어 모델** 인 Ministral 3 시리즈를 개발하는 것을 목표로 합니다. 대규모 모델을 처음부터 훈련하는 데 드는 비용의 일부만으로 경쟁력 있는 성능을 달성하고, **이미지 이해 능력** 과 긴 컨텍스트 길이를 갖춘 모델을 제공하고자 합니다.

## 핵심 방법론
핵심은 **Cascade Distillation** 이라는 반복적인 훈련 전략으로, 상위 사전 훈련 모델인 **Mistral Small 3.1** 을 **반복적인 프루닝(pruning)** 을 통해 더 작은 하위 모델(3B, 8B, 14B)로 축소한 후 **로그잇 증류(logit distillation)** 를 사용하여 지속적으로 훈련합니다. 각 베이스 모델은 **Supervised Fine-Tuning (SFT)** 및 **Online Direct Preference Optimization (ODPO)** 를 통해 명령어 추종 모델로, **Chain-of-Thought (CoT) SFT** , **Group Relative Policy Optimization (GRPO)** 및 **ODPO** 를 통해 추론 모델로 미세 조정됩니다. 모든 모델은 **410M 파라미터 ViT** 를 이미지 인코더로 사용하며, 이는 사전 훈련된 상태로 고정됩니다.

## 주요 결과
Ministral 3 모델은 **1조~3조 토큰** 으로 훈련되었음에도 불구하고, **Qwen3 (36조 토큰)** 또는 **Llama3 (15조 토큰)** 과 같은 대규모 훈련 모델과 경쟁력 있는 성능을 달성했습니다. 특히 **Ministral 3 14B Base 모델** 은 **Mistral Small 3.1 Base** 와 거의 동등한 성능을 보이며, 크기는 **40% 이상 작고** 훈련 기간도 짧습니다(Abstract, Table 3). **14B 스케일** 에서 Ministral 3는 **Qwen 3 14B** 를 **TriviaQA** 및 **MATH** 에서 능가하고, **Gemma 3 12B** 보다 모든 벤치마크에서 훨씬 우수합니다(Table 2). 명령어 추종 및 추론 모델 또한 강력한 성능을 보여줍니다(Table 4, 5).

## AI 실무자를 위한 시사점
**Cascade Distillation** 은 리소스 제약이 있는 환경에서 고성능 대규모 언어 모델을 효율적으로 개발하는 강력한 방법론을 제시합니다. **3B, 8B, 14B** 의 다양한 모델 크기와 **Base, Instruct, Reasoning** 변형은 특정 하드웨어 제약 및 애플리케이션 요구사항에 맞춰 유연한 모델 선택을 가능하게 합니다. 또한, **오픈 소스 Apache 2.0 라이선스** 와 **이미지 이해 능력** 기본 탑재는 연구 및 상업적 멀티모달 애플리케이션 개발에 즉각적인 활용 가치를 제공합니다.

> ⚠️ **알림:** 이 리뷰는 AI로 작성되었습니다.