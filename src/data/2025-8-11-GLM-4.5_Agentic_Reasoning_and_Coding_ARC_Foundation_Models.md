---
title: "[논문리뷰] GLM-4.5: Agentic, Reasoning, and Coding (ARC) Foundation Models"
excerpt: "GLM-4. 5 Team이 [arXiv]에 게시한 'GLM-4.5: Agentic, Reasoning, and Coding (ARC) Foundation Models' 논문에 대한 자세한 리뷰입니다."

categories:
  - Review
tags:
  - Review
  - Large Language Model
  - Mixture-of-Experts
  - Agentic AI
  - Reasoning
  - Code Generation
  - Reinforcement Learning
  - Foundation Model

permalink: /ai/review/2025-8-11-GLM-4.5_Agentic_Reasoning_and_Coding_ARC_Foundation_Models/

toc: true
toc_sticky: true

date: 2025-08-11 13:13:28+0900
last_modified_at: 2025-08-11 13:13:28+0900
published: true
---
> **링크:** [논문 PDF로 바로 열기](https://arxiv.org/abs/2508.06471)

**저자:** GLM-4.5 Team (Zhipu AI & Tsinghua University)



## 핵심 연구 목표
본 논문은 오픈소스 **MoE(Mixture-of-Experts)** 기반 대규모 언어 모델인 **GLM-4.5**를 소개합니다. 핵심 목표는 에이전트, 추론, 코딩(ARC) 태스크 전반에서 강력한 성능을 달성하고, 사고 및 직접 응답 모드를 지원하는 하이브리드 추론 방식을 통해 계산 효율성을 극대화하는 것입니다.

## 핵심 방법론
**GLM-4.5**는 **355B 총 파라미터**와 **32B 활성화 파라미터**를 가지며, **23T 토큰**에 대한 다단계 훈련과 전문가 모델 반복 및 **강화 학습(RL)**을 포함한 종합적인 후속 훈련을 거쳤습니다. 특히, 에이전트 시스템의 함수 호출 시 **XML-like 특수 토큰 태그**를 사용하는 혁신적인 템플릿을 도입하여 문자 이스케이프를 줄였습니다. 또한, RL 훈련 효율성을 위해 **동적 샘플링 온도** 및 **난이도 기반 커리큘럼 학습** 전략을 적용했습니다.

## 주요 결과
**GLM-4.5**는 **TAU-Bench**에서 **70.1%**, **AIME 24**에서 **91.0%**, **SWE-bench Verified**에서 **64.2%**라는 인상적인 성능을 기록했습니다. 평가된 모든 모델 중 **종합 3위**, 에이전트 벤치마크에서는 **2위**를 차지했습니다. 특히, **CC-Bench** 에이전트 코딩 평가에서 **90.6%**의 높은 함수 호출 성공률을 달성하며 여러 경쟁 모델들을 능가하거나 필적하는 성능을 보여주었습니다.

## AI 실무자를 위한 시사점
**GLM-4.5**의 출시는 **MoE 아키텍처**가 대규모 모델의 효율성과 성능을 동시에 달성할 수 있음을 입증하며, 차세대 **AI 시스템** 설계에 중요한 방향을 제시합니다. 모델의 **에이전트, 추론, 코딩 능력**을 강화하기 위한 **다단계 훈련 및 RL 기법**은 실제 AI 애플리케이션 개발에 실질적인 가이드라인을 제공합니다. **GLM-4.5** 및 **GLM-4.5-Air**의 오픈소스 공개는 연구자들이 **추론 및 에이전트 AI 시스템** 발전에 기여할 수 있는 중요한 자원이 될 것입니다.

> ⚠️ **알림:** 이 리뷰는 AI로 작성되었습니다.