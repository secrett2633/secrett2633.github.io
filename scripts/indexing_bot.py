#!/usr/bin/env python3
"""
Google Indexing APIë¥¼ ì‚¬ìš©í•œ ìë™ ìƒ‰ì¸ ë“±ë¡ ìŠ¤í¬ë¦½íŠ¸
GitHub Actionsìš©ìœ¼ë¡œ ìµœì í™”ë¨
"""

import os
import json
import random
import time
import requests
from datetime import datetime
from typing import List, Dict, Any
import xml.etree.ElementTree as ET
from google.oauth2 import service_account
from googleapiclient.discovery import build
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


class GoogleIndexingManager:
    def __init__(self, sitemap_url: str):
        self.sitemap_url = sitemap_url
        self.service = None
        self.credentials = None

    def setup_credentials(self) -> bool:
        """í™˜ê²½ë³€ìˆ˜ì—ì„œ Google ì„œë¹„ìŠ¤ ê³„ì • ì¸ì¦ ì •ë³´ ì„¤ì •"""
        try:
            # GitHub Secretsì—ì„œ JSON í‚¤ ê°€ì ¸ì˜¤ê¸°
            service_account_json = os.environ.get("GOOGLE_SERVICE_ACCOUNT_JSON")

            if not service_account_json:
                logger.error(
                    "GOOGLE_SERVICE_ACCOUNT_JSON í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
                )
                return False

            # JSON ë¬¸ìì—´ì„ ë”•ì…”ë„ˆë¦¬ë¡œ íŒŒì‹±
            credentials_info = json.loads(service_account_json)

            # ì„œë¹„ìŠ¤ ê³„ì • ì¸ì¦ ì •ë³´ ìƒì„±
            self.credentials = service_account.Credentials.from_service_account_info(
                credentials_info, scopes=["https://www.googleapis.com/auth/indexing"]
            )

            # Google Indexing API ì„œë¹„ìŠ¤ ìƒì„±
            self.service = build("indexing", "v3", credentials=self.credentials)

            logger.info("âœ“ Google API ì¸ì¦ ì™„ë£Œ")
            return True

        except json.JSONDecodeError as e:
            logger.error(f"JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
            return False
        except Exception as e:
            logger.error(f"ì¸ì¦ ì„¤ì • ì‹¤íŒ¨: {e}")
            return False

    def fetch_sitemap_urls(self) -> List[str]:
        """Sitemapì—ì„œ URLë“¤ì„ ì¶”ì¶œ"""
        try:
            logger.info(f"Sitemap ê°€ì ¸ì˜¤ëŠ” ì¤‘: {self.sitemap_url}")

            response = requests.get(self.sitemap_url, timeout=30)
            response.raise_for_status()

            # XML íŒŒì‹±
            root = ET.fromstring(response.content)

            # ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì²˜ë¦¬
            namespace = {"ns": "http://www.sitemaps.org/schemas/sitemap/0.9"}

            urls = []
            for url_element in root.findall(".//ns:url", namespace):
                loc_element = url_element.find("ns:loc", namespace)
                if loc_element is not None and loc_element.text:
                    urls.append(loc_element.text.strip())

            logger.info(f"âœ“ Sitemapì—ì„œ {len(urls)}ê°œì˜ URLì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")

            # ìƒ˜í”Œ URL ë¡œê·¸
            if urls:
                logger.info("ìƒ˜í”Œ URLë“¤:")
                for i, url in enumerate(urls[:3]):
                    logger.info(f"  {i+1}: {url}")
                if len(urls) > 3:
                    logger.info(f"  ... ê·¸ë¦¬ê³  {len(urls)-3}ê°œ ë”")

            return urls

        except requests.RequestException as e:
            logger.error(f"Sitemap ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
            return []
        except ET.ParseError as e:
            logger.error(f"XML íŒŒì‹± ì‹¤íŒ¨: {e}")
            return []
        except Exception as e:
            logger.error(f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
            return []

    def select_random_urls(self, urls: List[str], count: int = 200) -> List[str]:
        """ëœë¤í•˜ê²Œ ì§€ì •ëœ ê°œìˆ˜ë§Œí¼ URL ì„ íƒ"""
        if not urls:
            return []

        # ìš”ì²­í•  URL ê°œìˆ˜ ê²°ì •
        actual_count = min(count, len(urls))

        # ëœë¤ ì„ íƒ
        selected_urls = random.sample(urls, actual_count)

        logger.info(f"âœ“ {len(selected_urls)}ê°œì˜ URLì„ ëœë¤ ì„ íƒí–ˆìŠµë‹ˆë‹¤.")
        return selected_urls

    def submit_url_for_indexing(self, url: str) -> Dict[str, Any]:
        """ë‹¨ì¼ URLì„ ìƒ‰ì¸ ìš”ì²­"""
        try:
            request_body = {"url": url, "type": "URL_UPDATED"}

            response = (
                self.service.urlNotifications().publish(body=request_body).execute()
            )

            return {"success": True, "url": url, "response": response}

        except Exception as e:
            logger.error(f"URL ìƒ‰ì¸ ìš”ì²­ ì‹¤íŒ¨ ({url}): {e}")
            return {"success": False, "url": url, "error": str(e)}

    def batch_submit_urls(
        self, urls: List[str], delay_seconds: float = 1.0
    ) -> Dict[str, Any]:
        """ë°°ì¹˜ë¡œ URLë“¤ì„ ìƒ‰ì¸ ìš”ì²­"""
        if not urls:
            return {
                "total": 0,
                "successful": 0,
                "failed": 0,
                "success_urls": [],
                "failed_urls": [],
            }

        logger.info(f"ğŸš€ {len(urls)}ê°œ URLì˜ ìƒ‰ì¸ ìš”ì²­ì„ ì‹œì‘í•©ë‹ˆë‹¤...")

        results = {
            "total": len(urls),
            "successful": 0,
            "failed": 0,
            "success_urls": [],
            "failed_urls": [],
        }

        for i, url in enumerate(urls, 1):
            logger.info(f"[{i}/{len(urls)}] ì²˜ë¦¬ ì¤‘: {url}")

            result = self.submit_url_for_indexing(url)

            if result["success"]:
                results["successful"] += 1
                results["success_urls"].append(url)
                logger.info("  âœ“ ì„±ê³µ")
            else:
                results["failed"] += 1
                results["failed_urls"].append({"url": url, "error": result["error"]})
                logger.info(f"  âŒ ì‹¤íŒ¨: {result['error']}")

            # API ì œí•œì„ ìœ„í•œ ì§€ì—° (ë§ˆì§€ë§‰ ìš”ì²­ ì œì™¸)
            if i < len(urls):
                time.sleep(delay_seconds)

        return results

    def generate_summary_report(self, results: Dict[str, Any]) -> None:
        """ê²°ê³¼ ìš”ì•½ ë³´ê³ ì„œ ì¶œë ¥"""
        success_rate = (
            (results["successful"] / results["total"] * 100)
            if results["total"] > 0
            else 0
        )

        print(f"\n{'='*50}")
        print("ğŸ“Š ìƒ‰ì¸ ìš”ì²­ ê²°ê³¼ ìš”ì•½")
        print(f"{'='*50}")
        print(f"ì „ì²´ URL ìˆ˜:    {results['total']:>3}ê°œ")
        print(f"ì„±ê³µ:          {results['successful']:>3}ê°œ")
        print(f"ì‹¤íŒ¨:          {results['failed']:>3}ê°œ")
        print(f"ì„±ê³µë¥ :        {success_rate:>6.1f}%")
        print(f"{'='*50}")

        if results["failed_urls"]:
            print("\nâŒ ì‹¤íŒ¨í•œ URLë“¤:")
            for failed in results["failed_urls"]:
                print(f"  â€¢ {failed['url']}")
                print(f"    ì˜¤ë¥˜: {failed['error']}")

        # GitHub Actions í™˜ê²½ì—ì„œ ê²°ê³¼ë¥¼ í™˜ê²½ë³€ìˆ˜ë¡œ ì„¤ì •
        if os.environ.get("GITHUB_ACTIONS"):
            print(f"::set-output name=total::{results['total']}")
            print(f"::set-output name=successful::{results['successful']}")
            print(f"::set-output name=failed::{results['failed']}")
            print(f"::set-output name=success_rate::{success_rate:.1f}")

    def run(self, max_urls: int = 200, delay_seconds: float = 1.0) -> bool:
        """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
        try:
            print("ğŸ” Google ìƒ‰ì¸ API ìë™ ë“±ë¡ì„ ì‹œì‘í•©ë‹ˆë‹¤...\n")

            # 1. ì¸ì¦ ì„¤ì •
            if not self.setup_credentials():
                return False

            # 2. Sitemapì—ì„œ URL ì¶”ì¶œ
            all_urls = self.fetch_sitemap_urls()
            if not all_urls:
                logger.error("ì‚¬ìš© ê°€ëŠ¥í•œ URLì´ ì—†ìŠµë‹ˆë‹¤.")
                return False

            # 3. ëœë¤ URL ì„ íƒ
            selected_urls = self.select_random_urls(all_urls, max_urls)
            if not selected_urls:
                logger.error("ì„ íƒëœ URLì´ ì—†ìŠµë‹ˆë‹¤.")
                return False

            # 4. ë°°ì¹˜ ìƒ‰ì¸ ìš”ì²­
            results = self.batch_submit_urls(selected_urls, delay_seconds)

            # 5. ê²°ê³¼ ë³´ê³ ì„œ
            self.generate_summary_report(results)

            print("\nğŸ‰ ìƒ‰ì¸ ë“±ë¡ ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

            # ì„±ê³µí•œ URLì´ í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´ ì„±ê³µìœ¼ë¡œ ê°„ì£¼
            return results["successful"] > 0

        except Exception as e:
            logger.error(f"ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return False


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    # ì„¤ì •ê°’ë“¤
    SITEMAP_URL = "https://secrett2633.github.io/sitemap.xml"
    MAX_URLS = int(os.environ.get("MAX_URLS", "200"))
    DELAY_SECONDS = float(os.environ.get("DELAY_SECONDS", "1.0"))

    logger.info(f"ì„¤ì • - MAX_URLS: {MAX_URLS}, DELAY_SECONDS: {DELAY_SECONDS}")

    # Google Indexing Manager ì‹¤í–‰
    manager = GoogleIndexingManager(SITEMAP_URL)
    success = manager.run(MAX_URLS, DELAY_SECONDS)

    # ì¢…ë£Œ ì½”ë“œ ë°˜í™˜ (GitHub Actionsì—ì„œ ì„±ê³µ/ì‹¤íŒ¨ íŒë‹¨ìš©)
    exit_code = 0 if success else 1
    exit(exit_code)


if __name__ == "__main__":
    main()
